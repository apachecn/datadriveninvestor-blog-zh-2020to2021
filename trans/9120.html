<html>
<head>
<title>Сomparison of Sentinel-2 and PlanetScope imageries for Deforestation Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于森林砍伐探测的Sentinel-2和PlanetScope图像的比较</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/%D1%81omparison-of-sentinel-2-and-planetscope-imageries-for-deforestation-detection-efab5196d45c?source=collection_archive---------8-----------------------#2021-02-01">https://medium.datadriveninvestor.com/%D1%81omparison-of-sentinel-2-and-planetscope-imageries-for-deforestation-detection-efab5196d45c?source=collection_archive---------8-----------------------#2021-02-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/93431ffc60452aa7aba1224315d2f580.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w6YR9UG_cUikf1ZfSR4gJQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Deforestation imagery by Planet.com</figcaption></figure><p id="4d4b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi la translated">与其他国家的大多数森林一样，乌克兰的林地也面临着非法砍伐的风险。乌克兰非法伐木的官方统计数据显示，过去10年期间，非法伐木案件从每年10，000起减少到5，000起，但独立观察表明，违规数量有所增加。与此同时，根据国家和民间的估计，非法采伐量正在增加，2019年达到10万立方米以上。此外，最大数量的非法伐木案件和非法砍伐的木材只发生在乌克兰的森林草原地区，而不是山区。</p><p id="5b76" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">减少非法砍伐森林的有效机制是监测系统，这些系统大多以遥感为基础。为了系统地检测ClearCut，我们部署了<a class="ae lj" href="http://clearcut.quantumobile.com/" rel="noopener ugc nofollow" target="_blank">clear cut</a>——用于监控伐木区域的开源服务。如今，它使用Sentinel-2图像作为<a class="ae lj" href="https://ieeexplore.ieee.org/document/9241044" rel="noopener ugc nofollow" target="_blank">皆伐探测</a>的数据源。</p><p id="af76" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">但是，假设Sentinel-2任务的时空分辨率(每像素10米，重访时间为5天)，PlanetScope的图像似乎是一个非常有前途的森林变化监测平台，因为它具有非常高的时空分辨率。因此，在这个项目中，我们的目标是用PlanetScope数据确定森林砍伐检测的质量，并用Sentinel-2数据比较分割质量。</p><p id="2e6d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们用PlanetScope数据手工创建了一个清晰的数据集。然后，我们执行了行星镜和哨兵-2瓦片之间的匹配。在数据准备之后，我们使用深度学习模型对创建的数据集进行了森林变化检测，但使用了两个成像数据源:PlanetScope和Sentinel-2。在结果中，我们表明PlanetScope图像提供了更高质量的分割(F1值等于0.52对0.37，来自Sentinel-2数据)，因此可以用作检测伐木区的潜在平台。收集具有高空间和时间分辨率的大型PlanetScope数据集将提供一个高质量监测森林变化检测的机会，其质量高于Sentinel-2图像所能提供的质量。</p><h1 id="77c1" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">数据和方法</h1><h2 id="668e" class="mi ll iq bd lm mj mk dn lq ml mm dp lu kn mn mo ly kr mp mq mc kv mr ms mg mt bi translated">成像数据</h2><p id="e117" class="pw-post-body-paragraph kc kd iq ke b kf mu kh ki kj mv kl km kn mw kp kq kr mx kt ku kv my kx ky kz ij bi translated">作为成像数据的来源，我们使用了Sentinel-2和PlanetScope图像。表1给出了空间-时间-光谱信息的比较。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/627555a6df83d347655c3d80bdf148b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7QtKIyaI_3LBgZSZwYL7sQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Table 1. Comparison of Sentinel-2 and PlanetScope imagery features</figcaption></figure><p id="7570" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">作为来自Sentinel-2的数据，我们使用了A级光学(真彩色图像，B02、B03、B04波段)图像。在行星镜中，我们使用了光学波长范围(RGB波段)的分析产品。这两个数据源都包括NIR信息，但是我们的实验表明，在分析中加入NIR波段后，没有改善。</p><h2 id="cbce" class="mi ll iq bd lm mj mk dn lq ml mm dp lu kn mn mo ly kr mp mq mc kv mr ms mg mt bi translated">标签程序</h2><p id="e787" class="pw-post-body-paragraph kc kd iq ke b kf mu kh ki kj mv kl km kn mw kp kq kr mx kt ku kv my kx ky kz ij bi translated">一开始，我们决定使用现有的基于Sentinel-2的标记，但是分析表明我们不能用它来解决我们的问题。可用的PlanetScope数据覆盖了不同的日期范围，因此我们的实验需要收集一组新的标签。此外，这个新的标签集必须在可用的PlanetScope和Sentinel-2图像中有尽可能多的匹配图像。</p><p id="d2bc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">因此，基于PlanetScope的数据，我们收集并组合了新的清晰切割数据集。清晰切割的数据集来自100个PlanetScope瓦片，在时间和空间上与Sentinel-2瓦片重叠。这些地区覆盖了乌克兰的一些森林地区(哈尔科夫地区)，并在2016年10月2日和2019年10月31日期间由PlanetScope观测到。在这些瓦片中，我们发现并人工标记了212个森林砍伐事件。这些事件是在150个不同的皆伐区域内观察到的。</p><h2 id="dfe8" class="mi ll iq bd lm mj mk dn lq ml mm dp lu kn mn mo ly kr mp mq mc kv mr ms mg mt bi translated">毁林检测方法</h2><p id="b660" class="pw-post-body-paragraph kc kd iq ke b kf mu kh ki kj mv kl km kn mw kp kq kr mx kt ku kv my kx ky kz ij bi translated">为了检测皆伐区域，我们比较两幅按时间分开的图像，并突出显示出现新皆伐的像素。这个问题被称为图像分割。我们使用深度学习<a class="ae lj" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> UNet </a>模型解决了这个问题。</p><p id="5063" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了创建训练数据集，我们检索了每个皆伐区周围的小图像(见图1 ),并对毁林事件进行了分段，比较了相同皆伐区按时间划分的片段。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/5bcfa38843c31e7a59ac355d2555f3b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OuuLuEkfjENQIyjSF0YvaQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 1. Example of cropping images around each clearcut</figcaption></figure><p id="b82c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">行星镜。</strong>我们在每个图块上裁剪了每个清晰区域周围的168×168像素区域(504×504米)。在不同的日期(最长30天的时间间隔)比较每个皆伐的图像。结果，我们收到了1，042条数据(分别为798，132，112条训练、验证和测试数据)。这些作品中只有139张伐木面具。正如我们之前提到的，图像包括三个光学通道。</p><p id="3afd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">哨兵-2。</strong>我们在每个清晰的56×56像素区域(560×560米)周围进行裁剪。为了防止产生多余的作物，我们用PlanetScope瓦片几何图形截断了Sentinel-2瓦片。这一步是为了将Sentinel-2瓦片与相应的(时间和空间)行星镜瓦片对齐。在不同的日期(最长30天的时间间隔)比较每个皆伐的图像。结果，我们收到了1，042条数据(分别为798，132，112条训练、验证和测试数据)。这些作品中只有139张伐木面具。图像包括三个光学通道。</p><p id="feb1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们的数据集创建过程保证了在训练分割模型期间，以及在测试期间，我们将比较两个图像源的相同清晰界限(在时间和空间上)。这两个数据集之间的唯一区别在于所使用的图像来源(PlanetScope和Sentinel-2)。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/efc7f2c2f85520ecb96d2ff0222f4569.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tQTeeEEv69KlNvbY.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 2. PlanetScope RGB image tile</figcaption></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/abc3e7dfe0238806a85e3106a2b4a555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*POY6NJhU3sJVnc83.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 3. Cropped the True Color Image from the Sentinel-2 tile</figcaption></figure><h2 id="b5a2" class="mi ll iq bd lm mj mk dn lq ml mm dp lu kn mn mo ly kr mp mq mc kv mr ms mg mt bi translated">细分质量指标</h2><p id="c03a" class="pw-post-body-paragraph kc kd iq ke b kf mu kh ki kj mv kl km kn mw kp kq kr mx kt ku kv my kx ky kz ij bi translated">作为准确性指标，我们使用了以下评分函数，该函数比较了clearcut的基本事实屏蔽和模型预测的屏蔽。</p><p id="bee6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–<a class="ae lj" href="https://en.wikipedia.org/wiki/Jaccard_index" rel="noopener ugc nofollow" target="_blank">IoU</a>(交集超过并集)和<a class="ae lj" href="https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient" rel="noopener ugc nofollow" target="_blank">骰子</a>得分:</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/3877aa4fe3d43283b9e29d35237be91e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*m-nF1rDrGiPR0fhs.jpg"/></div></div></figure><p id="a566" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">此外，我们使用度量，它代表清晰检测的质量(但不是实际的分割)。为了计算这一指标，必须在IoU得分上设置一个阈值，并计算森林砍伐区域的数量，这些区域在假设分割质量阈值的情况下被正确分割和错误分割。这些数字表示检测的类型，即真阳性(地面真实遮罩具有清晰边界，并且模型预测其IoU大于阈值)、假阳性(地面真实遮罩中没有清晰边界，但是模型预测不真实的森林砍伐事件)和假阴性(地面真实遮罩具有清晰边界，但是模型不能检测其IoU大于阈值)。</p><p id="15f4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–<a class="ae lj" href="https://en.wikipedia.org/wiki/F1_score" rel="noopener ugc nofollow" target="_blank">F1-得分</a></p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/cf19f728d5681fa1f4648748534d70f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6JXC7oXf3nSsBcws.jpg"/></div></div></figure><p id="cfc3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">其中TP，FP，FN代表正确检测(TP)和错误检测(FP，FN)实例的数量。</p><h1 id="7d96" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">结果和结论</h1><p id="be44" class="pw-post-body-paragraph kc kd iq ke b kf mu kh ki kj mv kl km kn mw kp kq kr mx kt ku kv my kx ky kz ij bi translated">我们训练了深度学习模型，并将其应用于数据集。结果，我们在验证数据集上获得了以下分数(见表2):</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/364e0081f50843c8cb517c54cc8a0e71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VFkcHLbcx8zRTZgKTrZXOA.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Table 2. Values of different quality metrics for datasets. The highest metric among the two datasets is highlighted as bold-green text</figcaption></figure><p id="2457" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">PlanetScope为不同的IoU阈值提供了比Sentinel-2更高的骰子得分和F1得分值。我们具有几乎相等的骰子分数的事实意味着我们在两个数据集中几乎相等地分割清晰。但是F1-分数显示PlanetScope提供了对地面真实遮罩更严格的预测，因为与Sentinel-2相比，使用该图像，我们在设定IoU阈值的情况下获得了更多的TP和更少的FP+FN。因此，我们可以更有把握地用PlanetScope探测清晰的轮廓。</p><p id="875a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">正如我们从预测的视觉比较(图3–4)中看到的，我们可以推断出具有更高分割质量的清晰轮廓，并使用PlanetScope数据获得更平滑的预测。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/d09082c8f654ac0a24f7be2da33799cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GpAwelPahtxNhNDA.jpg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 4. Comparative visualization of model inference on both datasets. First row: PlanetScope imagery. Second row: Sentinel-2 imagery. First and second columns: images at the first and second dates; third column: the differences of images; fourth column: ground truth mask of forest changes; fifth column: model segmentation of clearcuts with IoU score on this mask.</figcaption></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/57a1060ea4f242c316b757353d21f89e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*H0mGEKXahJlqGLIM.jpg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 5. Comparative visualization of model inference on both datasets. First row: PlanetScope imagery. Second row: Sentinel imagery. First and second columns: images at the first and second dates; third column: the differences of images; fourth column: ground truth mask of forest changes; fifth column: model segmentation of clearcuts with IoU score on this mask.</figcaption></figure><p id="3f7a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">因此，我们可以得出结论，PlanetScope是ClearCut服务中监测森林砍伐区域的一个很好的平台。它的空间分辨率允许我们获得更好的探测质量，假设它的时间分辨率很高，使用PlanetScore数据，我们可以以非常高的频率精确地探测到清晰的轮廓。我们相信，作为ClearCut服务基础的模型的进一步改进，可以通过扩展clear cut的训练样本以及添加更多PlanetScope数据来实现。</p><p id="ec0c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这篇文章是米哈伊尔·尤舒克和塞尔吉·斯利普申科写的。</p></div></div>    
</body>
</html>