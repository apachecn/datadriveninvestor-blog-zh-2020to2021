<html>
<head>
<title>How to quickly deploy your Image models using Streamlit?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Streamlit快速部署您的映像模型？</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/how-to-quickly-deploy-your-image-models-using-streamlit-6d559163b313?source=collection_archive---------3-----------------------#2021-01-24">https://medium.datadriveninvestor.com/how-to-quickly-deploy-your-image-models-using-streamlit-6d559163b313?source=collection_archive---------3-----------------------#2021-01-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="0556" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">实践指南</h2><div class=""/><div class=""><h2 id="a8d5" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">部署映像模型的简单方法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/cda77ae4475760d9f4c68d1a76a2382f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4xyhlIr-CIESgpTfBvU3xA.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><a class="ae lh" href="https://www.thalesgroup.com/sites/default/files/gemalto/facial-recognition-banner.jpg" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="793b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这篇博客中，我们将尝试使用Streamlit部署一个多标签图像分类器。每个深度学习从业者都知道，用图像输入部署深度学习模型是非常繁琐的。对于文本，这很容易，因为输入文本可以通过API调用轻松地传递到JSON中，但是对于图像，需要一些额外的步骤。当通过API请求传递一个图像作为输入时，它应该首先被转换成一个<code class="fe me mf mg mh b">base64</code> <em class="mi">字符串</em>，或者应该直接从UI上传到一个桶，然后应该通过API调用提供该图像的链接，以便可以下载该图像并用于推断。这个过程相当困难，因为它涉及到转换为字符串或设置存储桶，然后允许更好地处理用户数据。</p><p id="b87f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是使用Streamlit，可以毫不费力地部署图像模型并通过UI提供推理。我们来详细看看流程。在这里，我们将部署在这个<a class="ae lh" href="https://thevatsalsaglani.medium.com/training-and-deploying-a-multi-label-image-classifier-using-pytorch-flask-reactjs-and-firebase-c39c96f9c427" rel="noopener">博客</a>中培训的模型之一。如果你想了解培训过程，请关注那个博客。接下来，让我们创建一个虚拟环境并安装Streamlit依赖项。</p><h1 id="849a" class="mj mk it bd ml mm mn mo mp mq mr ms mt ki mu kj mv kl mw km mx ko my kp mz na bi translated">创建虚拟环境并安装Streamlit</h1><pre class="ks kt ku kv gt nb mh nc nd aw ne bi"><span id="10f5" class="nf mk it mh b gy ng nh l ni nj"># creating conda env<br/>$ conda create -n envname python=python_version<br/>$ conda activate envname</span><span id="08f7" class="nf mk it mh b gy nk nh l ni nj"># install streamlit<br/>$ /path/to/anaconda3/envs/envname/bin/pip install streamlit pipreqs tqdm</span></pre><ul class=""><li id="1eb8" class="nl nm it lk b ll lm lo lp lr nn lv no lz np md nq nr ns nt bi translated"><em class="mi">对于MacOS来说，anaconda3文件夹的路径是</em> <code class="fe me mf mg mh b"><em class="mi">/Users/username/anaconda3/envs/envname/bin/pip</em></code></li><li id="aacd" class="nl nm it lk b ll nu lo nv lr nw lv nx lz ny md nq nr ns nt bi translated"><em class="mi">对于Linux来说，anaconda文件夹的路径是</em> <code class="fe me mf mg mh b"><em class="mi">/home/username/anaconda3/envs/envname/bin/pip</em></code></li><li id="b204" class="nl nm it lk b ll nu lo nv lr nw lv nx lz ny md nq nr ns nt bi translated"><em class="mi">对于Windows，用户可以打开</em> <code class="fe me mf mg mh b"><em class="mi">conda prompt</em></code> <em class="mi">并激活环境，使用</em> <code class="fe me mf mg mh b"><em class="mi">pip</em></code> <em class="mi">或</em> <code class="fe me mf mg mh b"><em class="mi">conda</em></code> <em class="mi">命令安装依赖项</em></li></ul><h1 id="35d0" class="mj mk it bd ml mm mn mo mp mq mr ms mt ki mu kj mv kl mw km mx ko my kp mz na bi translated">Streamlit中的模型推理和模型缓存</h1><p id="b6a3" class="pw-post-body-paragraph li lj it lk b ll nz kd ln lo oa kg lq lr ob lt lu lv oc lx ly lz od mb mc md im bi translated">我们将在<code class="fe me mf mg mh b">predictImage.py</code>文件中添加以下代码</p><ul class=""><li id="11f5" class="nl nm it lk b ll lm lo lp lr nn lv no lz np md nq nr ns nt bi translated">进口</li></ul><pre class="ks kt ku kv gt nb mh nc nd aw ne bi"><span id="f89c" class="nf mk it mh b gy ng nh l ni nj">import torch<br/>import torch.nn as nn<br/>from torchvision import transforms<br/>import torch.nn.functional as F<br/>from PIL import Image<br/>import numpy as np<br/>from model import MultiClassifier<br/>import io<br/>import streamlit as st</span></pre><ul class=""><li id="415f" class="nl nm it lk b ll lm lo lp lr nn lv no lz np md nq nr ns nt bi translated">模型负载函数</li></ul><pre class="ks kt ku kv gt nb mh nc nd aw ne bi"><span id="c49b" class="nf mk it mh b gy ng nh l ni nj">@st.cache<br/>def load_model():<br/>    with torch.no_grad():<br/>        model = MultiClassifier()<br/>        model_dict = torch.load('models/celeba_model_dict.pth', map_location = 'cpu')<br/>        model.load_state_dict(model_dict['model_dict'])<br/>        model = model.eval()<br/>        return model</span></pre><ul class=""><li id="8c4d" class="nl nm it lk b ll lm lo lp lr nn lv no lz np md nq nr ns nt bi translated">推理功能</li></ul><pre class="ks kt ku kv gt nb mh nc nd aw ne bi"><span id="0ea5" class="nf mk it mh b gy ng nh l ni nj">def predictFeatures(imgPath, model):</span><span id="90e3" class="nf mk it mh b gy nk nh l ni nj">    label_lst = ['5_o_Clock_Shadow','Arched_Eyebrows','Attractive','Bags_Under_Eyes','Bald','Bangs','Big_Lips','Big_Nose','Black_Hair',<br/>    'Blond_Hair', 'Blurry','Brown_Hair','Bushy_Eyebrows','Chubby','Double_Chin','Eyeglasses','Goatee','Gray_Hair','Heavy_Makeup',<br/>    'High_Cheekbones','Male','Mouth_Slightly_Open','Mustache','Narrow_Eyes','No_Beard','Oval_Face','Pale_Skin','Pointy_Nose',<br/>    'Receding_Hairline','Rosy_Cheeks','Sideburns','Smiling','Straight_Hair','Wavy_Hair','Wearing_Earrings','Wearing_Hat',<br/>    'Wearing_Lipstick','Wearing_Necklace','Wearing_Necktie','Young']</span><span id="488f" class="nf mk it mh b gy nk nh l ni nj">    def get_tensor(img):<br/>        # img = Image.open(img)<br/>        img = img.convert("RGB")<br/>        tfms = transforms.Compose([<br/>            transforms.Resize((256, 256)),<br/>            transforms.ToTensor()<br/>        ])<br/>        <br/>        return tfms(img).unsqueeze(0)<br/>    <br/>    imgTnsr = get_tensor(imgPath)<br/>    op = model(imgTnsr)<br/>    op_b = torch.round(op)<br/>    op_b_np = torch.Tensor.cpu(op_b).detach().numpy()<br/>    preds = np.where(op_b_np == 1)[1]</span><span id="66ca" class="nf mk it mh b gy nk nh l ni nj">    sigs_op = torch.Tensor.cpu(torch.round((op)*100)).detach().numpy()[0]</span><span id="6790" class="nf mk it mh b gy nk nh l ni nj">    o_p = np.argsort(torch.Tensor.cpu(op).detach().numpy())[0][::-1]</span><span id="65fb" class="nf mk it mh b gy nk nh l ni nj">    label = []<br/>    for i in preds:<br/>        label.append(label_lst[i])</span><span id="a66c" class="nf mk it mh b gy nk nh l ni nj">    arg_s = {}<br/>    for i in o_p:<br/>        arg_s[label_lst[int(i)]] = sigs_op[int(i)]<br/>    <br/>    _l = list(arg_s.items())[:10]</span><span id="2e50" class="nf mk it mh b gy nk nh l ni nj">    return _l</span></pre><p id="a056" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe me mf mg mh b">load_model</code>函数上的<code class="fe me mf mg mh b">@st.cache</code>装饰器缓存模型，因此，对于每个请求，模型加载过程不会重复。对于Flask和FastAPI服务器，可以将它们设置为全局变量，以避免每次请求都加载模型。</p><p id="3723" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上面的片段基本上类似于在<code class="fe me mf mg mh b">inference.ipynb</code>文件中准备的推理脚本😅。</p><h1 id="d95f" class="mj mk it bd ml mm mn mo mp mq mr ms mt ki mu kj mv kl mw km mx ko my kp mz na bi translated">带Streamlit的用户界面</h1><p id="64ed" class="pw-post-body-paragraph li lj it lk b ll nz kd ln lo oa kg lq lr ob lt lu lv oc lx ly lz od mb mc md im bi translated">这是创建一个界面来部署您的模型并使最终用户或互联网上的任何人与之交互的最简单的方法之一，如果不是最简单的话。这里，我们将创建<code class="fe me mf mg mh b">streamlitapp.py</code>文件，并将下面的代码放入其中，这将创建UI并与上面的推理脚本<code class="fe me mf mg mh b">predictImage.py</code>交互。</p><ul class=""><li id="81f2" class="nl nm it lk b ll lm lo lp lr nn lv no lz np md nq nr ns nt bi translated">进口</li></ul><pre class="ks kt ku kv gt nb mh nc nd aw ne bi"><span id="2d5e" class="nf mk it mh b gy ng nh l ni nj">import streamlit as st<br/>import io<br/>from PIL import Image<br/>import tempfile<br/>from predictImage import predictFeatures, load_model<br/>import pandas as pd</span></pre><ul class=""><li id="cd63" class="nl nm it lk b ll lm lo lp lr nn lv no lz np md nq nr ns nt bi translated">设置页面标题和图标</li></ul><pre class="ks kt ku kv gt nb mh nc nd aw ne bi"><span id="65f0" class="nf mk it mh b gy ng nh l ni nj">st.set_page_config(<br/>    page_title = 'Image Feature Prediction',<br/>    page_icon = '😇'<br/>)</span></pre><ul class=""><li id="9a02" class="nl nm it lk b ll lm lo lp lr nn lv no lz np md nq nr ns nt bi translated">图像实用程序</li></ul><p id="77db" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Streamlit文件选择器将图像文件转换成字节流，因此我们需要使用<code class="fe me mf mg mh b">io.BytesIO</code>将字节流转换成图像。</p><pre class="ks kt ku kv gt nb mh nc nd aw ne bi"><span id="9e03" class="nf mk it mh b gy ng nh l ni nj">def saveImage(byteImage):<br/>    bytesImg = io.BytesIO(byteImage)<br/>    imgFile = Image.open(bytesImg)   <br/>   <br/>    return imgFile</span></pre><ul class=""><li id="40d4" class="nl nm it lk b ll lm lo lp lr nn lv no lz np md nq nr ns nt bi translated">应用程序标题和文件上传程序</li></ul><pre class="ks kt ku kv gt nb mh nc nd aw ne bi"><span id="9766" class="nf mk it mh b gy ng nh l ni nj">st.header("Image Feature Predictor")<br/>fileUpload = st.file_uploader("Choose a file", type = ['jpg', 'png'])</span></pre><ul class=""><li id="e6d0" class="nl nm it lk b ll lm lo lp lr nn lv no lz np md nq nr ns nt bi translated">使用<code class="fe me mf mg mh b">predictImage.py</code>文件中的代码处理上传的文件</li></ul><pre class="ks kt ku kv gt nb mh nc nd aw ne bi"><span id="2ea9" class="nf mk it mh b gy ng nh l ni nj">if fileUpload:<br/>    file = fileUpload.read()<br/>    path = saveImage(file)<br/>    st.image(path, width = 300, height = 100)<br/>    model = load_model()<br/>    imgFs = predictFeatures(path, model)<br/>    tableArea = st.empty()<br/>    tableArea = tableArea.table()<br/>    with st.spinner("Prediction In Progress"):<br/>        for ix, (key, val) in enumerate(imgFs):<br/>            tableArea.add_rows(pd.DataFrame({"Attribute": key, "Percentage %": val}, index = [ix]))<br/>        st.success("Success")</span></pre><p id="0aee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mi">对于这个模型，我们有多个属性，每个属性都有值。所以我们可以有一个两列的表格，以简洁的方式显示出来。</em></p><p id="72a4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这样，我们就完成了UI的创建。很简单，对吧？没有HTML、CSS和JavaScript <code class="fe me mf mg mh b">onClick</code>来选择文件，然后再用一个按钮和一个<code class="fe me mf mg mh b">onClick</code>方法来调用API调用。</p><p id="ed82" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，让我们运行应用程序，试试它是否有效，看看它看起来有多好。转到包含<code class="fe me mf mg mh b">streamlitapp.py</code>文件的文件夹，使用以下命令。</p><pre class="ks kt ku kv gt nb mh nc nd aw ne bi"><span id="c8ad" class="nf mk it mh b gy ng nh l ni nj">$ streamlit run streamlitapp.py</span></pre><p id="f317" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">该命令一执行，您就会看到以下屏幕</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oe"><img src="../Images/d3f8d68c5482eff2e79c3f0d8f9f5c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8x5uGVNz_Iq1wytmi2sSuQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Image by Author</figcaption></figure><p id="b5ca" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们尝试上传一些图片，并获得一些预测。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="1997" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您可以在AWS或GCP实例上轻松部署这个Streamlit应用程序。用于做出推断的模型大小约为400 MBs，PyTorch CPU only build的大小约为125 MB，因此总计将超过500 MBs，否则这个应用程序可以非常容易地部署，并且可以免费使用Heroku。如果你想了解如何用Heroku免费部署一个Streamlit应用程序，请查看这个博客。就这样，我们结束了这篇博客。我写这个博客很开心，希望你也会喜欢。</p></div></div>    
</body>
</html>