<html>
<head>
<title>Artificial Intelligence — Agents and Environments</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能——代理和环境</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/artificial-intelligence-agents-and-environments-9b93d73791f3?source=collection_archive---------0-----------------------#2021-02-08">https://medium.datadriveninvestor.com/artificial-intelligence-agents-and-environments-9b93d73791f3?source=collection_archive---------0-----------------------#2021-02-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/2c466db5807cf75fbc9f818b530fc99e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JptaHdDfoQhOQqzPf7f0qg.png"/></div></div></figure><div class=""/><p id="c307" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">了解智能体(机器人、机器人、程序)和环境(工作场所)。</strong></p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi kw"><img src="../Images/cd3f4477545156f516fa98aa50e14d96.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*sjxcWTAW2EaYVQ_TZt83WQ.png"/></div></figure><ol class=""><li id="01dc" class="lb lc jb ka b kb kc kf kg kj ld kn le kr lf kv lg lh li lj bi translated"><strong class="ka jc">为什么是代理和环境？</strong></li><li id="f871" class="lb lc jb ka b kb lk kf ll kj lm kn ln kr lo kv lg lh li lj bi translated"><strong class="ka jc">特工</strong></li><li id="e379" class="lb lc jb ka b kb lk kf ll kj lm kn ln kr lo kv lg lh li lj bi translated"><strong class="ka jc">环境</strong></li><li id="2ba3" class="lb lc jb ka b kb lk kf ll kj lm kn ln kr lo kv lg lh li lj bi translated"><strong class="ka jc">代理和环境的示例</strong></li><li id="f7a7" class="lb lc jb ka b kb lk kf ll kj lm kn ln kr lo kv lg lh li lj bi translated"><strong class="ka jc">结论</strong></li></ol><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/924f10d8c039f490c412fb3b2178c56d.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*FXd_aEFR5aCeYYauvF77Fw.png"/></div></figure><p id="4375" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">主体和环境是人工智能的两大支柱，我们的目标是构建智能主体并在环境中工作。如果你广泛地考虑，代理是解决方案，环境是问题。</p><p id="d847" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">简单来说，即使是初学者或研究人员也能理解这一点，并将其定义为<strong class="ka jc">代理作为游戏，环境作为背景。</strong></p><p id="5138" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">用几个例子来定义代理和环境，以便读者可以注意到它的上下文。代理和环境不是那么简单的。这两种情况下都存在类型，下图总结了这些类型。</p><p id="d4f1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在我们开始之前，让我们定义几个将在整篇文章中遇到的术语。</p><p id="fef6" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">感知</strong>:什么智能体看环境。</p><p id="b099" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">感知历史</strong>:是特定时期出现的感知历史。</p><p id="d53b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">执行器</strong>:将某物付诸行动的机械装置。</p><p id="f7f0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">效应器</strong>:激活的代理器官(手和腿)。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lq"><img src="../Images/037d4d7d3c56de864dd51cbb5e1699bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bzc-w2D6SjhSEmc-EZ2c3A.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lv">Types of Agents and Environments</strong></figcaption></figure><p id="3489" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是更好地参考更多的第一和第二章在一个现代的方法由斯图尔特罗素，彼得诺维格。现在，我们以一种易于人工智能新手或初学者理解的方式来定义代理和环境的类型。在定义上述内容时，我们将会遇到在不同应用程序或领域中会遇到的其他概念。cc</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/f9b597a943fe2b2d20388bd4d20ee11a.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*wiPLTKn8_J33i_6F1EExAQ.png"/></div></figure><p id="1a70" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">环境是代理将要工作的地方。一般来说，环境给予代理人可能的奖励、状态和行动。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/94a301d424851476d37ebf4bef1fab8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*PgSzoQqSnC3jFulI6wpPXw.png"/></div></figure><p id="645f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">人工智能的任务环境显然是巨大的。我们确定了任务环境可以分类的几个维度。理解人工智能需要理解环境。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/df69a1c870bd92636a8e004e63f2396b.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/format:webp/1*eGRTyYRB9frzVIiDs46tkQ.png"/></div></figure><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lz"><img src="../Images/321fbea53ec859bf4e619ad5741be699.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IGv9UoV0B36-7INTK__27A.png"/></div></div></figure><p id="7d8c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果一个智能体的传感器能让它在每一个时间点上获得环境的完整状态，那么我们说任务环境是完全可观测的。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/67f1633ebc6f4c8b07a1dc37d6762f0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:378/format:webp/1*RF7V8tvRbpggaJHiut6VZA.png"/></div></figure><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mb"><img src="../Images/51b9a30d3aea76f17c93d7500d85a64d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-JzOpdswunv2avAzYqhz7w.png"/></div></div></figure><p id="8f57" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于噪声和不准确的传感器，或者由于状态的一部分仅仅从传感器数据中丢失，环境是部分可观察的。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/f4da1f7f6d1475842a59211ef26000b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:260/format:webp/1*en_18rts7QxfEcmB9H6Xlw.png"/></div></figure><p id="7472" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果代理根本没有传感器，那么环境是不可观察的</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi md"><img src="../Images/e3f3cf6d3921cec9b86b6214e142e5d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:410/format:webp/1*ZeIG9tGQTjmObDFkDnMQvg.png"/></div></figure><p id="03f2" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">只有一个代理参与环境是单个代理。一个以上的智能体与环境交互，这就是多智能体。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi me"><img src="../Images/4454bfdcdeaababc7f6c271c98f65896.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*nZCxK-xwCRn63ErTbWWxZQ.png"/></div></figure><p id="0faa" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果一个代理(实体)最大化其性能超过环境中的其他代理(实体),则是竞争多代理环境。一个代理可以基于物理法则被对待(根据物理法则行动)。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/701cc5c616b26d411dfd3fcdbb3b3f16.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*4LiFX8MGrOROJ5Avx1kk3g.png"/></div></figure><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/908fcb6e754f1938fe65dc0b2265c47a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*anUqtYPTVO9MNhBrWmZ-eQ.png"/></div></figure><p id="c1e7" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">避免冲突最大化所有代理的性能度量，因此，它是部分合作的多代理环境。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/45fb458f986232bd84b32beff69f814f.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*kddfXHmgECm3tMDWhCqbPg.png"/></div></figure><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/842f39444a03e140a584ac8321e0627e.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*zMTTP1P8YY8Z6FavnBfonQ.png"/></div></figure><p id="4ab4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果环境的下一个状态完全由当前状态&amp;主体执行的动作决定，那么我们说环境是确定性的，否则就是随机的。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mj"><img src="../Images/f660be7caa076acd6e5edda9e72971e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:236/format:webp/1*AKA7SOUXny2gmXeFSBcDkA.png"/></div></div></figure><p id="55c4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在多主体环境中，不确定性纯粹来自于其他主体的行为。在确定性中，其它智能体的动作不能被任何其它智能体(每个智能体)预测。</p><p id="ae7f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果一个环境不是完全可观察的或不确定的，那么它就是不确定的。在非确定性环境中，行动以其可能的结果为特征，但不附带任何概率。</p><p id="1744" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其中,<strong class="ka jc">随机</strong>通常意味着关于结果的不确定性根据<strong class="ka jc">概率</strong>来量化。<strong class="ka jc">不确定性</strong>环境描述通常与要求代理对其行动的所有可能结果取得成功的绩效测量相关联。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/e8e1a67338d25d30d521954828afb7d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*TtCvzxhrOz9eWkff49pXDg.png"/></div></figure><p id="dece" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在<strong class="ka jc">情节</strong>环境中，代理人的经历被分成原子情节。在每一集里，代理接收一个感知，然后执行一个动作。下一集不依赖于前几集采取的行动。许多分类任务是阶段性的。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/d187422d4ccd55b69b0e7b0203b4357b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*aDeLGi5oOi58-hJk2u4Ffg.png"/></div></figure><p id="1a1a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在<strong class="ka jc">连续</strong>环境中，当前的决策可能会影响所有未来的决策。情景环境比顺序环境简单得多，因为代理不需要提前考虑。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/3e121a5c1ec6a98b64e308b1fca32936.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*hAQw99mdYn9hSq1Cxsr4wA.png"/></div></figure><p id="43b4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">静态环境很容易处理，因为代理不需要一直观察世界。在决定一项行动时，也不需要担心时间的流逝。</p><p id="2aa0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果环境可以在一个代理人深思熟虑的时候改变，那么我们说这个环境对于这个代理人来说是动态的；否则环境是静态的。</p><p id="3dae" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">动态</strong>环境不断地询问代理它想做什么，如果它还没有决定，那就算作决定什么也不做。</p><p id="50da" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">半动态环境</strong>:如果环境本身不随时间的推移而变化，但代理人的绩效得分变化，则环境为<strong class="ka jc">半动态</strong>。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/165a6803126ea6f7be05de1797671656.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*JB0IyA3WeIp4VROFU_Vfdw.png"/></div></figure><p id="0f92" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这两个不同的环境中，适用于环境的状态，时间的处理方式，以及代理人的感知和行动。国际象棋-离散、连续-自动车辆驾驶。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/19db016fb421d319c82062919362049d.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*iZq9Q-GVfdLjyw0xeTv7NQ.png"/></div></figure><p id="3c32" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这两个都是专指环境本身而非动因；如果一个已知的环境，所有行动的结果是给定的。如果环境是未知的，代理将不得不学习它是如何工作的，以便做出好的决策。这些环境是<strong class="ka jc">强化学习</strong>中<strong class="ka jc">开发</strong>(已知环境)和<strong class="ka jc">探索</strong>(未知环境)的好例子。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/17986aaba20a61ee543122563a1fd8de.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*LTAY0jbUV7wLpTZf8360rg.png"/></div></figure><p id="11cc" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">代理是我们问题的解决方案。代理需要人工智能提供的智能在环境中工作。每个代理都必须执行自己的代理程序，代理功能，从感知到行动的映射。下图对此进行了描述。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mq"><img src="../Images/40f2fe1b4de216b702ac9ff45b11e61d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bNjzr0zUkDEZ1xQNHZPkRA.png"/></div></div></figure><p id="a6b9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">代理的操作</strong>:代理程序、代理函数是操作。</p><p id="188f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">代理程序</strong>:它运行在某种带有物理传感器和执行器的计算设备上——称之为架构。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/6dc6ffe5970c5a77e2ea02c7a5e8a0b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*deEf8FzH88PM9DZ1HBkmng.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lv">Structure of Agents</strong></figcaption></figure><p id="b442" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此<strong class="ka jc"> Agent =架构+程序</strong>；显然，程序应该适合于架构。程序动作和架构示例如下所示。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/a7b29abc75a464fc3d20a990892d9ded.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*MI0ZMG7_r02ju2sVHqxixA.png"/></div></figure><p id="bf43" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">体系结构使来自传感器的感知可用于程序，运行程序，并在生成程序的动作选择时将其提供给执行器。让我们讨论代理端的概念。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/eafe040362924a487bc0160b3dc0541e.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*-eQYX72_HN5c8cG19ceOKg.png"/></div></figure><p id="ab7a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">代理程序结构将当前感知作为来自传感器的输入，并将动作返回给执行器。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/86896928ba5ec83aeabb6b74b26cc8f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*vcpXA6aYXoGr7GJyddc88g.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lv">Relation among the components of an agent and environment</strong></figcaption></figure><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/2ca3a7ea6e6c25ffd9a49ff04972e6b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z6Cf1Iaw-_U5fe-hlTWNsA.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lv">Structure of Agent Program</strong></figcaption></figure><p id="07a4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">代理程序将当前感知作为输入，因为从环境中无法获得更多信息。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/28faaf4e17a483f8fe0a7cb9eab91300.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*mWNRNyL2LP6x8Uuiq_bHDg.png"/></div></figure><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mx"><img src="../Images/c6ca519719ce747a29211f2638f53a2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b7vDEPgWziSIjm81ykX0lQ.png"/></div></div></figure><p id="8fad" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">将整个感知历史作为输入的代理函数。将当前感知作为输入的代理程序和获取整个感知历史的代理函数之间的区别。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/8d829f4320d0d7b9ee34f60490dfe5c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*9iZ2m8PXHVgm10mOECqlog.png"/></div></figure><p id="657a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有四种基本的代理程序，它们体现了几乎所有智能系统的基本原理。它们是<strong class="ka jc">简单反射代理</strong>、<strong class="ka jc">基于模型的反射代理</strong>、<strong class="ka jc">基于目标的代理</strong>和<strong class="ka jc">基于效用的代理</strong>。每个代理程序以特定的方式组合特定的组件来生成动作。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/c4884e718dfb7dd774a5d0d76b73865c.png" data-original-src="https://miro.medium.com/v2/resize:fit:498/format:webp/1*YsFLOlZH5LKGGKD_3-vQiA.png"/></div></figure><p id="6415" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它是最简单的代理，因为这些代理直接从感知中选择动作，而忽略感知历史。简单的反射行为甚至发生在更复杂的环境中。让我们来定义条件-动作规则。</p><p id="150c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">条件动作规则</strong>:连接，定义为“对视觉输入进行处理，建立条件，然后在代理程序中触发动作。这种联系被称为<strong class="ka jc">“条件-动作规则”。</strong>简单反射剂的示意图，定义如下</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi na"><img src="../Images/9bcd309193456fa8a753a567e405cb4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*ZnGZom4RPY3XBaCHtr45Gw.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lv">Depicts how condition-action rule allow the Simple reflex agent to make the connection from percept to action</strong></figcaption></figure><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/1183365e05e62b460136b25cdeda2835.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*fMRp2152xWG36XlTtwwgsw.png"/></div></figure><p id="9f29" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当代理部分观察环境时，代理需要跟踪它现在看不到的世界的一部分。也就是说，主体应该保持某种内部状态，这取决于感知历史和当前状态的未观察方面。也就是说，在图像上，它被定义为</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/fa2f4b556b02115b279cad4e7233d4e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*YW5NDghSHSSCvIawiOqjlg.png"/></div></figure><p id="9e6d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">更新内部状态</strong>:代理程序中需要编码两种知识。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/78faec55f480bfeeed32961bbc99b8fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*YrEWMvguO9s1Uf7T__kHnA.png"/></div></figure><p id="c6db" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">模型</strong>:无论是在简单的布尔电路中实现，还是在完整的科学理论中实现的“世界如何运转”的知识，都称为世界的模型。使用这种模型的代理被称为基于<strong class="ka jc">模型的代理</strong>。</p><p id="faa4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">所以，<strong class="ka jc">当前状态=旧内部状态+当前感知</strong></p><p id="8583" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">基于模型的反射代理的结构</strong></p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/76c899e264865b8c8b09eaeb2ae59a8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*4xbfLGQ7mzY8L-U-ahtNPA.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lv">Structure of Model Reflex agent</strong></figcaption></figure><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/2dab7ddd575c14de29b1aed566f3c943.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*v4idD45-aihRHBCl2HBNmw.png"/></div></figure><p id="d8b6" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">代理需要某种描述理想情况的目标信息。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/ed1f81b9cb6bda5dd938be517eb8dd20.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*xzQNvosmo_5y6o3GxI1-lA.png"/></div></figure><p id="0e48" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">搜索和规划是人工智能中实现智能体目标的子领域。简单地通过将目的地指定为目标，基于目标的代理的行为可以很容易地被改变以前往不同的目的地。基于目标的代理结构被定义为</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/b028af9cedcf83133489b697b2f07f19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*GgPeUaKFDvfqxD2jgP0VFA.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lv">Structure of Goal-based Agent</strong></figcaption></figure><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/008afd2ceede99546e2be5356a609f00.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*Q4ezCDHGlR_YjqkyybysaQ.png"/></div></figure><p id="96bb" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">目标提供了快乐和不快乐状态之间的区别，用<strong class="ka jc">“快乐”&amp;“不快乐状态”</strong>具体说明。指定快乐&amp;不快乐并不意味着科学，经济学家&amp;计算机科学家使用术语<strong class="ka jc">“效用”。</strong></p><p id="77f1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一个代理的效用函数被描述为一个性能测量的内部化。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ni"><img src="../Images/d6e5700621f5ede524730a2104cee2d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QLXN6x7J4Eh1ZsA1ouoFtg.png"/></div></div></figure><p id="a2c2" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">基于目标的智能体和基于效用的智能体在灵活性和学习方面有很多优势。当目标不充分时，效用代理人做出理性的决策1)效用函数规定了适当的权衡。2)效用提供了成功的可能性，可以根据目标的重要性进行权衡。</p><p id="dc08" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一个理性的基于效用的主体选择最大化行动结果预期效用的行动。基于实用程序的代理结构的结构描述如下。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nj"><img src="../Images/b52def9a3c6f61cdc8420bce72d1e516.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*LiBfZFbYTMHQOrT_1Gf3MA.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lv">It is Model-based, Utility-based agent</strong></figcaption></figure><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/0e36bf8d90a3dc4a90c09004818d0c82.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/1*RY0bLVU6lLVL2OCPXLGXiQ.png"/></div></figure><p id="9c7a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于它们的上下文、应用和必要性，代理和环境的例子很多。下图中列出了可能的和众所周知的代理和环境。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/057b6d7d18e542bb1c0af9de974f0254.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4XRc_1MRwLaUiqLk0Xsyjw.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lv">Simple agents and environments</strong></figcaption></figure><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/1da095cbddabb9a223f397b5ff4089f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:412/format:webp/1*WYTBTr2XxNvr14dkK1OF6g.png"/></div></figure><p id="cb16" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在我们为我们的应用程序开发任何类型的智能代理之前，必须了解代理和环境。为了设计任何基于环境的智能代理，有必要了解需要构建什么类型的代理，它需要什么，什么样的设备，等等。，最好是参考更多的第一和第二章在一个现代的方法由斯图尔特罗素，彼得诺维格。<strong class="ka jc">。</strong></p><p id="061f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">感谢您阅读我的文章，感谢您的反馈、评论和分享。</p><h1 id="246d" class="nm nn jb bd lv no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh oi bi translated">参考资料:</h1><p id="b9c7" class="pw-post-body-paragraph jy jz jb ka b kb oj kd ke kf ok kh ki kj ol kl km kn om kp kq kr on kt ku kv ij bi translated">本文基于斯图尔特·拉塞尔、彼得·诺维格所著的《人工智能:现代方法》中的第二章。</p></div></div>    
</body>
</html>