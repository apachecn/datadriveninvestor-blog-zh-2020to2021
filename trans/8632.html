<html>
<head>
<title>Vanishing and Exploding Gradients in Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络中的消失梯度和爆炸梯度</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/vanishing-and-exploding-gradients-in-neural-networks-bddd4504e59c?source=collection_archive---------0-----------------------#2021-01-17">https://medium.datadriveninvestor.com/vanishing-and-exploding-gradients-in-neural-networks-bddd4504e59c?source=collection_archive---------0-----------------------#2021-01-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jp jq jr js gh gi paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="gh gi jo"><img src="../Images/f3994653cc661dcf5652ecacb23c88ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aDBvgXjXgKYY7sLAK-Vmeg.jpeg"/></div></div><figcaption class="jz ka gj gh gi kb kc bd b be z dk"><em class="jn">Image </em><a class="ae kd" href="https://unsplash.com/photos/GjCnF8InuXc" rel="noopener ugc nofollow" target="_blank"><em class="jn">Source</em></a></figcaption></figure><p id="12f3" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在这篇博客中，你会明白为什么渐变消失和爆炸的问题会发生。什么是消失和爆炸梯度问题，为什么会发生。</p><p id="392f" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="kg ir"> <em class="lc">什么是渐变？</em> </strong></p><p id="8e90" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">梯度只不过是损失函数相对于权重的导数。它用于在神经网络的反向传播过程中更新权重以最小化损失函数。</p><p id="8637" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="kg ir"> <em class="lc">什么是消失渐变？</em>T11】</strong></p><p id="526f" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="lc">在反向传播过程中，当我们对每一层进行反向传播时，导数或斜率会变得越来越小，这时就会出现消失梯度。</em></p><p id="da99" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="lc">当权值更新很小或指数级小时，训练时间过长，在最坏的情况下，这可能会完全停止神经网络训练。</em></p><p id="2671" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="lc">由于sigmoid和tanh激活函数的导数介于0到0.25和0–1之间，因此sigmoid和tanh激活函数会出现消失梯度问题。因此，更新的权重值很小，并且新的权重值与旧的权重值非常相似。这导致消失梯度问题。我们可以使用ReLU激活函数来避免这个问题，因为对于负输入和零输入，梯度为0，对于正输入，梯度为1。</em></p><p id="35c8" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="kg ir"> <em class="lc">什么是爆炸渐变？</em> </strong></p><p id="3ca0" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="lc">在反向传播过程中，当我们随着每一层向后移动，导数或斜率变得越来越大时，就会出现爆炸梯度。这种情况与消失梯度正好相反。</em></p><p id="826a" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="lc">这个问题的发生是因为权重，而不是因为激活功能。由于高权重值，导数也将更高，因此新的权重与旧的权重变化很大，梯度将永远不会收敛。所以可能会导致在极小点附近振荡，永远不会达到全局极小点。</em></p><p id="5320" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="kg ir">T27】结论:T29】</strong></p><p id="72fb" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="lc">在深度神经网络的反向传播期间，由于sigmoid和tan激活函数而出现消失梯度问题，并且由于大的权重而出现爆炸梯度问题。</em></p><p id="8f5e" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">如果你喜欢这个博客或者觉得它有帮助，请留下你的掌声！</p><p id="6dd4" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="kg ir"> <em class="lc">谢谢。</em> </strong></p></div></div>    
</body>
</html>