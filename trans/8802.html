<html>
<head>
<title>Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">强化学习</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/reinforcement-learning-cea620b89676?source=collection_archive---------25-----------------------#2021-01-21">https://medium.datadriveninvestor.com/reinforcement-learning-cea620b89676?source=collection_archive---------25-----------------------#2021-01-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/940bfe2f332e4ea257c310a6d617eb47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*YTTOspye8or7xWx0.jpeg"/></div></figure><p id="4fae" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">强化学习是一种受行为主义心理学启发的机器学习方法。强化学习与其他机器学习方法形成对比，因为算法没有明确地被告知如何执行任务，而是自行解决问题。</p><p id="8f07" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">强化学习与监督学习的不同之处在于，在监督学习中，训练数据带有答案，因此模型是用正确的答案来训练的，而在强化学习中，没有答案，而是由强化代理来决定如何执行给定的任务。在缺乏训练数据的情况下，它必然会借鉴其经验。</p><figure class="kw kx ky kz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi kv"><img src="../Images/d67cd69260d3b7c50a723779a84a919a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Sw3D8RJ7TCEk1Bas.jpg"/></div></div></figure><p id="fc7a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">作为一个代理，它与它的环境相互作用，并根据它的表现获得奖励状态。相反，代理人会因为表现不正确而受到惩罚。随着时间的推移，代理人使用动态规划做出决策，以最大化其奖励，最小化其惩罚。</p><h2 id="ea71" class="le lf it bd lg lh li dn lj lk ll dp lm ki ln lo lp km lq lr ls kq lt lu lv lw bi translated">强化学习的类型</h2><ul class=""><li id="b6d7" class="lx ly it jz b ka lz ke ma ki mb km mc kq md ku me mf mg mh bi translated"><strong class="jz iu">正向强化学习</strong>被定义为当一个事件由于一种特定的行为而发生时，增加该行为的强度和频率。在这种类型的强化学习中，算法为某个结果接收一种类型的奖励。换句话说，这里我们试图为每一个好的结果增加一个奖励，以增加一个好结果的可能性。</li><li id="0235" class="lx ly it jz b ka mi ke mj ki mk km ml kq mm ku me mf mg mh bi translated"><strong class="jz iu">负强化学习</strong>被定义为行为的强化，因为负面条件被阻止或避免。在这种类型中，我们试图去除一些负面的东西以提高性能。</li></ul><h2 id="3ee7" class="le lf it bd lg lh li dn lj lk ll dp lm ki ln lo lp km lq lr ls kq lt lu lv lw bi translated">强化学习的利与弊</h2><h2 id="2a78" class="le lf it bd lg lh li dn lj lk ll dp lm ki ln lo lp km lq lr ls kq lt lu lv lw bi translated"><strong class="ak">优势</strong></h2><ul class=""><li id="1639" class="lx ly it jz b ka lz ke ma ki mb km mc kq md ku me mf mg mh bi translated">可以解决高阶复杂问题。</li><li id="6930" class="lx ly it jz b ka mi ke mj ki mk km ml kq mm ku me mf mg mh bi translated">由于它的学习能力，它可以用于神经网络。</li><li id="d3b6" class="lx ly it jz b ka mi ke mj ki mk km ml kq mm ku me mf mg mh bi translated">由于模型不断学习，以前犯的错误将来不太可能发生。</li><li id="9d74" class="lx ly it jz b ka mi ke mj ki mk km ml kq mm ku me mf mg mh bi translated">当涉及到创建模拟器、自动汽车中的物体检测、机器人等时。，强化学习在模型中起着很大的作用。</li><li id="098d" class="lx ly it jz b ka mi ke mj ki mk km ml kq mm ku me mf mg mh bi translated">即使没有训练数据，它也会从处理训练数据的经验中学习。</li></ul><h2 id="71d6" class="le lf it bd lg lh li dn lj lk ll dp lm ki ln lo lp km lq lr ls kq lt lu lv lw bi translated"><strong class="ak">缺点</strong></h2><ul class=""><li id="6879" class="lx ly it jz b ka lz ke ma ki mb km mc kq md ku me mf mg mh bi translated">使用强化学习模型来解决更简单的问题是不正确的。原因是，这些模型通常处理复杂的问题。我们将浪费不必要的处理能力和空间来处理更简单的问题。</li><li id="5bb2" class="lx ly it jz b ka mi ke mj ki mk km ml kq mm ku me mf mg mh bi translated">我们需要大量数据来输入模型进行计算。强化学习模型需要大量的训练数据才能得出准确的结果。这消耗了时间和大量的计算能力。</li><li id="bef4" class="lx ly it jz b ka mi ke mj ki mk km ml kq mm ku me mf mg mh bi translated">当涉及到在真实世界的例子上建立模型时，维护成本是非常高的。就像建造无人驾驶汽车和机器人一样，我们需要对硬件和软件进行大量的维护。</li></ul></div></div>    
</body>
</html>