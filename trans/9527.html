<html>
<head>
<title>Volleyball Serve Detection on iPhone 12 Using Core ML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Core ML的iPhone 12排球发球检测</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/volleyball-serve-detection-on-iphone-12-using-core-ml-40e3b29f73d4?source=collection_archive---------9-----------------------#2021-02-13">https://medium.datadriveninvestor.com/volleyball-serve-detection-on-iphone-12-using-core-ml-40e3b29f73d4?source=collection_archive---------9-----------------------#2021-02-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/0a2bb9d4b0df6130b05f829002ab8c2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*juDRSBlOC7moXBLcuM3EWQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: Unsplash</figcaption></figure><p id="216c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi la translated">机器学习和人工智能解决方案将移动应用开发推向了一个新的高度。集成了机器学习技术的应用程序可以成功地识别和分类图像、人的声音和动作，从图像中识别文本并进行翻译。这个清单可以很容易地继续下去。然而，工程师们面临的主要问题仍然是在不损失处理速度的情况下，将具有数百万个连接的巨大模型传输到手机上，最重要的是，质量仍然保持不变。</p><figure class="lk ll lm ln gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lj"><img src="../Images/9f8013875f86f51383010c306f532f78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Igq3_66vVc2VoCmQ.jpg"/></div></div></figure><h1 id="dc7a" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">移动设备上ML的主要优势</h1><p id="a3fd" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">让我们来看看在移动设备上实现的ML模型的主要优势:</p><p id="5317" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">1)接近实时的处理。不需要进行API调用来发送数据并等待模型提供响应结果。对于处理来自设备上摄像机的视频流的应用程序来说，这可能是一个关键点。</p><p id="76af" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">2)离线可用性。不再需要连接到任何网络来使用这种应用程序。</p><p id="cde6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">3)隐私。您的数据永远不会离开设备。这意味着您不需要将数据发送到任何地方进行处理。所有计算都在设备上进行。</p><p id="6ea1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">4)成本低。应用程序在没有网络连接的情况下运行，并且没有API调用。这使您可以在任何地方使用应用程序，而没有任何脊约束。</p><h1 id="338c" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">移动设备上ML的主要缺点</h1><p id="1a54" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">尽管移动设备上的机器学习看起来很有前景，但它也有缺点。</p><p id="66c7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">1)应用程序大小。向移动应用程序添加机器学习模型会显著增加该应用程序的大小。</p><p id="2e19" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">2)系统利用率。移动设备上的预测涉及大量计算资源，这会增加电池消耗。</p><p id="b18d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">3)模特培训。通常，在移动设备上工作的模型应该在该设备之外被训练。当我们需要重新训练我们的模型时，这个问题也会重复出现。</p><p id="0315" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">苹果团队创建了一个名为Core ML的框架，旨在解决包含机器学习模型的移动应用程序开发过程中可能出现的问题。该工具是为移动设备上的机器学习模型集成而创建的，用于所有苹果产品，通过轻松集成预训练模型来提供快速预测。这使您可以开发在Apple设备上实时处理实时图像或视频的应用程序。</p><h1 id="af9d" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">核心ML的主要可能性</h1><p id="eb48" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">–实时图像识别</p><p id="2803" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–人脸检测</p><p id="2154" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–文本预测</p><p id="40ff" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–扬声器识别</p><p id="51f8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–行动分类</p><p id="22f9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–对表格数据的预测</p><p id="0558" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–不同的定制型号</p><h1 id="1358" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">它是如何工作的？</h1><p id="aee3" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">Core ML使用的是在外部某个地方(你的本地电脑或者云平台等)训练过的机器学习模型。)然后转换成Core ML合适的格式。为了开发应用程序，包括源代码创建和模型集成，使用了Apple兼容平台的IDE，称为Xcode。</p><figure class="lk ll lm ln gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lj"><img src="../Images/18765e611dec596603bb716f824d1bf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jFq2IgfYTo54FtBN.jpg"/></div></div></figure><h1 id="7de7" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">核心ML如何训练模型？</h1><p id="f41a" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">为了简化模型开发阶段，您可以使用Create ML应用程序构建和训练您的模型。这个工具已经和Xcode捆绑在一起了。使用Create ML训练的模型在核心ML中合适(。mlmodel)格式，并准备好在您的应用中使用。</p><p id="507a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Create ML支持五种不同类别的模型:</p><p id="3ffe" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">1)图像—分类和检测模型<br/> 2)声音—分类<br/> 3)运动—分类<br/> 4)文本—分类和标记<br/> 5)表格—分类、回归和推荐模型。</p><p id="9b4e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为Core ML训练模型的另一种方法是使用coremltools，这是一个python包，用于在。mlmodel格式。目前，它可用于解决以下任务:</p><p id="4e9e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–将来自流行机器学习工具的训练模型转换为核心ML格式(。mlmodel)</p><p id="b426" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–使用核心ML框架进行预测。</p><p id="1966" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">使用pip安装软件包:pip安装coremltools。这个简短的代码示例演示了如何将tf.keras模型转换为。适合核心ML的mlmodel格式。我们在项目中使用了coremltools的4.0版本。</p><figure class="lk ll lm ln gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lj"><img src="../Images/8ef000e471620fb25702621c4afddcd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OyNrQoAZ-eTeWKKQ.jpg"/></div></div></figure><h1 id="8f90" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">任务内容</h1><p id="1696" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">在我们的研究中，我们试图解决体育分析的一个典型问题——动作检测。主要条件——机型要集成到iPhone 12中。我们选择排球作为目标运动，选择“发球”作为目标动作。为了简化问题，我们假设从球场两边发出的球都应该被归类为发球。作为训练数据集，我们使用了公开的<a class="ae mr" href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/vb14/" rel="noopener ugc nofollow" target="_blank">排球活动数据集</a>，其中包含七个具有挑战性的排球活动类别，由奥地利排球联盟(2011/12赛季)的专业人士在六个视频中进行了注释。我们还通过自己收集的25个视频扩展了这个数据集。</p><p id="e405" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">主要的挑战是，有时我们看不到发球的球员(他在摄像机后面)。所以这个模型对于可见的和隐藏的服务都应该足够好。</p><h1 id="8359" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">我们尝试创建ML</h1><h2 id="574f" class="ms lp iq bd lq mt mu dn lu mv mw dp ly kn mx my mc kr mz na mg kv nb nc mk nd bi translated">动作分类器</h2><p id="ac8e" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">我们的第一个假设是来自createML的ActionClassifier应该可以解决我们的问题。我们受到了一些使用它的教程的启发。只是为了简单的概述，你可以从官方页面查看这个<a class="ae mr" href="https://developer.apple.com/videos/play/wwdc2020/10043/" rel="noopener ugc nofollow" target="_blank">视频</a>。</p><p id="004b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">简而言之，动作分类器将一组身体关键点(通常为19个)作为输入，并提供一类动作作为输出。窗口大小通常由开发者决定，但是对于我们的问题，我们将窗口大小设为30帧(大约1秒的持续时间)。</p><p id="b42f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在实验过程中，我们面临的问题是，当只有一个人出现在屏幕上时，动作分类器可以完美地工作。我们没有找到一个很好的方法来使用苹果的MLActionClassifier进行多人动作分类，这就是为什么我们在这个领域的研究没有成功。</p><h2 id="59b0" class="ms lp iq bd lq mt mu dn lu mv mw dp ly kn mx my mc kr mz na mg kv nb nc mk nd bi translated">图像分类器</h2><p id="e982" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">我们的第二个方法是使用createML的另一个工具——image classifier。如前所述，我们有一个包含可见和不可见服务的数据集，这就是为什么我们决定尝试事件分类而不是动作分类。换句话说，我们计划根据所有玩家的位置对图像进行分类。在发球的情况下，这并不困难——除了一个人之外，所有的球员都站在球网附近，试图不让对手看到自己的发球。对方球队也有一个强大的模式——所有球员都是静止的，准备接球。</p><p id="dab0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在CreateML中训练一个图像分类模型真的很容易——你不需要写任何一行代码。算法如下:</p><p id="8262" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">1)组织训练数据集目录。每一类图像都应该位于一个特定的目录中。</p><p id="58a3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">2)组织测试数据集目录。对训练集执行相同的操作。</p><p id="96d6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">3)创建图像分类项目。</p><p id="604c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">4)配置训练集，设置扩充，并设置历元数。</p><p id="8e0f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">5)根据图像的数量、大小和其他一些参数，等待一段时间。</p><p id="e4bf" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">6)保存模型并在XCode项目中使用它。</p><p id="c2ba" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">然而，我们在这一步也面临一些问题，即:</p><p id="f3b3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–图像分类器的精确度不够高。我们获得了大约70%的发球检测准确率。</p><p id="61b6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">–训练模型的时间真的很长——在Macbook上使用约15000个样本的数据集超过10个小时。</p><h1 id="9768" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">我们是如何解决这些问题的？</h1><p id="dff6" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">我们决定继续处理分类问题，但现在，我们准备了一个数据集，其中每个样本是一组30个连续的灰度帧。照常输出——类的标签。在使用tf.keras框架对模型进行训练后，我们将其转换为. mlmodel。最终得分约为0.87 (f1分)。</p><h1 id="6ba4" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">如何整合。mlmodel进入项目？</h1><p id="402d" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">一旦你训练完毕。mlmodel把它集成到你的Xcode项目中真的很容易——你只需要把它复制到项目的目录中。如果你点击一个带有模型的文件，你会看到一个窗口，里面有关于它的所有可用信息(见下面的截图)。</p><p id="7fcd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在第一个选项卡上，您可以看到有关神经网络内部各层的信息。</p><figure class="lk ll lm ln gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lj"><img src="../Images/1f690b8e38551aded5a8308431f6a25c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uC7hHhMHYGkij0AS.jpg"/></div></div></figure><p id="e89d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在第二个选项卡上，您可以检查输入和输出数据类型和维度。</p><figure class="lk ll lm ln gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lj"><img src="../Images/793402fafb63faebb5c2688448b20627.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UanMce8wPfzN9U54.jpg"/></div></div></figure><p id="cdff" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">还有一件更有用的事情——您可以点击“自动生成的Swift模型类”,查看为类生成的模型的所有定义、输入和输出。这些信息应该有助于您将模型集成到代码中。</p><h1 id="08f0" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">结论</h1><p id="8ebf" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">Core ML是一个非常强大的工具，它允许您将任何复杂的模型集成到您的移动设备中。为了简化集成过程，苹果团队开发了CreateML框架，允许人们用最少的代码编写创建不同的ML模型。然而，我们做的项目表明CreateML并不适合所有的任务。在我们的案例中，我们在排球发球检测领域进行了研究，但我们无法使用该框架获得良好的结果。总的来说，我们不能使用CreateML框架为多人实现一个动作分类器和一个分数足够高的图像分类器。</p><p id="5dd8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">因此，我们应用了使用tf.keras的另一种方法，并进一步转换为. ml模型。因此，排球比赛的发球检测模型以实时速度(26 FPS)工作，F1得分接近87%。</p></div></div>    
</body>
</html>