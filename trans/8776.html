<html>
<head>
<title>[ML UTD 32] Machine Learning Up-To-Date — Life With Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[ML UTD 32]最新的机器学习—数据生活</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/ml-utd-32-machine-learning-up-to-date-life-with-data-3921d18a1669?source=collection_archive---------29-----------------------#2021-01-20">https://medium.datadriveninvestor.com/ml-utd-32-machine-learning-up-to-date-life-with-data-3921d18a1669?source=collection_archive---------29-----------------------#2021-01-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7b11" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">第32期每周简讯来自<a class="ae ki" href="https://lifewithdata.org" rel="noopener ugc nofollow" target="_blank">生活有数据</a></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi kj"><img src="../Images/fa3307081f0ca3a0b6fa229a3d071141.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/0*DQCkyK-HSso3iK-J"/></div></figure><p id="f0ac" class="pw-post-body-paragraph kr ks it kt b ku kv ju kw kx ky jx kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这是来自<a class="ae ki" href="https://lifewithdata.org" rel="noopener ugc nofollow" target="_blank"> <strong class="kt iu"> LifeWithData </strong> </a>博客的ML UTD #32！在当今软件工程和机器学习的繁忙前线，我们帮助您将信号与噪声分离。</p><p id="bff3" class="pw-post-body-paragraph kr ks it kt b ku kv ju kw kx ky jx kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae ki" href="https://lifewithdata.org" rel="noopener ugc nofollow" target="_blank"> <strong class="kt iu"> LifeWithData </strong> </a>致力于提供精心策划的机器学习&amp;软件工程更新，为读者指出没有多余细节的关键发展。这使得整个行业能够进行频繁、简洁的更新，而不会出现信息过载。</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="0d78" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">应用程序</h1><ul class=""><li id="13c4" class="mm mn it kt b ku mo kx mp la mq le mr li ms lm mt mu mv mw bi translated">生产机器学习监控:异常值、漂移、解释者和统计性能</li><li id="7d6e" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated">MLCommons发起并联合了50多位全球技术和学术领袖</li><li id="804f" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated">OpenLineage简介</li></ul><h1 id="e9cb" class="lu lv it bd lw lx nc lz ma mb nd md me jz ne ka mg kc nf kd mi kf ng kg mk ml bi translated">理论</h1><ul class=""><li id="264e" class="mm mn it kt b ku mo kx mp la mq le mr li ms lm mt mu mv mw bi translated">无奖励评估代理</li><li id="f33d" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated">100种语言的实体链接</li><li id="dbf1" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated">谷歌发布其Objectron数据集</li></ul></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="fdca" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">生产机器学习监控:异常值、漂移、解释者和统计性能</h1><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nh"><img src="../Images/3ba0c7b9305d6af94d4ab0362f3aeefd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LSqVNurPQY46JJbJ1szQ8w.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk">The anatomy of production ML [<a class="ae ki" href="https://towardsdatascience.com/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158" rel="noopener" target="_blank">source</a>]</figcaption></figure><blockquote class="nq nr ns"><p id="1f51" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><em class="it">在本文中，我们展示了一个端到端示例，展示了在生产中监控机器学习模型的最佳实践、原则、模式和技术。我们将展示如何使标准微服务监控技术适应已部署的机器学习模型，以及更高级的范式，包括概念漂移、离群点检测和人工智能可解释性。</em></p><p id="e204" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><em class="it">我们将从零开始训练图像分类机器学习模型，将其作为微服务部署在Kubernetes中，并引入广泛的高级监控组件。监控组件将包括离群检测器、漂移检测器、人工智能解释器和度量服务器——我们将涵盖用于每一个的底层架构模式，这些模式是在考虑规模的情况下开发的，旨在跨数百或数千个异构机器学习模型有效工作。</em></p><p id="a903" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><a class="ae ki" href="https://towardsdatascience.com/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158" rel="noopener" target="_blank"> <em class="it"> …继续阅读</em> </a></p></blockquote><p id="70b4" class="pw-post-body-paragraph kr ks it kt b ku kv ju kw kx ky jx kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">《丛林奇兵》</p><ul class=""><li id="2505" class="mm mn it kt b ku kv kx ky la nx le ny li nz lm mt mu mv mw bi translated"><a class="ae ki" href="https://towardsdatascience.com/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158" rel="noopener" target="_blank">条</a></li><li id="6438" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://youtu.be/QcevzK9ZuDg" rel="noopener ugc nofollow" target="_blank">视频演示</a></li><li id="3760" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://github.com/axsaucedo/seldon_experiments/blob/master/monitoring-talk/cifar10_example.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本代号</a></li><li id="a1a0" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://github.com/SeldonIO/seldon-core/" rel="noopener ugc nofollow" target="_blank">谢顿核心</a></li><li id="815c" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated">信用:<a class="ae ki" href="https://twitter.com/AxSaucedo" rel="noopener ugc nofollow" target="_blank"> @AxSaucedo </a> | <a class="oa ob ep" href="https://medium.com/u/32de426f7278?source=post_page-----3921d18a1669--------------------------------" rel="noopener" target="_blank">亚历杭德罗·绍切多</a></li></ul></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="5f7b" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">MLCommons发起并联合了50多位全球技术和学术领袖</h1><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oc"><img src="../Images/f58ec8b1cdf5db9c0908203b3a78a13b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MFJh-8iBrw5D-4VH6Ne-bQ.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk">Snippet from the front page of the MLCommons website [<a class="ae ki" href="https://mlcommons.org/" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><blockquote class="nq nr ns"><p id="7e45" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><em class="it">今天，开放工程联盟MLCommons启动了其行业-学术合作伙伴关系，以加速机器学习创新，并为公众利益拓宽对这一关键技术的访问。这家非营利组织最初以MLPerf的名义成立，现在拥有一个创始董事会，包括来自阿里巴巴、脸书人工智能、谷歌、英特尔和英伟达的代表，以及哈佛大学的Vijay Janapa Reddi教授；和50多个创始成员。创始成员包括全球超过15家专注于半导体、系统和软件的初创公司和小公司，以及来自加州大学伯克利分校、斯坦福大学和多伦多大学等大学的研究人员。</em></p><p id="c87e" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><em class="it"> MLCommons将推进最新人工智能和机器学习数据集和模型、最佳实践、基准和指标的开发和获取。目的是让尽可能多的人尽可能快地访问机器学习解决方案，如计算机视觉、自然语言处理和语音识别。</em></p><p id="705d" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><a class="ae ki" href="https://mlcommons.org/en/news/mlcommons-launch" rel="noopener ugc nofollow" target="_blank"> <em class="it"> …继续阅读</em> </a></p></blockquote><p id="1de7" class="pw-post-body-paragraph kr ks it kt b ku kv ju kw kx ky jx kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">《丛林奇兵》</p><ul class=""><li id="0d2e" class="mm mn it kt b ku kv kx ky la nx le ny li nz lm mt mu mv mw bi translated"><a class="ae ki" href="https://mlcommons.org/en/news/mlcommons-launch" rel="noopener ugc nofollow" target="_blank">条</a></li><li id="9a7b" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="http://www.mlperf.org/" rel="noopener ugc nofollow" target="_blank"> MLPerf </a></li><li id="0fc0" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://mlcommons.org/en/peoples-speech/" rel="noopener ugc nofollow" target="_blank">人的语音数据集</a></li><li id="3b18" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated">MLCube </li><li id="25c8" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated">信用:<a class="ae ki" href="https://twitter.com/commons_ml" rel="noopener ugc nofollow" target="_blank"> @commons_ml </a></li></ul></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="c5d0" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">OpenLineage简介</h1><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi od"><img src="../Images/08a0a3c549a1e78c440f21796eeb203d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iONFZgswjIhkzx2Mf7FfYQ.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk"><a class="ae ki" href="https://datakin.com/introducing-openlineage/" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><blockquote class="nq nr ns"><p id="8e31" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated">对于任何关注这一领域的人来说，过去几年数据革命的加速已经非常令人兴奋。Hadoop早期的“大数据”项目的试验性部署现在已经演变为新数据工具整个生态系统的全面生产和任务关键型部署，不仅在领先的技术公司中，而且越来越多地在每个行业中进行。</p><p id="5649" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated">然而，随着数据技术征服世界，赌注也越来越高。</p><p id="9507" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated">特别是，当需要时，数据总是可用的、最新的和正确的变得非常重要。换句话说，需要信任数据来支持任务关键型活动。</p><p id="d2d5" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><em class="it">不幸的是，数据技术日益增长的重要性也伴随着整体复杂性的相应增加[…] </em></p><p id="c071" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><em class="it">在与每天操作这些数据生态系统的从业者交谈时，一方面，数据技术的重要性日益增加，另一方面，作为任务关键型系统来管理它们的可用工具之间存在明显的矛盾，导致许多效率低下，无法提供强有力的保证，从而对所使用的数据缺乏信任。</em></p><p id="bee5" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><a class="ae ki" href="https://datakin.com/introducing-openlineage/" rel="noopener ugc nofollow" target="_blank"> <em class="it"> …继续阅读</em> </a></p></blockquote><p id="6a69" class="pw-post-body-paragraph kr ks it kt b ku kv ju kw kx ky jx kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">《丛林奇兵》</p><ul class=""><li id="edc6" class="mm mn it kt b ku kv kx ky la nx le ny li nz lm mt mu mv mw bi translated"><a class="ae ki" href="https://datakin.com/introducing-openlineage/" rel="noopener ugc nofollow" target="_blank">条</a></li><li id="6d15" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://datakin.com/" rel="noopener ugc nofollow" target="_blank">数据金</a></li><li id="5e49" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://github.com/OpenLineage/OpenLineage" rel="noopener ugc nofollow" target="_blank"> OpenLineage Github </a></li><li id="aaf7" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="http://marquezproject.ai/" rel="noopener ugc nofollow" target="_blank">马尔克斯开源元数据项目</a></li><li id="1ebf" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated">信用:<a class="ae ki" href="https://twitter.com/datakinhq" rel="noopener ugc nofollow" target="_blank"> @DatakinHQ </a> |</li></ul></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="6a16" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">无奖励评估代理</h1><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oe"><img src="../Images/887bf0cde8bacc2e6319d1c75ab67e11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MTYQ4OMm1g34ghKXmlCu3w.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk">A flow of analyzing correlations between intrinsic and supervised objectives [<a class="ae ki" href="https://danijar.com/project/agenteval/" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><blockquote class="nq nr ns"><p id="b0c6" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated">强化学习使智能体能够在未知的环境中解决具有挑战性的任务。然而，手工制作奖励函数可能耗时、昂贵，并且容易出现人为错误。竞争目标已经被提出，让代理人在没有外部监督的情况下学习，但还不清楚它们在多大程度上反映了任务奖励或人类行为。为了加速内在目标的开发，我们在预先收集的代理行为数据集上追溯计算潜在目标，而不是在线优化它们，并通过分析它们的相关性来比较它们。我们研究了七个代理人、三个雅达利游戏和3D游戏《我的世界》的输入熵、信息增益和授权。我们发现，所有三个内在目标与人类行为相似性度量的相关性比与任务奖励的相关性更强。此外，输入熵和信息增益与人类相似性的相关性比任务回报更强，这表明使用内在目标来设计行为类似于人类玩家的代理。</p><p id="034c" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><a class="ae ki" href="https://arxiv.org/pdf/2012.11538.pdf" rel="noopener ugc nofollow" target="_blank"><em class="it">……继续阅读</em> </a></p></blockquote><ul class=""><li id="6b7b" class="mm mn it kt b ku kv kx ky la nx le ny li nz lm mt mu mv mw bi translated"><a class="ae ki" href="https://arxiv.org/pdf/2012.11538.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></li><li id="19dc" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://danijar.com/project/agenteval/" rel="noopener ugc nofollow" target="_blank">工程地点</a></li><li id="4aee" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://minerl.io/" rel="noopener ugc nofollow" target="_blank">密涅尔</a></li><li id="e253" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://github.com/openai/large-scale-curiosity" rel="noopener ugc nofollow" target="_blank">Github open ai/大型-好奇号</a></li><li id="e946" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://github.com/openai/random-network-distillation" rel="noopener ugc nofollow" target="_blank">Github open ai/随机网络蒸馏</a></li><li id="dab6" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://github.com/hill-a/stable-baselines" rel="noopener ugc nofollow" target="_blank"> Github希尔-a/稳定基线</a></li><li id="39a7" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated">鸣谢:<a class="ae ki" href="https://twitter.com/danijarh" rel="noopener ugc nofollow" target="_blank"> @danijarh </a>等论文作者</li></ul></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="2490" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">100种语言的实体链接</h1><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi of"><img src="../Images/1cf571910f7fbaa6c93c199596c861d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*tKyM2ESirOB4XrG9ttDWvw.png"/></div><figcaption class="nm nn gj gh gi no np bd b be z dk">Diagram of the Dual Encoder Model F [<a class="ae ki" href="https://arxiv.org/pdf/2011.02690.pdf" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><blockquote class="nq nr ns"><p id="91ee" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><em class="it">我们提出了一种新的多语言实体链接公式，其中特定语言的提及解析为语言不可知的知识库。我们在这个新的设置中训练了一个双编码器，基于先前的工作，改进了特征表示、负挖掘和辅助实体配对任务，以获得覆盖100多种语言和2000万个实体的单个实体检索模型。该模型优于来自更有限的跨语言链接任务的最先进的结果。罕见的实体和低资源语言在这种大规模上构成了挑战，所以我们提倡更加关注零次和少数几次评估。为此，我们提供了Mewsli-9，这是一个新的大型多语言数据集(</em><a class="ae ki" href="http://goo.gle/mewsli-dataset" rel="noopener ugc nofollow" target="_blank"><em class="it">【http://goo.gle/mewsli-dataset】</em></a><em class="it">)，与我们的设置相匹配，并展示了基于频率的分析如何为我们的模型和训练增强提供关键见解。</em></p><p id="1349" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><a class="ae ki" href="https://arxiv.org/pdf/2011.02690.pdf" rel="noopener ugc nofollow" target="_blank"><em class="it">……继续阅读</em> </a></p></blockquote><p id="e79a" class="pw-post-body-paragraph kr ks it kt b ku kv ju kw kx ky jx kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">《丛林奇兵》</p><ul class=""><li id="f540" class="mm mn it kt b ku kv kx ky la nx le ny li nz lm mt mu mv mw bi translated"><a class="ae ki" href="https://arxiv.org/pdf/2011.02690.pdf" rel="noopener ugc nofollow" target="_blank">条</a></li><li id="fbba" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://github.com/google-research/google-research/tree/master/dense_representations_for_entity_retrieval/mel" rel="noopener ugc nofollow" target="_blank">Github上的数据集</a></li><li id="ea2a" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated">鸣谢:论文作者</li></ul></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="7a10" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">谷歌发布其Objectron数据集</h1><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi kj"><img src="../Images/bde72f48725916d815fb208a468e7926.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/0*pV69AyN8UIvIJDPY"/></div><figcaption class="nm nn gj gh gi no np bd b be z dk">Visualizations of annotations in the Objectron data set [<a class="ae ki" href="http://www.google.com/" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><blockquote class="nq nr ns"><p id="c43d" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><em class="it">object Ron数据集是以对象为中心的短视频剪辑的集合，伴随着AR会话元数据，包括相机姿态、稀疏点云和周围环境中平面表面的特征。在每个视频中，摄像机围绕物体移动，从不同的角度捕捉它。数据还包含每个对象的手动注释的3D边界框，这些框描述了对象的位置、方向和尺寸。该数据集由15K个带注释的视频剪辑组成，辅以超过400万个带注释的图像，分类如下:自行车、书籍、瓶子、相机、麦片盒、椅子、杯子、笔记本电脑和鞋子。此外，为了确保地理多样性，我们的数据集收集自五大洲的10个国家。除了数据集，我们还分享了针对四类物体(鞋子、椅子、杯子和相机)的3D物体检测解决方案。这些模型使用该数据集进行训练，并在MediaPipe中发布，media pipe是谷歌为直播和流媒体提供跨平台可定制ML解决方案的开源框架。</em></p><p id="f422" class="kr ks nt kt b ku kv ju kw kx ky jx kz nu lb lc ld nv lf lg lh nw lj lk ll lm im bi translated"><a class="ae ki" href="http://www.google.com" rel="noopener ugc nofollow" target="_blank"> <em class="it"> …继续阅读</em> </a></p></blockquote><p id="eea0" class="pw-post-body-paragraph kr ks it kt b ku kv ju kw kx ky jx kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">《丛林奇兵》</p><ul class=""><li id="fdb2" class="mm mn it kt b ku kv kx ky la nx le ny li nz lm mt mu mv mw bi translated">github<a class="ae ki" href="https://github.com/google-research-datasets/Objectron" rel="noopener ugc nofollow" target="_blank">Google-research-datasets/Objectron</a></li><li id="d642" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://github.com/google-research-datasets/Objectron#dataset-format" rel="noopener ugc nofollow" target="_blank">数据集格式</a></li><li id="0209" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://github.com/google-research-datasets/Objectron#tutorials" rel="noopener ugc nofollow" target="_blank">教程</a></li><li id="e75d" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated"><a class="ae ki" href="https://mediapipe.dev/" rel="noopener ugc nofollow" target="_blank">媒体管道</a></li><li id="1a6f" class="mm mn it kt b ku mx kx my la mz le na li nb lm mt mu mv mw bi translated">信用:<a class="ae ki" href="https://twitter.com/GoogleAI" rel="noopener ugc nofollow" target="_blank"> @GoogleAI </a></li></ul></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="66a6" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">保持最新状态</h1><p id="cf41" class="pw-post-body-paragraph kr ks it kt b ku mo ju kw kx mp jx kz la og lc ld le oh lg lh li oi lk ll lm im bi translated">ML UTD #32到此为止。然而，在学术界和工业界，事情发生得很快！除了<a class="ae ki" href="https://www.lifewithdata.org/newsletter" rel="noopener ugc nofollow" target="_blank">这份时事通讯</a>之外，让自己在<a class="ae ki" href="https://lifewithdata.org/" rel="noopener ugc nofollow" target="_blank"> LifeWithData </a>博客、<a class="ae ki" href="https://medium.com/@anthonyagnone" rel="noopener">Medium</a>上的文章和<a class="ae ki" href="https://twitter.com/@anthonyagnone" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上保持更新。</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="12db" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">不断学习</h1><div class="oj ok gp gr ol om"><a href="https://medium.com/datadriveninvestor/ml-utd-31-machine-learning-up-to-date-life-with-data-b077bd2c14bd" rel="noopener follow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">[ML UTD 31]机器学习最新—数据生活</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">《生活与数据》周刊第31期</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">medium.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa kp om"/></div></div></a></div><div class="oj ok gp gr ol om"><a href="https://medium.com/datadriveninvestor/checkthisout-pythons-rich-library-for-terminal-text-formatting-e4da97a0beda" rel="noopener follow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">[CheckThisOut] Python丰富的终端文本格式化库</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">Rich是一个Python库，用于终端中丰富的文本和漂亮的格式。</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">medium.com</p></div></div><div class="ov l"><div class="pb l ox oy oz ov pa kp om"/></div></div></a></div><div class="oj ok gp gr ol om"><a href="https://towardsdatascience.com/tips-to-survive-and-thrive-in-the-remote-first-data-workforce-34944abddd29" rel="noopener follow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">在远程优先的数据工作人员中生存和发展的技巧</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">提示:它不仅仅是Zoom和Github</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="pc l ox oy oz ov pa kp om"/></div></div></a></div></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><p id="535a" class="pw-post-body-paragraph kr ks it kt b ku kv ju kw kx ky jx kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="nt">原载于2021年1月20日</em><a class="ae ki" href="http://www.lifewithdata.org/newsletter/mlutd32" rel="noopener ugc nofollow" target="_blank"><em class="nt">【https://www.lifewithdata.org】</em></a><em class="nt">。</em></p></div></div>    
</body>
</html>