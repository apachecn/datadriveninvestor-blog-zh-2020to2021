# 算法与辨别:技术中立的不真实性

> 原文：<https://medium.datadriveninvestor.com/algorithms-and-discrimination-untruthfulness-of-technological-neutrality-d8e45c74f5a7?source=collection_archive---------29----------------------->

![](img/037eb9f454a78d41d313aa95617baeaf.png)

意大利博洛尼亚法院最近的一项裁决代表了一个真正的分水岭，该裁决涉及将一个声誉排名算法系统应用于 ***Deliveroo*** 骑手:这个人工智能系统也被称为“弗兰克”，在一审中被判定为歧视性和“盲目的”，因为它无法评估美国快递公司的工人，即送货员，既有权利也有义务。

尼迪尔 NIdiL、菲尔卡姆斯 NIdiL 和过滤器 NIdiL 提出上诉，谴责该算法在判断可能的缺勤时存在“*不平等*”,对他们的评价都是负面的，没有考虑到缺勤的原因。CGIL 秘书*塔尼亚·萨凯蒂*在一份声明中说:*法官认为，食品交付平台采用的评估模式是公司“有意识的选择”的结果，以优先考虑骑手的可用性，而从未考虑他可能与平台缺乏联系的原因*。

这一裁决不仅是关于被食品配送部门的跨国公司“吞没”的剥削问题工人的更广泛争议的一部分，也代表着朝着日益成熟的“ ***意识*** ”所谓的*技术中立*的不真实性迈出的第一步。

诚然，在意大利，我们现在开始适应创新技术的工具，但在其他地方，例如在美国，我们还有很长的路要走！

巴尔的摩大学的法学教授米歇尔·吉尔曼(Michele Gilman)起草了一份有趣的报告，阐述了这些自动化系统是如何损害不太富裕的阶层的，一方面是因为他们准备不足，信息不灵通，另一方面是因为这些系统制造了真正的陷阱，而这些陷阱往往是看不见的。

数字建档是对个人数据的自动处理，目的是评估人们和/或预测他们的行为。算法用于剖析。

信用评分是剖析的一个例子。 ***银行排名*** ，能够申请贷款购买汽车、房子或任何其他商品所必需的分数，用博洛尼亚法官的话来说，是如此“盲目”，以至于当阈值被超过为负时，受试者几乎不可能获得允许他在未来获得贷款的分数！应该补充的是，通常这些属于私人公司的系统，很好地隐藏了决定具体决策的机制！

正如吉尔曼正确指出的，“一些经常纳入法律的概念，如合理、必要和可信，需要人的判断，因此很难(如果不是不可能的话)转化为法典。谨慎的另一个原因是数据不是中性的。

对于生活在经济边缘的人来说，信用报告可能会在经济上造成毁灭性的影响，因为正如消费者权益倡导者吴启智(Chi Chi Wu)所言，它们惩罚了“那些并非因自己的过错而陷入困境的消费者——可能是因为疾病、失业，或者是因为他们是欺诈或自然灾害的受害者——而是将他们视为不负责任的赖账者”。这些消费者会发现自己处于一个恶性循环中，不支付账单会被编码到他们的数字档案中，这反过来又会使他们难以找到工作或支付租金，这反过来又会恶化他们支付账单和提高信用评级的希望。由于经济中的结构性劣势，这些周期对有色人种社区打击最大。

管理消费者报告的主要法规是《公平信用报告法》( FCRA ),根据该法，消费者报告机构必须采用合理的程序来确保其报告信息的准确性。包括三大信用机构 Experian、Equifax 和 TransUnion 在内的信用评级机构是私人公司，与股东相关，其客户主要是债权人和收债人；因此，低收入消费者的利益不是他们商业模式的一部分。

私人诉讼权至关重要，因为不准确的消费者报告是一个严重的问题。美国联邦贸易委员会(FTC)为消费者提供自助指南，帮助他们更正信用报告中的信息。联邦贸易委员会报告说，五分之一的美国人在他们的信用报告上有错误，20 分之一的人有严重到导致拒绝信用或更高的信用成本的错误。

*“人们在很大程度上仍然不知道这些大数据系统，这造成了信息不对称，其破坏性后果对低收入人群影响最大。以数据为中心的技术增加了穷人负面推论的规模、范围和速度*

技术工具的潜力必须与它们的正确使用相平衡，这样它们才能在不伤害最危险人群的情况下使用！这种意识有助于促进创新系统的引入，但能够被“引导”到正确和公平的应用。

版权所有

**律师拉斐尔·阿格莫**