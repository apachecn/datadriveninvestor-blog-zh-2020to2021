<html>
<head>
<title>How to Implement K-Nearest Neighbors?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何实现K近邻？</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/how-to-implement-k-nearest-neighbors-4c46da0396fb?source=collection_archive---------14-----------------------#2021-01-19">https://medium.datadriveninvestor.com/how-to-implement-k-nearest-neighbors-4c46da0396fb?source=collection_archive---------14-----------------------#2021-01-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="d81a" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">K近邻指南</h2><div class=""/><div class=""><h2 id="1d72" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">第2部分:用Python构建模型</h2></div><p id="fdcc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">参考</em> <a class="ae ll" href="https://kopaljain95.medium.com/what-are-k-nearest-neighbors-8ee761730d98" rel="noopener"> <strong class="kq ja"> <em class="lk">什么是K-最近邻？第1节:定义模型</em> </strong> </a> <em class="lk">，在继续… </em>之前</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lm"><img src="../Images/c4bcc65bcdcf8bb758a79e28b1ded6df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6PKX8OjaPa40WkcnTAyjfA.png"/></div></div></figure><blockquote class="ly lz ma"><p id="8ead" class="ko kp lk kq b kr ks ka kt ku kv kd kw mb ky kz la mc lc ld le md lg lh li lj ij bi translated"><strong class="kq ja"><em class="iq">【1】导入库</em> </strong></p></blockquote><pre class="ln lo lp lq gt me mf mg mh aw mi bi"><span id="3b35" class="mj mk iq mf b gy ml mm l mn mo">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd</span></pre><ul class=""><li id="8d86" class="mp mq iq kq b kr ks ku kv kx mr lb ms lf mt lj mu mv mw mx bi translated">NumPy是一个用于处理数组的Python库。</li><li id="e889" class="mp mq iq kq b kr my ku mz kx na lb nb lf nc lj mu mv mw mx bi translated">Matplotlib 是一个Python库，用于创建静态、动画和交互式可视化。</li><li id="0d22" class="mp mq iq kq b kr my ku mz kx na lb nb lf nc lj mu mv mw mx bi translated">Pandas 是一个Python库，用于提供快速、灵活、富于表现力的数据结构。</li></ul><p id="6c8c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> W </span> hy这一步:<strong class="kq ja"> Python库</strong>是一组有用的函数，消除了从头编写代码的需要，尤其是在开发机器学习、深度学习、数据科学、数据可视化应用等时！</p><blockquote class="ly lz ma"><p id="b084" class="ko kp lk kq b kr ks ka kt ku kv kd kw mb ky kz la mc lc ld le md lg lh li lj ij bi translated"><strong class="kq ja"><em class="iq">【2】读取&amp;存储数据</em> </strong></p></blockquote><pre class="ln lo lp lq gt me mf mg mh aw mi bi"><span id="8376" class="mj mk iq mf b gy ml mm l mn mo">df = pd.read_csv('Mammographic_Data_Cleaned.csv')<br/>df.info()</span><span id="4339" class="mj mk iq mf b gy nm mm l mn mo">...</span><span id="959e" class="mj mk iq mf b gy nm mm l mn mo"><em class="lk">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 831 entries, 0 to 830<br/>Data columns (total 5 columns):<br/>AGE         831 non-null float64<br/>SHAPE       831 non-null int64<br/>MARGIN      831 non-null int64<br/>DENSITY     831 non-null int64<br/>SEVERITY    831 non-null int64<br/>dtypes: float64(1), int64(4)<br/>memory usage: 32.6 KB</em></span></pre><p id="9770" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意:这里使用的<a class="ae ll" href="https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass" rel="noopener ugc nofollow" target="_blank">数据集</a>是经过预处理和清洗的。要遵循这些步骤，请参考<a class="ae ll" href="https://github.com/kopaljain95/import-data.science-classification/blob/main/DataPreprocessing%5B0%5D/Mammographic_DataPreprocessing.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub代码</a>。</p><p id="40cb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">请注意形状、边距和密度是怎样的数据类型。由于这些特性是名义上的，它们需要被转换成<code class="fe nn no np mf b">object</code>数据类型。如果数据集的数据类型是正确的，那么可以跳过这一步，或者参考下面的代码:</p><pre class="ln lo lp lq gt me mf mg mh aw mi bi"><span id="c094" class="mj mk iq mf b gy ml mm l mn mo">for data in [df]:</span><span id="5bad" class="mj mk iq mf b gy nm mm l mn mo"># Convert Data Type for SHAPE<br/>    data['SHAPE'] = data['SHAPE'].astype(str)</span><span id="f1c6" class="mj mk iq mf b gy nm mm l mn mo"># Convert Data Type for MARGIN<br/>    data['MARGIN'] = data['MARGIN'].astype(str)</span><span id="8837" class="mj mk iq mf b gy nm mm l mn mo"># Convert Data Type for DENSITY<br/>    data['DENSITY'] = data['DENSITY'].astype(str)</span></pre><p id="5dc2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi nd translated">通过这个步骤:为了使用数据和执行数据操作，数据必须以统一的结构读取和存储。熊猫被用来阅读。csv文件，并将数据存储为名为df的数据帧格式。</p><blockquote class="ly lz ma"><p id="673f" class="ko kp lk kq b kr ks ka kt ku kv kd kw mb ky kz la mc lc ld le md lg lh li lj ij bi translated"><strong class="kq ja"><em class="iq">【3】拆分数据(自变量【X】&amp;【因变量【y】)</em></strong></p></blockquote><pre class="ln lo lp lq gt me mf mg mh aw mi bi"><span id="e871" class="mj mk iq mf b gy ml mm l mn mo">dependentVar = 'SEVERITY'</span><span id="2ee1" class="mj mk iq mf b gy nm mm l mn mo">X = df.loc[:, df.columns != dependentVar]<br/>y = df[dependentVar].values</span><span id="1593" class="mj mk iq mf b gy nm mm l mn mo">print("Number of observations and dimensions in 'X':", X.shape)<br/>print("Number of observations in 'y':", y.shape)</span><span id="b7e9" class="mj mk iq mf b gy nm mm l mn mo">...</span><span id="9733" class="mj mk iq mf b gy nm mm l mn mo"><em class="lk">Number of observations and dimensions in 'X': (831, 4)<br/>Number of observations in 'y': (831,)</em></span></pre><p id="8594" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> W </span>这一步的目的是用自变量(或特征)来预测因变量(或结果)。因此，需要将这些变量分为X和y，其中X表示输入模型的所有特征，y表示模型的结果。</p><blockquote class="ly lz ma"><p id="0792" class="ko kp lk kq b kr ks ka kt ku kv kd kw mb ky kz la mc lc ld le md lg lh li lj ij bi translated"><strong class="kq ja"><em class="iq">【4】编码自变量【X】</em></strong></p></blockquote><pre class="ln lo lp lq gt me mf mg mh aw mi bi"><span id="1a47" class="mj mk iq mf b gy ml mm l mn mo">X = pd.get_dummies(X)</span><span id="2385" class="mj mk iq mf b gy nm mm l mn mo">print("Number of observations and dimensions in 'X':", X.shape)<br/>print("Number of observations in 'y':", y.shape)</span><span id="c048" class="mj mk iq mf b gy nm mm l mn mo">...</span><span id="ee02" class="mj mk iq mf b gy nm mm l mn mo"><em class="lk">Number of observations and dimensions in 'X': (831, 14)<br/>Number of observations in 'y': (831,)</em></span></pre><p id="76f5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意:注意X.shape特性是如何从4个增加到14个的。这意味着模型中又增加了10个特性。要了解添加的功能，请参考以下代码:</p><pre class="ln lo lp lq gt me mf mg mh aw mi bi"><span id="6165" class="mj mk iq mf b gy ml mm l mn mo">features = X.columns.tolist()</span><span id="7d30" class="mj mk iq mf b gy nm mm l mn mo">print(features)</span><span id="8494" class="mj mk iq mf b gy nm mm l mn mo">...</span><span id="1e8a" class="mj mk iq mf b gy nm mm l mn mo"><em class="lk">['AGE', 'SHAPE_1', 'SHAPE_2', 'SHAPE_3', 'SHAPE_4', 'MARGIN_1', 'MARGIN_2', 'MARGIN_3', 'MARGIN_4', 'MARGIN_5', 'DENSITY_1', 'DENSITY_2', 'DENSITY_3', 'DENSITY_4']</em></span></pre><p id="7ac5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意:例如，特征形状如何被分解成四个新特征:形状_1、形状_2、形状_3和形状_4。</p><p id="6091" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">SHAPE_1表示为[1，0，0，0]</p><p id="4e3f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">SHAPE_2表示为[0，1，0，0]</p><p id="b2d9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">SHAPE_3表示为[0，0，1，0]</p><p id="4f44" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">SHAPE_4表示为[0，0，0，1]</p><ul class=""><li id="77e3" class="mp mq iq kq b kr ks ku kv kx mr lb ms lf mt lj mu mv mw mx bi translated"><strong class="kq ja">一个热编码</strong>:每个标签映射到一个二进制向量。</li></ul><p id="3567" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> W </span> hy这一步:机器学习算法要求输入输出变量用数字表示。由于此数据集包含分类特征，因此必须先将其编码为数字，然后才能用于拟合和评估模型。</p><blockquote class="ly lz ma"><p id="a730" class="ko kp lk kq b kr ks ka kt ku kv kd kw mb ky kz la mc lc ld le md lg lh li lj ij bi translated"><strong class="kq ja"> <em class="iq">【特征缩放】</em> </strong></p></blockquote><pre class="ln lo lp lq gt me mf mg mh aw mi bi"><span id="3b23" class="mj mk iq mf b gy ml mm l mn mo">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>X = sc.fit_transform(X)</span><span id="bd11" class="mj mk iq mf b gy nm mm l mn mo">print(X)</span><span id="68fe" class="mj mk iq mf b gy nm mm l mn mo">...</span><span id="a678" class="mj mk iq mf b gy nm mm l mn mo"><em class="lk">[[ 0.76580356 -0.54443719 -0.52583048 ... -0.2688086   0.31497039<br/>  -0.09859277]<br/> [ 0.15166622 -0.54443719 -0.52583048 ... -0.2688086   0.31497039<br/>  -0.09859277]<br/> [-1.89545824  1.83675916 -0.52583048 ... -0.2688086   0.31497039<br/>  -0.09859277]<br/> ...<br/> [ 0.56109111 -0.54443719 -0.52583048 ... -0.2688086   0.31497039<br/>  -0.09859277]<br/> [ 0.69756608 -0.54443719 -0.52583048 ... -0.2688086   0.31497039<br/>  -0.09859277]<br/> [ 0.42461615 -0.54443719 -0.52583048 ... -0.2688086   0.31497039<br/>  -0.09859277]]</em></span></pre><p id="cc34" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> W </span> hy这一步:一些机器学习算法使用欧几里德距离计算两点之间的距离。如果其中一个要素的值范围很大，则距离将由该要素决定。标准化和规范化是在独立变量范围内使用的技术，允许每个要素成比例地影响最终距离。</p><blockquote class="ly lz ma"><p id="85db" class="ko kp lk kq b kr ks ka kt ku kv kd kw mb ky kz la mc lc ld le md lg lh li lj ij bi translated"><strong class="kq ja"><em class="iq">【6】分割数据(训练&amp;测试)</em> </strong></p></blockquote><pre class="ln lo lp lq gt me mf mg mh aw mi bi"><span id="40b9" class="mj mk iq mf b gy ml mm l mn mo">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 32)</span><span id="7dda" class="mj mk iq mf b gy nm mm l mn mo">print("Number of observations and dimensions in training set:", X_train.shape)<br/>print("Number of observations and dimensions in test set:", X_test.shape)<br/>print("Number of observations in training set:", y_train.shape)<br/>print("Number of observations in test set:", y_test.shape)</span><span id="faad" class="mj mk iq mf b gy nm mm l mn mo">...</span><span id="dc14" class="mj mk iq mf b gy nm mm l mn mo"><em class="lk">Number of observations and dimensions in training set: (623, 14)<br/>Number of observations and dimensions in test set: (208, 14)<br/>Number of observations in training set: (623,)<br/>Number of observations in test set: (208,)</em></span></pre><ul class=""><li id="65c2" class="mp mq iq kq b kr ks ku kv kx mr lb ms lf mt lj mu mv mw mx bi translated"><strong class="kq ja">训练集</strong>用于训练或拟合模型。</li><li id="e742" class="mp mq iq kq b kr my ku mz kx na lb nb lf nc lj mu mv mw mx bi translated"><strong class="kq ja">测试集</strong>用于获得最终模型的无偏评估。</li></ul><p id="0daa" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> W </span>通过这一步:要评估模型的预测性能，重要的是要有一个无偏的评估。这可以通过在使用数据集之前对其进行拆分来实现。数据随机分为训练集和测试集，其中75%的数据留作训练数据，其余25%的数据留作测试数据。</p><blockquote class="ly lz ma"><p id="13f3" class="ko kp lk kq b kr ks ka kt ku kv kd kw mb ky kz la mc lc ld le md lg lh li lj ij bi translated"><strong class="kq ja"><em class="iq">【7】在训练数据上建立模型</em> </strong></p></blockquote><pre class="ln lo lp lq gt me mf mg mh aw mi bi"><span id="3101" class="mj mk iq mf b gy ml mm l mn mo">from sklearn.neighbors import KNeighborsClassifier</span><span id="84ff" class="mj mk iq mf b gy nm mm l mn mo">kNNModel = KNeighborsClassifier()<br/>kNNModel.fit(X_train, y_train)</span><span id="63c4" class="mj mk iq mf b gy nm mm l mn mo">...</span><span id="3c6f" class="mj mk iq mf b gy nm mm l mn mo"><em class="lk">KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights='uniform')</em></span></pre><p id="9594" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi nd translated">通过这一步:根据训练数据训练模型，使其能够准确预测结果。</p><blockquote class="ly lz ma"><p id="894a" class="ko kp lk kq b kr ks ka kt ku kv kd kw mb ky kz la mc lc ld le md lg lh li lj ij bi translated"><strong class="kq ja"><em class="iq">【8】对测试数据进行预测</em> </strong></p></blockquote><pre class="ln lo lp lq gt me mf mg mh aw mi bi"><span id="d8e3" class="mj mk iq mf b gy ml mm l mn mo">y_pred = kNNModel.predict(X_test)</span><span id="9fbd" class="mj mk iq mf b gy nm mm l mn mo">print(y_pred)</span><span id="ba3b" class="mj mk iq mf b gy nm mm l mn mo">...</span><span id="18cc" class="mj mk iq mf b gy nm mm l mn mo"><em class="lk">[1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0]</em></span></pre><p id="6f64" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> W </span>通过这一步:获得对测试数据的模型预测，以评估模型的准确性和效率。</p><blockquote class="ly lz ma"><p id="bb51" class="ko kp lk kq b kr ks ka kt ku kv kd kw mb ky kz la mc lc ld le md lg lh li lj ij bi translated"><strong class="kq ja"><em class="iq">【9】数值分析</em> </strong></p></blockquote><pre class="ln lo lp lq gt me mf mg mh aw mi bi"><span id="71f2" class="mj mk iq mf b gy ml mm l mn mo">from sklearn.metrics import confusion_matrix<br/>print(confusion_matrix(y_test, y_pred), ": is the confusion matrix")</span><span id="9658" class="mj mk iq mf b gy nm mm l mn mo">from sklearn.metrics import accuracy_score<br/>print(accuracy_score(y_test, y_pred), ": is the accuracy score")</span><span id="4520" class="mj mk iq mf b gy nm mm l mn mo">from sklearn.metrics import precision_score<br/>print(precision_score(y_test, y_pred), ": is the precision score")</span><span id="379f" class="mj mk iq mf b gy nm mm l mn mo">from sklearn.metrics import recall_score<br/>print(recall_score(y_test, y_pred), ": is the recall score")</span><span id="f2a4" class="mj mk iq mf b gy nm mm l mn mo">from sklearn.metrics import f1_score<br/>print(f1_score(y_test, y_pred), ": is the f1 score")</span><span id="1acc" class="mj mk iq mf b gy nm mm l mn mo">...</span><span id="41d1" class="mj mk iq mf b gy nm mm l mn mo"><em class="lk">[[83 32]<br/>[22 71]] : is the confusion matrix <br/><br/>0.7403846153846154 : is the accuracy score<br/>0.6893203883495146 : is the precision score<br/>0.7634408602150538 : is the recall score<br/>0.7244897959183674 : is the f1 score</em></span></pre><p id="6a84" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意:使用混淆矩阵，可以提取真阳性、假阳性、假阴性和真阴性值，这将有助于计算准确度分数、精确度分数、回忆分数和f1分数:</p><ul class=""><li id="e2e9" class="mp mq iq kq b kr ks ku kv kx mr lb ms lf mt lj mu mv mw mx bi translated"><strong class="kq ja">真阳性</strong> = 83</li><li id="3402" class="mp mq iq kq b kr my ku mz kx na lb nb lf nc lj mu mv mw mx bi translated"><strong class="kq ja">假阳性</strong> = 32</li><li id="44da" class="mp mq iq kq b kr my ku mz kx na lb nb lf nc lj mu mv mw mx bi translated"><strong class="kq ja">假阴性</strong> = 22</li><li id="38b8" class="mp mq iq kq b kr my ku mz kx na lb nb lf nc lj mu mv mw mx bi translated"><strong class="kq ja">真负</strong> = 71</li></ul><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi nq"><img src="../Images/26e4f1261eb17819c55ee2fbef5092cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1rB5CecD6UPllcQhtdIx6Q.png"/></div></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">Equations for Accuracy, Precision, Recall, and F1.</figcaption></figure><p id="1acf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> W </span>通过这一步:评估一个分类模型的性能。</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><div class="ln lo lp lq gt oc"><a href="https://github.com/kopaljain95/import-data.science-classification/blob/main/KNearestNeighbors%5B2%5D/KNearestNeighbors.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd ja gy z fp oh fr fs oi fu fw iz bi translated">kopaljain 95/import-data . science-分类</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">在GitHub上创建一个帐户，为kopaljain 95/import-data . science-classification的开发做出贡献。</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">github.com</p></div></div><div class="ol l"><div class="om l on oo op ol oq lw oc"/></div></div></a></div><p id="9d41" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">接下来——</em><a class="ae ll" href="https://kopaljain95.medium.com/how-to-improve-k-nearest-neighbors-1e9170fb1a89" rel="noopener"><em class="lk">如何提高K近邻？第3节:在Python中调优模型</em> </a> <em class="lk"> … </em></p></div></div>    
</body>
</html>