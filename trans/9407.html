<html>
<head>
<title>Machine Learning Concepts ✅</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习概念✅</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/machine-learning-concepts-207ec1e352f9?source=collection_archive---------27-----------------------#2021-02-09">https://medium.datadriveninvestor.com/machine-learning-concepts-207ec1e352f9?source=collection_archive---------27-----------------------#2021-02-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7cc3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">特征、正则化、缺失值等！</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/63c57a7ab3f9b58d0ba89aae770b5be6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wzlipL-tmDVFo1nBt8czwA.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@matthewhenry?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Matthew Henry</a> on <a class="ae kv" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="861c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是机器学习系列的第二篇博文，在这里，我们将讨论机器学习最常见的概念，如特征类型、缺失值、正则化等</p><h2 id="844c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">特征</h2><p id="9ca8" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">当设计一个学习特征的算法时，我们的目标是分离变异的<strong class="ky ir">个因素</strong>📊解释观察到的数据。</p><p id="a404" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">特征是我们的数据集中有助于构建ML算法的组件。基于这些值有不同类型的特征，如<strong class="ky ir">数字、序数</strong>等。</p><blockquote class="mq mr ms"><p id="d187" class="kw kx mt ky b kz la jr lb lc ld ju le mu lg lh li mv lk ll lm mw lo lp lq lr ij bi translated"><strong class="ky ir">名义值— </strong>具有名义值的变量自然没有任何顺序。例如，一个人的名字可以被认为是一种名义上的数据类型，因为我们不能将一个名字与另一个名字进行比较。</p><p id="babe" class="kw kx mt ky b kz la jr lb lc ld ju le mu lg lh li mv lk ll lm mw lo lp lq lr ij bi translated"><strong class="ky ir">序数— </strong>具有自然顺序的变量本质上是序数。例如，<strong class="ky ir">教育程度</strong>(“高中”、“理科”、“理科”、“博士”)。</p></blockquote><p id="3ca7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，在对数据集应用算法之前，我们需要将数据集转换为算法可以使用的格式。例如，我们可以处理分类值，通过将它转换成一个<strong class="ky ir">独热编码</strong>，类似于将类别映射到数值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/c534d000c63aff315fe53da525aabd78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7kSXLMp5mCqRMc7D"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd lu">Figure 1:</strong> AILabPage Machine Learning Series — Machine Learning Process</figcaption></figure><h2 id="696a" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">特征工程</strong></h2><p id="ea92" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">机器学习中的任何问题都需要大量的特征工程，这意味着人们不能简单地在数据集上做<code class="fe my mz na nb b">model.fit(x, y)</code>并获得SOTA结果。</p><p id="61df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">特征工程需要创造力和对领域的理解。</strong></p><blockquote class="mq mr ms"><p id="f3a1" class="kw kx mt ky b kz la jr lb lc ld ju le mu lg lh li mv lk ll lm mw lo lp lq lr ij bi translated">例如，在X地区，大小为“a”的房屋的价格高于Y地区相同大小的房屋，即使该地区不是原始数据集中的一个要素。</p></blockquote><h2 id="e4b0" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">一个热编码</strong></h2><p id="3504" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">很少有像决策树这样的算法，它将具有值为“红”、“蓝”等的颜色等分类特征作为输入，而不进行一次性编码，但大多数算法要求特征值为<strong class="ky ir">数字</strong>。要转换这些功能，我们可以使用一个热编码。</p><pre class="kg kh ki kj gt nc nb nd ne aw nf bi"><span id="dfdb" class="ls lt iq nb b gy ng nh l ni nj">   red = [1, 0, 0]    <br/>  blue = [0, 1, 0]<br/>orange = [0, 0, 1]</span></pre><blockquote class="mq mr ms"><p id="3d03" class="kw kx mt ky b kz la jr lb lc ld ju le mu lg lh li mv lk ll lm mw lo lp lq lr ij bi translated">一种热编码增加了特征向量的维数，并且还变换了像颜色这样的特征——红色为1，蓝色为2等，这将使颜色特征生成算法的值“有序”,以将某种颜色比其他颜色分配更大的重要性。一定是avoided❌.</p></blockquote><h2 id="c89f" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">处理缺失值</strong></h2><p id="5e01" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">原始数据面临着不同的挑战，一个常见的挑战是要素值缺失。要克服缺失值问题，可以采取以下措施:</p><ul class=""><li id="8183" class="nk nl iq ky b kz la lc ld lf nm lj nn ln no lr np nq nr ns bi translated">如果数据集足够大，则丢弃样本。</li><li id="9040" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated">进行数据插补，以填补缺失值的缺口。</li><li id="bac5" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated">很少有算法对缺失值具有鲁棒性。</li></ul><h2 id="6591" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">数据插补</strong></h2><ul class=""><li id="06ad" class="nk nl iq ky b kz ml lc mm lf ny lj nz ln oa lr np nq nr ns bi translated">一种估算方法是找出特征的平均值并替换缺失值。(如果存在异常值，请小心)。</li><li id="3826" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated">替换为特征范围之外的值，即如果特征x为[0，1]，则用-1或2替换缺少的值。它单独为这个样本提供了一个独特的特征值。</li><li id="0862" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated">替换为范围中间的值，即如果特征x为[-1，1]，则用0替换缺少的值。这使得算法较少受到0的影响。</li></ul><h2 id="c910" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">缩放</strong></h2><h2 id="d35c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">为什么要缩放？</strong></h2><p id="afee" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在构建/应用ML算法之前，缩放特征是一项重要的任务。例如，如果某个算法没有使用要素缩放，那么它会认为300米的值大于5 km，这是不正确的，在这种情况下，该算法会通过赋予300米比3 km更大的重要性来给出错误的预测。因此，我们使用特征缩放来归一化它的值。</p><h2 id="b7d3" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">缩放类型</strong></h2><ul class=""><li id="237b" class="nk nl iq ky b kz ml lc mm lf ny lj nz ln oa lr np nq nr ns bi translated">最小-最大缩放或归一化</li><li id="033e" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated">均值归一化</li><li id="c9f7" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated">标准化或Z分数标准化</li></ul><p id="6fe1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="mt">最小-最大缩放</em> </strong>有助于将特征值重新缩放到[0，1]或[-1，1]的范围内。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/2799e550c419e3767f769e54f834a314.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*cv3htT1Ow1Xzofu4ISQkVQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Min-Max Scaling</figcaption></figure><p id="2b44" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="mt">表示归一化</em> </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/31fd9aeddb8749feb5fb42d7e5416ef9.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*4JCQJOa4A-O9DQ1ANf_Fqw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Mean Normalization</figcaption></figure><p id="1cd8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="mt">特征的标准化</em> </strong>使数据中每个特征的值具有零均值和单位方差。这是一种广泛使用的标准化技术，因为像SVM、神经网络和逻辑回归这样的主要算法都遵循这种标准化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/e2ee8ad1d6a1182c474c7390b9ce15e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:312/format:webp/1*kkj9On0qmCRC1Y4XBZ572w.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Standaridization</figcaption></figure><h2 id="f442" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">偏差和方差的权衡</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/dc80ab89b36c5f4c4b30885dac53da6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Mcp4WbyKucNuJ1Rg.jpg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Model Complexity vs Error</figcaption></figure><p id="e29b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi of translated"><span class="l og oh oi bm oj ok ol om on di"> B </span>例如，在抽样调查中，偏差是样本统计系统地高估或低估总体参数的趋势。在机器学习中，当模型在训练集上表现不佳时，即模型不能识别训练集中的模式，使其过于简单时，该模型被称为遭受偏差。<strong class="ky ir">随着模型复杂度的增加，偏倚减小。</strong></p><p id="3874" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi of translated">当统计模型或机器学习算法无法捕捉数据的潜在趋势时，就会出现欠拟合。直观地说，当模型或算法与数据拟合得不够好时，就会出现拟合不足。具体来说，<strong class="ky ir">如果模型或算法显示低方差但高偏差，则出现欠拟合</strong>😥<strong class="ky ir">。</strong></p><p id="3599" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi of translated"><span class="l og oh oi bm oj ok ol om on di"> V </span> <strong class="ky ir">方差</strong>在机器学习的上下文中，是由于模型对训练集中的小波动的敏感性而发生的一种错误。高方差会导致算法对训练集中的噪声进行建模。这通常被称为过度拟合。</p><p id="7691" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上图中，随着模型复杂性的增加，方差也在增加，导致模型过度拟合。<strong class="ky ir">为了避免这种情况，我们跟踪验证损失，如果模型过拟合，验证损失会很高。在深度学习中，我们执行<em class="mt">提前停止</em> </strong>🙂<strong class="ky ir">避免过度拟合。</strong></p><p id="ef09" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi of translated"><span class="l og oh oi bm oj ok ol om on di"> O </span> <strong class="ky ir">过拟合</strong>是指过于拟合训练数据的模型。当一个模型学习了训练数据中的所有细节和噪声，以至于对新数据的模型性能产生负面影响时，称为<strong class="ky ir">过拟合模型</strong>😥<strong class="ky ir">。</strong></p><h2 id="5654" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">权重多久更新一次</h2><p id="8ea5" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在训练模型时，算法迭代地更新权重或参数，以减少估计y和目标y之间的误差，权重更新的频率取决于训练集的批量大小。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/dfddaf8d016140637439cfb09b7b5843.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/0*715Y8AYc8vV0PuoM.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Batch vs Stochastic vs Mini-Batch</figcaption></figure><p id="eb1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">批量梯度下降</strong>是对权重矩阵进行梯度更新(权重更新)的过程。<strong class="ky ir">如果我们有1000个数据点，那么在对模型的权重进行任何更新之前，模型在1000个数据点上被训练。</strong></p><p id="9719" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">随机梯度下降</strong>是对权重矩阵进行梯度更新(权重更新)的过程。<strong class="ky ir">如果我们有1000个数据点，那么在1个数据点上训练模型，并更新模型的权重。</strong></p><p id="06f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">小批量梯度下降</strong>是对权重矩阵进行梯度更新(权重更新)的过程。<strong class="ky ir">如果我们有1000个数据点，那么我们给batch_size赋值，如果batch_size是10，那么在10个数据点上训练模型，并且对模型的权重进行更新。这种情况反复发生，取10个数据点，然后更新。</strong></p><h2 id="1b6c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">正规化</strong></h2><p id="2ac1" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">假设我们有一个包含两个要素和一个目标变量的简单数据集，我们可以对两个变量使用具有两个系数的简单模型，也可以使用具有更多系数的复杂模型来了解潜在因素，并且会过度拟合简单数据集。复杂模型不会对新数据进行归纳，因为它是一个过拟合模型。</p><p id="d5e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="mt">为了克服过拟合，选择一个简单的模型，我们可以使用正则化。</em> </strong></p><h2 id="d278" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak"> L1正规化</strong></h2><p id="96da" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在计算误差(E)时，我们添加模型系数的绝对值。在简单模型情况下，我们有2个系数w1，w2，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/7f6e110c4c618439432fac8679a068f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*pPTKqbhuVnzfuETiH9wyIg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Total Error with two coefficients</figcaption></figure><p id="8dc0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在复杂模型情况下，假设有5个系数w_1，w_2，w_3，w_4，w_5，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/e0110c923c20f3d93fb4d966d85d6fa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*dIcabBtcZ1CXz6NlS2fp0Q.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Total Error with five Coefficients</figcaption></figure><p id="405f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，对于简单模型，我们得到较小的误差，并且将同样用于一般化。</p><p id="da5e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> L2正规化</strong></p><p id="ee12" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在计算误差(E)时，我们对模型的系数取平方值。在简单模型情况下，我们有2个系数w1，w2，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/7fd7f1d2379c869bb01e4120257327f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*35_b9r-m0SeCuElR_oqFZg.png"/></div></figure><p id="a1f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在复杂模型情况下，假设有5个系数w_1，w_2，w_3，w_4，w_5，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/822b012ed66aeb98bd0d3808b629d58c.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*hzO68GhP4HUH6o7Y5orcIQ.png"/></div></figure><p id="b6e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，对于简单模型，我们得到较小的误差，并且将同样用于一般化。<strong class="ky ir">参数数量越多，模型越复杂。</strong></p><p id="d5a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">如何选择正则化参数(</strong> ƛ <strong class="ky ir">)？</strong></p><p id="04ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基于数据的复杂性，模型往往是复杂的。所以ƛ值就像一个开关，要么增加复杂性，要么不增加复杂性。如果我们保持小的ƛ值，并将其乘以模型的复杂性部分，即“w”参数，那么与具有“w”参数的简单模型相比，我们得到更小的误差。而如果ƛ很大，那么我们就把复杂的部分罚得很重，从而使得复杂的模型有很大的误差。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/d24e2fd8f3a486dd61cb989c6b8f3ef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*_lJypnR_M-GSiyTtXXs7fQ.png"/></div></figure><p id="4e6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型的复杂性由方程中参数(w)的数量来定义。</p><p id="8833" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<a class="ae kv" href="https://www.youtube.com/channel/UCFKxdpoc4KdMjUaAsMi7gmg" rel="noopener ugc nofollow" target="_blank"> YouTube </a>、<a class="ae kv" href="https://www.linkedin.com/in/mayur-jain-ds" rel="noopener ugc nofollow" target="_blank"> LinkedIn、</a>和<a class="ae kv" href="https://twitter.com/mayur__22" rel="noopener ugc nofollow" target="_blank"> Twitter </a> ✋上与我联系</p></div></div>    
</body>
</html>