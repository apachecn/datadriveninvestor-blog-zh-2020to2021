<html>
<head>
<title>Basic XAI with LIME for CNN Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN模型的基本XAI加石灰</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/xai-with-lime-for-cnn-models-5560a486578?source=collection_archive---------1-----------------------#2021-02-02">https://medium.datadriveninvestor.com/xai-with-lime-for-cnn-models-5560a486578?source=collection_archive---------1-----------------------#2021-02-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="efc3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇博客中，我们将使用LIME来解释为什么使用keras训练的基本MNIST手写数字分类模型会做出特定的预测。</p><h2 id="7f1f" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">什么是石灰？</h2><p id="82a7" class="pw-post-body-paragraph jn jo iq jp b jq le js jt ju lf jw jx jy lg ka kb kc lh ke kf kg li ki kj kk ij bi translated">LIME，或局部可解释的模型不可知解释，是一种算法，它可以通过用可解释的模型局部地近似它，以忠实的方式解释任何分类器或回归器的预测。它通过调整特征值来修改单个数据样本，并观察对输出产生的影响。它扮演“解释者”的角色，解释来自每个数据样本的预测。LIME的输出是一组解释，表示每个特征对单个样本预测的贡献，这是局部可解释性的一种形式。下图演示了石灰在回归模型中的应用。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/5e932ec926e86e2901db176af714300c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*CDaQV4oYPysWIV5VJNNo9w.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">LIME explanation as to why the predicted value is 4.50 for this regression problem</figcaption></figure><h2 id="c4c1" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">构建数字分类器</h2><p id="865e" class="pw-post-body-paragraph jn jo iq jp b jq le js jt ju lf jw jx jy lg ka kb kc lh ke kf kg li ki kj kk ij bi translated">在cmd上使用以下命令安装tensorflow。首先，确保你已经安装了<em class="lv"> python </em>和<em class="lv"> pip </em>并设置为环境变量。</p><pre class="lk ll lm ln gt lw lx ly lz aw ma bi"><span id="043a" class="kl km iq lx b gy mb mc l md me">pip install tensorflow</span></pre><p id="bf84" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Tensorflow是深度学习中使用最广泛的框架之一。Keras现在已经包含在tensorflow发行版中，因此您无需单独安装它。Keras前端有助于降低低级培训的复杂性，是快速建立模型的好地方。</p><pre class="lk ll lm ln gt lw lx ly lz aw ma bi"><span id="d501" class="kl km iq lx b gy mb mc l md me">import tensorflow as tf<br/>from tensorflow import keras<br/>from tensorflow.keras import layers<br/>from tensorflow.keras.datasets import mnist</span></pre><p id="c3a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Keras将<em class="lv"> mnist </em>数据集作为其发行版的一部分，可以使用<em class="lv"> mnist </em>模块的<em class="lv"> load_data() </em>方法加载该数据集。该方法返回表示为监督学习安排的训练和测试数据的两个元组，因此我们在代码片段中使用了分别表示图像和目标标签的<em class="lv"> x </em>和<em class="lv"> y </em>。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mf"><img src="../Images/7108a4e30ebba6efe53babfaa838e87b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xd9V4kNiaNi8KOWuZpUZfQ.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">MNIST handwritten digits dataset of Keras</figcaption></figure><p id="b063" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，该方法返回的图像是一维numpy向量，每个向量的大小为784。图像从u <em class="lv"> int8 </em>到<em class="lv"> float32 </em>进行排版，并转换为大小为28x28的二维矩阵。由于图像是灰度级的，它们的像素值范围从0到255，因此，我们通过除以255.0将其标准化。这一步很重要，因为大的数字会增加训练的复杂性，因此建议将它们标准化到0到1之间。</p><pre class="lk ll lm ln gt lw lx ly lz aw ma bi"><span id="3868" class="kl km iq lx b gy mb mc l md me">(x_train, y_train), (x_test, y_test) = mnist.load_data()<br/>x_train = x_train.reshape((-1,28,28,1)).astype('float32') / 255.0<br/>x_test = x_test.reshape((-1,28,28,1)).astype('float32') / 255.0</span></pre><p id="b9fe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于我们将使用的lime模块仅适用于3-D图像，即具有3个通道的图像，因此我们在此复制灰度平面。下面的代码片段通过复制可用平面将灰度图像转换为RGB。</p><pre class="lk ll lm ln gt lw lx ly lz aw ma bi"><span id="c07f" class="kl km iq lx b gy mb mc l md me">import numpy as np</span><span id="386d" class="kl km iq lx b gy mk mc l md me">def to_rgb(x):<br/>    x_rgb = np.zeros((x.shape[0], 28, 28, 3))<br/>    for i in range(3):<br/>        x_rgb[..., i] = x[..., 0]<br/>    return x_rgb</span><span id="81f2" class="kl km iq lx b gy mk mc l md me">x_train = to_rgb(x_train)<br/>x_test = to_rgb(x_test)</span></pre><p id="9de1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里使用的keras的顺序API帮助我们快速创建模型，但唯一的缺点是它不是很灵活，即我们可以有一个输入和一个输出，不像keras的功能API，我们可以有多个输入和多个输出。对于我们的例子，顺序API是合适的。</p><p id="7360" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们创建模型！！！我们正在创建的模型是一个普通的CNN模型，它获取一个3-D图像并将其传递给一个<em class="lv"> Conv2D </em>层，该层有16个大小为3x3的过滤器，每个过滤器的激活函数为ReLU。这一层学习卷积滤波器的权重和偏差，直观地充当模型的“眼睛”,并返回特征图，然后将特征图传递给<em class="lv"> MaxPooling2D </em>,默认情况下，它具有大小为2x2的最大滤波器，它仅减少特征图的维度，并在一定程度上保留感兴趣的区域。</p><p id="3bc0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们展平特征地图，并添加一个完全连接的密集层，这将为我们提供一个大小为10的矢量，因为对于<em class="lv"> mnist </em>数据集，我们有10个从0到9的目标标签。</p><pre class="lk ll lm ln gt lw lx ly lz aw ma bi"><span id="fb61" class="kl km iq lx b gy mb mc l md me">model = keras.Sequential(<br/>    [<br/>     keras.Input(shape=(28,28,3)),<br/>     layers.Conv2D(16, 3, activation='relu'),<br/>     layers.MaxPooling2D(),<br/>     layers.Flatten(),<br/>     layers.Dense(10)<br/>    ]<br/>)</span></pre><p id="ff5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用<em class="lv">SparseCategoricalCrossentropy(from _ logits = True)</em>因为我们得到了代表10个类别的大小为10的向量，并且我们希望对其应用softmax以得到一个独热编码向量。在这里，Adam optimizer用于根据实际和预测的一次性向量中的误差来训练模型。该向量应该仅在图像所属的索引=标签处具有1。</p><pre class="lk ll lm ln gt lw lx ly lz aw ma bi"><span id="34a4" class="kl km iq lx b gy mb mc l md me">model.compile(<br/>  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),<br/>  optimizer=keras.optimizers.Adam(),<br/>  metrics=['accuracy']<br/>)</span></pre><p id="2686" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<em class="lv"> model.fit() </em>对2个<em class="lv">时期</em>的基本CNN模型进行训练，其中<em class="lv"> batch_size </em>为32，并且在加载<em class="lv"> mnist </em>数据时馈入之前分离的验证集。<em class="lv"> Epochs </em>是为了训练模型而需要查看整个训练数据的次数，而<em class="lv"> batch_size </em>是为了计算一次向前和向后训练的损失而必须考虑的记录数。</p><pre class="lk ll lm ln gt lw lx ly lz aw ma bi"><span id="ade1" class="kl km iq lx b gy mb mc l md me">model.fit(<br/>        x_train, <br/>        y_train, <br/>        epochs=2, <br/>        batch_size=32, <br/>        validation_data = (x_test, y_test))</span><span id="7c6d" class="kl km iq lx b gy mk mc l md me"><br/>Epoch 1/2<br/>1875/1875 [==============================] - 22s 12ms/step - loss: 0.4055 - accuracy: 0.8816 - val_loss: 0.0895 - val_accuracy: 0.9731<br/>Epoch 2/2<br/>1875/1875 [==============================] - 21s 11ms/step - loss: 0.0912 - accuracy: 0.9726 - val_loss: 0.0768 - val_accuracy: 0.9748</span></pre><h2 id="5edd" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">用石灰解释人工智能</h2><p id="f8ce" class="pw-post-body-paragraph jn jo iq jp b jq le js jt ju lf jw jx jy lg ka kb kc lh ke kf kg li ki kj kk ij bi translated">我们的模型现在被训练成97%的训练准确率和97%的验证准确率，这对于这个演示来说已经足够好了。现在，我们使用<em class="lv"> pip </em>安装python的<em class="lv"> lime </em>模块。</p><pre class="lk ll lm ln gt lw lx ly lz aw ma bi"><span id="7dc0" class="kl km iq lx b gy mb mc l md me">pip install lime</span></pre><p id="160d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意:你也可以在jupyter笔记本或google colab笔记本上使用！(感叹号)如图所示。</p><pre class="lk ll lm ln gt lw lx ly lz aw ma bi"><span id="2e6a" class="kl km iq lx b gy mb mc l md me">!pip install lime<br/><br/>import lime<br/>from lime import lime_image<br/>from skimage.segmentation import mark_boundaries<br/>import matplotlib.pyplot as plt<br/>import random</span></pre><p id="f15b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的模型已经做好了，是时候用石灰做XAI了。使用<em class="lv"> lime </em>包的<em class="lv"> lime_image </em>模块，我们创建了一个<em class="lv"> LimeImageExplainer </em>类的解释器对象。这个对象有一个方法<em class="lv"> explain_instance() </em>，它接受三维图像数据和一个预测函数，这里是<em class="lv"> model.predict </em>，并根据函数的预测返回一个解释。</p><p id="e77a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">解释对象有一个<em class="lv"> get_image_and_mask() </em>方法<em class="lv"> </em>，该方法获取对应于之前解析的3d图像数据的预测标签，并返回<em class="lv"> (image，mask) </em>元组，其中<em class="lv"> image </em>是3d numpy数组，<em class="lv"> mask </em>是2d numpy数组，可与<em class="lv">skimage . segmentation . mark _ boundaries</em>一起使用。带有相应遮罩的返回图像表示图像中负责预测的特征。</p><pre class="lk ll lm ln gt lw lx ly lz aw ma bi"><span id="cbd9" class="kl km iq lx b gy mb mc l md me">explainer = lime_image.LimeImageExplainer(random_state=42)<br/>explanation = explainer.explain_instance(<br/>         x_train[10], <br/>         model.predict<br/>)<br/>plt.imshow(x_train[10])<br/>image, mask = explanation.get_image_and_mask(<br/>         model.predict(<br/>              x_train[10].reshape((1,28,28,3))<br/>         ).argmax(axis=1)[0],<br/>         positive_only=True, <br/>         hide_rest=False)<br/>plt.imshow(mark_boundaries(image, mask))</span></pre><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="ab gu cl ml"><img src="../Images/3a7c26de13b65e7a91051fc5a1281aec.png" data-original-src="https://miro.medium.com/v2/format:webp/1*GyFzIXiwdfhTbk8kG0U_oA.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Image with mask explaining the prediction</figcaption></figure><p id="4acf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的博客到此结束，我希望它足够全面。有关python的lime模块的更多信息，请参考<a class="ae mm" href="https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_image" rel="noopener ugc nofollow" target="_blank">文档</a>。你可以在这里找到本教程<a class="ae mm" href="https://github.com/SAH-UJA/Basic-XAI-with-LIME" rel="noopener ugc nofollow" target="_blank">的代码。</a></p><p id="9d20" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你觉得这篇文章有用，请继续欣赏，不要忘记喜欢这篇文章，并关注我未来文章的更新。</p></div></div>    
</body>
</html>