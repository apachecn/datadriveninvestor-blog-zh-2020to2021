<html>
<head>
<title>Machine Learning Zuihitsu — IV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习Zuihitsu-IV</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/machine-learning-zuihitsu-iv-cbbe4ffdf483?source=collection_archive---------16-----------------------#2021-02-18">https://medium.datadriveninvestor.com/machine-learning-zuihitsu-iv-cbbe4ffdf483?source=collection_archive---------16-----------------------#2021-02-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1d4b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kl">数据混合:一个简单而强大的反过拟合工具</em> </strong></p><p id="5e94" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">巴黎@Datategy数据科学家和机器学习工程师埃伦·云吕博士</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/95bd8c28dcd8f89f5ccec9d24fc24b14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z7VmKGt9q94tTQNeHDacjQ.png"/></div></div></figure><p id="196c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我不知道为什么，但对我来说，没有什么比钻研一个直截了当的、陈旧的表格数据挑战更好的了。在公司的大部分时间里，我们的工作负载只是转向复杂的图像分割、视频分析和一些非常复杂的时间序列预测。但是，我只是怀念2D表格数据的简单性。也许，只是对懒惰的向往，或者是30秒的训练次数，或者是对我大三学机器的纯粹怀念。但是我敢肯定，有很多人和我一样对口味有着明显的偏好:)。</p><p id="7cd3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">图像识别中隐藏的对抗性攻击</strong></p><p id="317c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你不可能得到生活中的一切。人生不过是对取舍的妥善管理。人工神经网络(ann)以牺牲其增强的性能为代价，带来了一些代价，其中最显著的是过拟合。</p><p id="ace7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有一套工具和策略来对付人工神经网络的过度适应，从简单的辍学到数据扩充或仔细审查的培训政策。不管你用测试数据集做多少验证，相信我；你的ANN总是过拟合，即使你不会注意到你的用例，会让你满意。</p><p id="4972" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种无处不在的人工神经网络过度拟合的最显著的证据是隐藏的敌对噪音现象。在基于深度学习的计算机视觉系统中，这是一个经过充分研究的概念。即使你在像素上添加了非常小的随机噪声；即使你看不到这种变化，它也会极大地扰乱人工神经网络的性能。这几乎完全是由于无处不在的过度拟合效应。在人工神经网络的混沌路径上，输入中的极小扰动可以产生无界梯度。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ky"><img src="../Images/18b22ad1a95a89125094ebab31e8f9c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5L9igncsXFzs0j5dlRn9RQ.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Well, you are really 99.3% sure that it’s a gibbon mate ? Courtesy of legendary ML researcher Ian Goodfellow et al [1]</figcaption></figure><p id="d18b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有许多方法来对抗这些类型的影响，已经构成了大量的文献。基于度量学习的方法，例如对比损失，还包括复杂的鉴别器网络等。优雅的数据扩充技术，实现伪贝叶斯蒙特卡罗退出等。</p><p id="5a2c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一种非常简单的对抗隐藏的敌对噪声效应的数据增强策略是简单地混合两幅(或多幅)图像；用模糊类生成全新类型的数据点。最简单的混合形式是创建两个不同类别的两个图像的加权和(例如，0.6x(猫的像素)+ 0.4x(狗的像素)= &gt;类别= 60%猫，% 40%狗)</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ld"><img src="../Images/59e9bddc5732018fd93aeaad1907c523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*buZsfiA5JokqZKpstrCqxQ.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Half cat, Half dog. This type of fuzzy representations force neural networks to learn feature relationships more smoothly, providing a basic countermeasure against hidden adversarial noise phenomenon. Courtesy of [2][3].</figcaption></figure><p id="5985" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们只是简单地将它应用于表格数据集，会发生什么？</p><p id="0f37" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我阅读这些论文时，我只是想知道它会如何影响神经网络在表格数据集上的性能。当我们需要一个具有混合分类和连续特征的二元分类的代表性数据集时，我们在哪里引用？是的，你猜对了！让我们用<em class="kl">泰坦尼克号</em>试试这个简单的技巧。</p><p id="54b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">预处理</strong></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi le"><img src="../Images/196def801e00f700c5d85536177abf9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cyLf7zQZdqtVqliO9P-B_g.png"/></div></div></figure><p id="3896" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们保持一切简单。这只是一个简单的自我教育实验。我只保留2个分类特征(<strong class="jp ir">性别</strong>(男或女)，<strong class="jp ir">p类别</strong> (0，1，2))和2个连续特征(<strong class="jp ir">费用</strong>和<strong class="jp ir">年龄</strong>)。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lf"><img src="../Images/f58aeb77c6ac49cd294ed67d88321402.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aPiPlgldv3USxNGE5khiCA.png"/></div></div></figure><p id="79e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">用于数据处理和缩放的类</strong></p><p id="21a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我写了一个类，负责原始数据集和合成数据集的所有必要操作，然后将它们输入神经网络。这里有一个重要的备注，机器学习新手最常犯的一个错误是在拟合缩放器时包含测试样本(应归咎于sklearn的easy fit_transform函数)；所以我们要确保我们不会这么做。</p><p id="d672" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们稍微解构一下代码。我们有两个独立的函数:一个直接返回训练数据集，另一个返回随机混合的数据集。正如您所看到的，我只是简单地打乱了训练数据集的两个版本，并对它们进行了随机加权求和(您可以将此视为混合两个不同样本的矢量方式。我们希望尽可能地利用numpy的极端并行性。给你们python爱好者一个小小的建议；不断地问自己:“我能用numpy以矢量的方式做到这一点吗？”).此外，请注意，在我们的实验中，为了公平起见，两种情况(混合或非混合)的数据集大小相等。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lg"><img src="../Images/2f77de5a9503dc678f12b2ae7992b6b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ADnIZXWKt-n9yidrzo3EQQ.png"/></div></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lh"><img src="../Images/554ae431d139dba3e1e9d28f27960f51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*psbJCwaCazv7QNuuZhSZDg.png"/></div></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi li"><img src="../Images/76032c2f8f39f5ea66f628af9bb30033.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PS2hl6SBmaMpUe38ZNcmvg.png"/></div></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lj"><img src="../Images/bcd7e478d40ba70616d668dc35a2ea37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v-QS_IlSbFsixnFa_hRzjQ.png"/></div></div></figure><p id="6339" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">走向极端:用非常少的训练样本测试过拟合鲁棒性</strong></p><p id="958d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">到目前为止，scikit-learn最不受重视的机器学习模型是多层感知器(人工神经网络)。大多数人甚至不知道它的存在。当需要高级神经网络框架时，我们倾向于首先调用Keras，但是如果您处理简单的表格数据，并且不需要深入研究您的模型的细节；MLPRegressor和MLPClassifier是您的单线解决方案。它的默认参数和提前停止非常健壮。你只需要在一个简单的列表中用神经元的数量定义你的层。</p><p id="8ff8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，对于常规情况(二进制分类)，我们需要使用MLPClassifier (sklearn模块会自动设置自己使用sigmoid激活和二进制交叉熵)。混合案例需要MLPRegressor，因为现在我们有模糊的结果，如0.45幸存。(我们将简单地对测试输入的结果进行舍入，以预测它们的类别)</p><p id="d1ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了测试简单线性混合的潜力，我想用少量的训练数据点进行实验(90%测试，10%训练)。以下是十重交叉验证的片段:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lk"><img src="../Images/0264de6e0cce268260e539fd052e1991.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3YgPod75r4d-ABr6NZ7sZA.png"/></div></div></figure><p id="5c10" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些是10个实验中每个实验的测试精度(橙色:混合，蓝色:常规)。显然，即使是非常简单的2样本线性混合也可以在某些情况下利用非常有限的训练数据稍微提高准确度。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ll"><img src="../Images/384a6dece1fb8be18baa934cbc28dbdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B1orhcQqo3CsfaiKHL_3Rw.png"/></div></div></figure><p id="aa74" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们能够利用这种混合策略的组合特性，性能可以进一步提高。当我们混合两个不同的样本以产生新的合成样本时，我们的搜索空间是(N，2)的二项式，这是一种属性增强的度量学习算法。我们在我们的类中插入了两个新函数，以产生比给定训练数据集有更多样本的合成数据集。为了公平起见(将相同数量的训练样本传递给MLP优化算法)，我们简单地复制正常数据集的行。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lm"><img src="../Images/2bf8f3da4d193d336376d19bf53c191f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2gnvqarMtZCeOy1fM9bEow.png"/></div></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ln"><img src="../Images/d0d18d84da6a8c6d448fe4841d33bd87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ldukm1vk46TQHIfL58bOfA.png"/></div></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lo"><img src="../Images/d7eaee8c49474f2c61f82d99bc60de53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0iBZq92d94HmYYBnwIHPzg.png"/></div></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/50dd5e464b591c591b818e53e45de272.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*Nr_r_m7SLeS57qw_jmHUXQ.png"/></div></figure><p id="cc6b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如您所见，随着我们增加数据混合搜索空间的边界，性能会继续进一步提高。</p><p id="2a86" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结论</strong></p><p id="c787" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我只是想在表格数据上测试简单的图像混合策略。显然，这种方法在表格数据上有潜力。对抗过拟合的优点有两个方面:(1)通过引入模糊性，我们加强了神经网络在更平滑的协变空间而不是刚性空间中学习。(ii)我们可以假设我们还没有看到的测试样本将落在训练数据点之间的特征范围上；这种方法增加了可能性。</p><p id="9abc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，请注意，合成训练数据集是一个庞大的学科；这种混合可能是最简单的。也进入度量学习，对比损失，变分自动编码器等。</p><p id="6975" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">干杯，</p><p id="bb5c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[1] Goodfellow，I. J .，Shlens，j .，&amp; Szegedy，C. (2014年)。解释和利用对立的例子。<em class="kl"> arXiv预印本arXiv:1412.6572 </em>。</p><p id="3b94" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[2] Tokozume，y .，Ushiku，y .，&amp; Harada，T. (2017年)。从课堂示例中学习深度声音识别。<em class="kl"> arXiv预印本arXiv:1711.10282 </em>。</p><p id="8c4d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[3]<a class="ae lq" href="https://vitalab.github.io/article/2018/04/17/BCLearningClass.html" rel="noopener ugc nofollow" target="_blank">https://vitalab . github . io/article/2018/04/17/bclearning class . html</a></p></div></div>    
</body>
</html>