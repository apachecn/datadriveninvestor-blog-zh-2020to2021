# Python 中的层次聚类算法示例

> 原文：<https://medium.datadriveninvestor.com/hierarchical-clustering-algorithm-example-in-python-b1de1e21a04a?source=collection_archive---------4----------------------->

分层聚类使用在数据中查找组的方法，使得实例彼此之间比不同组中的事例更相似。这种相似性度量通常是数据点之间的欧几里得距离，但是也可以使用花旗块距离和测地线距离。

数据以分层的方式被分解成簇。簇的数量在顶部是 0，在底部是最大值。从这个层次结构中选择最佳的集群数量。

有两种主要类型的分层聚类算法:

*   **凝聚:**自下而上的方法。从许多小集群开始，合并它们以创建更重要的集群。
*   **分裂的**——自上而下的方法。从单个集群开始，然后将其分解成更小的集群。

![](img/4db552735d6a764499e51dfaefd887a1.png)

## 层次聚类的一些利弊
利弊:

*   不假设特定数量的聚类(即 k 均值)
*   它可能对应于有意义的分类法。

## 缺点:

*   一旦做出整合两个集群的选择，就无法撤销。
*   对于大型数据集太慢，O(𝑛2 log(𝑛))

# 它是如何工作的

1.  使每个数据点成为一个群集。

![](img/6ca92c2b3d9b3e2e2720f9e350e6a470.png)

2.取两个最近的聚类，并使它们成为一个聚类。

![](img/eb0df2939a35a30d5f8f072a9ca431f4.png)

3.重复步骤 2，直到只剩下一个集群

![](img/47505aaadc0425307465c579ba1bba7c.png)

# 系统树图

我们可以使用树状图来可视化聚类的历史，并计算出最佳的聚类数。
确定不与任何其他聚类相交的最大垂直距离
在两端画一条水平线
聚类的最佳数量等于穿过水平线的垂直线的数量。
例如，在下面的例子中，聚类数的最佳选择将是 4。

![](img/5d24da4bbc06d1d99e768737d597d2f0.png)

# 链接标准

类似于梯度下降，您可以调整特定的参数，以获得截然不同的结果。

![](img/ee003c2ca4a6539586ba4e2fdb7c59b4.png)

链接标准指的是如何计算聚类之间的距离。

# 单键

两个聚类之间的距离是每个聚类中两点之间的最小距离。

![](img/dc5d066d51c90fa0503e5b67a97e26d1.png)

# 完全连锁

两个聚类之间的距离是每个聚类中两点之间的最大距离。

![](img/d0cc2996206635eba3950b544ece191d.png)

# 平均连锁

聚类之间的距离是一个聚类中的每个点到另一个聚类中的每个特定点之间的平均距离。

![](img/e93b29a726e76bb0bccd21ab200ea9bd.png)

# 病房联动

聚类之间的距离是所有聚类内的平方差之和。

![](img/bd61f0627f2bddc6e5d19097d3bf2094.png)

# 距离度量

您用来计算数据点之间距离的方法将影响最终结果。

# 欧几里得距离

两点之间的最小距离。例如，如果 x=(a，b)且 y=(c，d)，则 x 和 y 之间的欧几里德距离为√(a c)+(b d)

![](img/2b5b12d9e1fd09de9f7ba757303bbb9a.png)

# 曼哈顿距离

假设你在一个大城市的市中心，想要从 A 点到 b 点，你将无法穿过建筑物。相反，你必须在不同的街道上行走。例如，如果 x=(a，b)且 y=(c，d)，则 x 和 y 之间的曼哈顿距离为| a c |+| b d |

![](img/8ac21271b8b64a1eb1143e4b88e4b6dd.png)

# python 中的示例

让我们看一个真实的例子，看看我们如何使用层次凝聚聚类算法来标注数据。

在本教程中，我们使用 CSV 文件，其中包含一个客户列表，包括他们的性别、年龄、年收入和支出分数。

如果你想跟进，你可以从*超级数据科学*网站获得数据集。

[](https://www.superdatascience.com/machine-learning/) [## 机器学习 A-Z:下载实践数据集-超级数据科学页面-大数据|分析…

### 欢迎来到由基里尔·叶列缅科和哈德琳·德·庞特维斯教授的机器学习课程的数据仓库。数据集…

www.superdatascience.com](https://www.superdatascience.com/machine-learning/) 

为了稍后在图表上显示我们的数据，我们只能取两个变量(年收入和支出分数)。

查看树状图，不与任何集群相交的最高垂直距离是中间的绿色。假设有 5 条垂直线穿过阈值，则最佳聚类数是 5。

我们创建了一个`AgglomerativeClustering`的实例，使用欧几里德距离作为点之间距离的度量，并使用 ward 链接来计算聚类的接近度。

属性返回一个整数数组，其中的值对应于不同的类别。

我们可以使用简写符号将属于某一类别的所有样本显示为特定的颜色。

![](img/b4b567b3fe79b3bbced6212fa23ee694.png)![](img/c03d1fa86eb43c50b2066a0cf83a2bb1.png)![](img/1982012f2742b666e22bf74e677ac56b.png)