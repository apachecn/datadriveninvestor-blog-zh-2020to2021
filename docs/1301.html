<html>
<head>
<title>Softmax Classifier Using Gradient Descent (From Scratch)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用梯度下降的Softmax分类器(从头开始)</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/softmax-classifier-using-gradient-descent-and-early-stopping-7a2bb99f8500?source=collection_archive---------0-----------------------#2020-03-12">https://medium.datadriveninvestor.com/softmax-classifier-using-gradient-descent-and-early-stopping-7a2bb99f8500?source=collection_archive---------0-----------------------#2020-03-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/c355b5a23568dcb4012e08f6d6cedb74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P63j44Xc7MbzB7szNWdz8Q.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Some drawing of an Iris that I found on Google Images</figcaption></figure><h1 id="e808" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated"><strong class="ak">简介</strong></h1><p id="0c0c" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我最近从零开始创建了一个机器学习模型，用于解决一个分类问题。具体地，该模型是使用梯度下降的Softmax分类器。我的希望是，您将继续使用这篇文章来创建和修改您自己的Softmax分类器，并学习我们正在使用的函数背后的一些理论。</p><p id="24be" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">在我们进入模型的复杂性之前，我要求大家事先了解以下一些主题，以免陷入未知:</p><ul class=""><li id="3bd1" class="mg mh it lf b lg mb lk mc lo mi ls mj lw mk ma ml mm mn mo bi translated">交叉熵</li><li id="ce7d" class="mg mh it lf b lg mp lk mq lo mr ls ms lw mt ma ml mm mn mo bi translated">梯度下降</li><li id="d513" class="mg mh it lf b lg mp lk mq lo mr ls ms lw mt ma ml mm mn mo bi translated">一次热编码</li></ul><p id="c624" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">如果你碰巧不知道这些话题，我会自己解释或者参考一些我认为最有帮助的材料。</p><p id="6fe8" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">我把我在这篇文章中获得的知识归功于<a class="ae mu" href="https://github.com/ageron" rel="noopener ugc nofollow" target="_blank"> Aurélien Geron </a> ( <a class="ae mu" href="https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646" rel="noopener ugc nofollow" target="_blank">动手机器学习</a>)和<a class="ae mu" href="https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw" rel="noopener ugc nofollow" target="_blank"> Josh Starmer </a>，所以如果你对这些话题中的任何一个不熟悉，我肯定会从他们中的任何一个/两个开始。先不说这个，让我们开始吧！</p><h1 id="f496" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated"><strong class="ak">车型</strong></h1><p id="3cf8" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在我们深入研究任何代码之前，理解我们实际上在创建什么是很重要的。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mv"><img src="../Images/bb33afbcb8c052c476eac970e6dcfd26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wAgSh561WqpYuiX1T02zxQ.png"/></div></div></figure><p id="7e15" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">上面，你会看到一个我创建的很好的视觉效果，它(希望)足够容易理解。我们有一些输入(<strong class="lf iu"> <em class="na"> x </em> </strong>)，一些权重(<strong class="lf iu"> <em class="na"> w </em> </strong>)，一个激活函数(<strong class="lf iu"> softmax </strong>)，一个代价函数(<strong class="lf iu">交叉熵</strong>)。如果这个图让你感到困惑，不要担心，我会单独解释每个部分发生了什么。让我们从输入和权重开始。</p><h1 id="b588" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">第1部分(输入和权重)</h1><p id="80e4" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">对于我们训练数据的一个实例(<strong class="lf iu"> <em class="na"> x </em> </strong>)，我们将拥有<strong class="lf iu"><em class="na"/></strong>个特征(<em class="na"> x1，x2，…，xn </em>)，因此我们的数据将如下所示:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/ee1e9ac7d94ae862bb33701c93761e92.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*QA6Rz2CeGZ7GMxcWXlzsgA.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">features (n) : length of data (m)</figcaption></figure><p id="e335" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">我们将在训练数据中为每个类别<strong class="lf iu"><em class="na"/></strong>设置<strong class="lf iu"> <em class="na"> n </em> </strong> <em class="na"> </em>权重，因此权重将如下所示:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/6764ad424d578d0b76d83be725e91435.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*xpC9JY2Hz7J9KROpBIS9xg.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">features (n) : classes in data (k)</figcaption></figure><p id="595f" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">Softmax分类的第一步是给定我们的训练数据和权重的实例，计算每个类k的分数。从数学上讲，这看起来会像下面这样:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/543084c1778ee32e4a118367c8607f13.png" data-original-src="https://miro.medium.com/v2/resize:fit:412/format:webp/1*JdcQZ7flFXA29IjxNy0Uag.png"/></div></figure><p id="050f" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">换句话说:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/d69916fa323d128c3d745dbcac2338de.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*LbYqpO8aajR4TgFAbiu4XQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Calculates a score for an instance of <strong class="bd kh">x</strong> given class <strong class="bd kh">k</strong>. (Eq. 1)</figcaption></figure><p id="e10d" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">现在我们可以开始写一些代码了，因为我们已经引入了一些函数。首先，我们应该创建一个具有构造函数、得分函数和训练函数的类。</p><p id="b501" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">在我继续之前，我想提一个建议。其中一些函数处理矩阵，因此代码可能有些难以理解；因此，我恳求大家用垃圾数据来测试这些函数，并尽可能多地打印出来。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/b79783ce86a9c151b8621b7f6b690e4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*I8_jzp-bDmUUmtpYLKYGTQ.png"/></div></figure><p id="a0ff" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">我们的类将假设我们的标签是<a class="ae mu" href="https://medium.com/@michaeldelsole/what-is-one-hot-encoding-and-how-to-do-it-f0ae272f1179" rel="noopener"> one-hot-encoded </a>，所以我们标签的一个实例的长度实际上将告诉我们有多少个类(<strong class="lf iu"> <em class="na"> k </em> </strong>)。我们用这个作为我们的权重，这是一个<strong class="lf iu"><em class="na">k</em></strong><em class="na"/>x<strong class="lf iu"><em class="na">n</em></strong>矩阵。</p><p id="87ce" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">我们的得分函数将如下所示:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/8283183d98dc571284d94d6f09667f33.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*iurguyOEnw6Gwm4EAbhgXA.png"/></div></figure><p id="72fc" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">该函数的参数是实例<strong class="lf iu"> <em class="na"> x </em> </strong>和索引<strong class="lf iu"> <em class="na"> k </em> </strong>。索引告诉我们在计算分数时要使用哪些权重。如果你没注意到，我其实没用情商。1因为以下属性:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/6e8138220c92400335ae58be09e4d506.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*4Vxc_MdKsRWiUx8hIHMsaQ.png"/></div></figure><p id="9069" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">这意味着在<strong class="lf iu"> <em class="na"> x </em> </strong>和<strong class="lf iu"> <em class="na"> w </em> </strong>之间做<strong class="lf iu">点积</strong>就足够了，不需要转置任何向量。</p><p id="08e8" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">使用此代码，您将成功完成Softmax分类器的第一部分，如下所示:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/9f830f58708f5a5c921d829acb9afa51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*jEsnUAmRz6gyTIR7mK0k6g.png"/></div></figure><p id="a370" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">现在，我们可以转到模型的<strong class="lf iu">激活功能</strong>部分。</p><h1 id="5a5a" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">第2部分(Softmax函数)</h1><p id="8690" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">Softmax函数的目的是给我们一个有意义的输出，可用于训练或预测。激活函数看起来像这样:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/3cfebe57d24b42a83ba2a934200b9285.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*TPH6v2k3dZkRsEeZ0r1bYg.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Equation 4–20 (Hands-On Machine Learning p.148)</figcaption></figure><p id="5fe8" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">这个函数实际上比看起来简单得多。我们本质上是在获取实例<strong class="lf iu"> <em class="na"> x </em> </strong>是类<strong class="lf iu"> <em class="na"> k </em> </strong>的概率。这就像你之前在概率/统计课上无疑遇到过的袋中球问题。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/9c06efde31b0f88f135b548e63b1f33f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*0EqhWlz2g8DUxXsTXtJy_g.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Ball-In-Hat problem. Probability that x is red, blue, or green.</figcaption></figure><p id="3456" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">唯一的区别是分数是通过<strong class="lf iu"> <em class="na">自然指数函数</em> </strong> <em class="na"> </em>作为一种处理低于0分的分数的方法。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/d8865cf2c32bc1708ed38e26f4ca624f.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*Zv1O_zXClBVjGBqJQR_TGw.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Natural Exponential Function. Notice y is never negative.</figcaption></figure><p id="3b6c" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">关于softmax激活功能的更详细的解释可以在<a class="ae mu" href="https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d" rel="noopener">这里</a>找到。现在是代码！</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/c049c50ab3638290c3731d6dc2ae7359.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*pZVsQIv74gjDqQlBjYu_YQ.png"/></div></figure><p id="8aaf" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">注意，这个函数的参数是实例<strong class="lf iu"> <em class="na"> x </em> </strong>和索引<strong class="lf iu"> <em class="na"> k </em> </strong>，它们与score函数的参数完全相同。softmax函数循环执行<strong class="lf iu"> <em class="na"> i </em> </strong>次，其中<strong class="lf iu"> <em class="na"> i </em> </strong>是类的数量，给定类<strong class="lf iu"> i </strong>，我们将<strong class="lf iu"> x </strong>的分数相加。最后，给定<strong class="lf iu">参数</strong> <strong class="lf iu"> <em class="na"> k，</em> </strong>，我们计算出<strong class="lf iu"> x </strong>的得分，并将其除以指数之和。</p><h1 id="98d6" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">第三部分(交叉熵:理论)</h1><p id="e939" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">没有成本函数，任何机器学习模型都是不完整的。对于那些不知道什么是成本函数的人来说，它只是一个通过比较我们的<strong class="lf iu">预测</strong>结果和我们的<strong class="lf iu">真实</strong>标签来测量我们的模型在训练期间的性能的函数。</p><p id="3a1d" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">交叉熵植根于信息论，可以由比我聪明得多的人更详细地解释，但我将尝试强调我认为重要的东西。请注意，如果你对学习交叉熵理论不感兴趣，你应该跳到第4部分。</p><p id="7004" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">首先，什么是熵？熵，就信息论而言，是你从一个概率分布<strong class="lf iu"> <em class="na"> p </em> </strong>中得到的<strong class="lf iu">最小平均信息量</strong>。熵也正好告诉你概率分布是多么不可预测。让我举一个例子，这样我们可以解析这个解释并获得更好的理解。</p><p id="b34e" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">让我们假设我们是预测天气的气象学家。我们的工作是通过发送尽可能少的信息来通知新闻台明天的天气情况。看下面的例子:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/54da147fe1bc1c7f3b442a45b294f0a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*UTzX2fHzeL14mklYT45dMw.png"/></div></figure><p id="66ea" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">我们可以看到我们的概率分布<strong class="lf iu"> <em class="na"> p </em> </strong>是100%晴天。这意味着，在这个镇上，无论发生什么，永远都是晴天。如果天气总是晴朗的，我们想要计算这个概率分布的熵，其中熵是从气象学家那里接收的<strong class="lf iu">最小信息量</strong>，熵也是<em class="na">、</em>、的<strong class="lf iu">不可预测性，我们会发现熵是<strong class="lf iu">、<em class="na">、</em> 0。</strong>这是因为如果一直是晴天，我们就没必要给新闻发什么信息了。新闻人已经知道他们的城镇是并且将永远是阳光明媚的。这种分布也没有不可预测性，因为天气除了晴朗之外没有任何机会。</strong></p><p id="64d5" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">让我们看另一个天气的例子:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/4ddb7b391a00d20be504a3012f549fff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*eoSkZ9uiG94PQrhu4PDr5Q.png"/></div></figure><p id="1030" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">我们可以看到概率分布<strong class="lf iu"> <em class="na"> p </em> </strong>在晴天和阴天之间平均分配。如果我们想向新闻人发送最少的信息来通知他们天气情况，我们将不得不使用位(1和0)。因为天气多云或晴朗的可能性相等，所以我们可以用1代表晴朗，用0代表多云，这意味着我们正好给新闻人发送了一位。由于熵是新闻人接收的最小信息量，我们的熵就是<strong class="lf iu"> 1 </strong>。这也表明这个概率分布比之前的例子更加<strong class="lf iu">不可预测</strong>，之前的例子的熵值为<strong class="lf iu"> 0 </strong>。这是有意义的，因为这种概率分布有更多的城镇可以忍受的天气类型。下面，您将看到常用于计算熵的函数:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi no"><img src="../Images/39de0a017061fe2247d062984bc8cba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*tZHA_m4A2WmQEE1nD6XPHw.png"/></div></figure><p id="2022" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">那么交叉熵在哪里起作用呢？交叉熵是<strong class="lf iu">平均消息长度</strong>，其中信息来自<strong class="lf iu">真</strong>分布<strong class="lf iu"> <em class="na"> p </em> </strong>，但是我们正在传输具有消息长度的数据，就好像分布是<strong class="lf iu"> <em class="na"> q </em> </strong>。最高级别的交叉熵是两个概率分布之间的差异的度量，<strong class="lf iu"> <em class="na"> p </em> </strong>和<strong class="lf iu"><em class="na"/></strong></p><p id="eb75" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">先来看看<strong class="lf iu"> <em class="na"> p </em> </strong>:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/1fb19575d5233bd3ada9b0d00b75cfff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*unH0R5dZsgGcJ6SkDpKoXQ.png"/></div></figure><p id="5752" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">给定有8种不同天气类型的<strong class="lf iu"> <em class="na"> p </em> </strong>，其中每种天气类型出现的可能性相同，我们的熵将是<strong class="lf iu"> 3 </strong>。</p><p id="3962" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">现在我们来看看<strong class="lf iu"> <em class="na"> q </em> </strong>:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/ad99f3999cdd39d6ed145cf0e00d57d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*wnAv3IJGe30RpxK_K5epRA.png"/></div></figure><p id="f423" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated"><strong class="lf iu"> <em class="na"> q </em> </strong>的熵将是<strong class="lf iu"> 2.5625 </strong>。</p><p id="35d0" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">我应该注意到每种天气类型的位数与百分比有关。例如，两位表示特定天气类型每4天(1/2)发生一次，5位表示特定天气类型每32天发生一次(1/2⁵).我还要注意的是<strong class="lf iu"> <em class="na"> q </em> </strong>加起来并不是100%。这是故意的，为了有完整的位。</p><p id="43fb" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">当我们问这个问题时，交叉熵就起作用了，<strong class="lf iu">如果我们发送的信息位来自于<em class="na"> q </em>分布，但是天气的概率分布实际上是<em class="na"> p </em>呢？</strong>这样，交叉熵就回答了这个问题，<strong class="lf iu">q<em class="na">与<em class="na"> p </em>有多大不同？</em></strong></p><p id="f9ea" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">我们来考虑一下<strong class="lf iu">暴雪</strong>天气类型。气象学家假设暴风雪只在百分之<strong class="lf iu"> 3.125% </strong>的时间里发生(<strong class="lf iu"> <em class="na"> q </em> </strong>是估计的分布)，但实际上暴雪发生的时间<strong class="lf iu">12.5%</strong>(<strong class="lf iu"><em class="na">p</em></strong>是真实的分布)。由于我们使用了<strong class="lf iu"> <em class="na"> q </em> </strong>来构造我们的消息长度，我们将发送<strong class="lf iu"> 5 </strong>位(11101) <strong class="lf iu"> 12.5% </strong>，而实际上我们应该发送<strong class="lf iu"> 3 </strong>。这不是最佳的，因为它使我们的平均消息长度超过了它应有的长度。</p><p id="58f0" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">交叉熵将为我们提供概率分布<strong class="lf iu"> <em class="na"> p </em> </strong>的消息长度，其中我们的消息(模型)是由<strong class="lf iu"> <em class="na"> q </em> </strong>、<strong class="lf iu"> <em class="na"> </em> </strong>构成的，它为我们提供了一个可以用来与<strong class="lf iu"> <em class="na"> p </em> </strong>的熵进行比较的数字。在这种情况下，我们的交叉熵将是<strong class="lf iu"> 3.5 </strong>。这是使用以下函数计算的:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi np"><img src="../Images/853881d66a4036f9b10a2d48ba34e30c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*aRysJO28SFqSjP4DYW_Icg.png"/></div></figure><p id="313b" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">如果<strong class="lf iu"><em class="na">p</em></strong>=<strong class="lf iu"><em class="na">q</em></strong>，那么交叉熵就简单地等于<strong class="lf iu"> <em class="na"> p、</em> </strong>的熵既然两个分布没有区别；否则，交叉熵将等于:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nq"><img src="../Images/fcb41e1fe82ea440e842d8fe73e5acfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XrNOclN4V37SB4QNMH45rw.png"/></div></div></figure><p id="643a" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">当训练我们的模型时，我们有效地试图将KL-Divergence最小化到0。</p><p id="3ca3" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">交叉熵与Softmax分类器有关，因为softmax函数将为我们提供一些概率分布<strong class="lf iu"><em class="na"/></strong>，例如<strong class="lf iu"><em class="na">【x</em></strong>，并且我们试图让它与真正的标签<strong class="lf iu"> <em class="na"> p </em> </strong>匹配，例如<strong class="lf iu"> <em class="na"> x </em> </strong>。交叉熵会给出我们当前分布<strong class="lf iu"> <em class="na"> q </em> </strong>的代价(误差)。</p><h1 id="6540" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">第4部分(交叉熵:代码)</h1><p id="2a40" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在我们对交叉熵的理论有了更好的理解，我们终于可以开始编码了。</p><p id="cac9" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">我们将对交叉熵使用以下函数:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nr"><img src="../Images/8f55a4d7e831df4a7983ba72ed71fa34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*U5pkf3xEppPblXEn6pFfzw.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Equation 4–22. Cross entropy cost function (Hands-On Machine Learning p.149)</figcaption></figure><p id="c9b7" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">如果你以前从未见过这个交叉熵成本函数的梯度版本，这里的<a class="ae mu" href="https://math.stackexchange.com/questions/2852620/how-do-you-take-the-gradient-vector-of-the-cross-entropy-cost-function" rel="noopener ugc nofollow" target="_blank"/>是一个衍生到这个变体的论坛帖子。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/a51f13064eea0878a05492799be952fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F71bl2eOKV86hTWTmjTGJA.png"/></div></div></figure><p id="4f53" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">这里的代码与上面提供的函数几乎相同，所以我不解释代码。如果您在理解所发生的事情时有困难，我将再次建议您在整个函数中使用print语句。</p><h1 id="1269" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">第5部分(调整权重)</h1><p id="0032" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在我们有了给定类别<strong class="lf iu"> <em class="na"> k </em> </strong>的权重的<strong class="lf iu">成本</strong>，我们将使用它们来稍微调整它们的值，这将有望使我们更接近它们的最优值。这种训练形式被称为<strong class="lf iu">梯度下降</strong>。我不会深入讨论梯度下降，因为我相信Josh Starmer已经很好地解释了它，你可以在这里找到<a class="ae mu" href="https://www.youtube.com/watch?v=sDv4f4s2SB8&amp;list=PLgqYy6R2-N_QrSnFcPJG3GWvU7fAzJAVL" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="aebf" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">如果你已经知道梯度下降，或者你刚刚看完Josh Starmer对它的解释，你会知道我们需要一个<strong class="lf iu">学习率</strong>，它通知模型在训练的每次迭代中应该改变多少权重。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/b0ac9562408a18899d3526c21550713e.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*kTKIl65ErL5fv9PqM9iqpw.png"/></div></figure><p id="c04d" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">一旦模型知道学习率是多少，它就可以开始改变权重，如下所示:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/112197ac4d17ce7a7cd5ad92df0b14b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NaFeVhG-6lZ4974thEEexQ.png"/></div></div></figure><h1 id="160f" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated"><strong class="ak">第六部分(训练模型)</strong></h1><p id="b857" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们终于可以开始训练模型了！我们现在要做的就是利用我们创建的所有函数，这对于我们如何构建模型来说非常简单；然而，模型还需要知道一件事。它需要知道它需要训练多长时间，我们可以很容易地提供，如下所示:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/594d288b5693bff814f8be4d993e19e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*z5ExaKux09-bVtja8UxQMA.png"/></div></figure><p id="29c6" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">现在，培训部分非常简单:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nw"><img src="../Images/726e1219db1d3be058521e944a8a33af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lIPIYMpJ3jISzxLY18_1nw.png"/></div></div></figure><p id="6487" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">对于每次迭代，我们将为每个可能的类计算一组新的权重。一旦训练完成，我们将有希望拥有一个模型，可以准确地预测我们的数据实例的正确类别。</p><h1 id="26b7" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated"><strong class="ak">第7部分(测试模型)</strong></h1><p id="e9bc" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们快完成了！一旦模型被训练，我们现在想看看我们的模型能做得多好，所以我们必须创建一个能预测一些测试数据的函数。代码如下所示:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nx"><img src="../Images/fbe21146045eb41f96e89752fefca4ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*3BxisSJnOltXi3yv2UZr6g.png"/></div></div></figure><p id="87aa" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">从我们的模型中获得预测并不太复杂。我们需要一个<strong class="lf iu"> y </strong>矩阵，即<strong class="lf iu">T5】nT7】x<strong class="lf iu">T9】kT11】，它将保存我们所有的预测作为<strong class="lf iu">单热编码</strong>值。给定一组测试数据，我们迭代每个实例，计算实例<strong class="lf iu"> <em class="na"> x </em> </strong>相对于每个类<strong class="lf iu"> k </strong>的得分。然后，我们选择具有最高softmax值的类，并在其索引处插入一个<strong class="lf iu"> 1 </strong>。</strong></strong></p><h1 id="146d" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">第八部分(数据集)</h1><p id="2d21" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我故意将训练集留到最后，因为这个模型应该适用于任何多类分类问题。非常欢迎你使用任何你想要的数据集，只要它是多类的而不是多标签的。你可以在这里阅读分类<a class="ae mu" href="https://www.quora.com/What-is-the-difference-between-multilabel-and-multiclass-classification" rel="noopener ugc nofollow" target="_blank">的不同变体。</a></p><p id="89ac" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">对于这个例子，我将使用Scikit-Learn提供的<a class="ae mu" href="https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lf iu">虹膜</strong> </a> <strong class="lf iu"> </strong>数据集<strong class="lf iu"> </strong>。数据集非常简单。我们有以下形式的数据:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/8710f81141d91ca51592c20b766287cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*tIl2fqhUk6RpQ29sN7Wsgw.png"/></div></figure><p id="64e1" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">我们的标签是这样的:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/80abce61e38e7ce367fba62aa813c16e.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*uwuqHHVncd-acBKuSOupPg.png"/></div></figure><p id="d9a8" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">如果您还记得前面的内容，在将标签传递给模型之前，我们还必须对标签进行一次热编码。下面是对序号标签值进行编码的相应代码。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/0e78c6768ef5e6a7e6ce8c57e0e8e0d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*MI9eQCP_6mLtCiGqeIOGRA.png"/></div></figure><p id="00b1" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">在这个函数中，我们通过获取标签的<strong class="lf iu">集合</strong>的长度来获得类的数量。如果你不知道，取一个列表的<strong class="lf iu">集合</strong>，会返回一个没有重复的列表；因此，我们将得到一个长度只有3个元素的列表。然后我们创建一个形状为<strong class="lf iu"><em class="na">n</em></strong>x<strong class="lf iu"><em class="na">k</em></strong>的矩阵。最后，我们在每个标签实例的正确位置插入一个1。</p><h1 id="6fb0" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">第9部分(实现模型)</h1><p id="57d6" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">最后冲刺！我们在本教程的最后一部分。我们最终可以为我们的模型提供一些数据，对其进行训练，并根据训练集进行预测。这段代码非常容易阅读，所以我不会详细介绍它:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ob"><img src="../Images/5c8e2fc4fcd2662c4ccf89839bce4e31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ff-XowcLGCbc5NJquC8E1g.png"/></div></div></figure><h1 id="33de" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">挑战</h1><p id="d7ba" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在你决定解决这个问题之前，我恳求你改进和定制你的Softmax分类器，以进一步提高准确率！</p><p id="d136" class="pw-post-body-paragraph ld le it lf b lg mb li lj lk mc lm ln lo md lq lr ls me lu lv lw mf ly lz ma im bi translated">以下是一些你可以尝试的事情:</p><ul class=""><li id="c969" class="mg mh it lf b lg mb lk mc lo mi ls mj lw mk ma ml mm mn mo bi translated">实施提前停止</li><li id="f69d" class="mg mh it lf b lg mp lk mq lo mr ls ms lw mt ma ml mm mn mo bi translated">实现最小步长</li><li id="8ffd" class="mg mh it lf b lg mp lk mq lo mr ls ms lw mt ma ml mm mn mo bi translated">降低每次迭代的学习率。</li></ul><h1 id="0b3b" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated"><strong class="ak">结论</strong></h1><p id="885e" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">恭喜你！您已经从头开始创建了一个Softmax分类器。希望你一路走来学到了一些东西，如果你有任何问题或建议，请在下面留下评论。你可以在这里访问完整的源代码<a class="ae mu" href="https://github.com/FezTheImmigrant/OReillyBookCodeAlong/blob/master/Chapter%204%20-%20Training/soft_max_scratch.py" rel="noopener ugc nofollow" target="_blank">，在这里</a>访问<a class="ae mu" href="https://github.com/FezTheImmigrant/OReillyBookCodeAlong/blob/master/Chapter%204%20-%20Training/chapter_4_exercise_12.py" rel="noopener ugc nofollow" target="_blank">。编码快乐！</a></p></div></div>    
</body>
</html>