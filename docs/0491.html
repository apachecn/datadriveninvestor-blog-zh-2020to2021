<html>
<head>
<title>5 Machine Learning Classifiers you must know</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你必须知道的5个机器学习分类器</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/5-machine-learning-classifiers-you-must-know-925655c75e02?source=collection_archive---------8-----------------------#2020-02-01">https://medium.datadriveninvestor.com/5-machine-learning-classifiers-you-must-know-925655c75e02?source=collection_archive---------8-----------------------#2020-02-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4aed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi kl translated">机器学习之旅的最终目的地是达到这样一个阶段，即可以在迄今为止没有人尝试过的数据集或你自己的数据上应用学到的技术。换句话说，就是解决一个尚未解决的新问题。<strong class="jp ir"> MNIST </strong>和<strong class="jp ir">爱丽丝</strong>的数据很好，但对于刚刚开始的旅程来说是好的。但是我们应该使用什么数据集呢？从现实世界的问题中获取实际数据可能是昂贵的，有时甚至是不可行的，然而，我们可以使用像<strong class="jp ir"> Numpy </strong>这样的工具轻松地“创建”或“模拟”数据。</p><p id="a760" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们将为6个科目的1000名学生(您可以轻松地更改数字)创建一个考试结果数据集，范围为1到100(使用<strong class="jp ir"> Numpy随机选择)。随机)。如果学生在某一科目上的分数低于33分，则被视为不及格；如果有两门或两门以上的科目不及格，则被视为总体不及格。我们用“0”表示失败，用“1”标签表示通过。现在，我们已经为二元分类准备好了数据集，我们希望我们的分类器能够学习一些复杂的规则。</strong></p><p id="77cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，对于多级分类，如果学生的总分分别低于33 %、高于60 %、介于60%和45 %之间以及介于45%和33 %之间，我们会将学生分为0、1、2和3四类。</p><p id="71d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用来自<strong class="jp ir"> Scikit-Learn </strong>的以下五个分类器来完成分类任务。</p><p id="db23" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1.支持向量机</p><p id="41e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.逻辑回归</p><p id="17d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.朴素贝叶斯</p><p id="8fbe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4.决策图表</p><p id="7a6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">5.k-最近邻</p><p id="fc91" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">分类器的性能用混淆矩阵来衡量。</p><p id="baf1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">每个分类器都有自己的理论，我们在这里不讨论，但是你可以使用下面给出的参考资料。请注意，我们上面列出的五种算法也可以用于回归目的，我们在这里省略了神经网络，因为它需要更多的代码行来实现。</p><h1 id="be11" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">1.创建数据</h1><p id="2e51" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">注意，我们将使用以下两个库<strong class="jp ir"> Numpy </strong>和<strong class="jp ir"> Pandas </strong>来创建数据。我们使用Pandas数据框架来存储和操作数据。</p><pre class="lx ly lz ma gt mb mc md me aw mf bi"><span id="38eb" class="mg kv iq mc b gy mh mi l mj mk">import numpy as np<br/>import pandas as pd</span><span id="d418" class="mg kv iq mc b gy ml mi l mj mk">def get_exam_data ():<br/>    # create marks for six subjects in the range 0-50<br/>    subjects =      ["Hindi","English","Science","Maths","History","Geograpgy"]</span><span id="6be7" class="mg kv iq mc b gy ml mi l mj mk">    # set the seed <br/>    np.random.seed(seed=167)<br/>    # set the marks randomly<br/>    marks = np.random.randint(100, size=(1000,6))</span><span id="45b2" class="mg kv iq mc b gy ml mi l mj mk">    df = pd.DataFrame(data=marks, columns=subjects)<br/>    df['Total'] =  df[subjects].sum(axis=1)</span><span id="5692" class="mg kv iq mc b gy ml mi l mj mk">    # this is to find whether the student is failed or passed<br/>    # in a subject <br/>  <br/>    df1 = df.copy()<br/>    # set the result fail is marks in a subject &lt; 17</span><span id="7830" class="mg kv iq mc b gy ml mi l mj mk">    for s in subjects:<br/>       df1[s] =[1 if i &gt; 33 else 0 for i in  df[s].tolist()]</span><span id="feaa" class="mg kv iq mc b gy ml mi l mj mk">    # get the total <br/>    df1['Results'] =  df1[subjects].sum(axis=1)<br/>    # declare the result fail (0) if fail in more than 2 subjects</span><span id="1ec1" class="mg kv iq mc b gy ml mi l mj mk">    df['Results'] = df1['Results'].apply(lambda x : 0 if x &lt;=4 else 1)</span><span id="5ef4" class="mg kv iq mc b gy ml mi l mj mk">    # get the divison :  1  for &gt; 60 %, 2 for &gt; 45 % and &lt; 60 %, 3 for  &lt; 45 % and &gt; 33 %, # 0 for &lt; 33 %</span><span id="3ccd" class="mg kv iq mc b gy ml mi l mj mk">    df['Div'] = [1 if i &gt; 360  else 2 if i &lt; 360 and i &gt; 270<br/>     else 3 if i &lt; 270 and i &gt; 198 else 0 for i in df['Total'].tolist() ]</span><span id="e896" class="mg kv iq mc b gy ml mi l mj mk">    # return the result data frame<br/>    return df</span></pre><p id="e64e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，仅通过复制和粘贴程序将无法编译，因此要么在粘贴后编辑它，要么从这里的<a class="ae mm" href="https://github.com/jayanti-prasad/ml-projects/blob/master/exam-results/data_sim.py" rel="noopener ugc nofollow" target="_blank">下载原始程序。</a></p><p id="3c8e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对上述函数的调用程序非常简单:</p><pre class="lx ly lz ma gt mb mc md me aw mf bi"><span id="1fbd" class="mg kv iq mc b gy mh mi l mj mk">if __name__ == “__main__”:<br/>   df = get_exam_data ()<br/>   df.to_csv(“results.csv”)</span></pre><p id="711e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们已经创建了写在csv文件中的数据，我们可以使用该文件进行分类。</p><p id="c97f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据的前几行如下:</p><figure class="lx ly lz ma gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mn"><img src="../Images/f029e745ce0316b1d9c060d0d558b070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gll1VwiPOfYHx4xcVthvhw.png"/></div></div></figure><p id="bf2d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以在这里从<a class="ae mm" href="https://github.com/jayanti-prasad/ml-projects/blob/master/exam-results/results.csv" rel="noopener ugc nofollow" target="_blank">获得完整的数据文件。</a></p><h1 id="544c" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">2.分类</h1><p id="6e57" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">首先，我们导入所需的库:</p><pre class="lx ly lz ma gt mb mc md me aw mf bi"><span id="70f0" class="mg kv iq mc b gy mh mi l mj mk">import sys<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import confusion_matrix<br/>from sklearn import svm<br/>from sklearn import tree<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.naive_bayes import GaussianNB<br/>from sklearn import neighbor</span></pre><p id="bc48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们给五个不同的分类器五个函数如下。</p><pre class="lx ly lz ma gt mb mc md me aw mf bi"><span id="74d2" class="mg kv iq mc b gy mh mi l mj mk"># 1. This is for Support Vector Machines</span><span id="b2d9" class="mg kv iq mc b gy ml mi l mj mk">def svm_clf (x_train, y_train):<br/>    print(“SVM Classifier”)<br/>    #clf = svm.LinearSVC()<br/>    #clf = svm.SVC(kernel=’rbf’)<br/>    clf = svm.SVC(kernel=’poly’, degree=8)<br/>    clf.fit(x_train, y_train)<br/>    return clf</span><span id="f699" class="mg kv iq mc b gy ml mi l mj mk"># 2. This is for Logistic Regression</span><span id="14a6" class="mg kv iq mc b gy ml mi l mj mk">def logistic_clf (x_train, x_test):<br/>    print(“Logistic Classifier”)<br/>    clf = LogisticRegression(C=1e5)<br/>    clf.fit(x_train, y_train)<br/>    return clf</span><span id="f504" class="mg kv iq mc b gy ml mi l mj mk">#3. This is for Naive Bayes<br/> <br/>def naive_bayes (x_train, x_test):<br/>    print(“Naive Bayes Classifier”)<br/>    clf = GaussianNB()<br/>    clf.fit(x_train, y_train)<br/>    return clf</span><span id="3cd9" class="mg kv iq mc b gy ml mi l mj mk">#4. This is for Decision Tree</span><span id="5365" class="mg kv iq mc b gy ml mi l mj mk">def tree_clf (x_train, y_train):<br/>    print(“Decision Tree Classifier”)<br/>    clf = tree.DecisionTreeClassifier(criterion=’entropy’)<br/>    clf.fit(x_train, y_train)<br/>    return clf</span><span id="63d9" class="mg kv iq mc b gy ml mi l mj mk"># 5. This is knn classifier</span><span id="88f6" class="mg kv iq mc b gy ml mi l mj mk">def knn_clf (x_train, y_train):<br/>    print(“KNN Classifier”)<br/>    n_neighbors = 15<br/>    clf = neighbors.KNeighborsClassifier(n_neighbors,    weights=’uniform’)</span><span id="e966" class="mg kv iq mc b gy ml mi l mj mk">    clf.fit(x_train, y_train)</span><span id="7f4e" class="mg kv iq mc b gy ml mi l mj mk">    return clf</span></pre><p id="0ed7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，您可能需要编辑程序，以确保遵循python缩进规则，否则您可以从这里的<a class="ae mm" href="https://github.com/jayanti-prasad/ml-projects/blob/master/exam-results/classifier.py" rel="noopener ugc nofollow" target="_blank">直接下载代码。</a></p><p id="f723" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">主要程序如下:</p><pre class="lx ly lz ma gt mb mc md me aw mf bi"><span id="acf0" class="mg kv iq mc b gy mh mi l mj mk">if __name__ == “__main__”:</span><span id="6f68" class="mg kv iq mc b gy ml mi l mj mk">  # Read the data file from sys.argv please change it if you wish <br/>  df = pd.read_csv(sys.argv[1])<br/>  print(“Input data frame:”, df.shape)<br/>  print(“Columns:”, df.columns)<br/>  data = df.to_numpy()<br/>  X = data[:,1:7]</span><span id="0345" class="mg kv iq mc b gy ml mi l mj mk">  # for binary set<br/>  #Y = data[:,8]</span><span id="8394" class="mg kv iq mc b gy ml mi l mj mk">  # for multi-class<br/>  Y = data[:,9]</span><span id="217e" class="mg kv iq mc b gy ml mi l mj mk">  x_train, x_test, y_train, y_test \<br/>    = train_test_split(X, Y, test_size=0.20, random_state=42)</span><span id="0013" class="mg kv iq mc b gy ml mi l mj mk">  models = [svm_clf, logistic_clf, naive_bayes, tree_clf, knn_clf]</span><span id="9452" class="mg kv iq mc b gy ml mi l mj mk">  conf_mat = []</span><span id="2b4b" class="mg kv iq mc b gy ml mi l mj mk">   # Let us iterate over all the five classifiers <br/>  for m in models:<br/>     clf = m(x_train, y_train)</span><span id="8757" class="mg kv iq mc b gy ml mi l mj mk">     # Now make the prediction <br/>     y_hat = clf.predict(x_test)</span><span id="d194" class="mg kv iq mc b gy ml mi l mj mk">     # Create the confusion matrix from the <br/>     # true value and predicted ones<br/>     cm = confusion_matrix(y_test, y_hat)<br/>     print(“Confusion matrix:\n”, cm)<br/>     print(“========”)</span></pre><h1 id="6d38" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">3.准确(性)</h1><p id="8a22" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">我们可以根据混淆矩阵来报告分类器的准确性，混淆矩阵基本上告诉我们有多少个0被预测为0，有多少个1被预测为0，有多少个1被预测为1。</p><p id="cda0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于二进制情况，我们得到以下混淆矩阵:</p><figure class="lx ly lz ma gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/d81553c5dc229b7169d602fb2ce21906.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*L80gYSUYhyOz91VQ6B-yjA.png"/></div></figure><figure class="lx ly lz ma gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/f7113965b695d628fa922350b3f01a56.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*wpGekwX_xyPSRBHaP5nKlw.png"/></div></figure><figure class="lx ly lz ma gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/10f1abcf85dbcc46939675fb5207361d.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*P5Lzr9LSGtawWa7t0_3e3w.png"/></div></figure><figure class="lx ly lz ma gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/faa38733cff8828daa3f0ee660fd2469.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*JK8LxFqx93Po8YCDrGCrvg.png"/></div></figure><figure class="lx ly lz ma gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/ceaebccf6b2ebc8134266158acd32c21.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*bFLuYMii6DGY11YcMbq_-g.png"/></div></figure><p id="98b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于多类情况，我们得到以下混淆矩阵:</p><figure class="lx ly lz ma gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/6ee138e39fa43415625d50f5401cf4d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*gVfp-nDw1XZZ1F4O_Ky9sQ.png"/></div></figure><figure class="lx ly lz ma gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/cb354f82aada69f5b661dc6072015f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*iYns82oMonEzXpPpHIi4Zg.png"/></div></figure><figure class="lx ly lz ma gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/f2cc4edc27116a484a0674bb921e3b67.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*CGEfh9q8Bnd6_Qnlem5RHg.png"/></div></figure><figure class="lx ly lz ma gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/6bbf0c165e22e8470792a9864ed67981.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*MNGWfS1y76iNh5NTis3vug.png"/></div></figure><figure class="lx ly lz ma gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/fea4fb59bb5f437017986334d7ca75a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*CcTISFjfaJS5T5ShwtLyEQ.png"/></div></figure><h1 id="2d4e" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">4.结论:</h1><p id="36cd" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">在本文中，我们讨论了在<strong class="jp ir"> Scikit-learn </strong>中为1000名学生的模拟考试分数数据集实现的五种不同的分类器。我们可以看到，即使使用默认的参数设置，我们也可以得到相当令人满意的结果。但是，可以通过调整超参数来改善结果。</p><p id="154b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你发现这篇文章请喜欢(鼓掌！)&amp;分享，如果有意见，在这里张贴或邮件给我。你可以从<a class="ae mm" href="https://github.com/jayanti-prasad/ml-projects/tree/master/exam-results" rel="noopener ugc nofollow" target="_blank">这里得到完整的代码。</a></p><h1 id="abb7" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> 5。参考文献:</strong></h1><p id="36e9" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated"><a class="ae mm" href="https://scikit-learn.org/stable/modules/svm.html" rel="noopener ugc nofollow" target="_blank">支持向量机</a></p><p id="7bc3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mm" href="https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#" rel="noopener ugc nofollow" target="_blank">最近邻分类</a></p><p id="d67d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mm" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">逻辑回归</a></p><p id="b8e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mm" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" rel="noopener ugc nofollow" target="_blank">决策树</a></p><p id="368f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mm" href="https://scikit-learn.org/stable/modules/naive_bayes.html" rel="noopener ugc nofollow" target="_blank">朴素贝叶斯</a></p><p id="9857" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mm" href="https://github.com/jayanti-prasad/ml-projects/tree/master/exam-results" rel="noopener ugc nofollow" target="_blank">考试成绩数据</a></p></div></div>    
</body>
</html>