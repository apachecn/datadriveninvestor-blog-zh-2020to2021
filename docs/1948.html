<html>
<head>
<title>How self-driving cars see</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动驾驶汽车如何看待</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/how-self-driving-cars-see-deeb87cac531?source=collection_archive---------2-----------------------#2020-04-07">https://medium.datadriveninvestor.com/how-self-driving-cars-see-deeb87cac531?source=collection_archive---------2-----------------------#2020-04-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="33ed" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">你只看一次| YOLO物体探测算法</h2></div><p id="231d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">人眼是人体中最快的肌肉，经过数百年的进化而完善。当与大脑的处理能力相结合时，我们可以在几分之一秒内对物体进行分析和分类。</p><p id="1d5c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是我们如何为计算机重现这个过程呢？将摄像头贴在自动驾驶汽车上，祈祷它不会撞到人，这不是一个安全的赌注。自动驾驶汽车不仅仅需要看到图像，它们需要极其快速地检测图像中<strong class="kk iu">种类型的物体</strong>及其<strong class="kk iu">位置</strong><strong class="kk iu">。</strong></p><p id="00e7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自60年代以来，我们已经能够使用算法检测物体。但我们只能通过扫描图像的一部分来检测特定配置中的特定对象，像快速RCNN这样的网络必须进行多次预测，这意味着更多的时间。</p><div class="le lf gp gr lg lh"><a href="https://www.datadriveninvestor.com/2019/03/22/fixing-photography/" rel="noopener  ugc nofollow" target="_blank"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd iu gy z fp lm fr fs ln fu fw is bi translated">修复摄影|数据驱动的投资者</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">汤姆·津伯洛夫在转向摄影之前曾在南加州大学学习音乐。作为一个…</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="lq l"><div class="lr l ls lt lu lq lv lw lh"/></div></div></a></div><p id="c743" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是通过一种叫做<a class="ae lx" href="http://paper in 2015" rel="noopener ugc nofollow" target="_blank"> YOLO </a>的物体检测算法，我们能够检测<strong class="kk iu">多个物体，并以高达每秒155帧的速度确定它们的位置！YOLO <strong class="kk iu"> </strong>通过捕捉整个图像并只通过它的网络传递一次来做到这一点。与大多数逐段扫描图像的对象检测算法不同，<strong class="kk iu"> Yolo一次扫描整幅图像，</strong>因此得名“你只看一次”。</strong></p><p id="d182" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Yolo将对象限制在边界框中，同时对对象进行分类，并测量某个对象在边界框中的可信度。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/4206f91249f9dc0d6f3a7ddfa8a2c53a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*mnKLHE-IGLQwkIQ4VZgh4w.png"/></div></figure><p id="600e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">神经网络模拟了大脑中神经元如何相互作用。一个节点输出作为另一个节点的输入，依此类推。</p><p id="11c6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Yolo使用<strong class="kk iu">卷积神经网络，因为它们非常适合理解空间信息。他们能够提取边缘、线条和纹理等特征。这对图像特别有用。</strong></p><p id="5186" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以使用预先存在的CNN，它已经在<a class="ae lx" href="http://host.robots.ox.ac.uk:8080/pascal/VOC/" rel="noopener ugc nofollow" target="_blank"> Pascal数据集</a>上进行了数千次测试，可以对20类物体进行分类。</p><p id="24ed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它使用一种称为卷积层的特殊层，从图像中提取特征。它扫描图像寻找特征。YOLO有24个这样的卷积层。更密集的层将所有东西放在一起，获取空间信息和特征，以便能够检测一个对象在图像中的位置。</p><h2 id="1635" class="mf mg it bd mh mi mj dn mk ml mm dp mn kr mo mp mq kv mr ms mt kz mu mv mw mx bi translated">但是首先快速看一下CNN是如何工作的</h2><p id="a4b0" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">计算机把一幅图像分解成一个数字矩阵。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/5a25a171c03461d808f5ce2fcc3e722d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_Cz0Ea5VRIRAausA.jpg"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">What we see vs what computers see</figcaption></figure><p id="3d90" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">卷积层</strong>就像扫描一幅图像的滤镜；这些较小的矩阵被称为卷积核。内核在图像周围移动。每个矩阵负责扫描更大矩阵的一部分。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ni"><img src="../Images/bbfb77f94f886dbe4accd688fca1aaa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RgY33yVYXaPuo2H8.gif"/></div></div></figure><p id="87b0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">内核矩阵中的数字会乘以它们正在扫描的更大矩阵的权重。这些数字加在一起就形成了一幅地图。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/744d74261d79a11d568cd92086ff6a67.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/0*Ol0I7BOE_5C829jo"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">convolutional kernel scanning</figcaption></figure><p id="c7c4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将应用一个激活函数来压缩我们的数字。<strong class="kk iu"> ReLu </strong>是CNN常用的激活功能。</p><p id="433c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">拥有太多的特征地图会给我们带来很多维度需要处理，我们可以使用一个<strong class="kk iu">最大池层</strong>，它像一个卷积核，但没有权重。它扫描地图的各个部分。它会从正在扫描的区域中选择最大的数字，创建一个维数更少的更小的新矩阵。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi no"><img src="../Images/4f80d7b5ed1a5f6cc2bea1c2b01007c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LXc9F_yLcX1-MTqy.png"/></div></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">The biggest number out of the section is used for the new matrix</figcaption></figure><h2 id="b3c7" class="mf mg it bd mh mi mj dn mk ml mm dp mn kr mo mp mq kv mr ms mt kz mu mv mw mx bi translated">YOLO是如何运作的</h2><p id="6b6e" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">在YOLO的建筑中，我们将重复这些层次:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi np"><img src="../Images/933bc1bc73f3d39533319efc65d9f2b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KZA55PtI844nhcHG"/></div></div></figure><p id="e061" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，YOLO将图像划分成一个100×100的网格.</p><p id="bc8f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它根据相邻的纹理、颜色或亮度来创建边界框，以找到一个对象。在每个网格单元内，YOLO检查是否可能有一个对象创建五个边界框和一个类别概率图，告诉我们如果一个对象位于该区域，它可能是一个特定的对象。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/b57eb80ffff156cc17fe2fafd68dffce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*3fACdBm_znCyp3WD.jpg"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">For example, if there’s an object in the blue area, it is likely a dog</figcaption></figure><p id="c572" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每个边界框预测五个元素:(x，y，w，h，置信度)。框的x，y坐标，宽度和高度及其置信度得分。如果一个单元格有一个对象，YOLO记录该对象中心的x，y坐标。它负责在对象周围创建一个边界框，它将找到该框的高度和宽度，并使用置信度得分来测量对象在该边界框中的可能性。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nr"><img src="../Images/a55516047534f716ef7213902f3228e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tgU74JpiAdlkSCa_.jpg"/></div></div></figure><p id="33f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用类别概率和联合上的<strong class="kk iu">交集来测量置信度得分。它将实际的包围盒与预测的包围盒进行比较，我们通过将重叠面积除以并集面积来获得并集上的交集(IoU)。</strong></p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/52adeb1336544ac5dc5538f17cd67efb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*Z__fyyMr2qV_2_Ck"/></div></figure><p id="dd7c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">到目前为止，我们将有一吨的边界框，我们；我将确保只显示满足某个置信度阈值的边界框。通过运行非最大值抑制，我们去掉了低概率预测，只剩下相关的预测。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ns"><img src="../Images/4b2fcb202e14bc87b88e09bc4be10fff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u4zudM5OMc4ZIPsEEQRPOw.png"/></div></div></figure><p id="5d4c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，通过使用预训练的CNN从图像中提取特征，它将对对象进行分类。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nt"><img src="../Images/55a85a45b3fa7cf64818723ccf87c237.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O_kOXg1gEK14kOToKLe99w.png"/></div></div></figure><h2 id="f479" class="mf mg it bd mh mi mj dn mk ml mm dp mn kr mo mp mq kv mr ms mt kz mu mv mw mx bi translated">大局</h2><p id="9743" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">能够检测视频中的物体具有重大意义，看看它在自动驾驶汽车中的潜力:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/3cf94dfa1882dfd1a092f06c6e7fd1b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/0*QUO3B46nLGXC8ZVN.gif"/></div></figure><p id="5fda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当他们的激光雷达传感器与YOLO配对时，他们能够在密集的交通中导航，能够识别多个对象及其相互之间的空间关系。</p><p id="d0b4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">YOLO速度很快。当生命危在旦夕的时候，autonomous没有多余的时间来做决定。计算机视觉和其他物体检测算法完成了这项工作。在某些情况下甚至比YOLO更准确，但它们要慢得多。这使得人们对使用人工智能进行自主任务犹豫不决。现在算法可以实时做出决定。</p><p id="d60d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">人眼可以在13毫秒内检测和处理物体，但有了YOLO，我们可以检测得更快，可能有助于减少100多万例车祸死亡。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><p id="b57e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望你学到了新的东西！当我更深入地研究机器学习、指数技术和世界时，请随时联系LinkedIn，查看我的T2网站或订阅我的T4时事通讯😊</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="oc od l"/></div></figure></div></div>    
</body>
</html>