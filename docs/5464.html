<html>
<head>
<title>Alternative Hyperparameter Optimization Techniques You Need to Know — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">您需要了解的替代超参数优化技术—第1部分</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/alternative-hyperparameter-optimization-techniques-you-need-to-know-part-1-3f68d0448fcd?source=collection_archive---------3-----------------------#2020-09-21">https://medium.datadriveninvestor.com/alternative-hyperparameter-optimization-techniques-you-need-to-know-part-1-3f68d0448fcd?source=collection_archive---------3-----------------------#2020-09-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b658" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">超参数优化技术。</h2><div class=""/><div class=""><h2 id="48b6" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">微调机器学习模型以提高性能的不同方法。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/cc5980de889b0d7cca1b65a41edb6946.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KyS36RHmvfxh7UdZ1Nr7dA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Image by <a class="ae le" href="https://pixabay.com/users/dmwcebi-6228068/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2666136" rel="noopener ugc nofollow" target="_blank">dmwcebi</a> from <a class="ae le" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2666136" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="c148" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在进行机器学习项目时，您需要遵循一系列步骤，直到您达到目标，其中一个步骤是对您选择的模型进行超参数优化。该任务总是在模型选择过程之后(选择比其他模型表现更好的最佳模型)。</p><h1 id="884a" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">什么是超参数优化？</h1><p id="4bb5" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在我定义超参数优化之前，你需要理解什么是<strong class="lh ja">超参数</strong>。简而言之，超参数是用于控制学习过程的不同参数值，并且对机器学习模型的性能具有显著影响。随机森林算法中超参数的例子是估计量的数量(<em class="my">n _估计量</em>)、最大深度(<em class="my"> max_depth </em>)和标准。这些参数<strong class="lh ja">是可调的</strong>，可以直接影响模型训练的好坏。</p><p id="f379" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后<strong class="lh ja">超参数优化</strong>是寻找超参数值的正确组合的过程，以便在合理的时间内实现数据的最高性能。它在机器学习算法的预测准确性方面起着至关重要的作用。因此，超参数优化被认为是构建机器学习模型中最棘手的部分。</p><p id="9c44" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这些机器学习算法中的大多数都带有默认的超参数值。默认值并不总是在不同类型的机器学习项目中表现良好，这就是为什么你需要优化它们，以获得最佳性能的正确组合。</p><blockquote class="mz"><p id="c3d1" class="na nb iq bd nc nd ne nf ng nh ni ma dk translated">一个好的超参数选择真的可以让一个算法大放异彩。</p></blockquote><p id="5974" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">有一些优化超参数的常用策略:</p><h2 id="465a" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">(a)网格搜索</h2><p id="0ccd" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">这是一种广泛使用的传统方法，通过执行超参数调整来确定给定模型的最佳值。网格搜索通过尝试你想要在你的模型中尝试的参数的每一个可能的组合来工作，这意味着它将花费<strong class="lh ja">很多时间</strong>来执行整个搜索，这可能变得非常计算昂贵。</p><p id="cb2b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">注意:</strong>你可以在这里学习如何实现网格搜索<a class="ae le" href="https://github.com/Davisy/Hyperparameter-Optimization-Techniques/blob/master/GridSearchCV%20.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="c1cd" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">随机搜索</h2><p id="e5c8" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">这种方法的工作方式不同，其中超参数值的<strong class="lh ja">随机</strong>组合被用于<strong class="lh ja">寻找</strong>所建模型的最佳解决方案。随机搜索的缺点是有时会错过搜索空间中的重要点(值)。</p><p id="a97c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">注意:你可以在这里了解更多实现随机搜索的方法。</p><h1 id="54b3" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">替代超参数优化技术。</h1><p id="879d" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在这一系列文章中，我将向您介绍不同的高级超参数优化技术/方法，它们可以帮助您获得给定模型的最佳参数。我们将研究以下技术。</p><ul class=""><li id="b009" class="nz oa iq lh b li lj ll lm lo ob ls oc lw od ma oe of og oh bi translated">远视</li><li id="f5ce" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated">Scikit优化</li><li id="515d" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated">奥普图纳</li></ul><p id="b86c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在本文中，我将重点介绍<strong class="lh ja">hyperpt</strong>的实现。</p><blockquote class="mz"><p id="db9e" class="na nb iq bd nc nd ne nf ng nh ni ma dk translated"><em class="on">如果您没有执行超参数优化，您需要现在就开始。</em></p></blockquote><h1 id="bcd8" class="mb mc iq bd md me mf mg mh mi mj mk ml kf oo kg mn ki op kj mp kl oq km mr ms bi translated">什么是远视</h1><p id="57bf" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">Hyperopt是一个强大的超参数优化python库，由James Bergstra开发。Hyperopt使用一种贝叶斯优化形式进行参数调整，允许您获得给定模型的最佳参数。它可以大规模地优化一个具有数百个参数的模型。</p><div class="or os gp gr ot ou"><a href="https://www.datadriveninvestor.com/2020/07/23/learn-data-science-in-a-flash/" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd ja gy z fp oz fr fs pa fu fw iz bi translated">一瞬间学会数据科学！？数据驱动的投资者</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">在我之前的职业生涯中，我是一名训练有素的古典钢琴家。还记得那些声称你可以…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi ky ou"/></div></div></a></div><h1 id="e05c" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">远视的特征</h1><p id="669a" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">Hyperopt包含4个你需要知道的重要特性，以便运行你的第一次优化。</p><h2 id="9763" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">(一)搜索空间</h2><p id="316b" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">超点具有不同的函数来指定输入参数的范围，这些是随机搜索空间。搜索空间最常见的选项有:</p><ul class=""><li id="16b1" class="nz oa iq lh b li lj ll lm lo ob ls oc lw od ma oe of og oh bi translated"><strong class="lh ja"> hp.choice(label，options) </strong> —这可用于分类参数，它返回选项之一，应该是列表或元组。例如:hp.choice("criterion "，["gini "，" entropy",])</li><li id="5a96" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated"><strong class="lh ja"> hp.randint(label，upper) </strong> —可用于整数参数，返回(0，upper)范围内的随机整数。示例:hp.randint("max_features "，50)</li><li id="9a1e" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated"><strong class="lh ja"> hp.uniform(label，low，high) </strong> —在<code class="fe pj pk pl pm b">low</code>和<code class="fe pj pk pl pm b">high</code>之间统一返回值，例如:hp.uniform("max_leaf_nodes "，1，10)</li></ul><p id="60dd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您可以使用其他选项有:</p><ul class=""><li id="925b" class="nz oa iq lh b li lj ll lm lo ob ls oc lw od ma oe of og oh bi translated"><strong class="lh ja"> hp.normal(label，mu，sigma)</strong>-返回一个正态分布的真实值，其平均值为mu，标准差为sigma</li><li id="5996" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated"><strong class="lh ja"> hp.qnormal(label，mu，sigma，q) </strong> —这将返回一个类似round(normal(mu，sigma) / q) * q的值</li><li id="cd9f" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated"><strong class="lh ja"> hp.lognormal(label，mu，sigma) </strong> —返回根据exp(normal(mu，sigma))得出的值</li><li id="d435" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated"><strong class="lh ja"> hp.qlognormal(label，mu，sigma，q) </strong> —返回类似round(exp(normal(mu，sigma)) / q) * q的值</li></ul><p id="62ae" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">你可以在这里了解更多搜索空间选项<a class="ae le" href="https://github.com/hyperopt/hyperopt/wiki/FMin#21-parameter-expressions" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="7d3e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">注意:</strong>每个可优化的随机表达式都有一个标签(例如n个估计量)作为第一个参数。这些标签用于在优化过程中向调用者返回参数选择。</p><h2 id="2dff" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">目标函数</h2><p id="350c" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">这是一个最小化函数，它从搜索空间接收超参数值作为输入，并返回损失。这意味着在优化过程中，我们用选定的超参数值训练模型，预测目标特征，然后评估预测误差并将其反馈给优化器。优化器将决定检查哪些值并再次迭代。你将在一个实例中学习如何创建一个目标函数。</p><h2 id="cf35" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">fmin</h2><p id="2804" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">fmin函数是优化函数，其迭代不同组的算法及其超参数，然后最小化目标函数。fmin接受5个输入，它们是:-</p><ul class=""><li id="1fd5" class="nz oa iq lh b li lj ll lm lo ob ls oc lw od ma oe of og oh bi translated">最小化的目标函数</li><li id="c5bc" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated">定义的搜索空间</li><li id="1965" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated">要使用的搜索算法，例如随机搜索、TPE(树Parzen估计器)和自适应TPE。<br/> <strong class="lh ja"> NB: </strong> <code class="fe pj pk pl pm b">hyperopt.rand.suggest</code>和<code class="fe pj pk pl pm b">hyperopt.tpe.suggest</code>为超参数空间的顺序搜索提供逻辑。</li><li id="e0c4" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated">最大评估次数。</li><li id="f37d" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated">trials对象(可选)。</li></ul><p id="2983" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">示例:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><h2 id="e758" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">(四)审判对象</h2><p id="eeae" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">Trials对象用于保存所有超参数、损耗和其他信息，这意味着您可以在运行优化后访问它们。此外，试验可以帮助您保存重要信息，稍后加载，然后恢复优化过程。(您将在实际示例中了解更多信息)。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="b097" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在了解了远视的重要特征之后，在以下步骤中描述了使用远视的方法。</p><ul class=""><li id="b41b" class="nz oa iq lh b li lj ll lm lo ob ls oc lw od ma oe of og oh bi translated">初始化要搜索的空间。</li><li id="da2b" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated">定义目标函数。</li><li id="22f9" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated">选择要使用的搜索算法。</li><li id="feb6" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated">运行远视功能。</li><li id="8cee" class="nz oa iq lh b li oi ll oj lo ok ls ol lw om ma oe of og oh bi translated">分析存储在<strong class="lh ja">试验对象</strong>中的评估输出。</li></ul><h1 id="985c" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">实践中的超波特</h1><p id="268a" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">现在您已经知道了Hyperopt的重要特性，在这个实际例子中，我们将使用<strong class="lh ja">手机价格数据集</strong>，任务是创建一个模型来预测手机的价格有多高，即0( <em class="my">低成本</em>)或1( <em class="my">中等成本</em>)或2( <em class="my">高成本</em>)或3( <em class="my">非常高成本</em>)。</p><h2 id="d3e0" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">安装Hyperopt</h2><p id="d25b" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">您可以从PyPI安装hyperopt。</p><pre class="kp kq kr ks gt pp pm pq pr aw ps bi"><span id="15f5" class="no mc iq pm b gy pt pu l pv pw">pip install hyperopt</span></pre><p id="59f0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后进口重要包包括Hyperopt。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><h2 id="c668" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">资料组</h2><p id="09b2" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">让我们从数据目录加载数据集。要获得关于数据集的更多信息，请阅读此处的<a class="ae le" href="https://www.kaggle.com/iabhishekofficial/mobile-price-classification?select=train.csv" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="60e7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">检查数据集的前五行。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi px"><img src="../Images/eda23aee8d93772540172deec902a823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WhTZ7XNaXbdbo6cs0jS9Yw.png"/></div></div></figure><p id="21e9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如您所见，在我们的数据集中，我们有不同的带有数值的要素。</p><p id="dbc8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们观察数据集的形状。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="4ebf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi">(2000, 21)</p><p id="d32a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这个数据集中，我们有<em class="my"> 2000行</em>和<em class="my"> 21列</em>。现在，让我们来了解一下该数据集中的要素列表。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="9844" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">['battery_power '，' blue '，' clock_speed '，' dual_sim '，' fc '，' four_g '，' int_memory '，' m_dep '，' mobile_wt '，' n_cores '，' pc '，' px_height '，' px_width '，' ram '，' sc_h '，' sc_w '，' talk_time '，' three_g '，' touch_screen '，' wifi '，' price_range']</p><p id="e5d7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">你可以在这里找到每个列名<a class="ae le" href="https://www.kaggle.com/iabhishekofficial/mobile-price-classification" rel="noopener ugc nofollow" target="_blank">的含义。</a></p><h2 id="1b7c" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">将数据集分割成目标要素和独立要素</h2><p id="1577" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">这是一个分类问题，我们将从数据集中分离目标特征和独立特征。我们的目标功能是<strong class="lh ja">价格范围</strong>。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><h2 id="3fd6" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">预处理数据集。</h2><p id="22b0" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">然后使用scikit-learn中的<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank">standard scaler</a>方法对独立特征进行标准化。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><h2 id="37ab" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">定义优化的参数空间</h2><p id="a94a" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">我们将使用<strong class="lh ja">随机森林算法</strong>的三个超参数，即<em class="my"> n_estimators、max_depth和criterion </em>。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="07e4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们在上面选择的超参数中设置了不同的值。然后我们将定义目标函数。</p><h2 id="a3f1" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">定义一个函数来最小化(目标函数)</h2><p id="3913" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">我们最小化的函数叫做<strong class="lh ja">超参数调整</strong>，优化其超参数的分类算法是<strong class="lh ja">随机森林</strong>。我使用交叉验证来避免过度拟合，然后函数将返回一个损失值及其状态。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="d16a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">注意:记住<a class="ae le" href="https://github.com/hyperopt/hyperopt/tree/master/hyperopt" rel="noopener ugc nofollow" target="_blank">远视</a>最小化功能，这就是为什么我在<strong class="lh ja"> acc </strong>中添加负号:</p><h2 id="2332" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">微调模型</h2><p id="07a9" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">最后，首先实例化试验对象，微调模型，然后打印最佳损失及其超参数值。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="11f5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">100%|█████████████████████████████████████████████████████████| 100/100[10:30 &lt; 00:00，6.30s/试，最佳损失:-0.8915]最佳:{'criterion': 1，' max_depth': 11.0，' n_estimators': 2}。</p><p id="22c0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在进行超参数优化后，损失为<strong class="lh ja"> -0.8915 </strong>意味着在随机森林分类器中使用<em class="my"> n_estimators = 300，max_depth = 11，criterion = "entropy" </em>，模型性能具有<strong class="lh ja"> 89.15% </strong>的准确度。</p><h2 id="9649" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">使用试验对象分析结果</h2><p id="3fa4" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">trials对象可以帮助我们检查在实验过程中计算的所有返回值。</p><p id="bda1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> (a) trials.results <br/> </strong>这显示了搜索期间“目标”返回的词典列表。</p><pre class="kp kq kr ks gt pp pm pq pr aw ps bi"><span id="4143" class="no mc iq pm b gy pt pu l pv pw">trials.results</span></pre><p id="871a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[{'loss': -0.879000000000001，' status': 'ok'}，{'loss': -0.877，' status': 'ok'}，{'loss': -0.768，' status': 'ok'}，{'loss': -0.8205，' status': 'ok'}，{ ' loss ':-0.87200000000000001，' status': 'ok'}，{ ' loss ':' loss ':' ok ' }，{ ' loss ':-0.]</p><p id="1bfd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">(b)trials . loss()<br/></strong>这显示了一个损失列表(每个‘ok’试验的浮动)。</p><pre class="kp kq kr ks gt pp pm pq pr aw ps bi"><span id="93ef" class="no mc iq pm b gy pt pu l pv pw">trials.losses()</span></pre><p id="97b4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi">[-0.8790000000000001, -0.877, -0.768, -0.8205, -0.8720000000000001, -0.883, -0.8554999999999999, -0.8789999999999999, -0.595, -0.8765000000000001, -0.877, ………]</p><p id="5043" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">(c)trials . status()<br/></strong>显示状态字符串列表。</p><pre class="kp kq kr ks gt pp pm pq pr aw ps bi"><span id="7bd5" class="no mc iq pm b gy pt pu l pv pw">trials.statuses()</span></pre><p id="3fd5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">['ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '，' ok '。]</p><p id="7ad4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">注意:</strong>该试验对象可以被保存，传递给内置绘图程序，或使用您自己的定制代码进行分析。</p><h1 id="c94e" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">包扎</h1><p id="e84c" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">恭喜你，你已经完成了这篇文章的结尾！</p><p id="106f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您可以在这里下载本文中使用的数据集和笔记本:<br/><a class="ae le" href="https://github.com/Davisy/Hyperparameter-Optimization-Techniques" rel="noopener ugc nofollow" target="_blank">https://github . com/Davisy/Hyperparameter-Optimization-Techniques</a></p><h2 id="7b5e" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">下一步是什么？</h2><p id="c485" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在第2部分中，我将介绍第二种可选的超参数优化技术，称为<strong class="lh ja"> Scikit-Optimize </strong>。</p><p id="72ce" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="my">更新:系列第二部现已面世点击</em> <a class="ae le" href="https://medium.com/datadriveninvestor/alternative-hyperparameter-optimization-techniques-you-need-to-know-part-2-e9b0d4d080a9" rel="noopener"> <em class="my">此处</em> </a> <em class="my">阅读。</em></p><p id="81b1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你学到了新的东西或者喜欢阅读这篇文章，请分享给其他人看。在那之前，第2部分再见！。也可以通过Twitter <a class="ae le" href="https://twitter.com/Davis_McDavid" rel="noopener ugc nofollow" target="_blank"> @Davis_McDavid </a>找到我</p><h2 id="a562" class="no mc iq bd md np nq dn mh nr ns dp ml lo nt nu mn ls nv nw mp lw nx ny mr iw bi translated">访问专家视图— <a class="ae le" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>