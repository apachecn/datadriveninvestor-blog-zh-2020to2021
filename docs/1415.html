<html>
<head>
<title>Loan Borrower Classification Using Random Forest and Support Vector Machine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于随机森林和支持向量机的借款人分类</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/loan-borrower-classification-using-random-forest-and-support-vector-machine-5226c81bcf02?source=collection_archive---------3-----------------------#2020-03-17">https://medium.datadriveninvestor.com/loan-borrower-classification-using-random-forest-and-support-vector-machine-5226c81bcf02?source=collection_archive---------3-----------------------#2020-03-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9789" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何实现虚拟变量、使用StandardScaler缩放特征、通过GridSearchCV优化参数以及选择最佳模型。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9c143d91c536f83dd0eadc882f359432.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*d0ErNhHAlVvGYDJj"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@alschim?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Alexander Schimmeck</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="c5e5" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">背景</h1><p id="4dc0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="http://www.lendingclub.com/" rel="noopener ugc nofollow" target="_blank"> Lending Club </a>把需要钱的人(借款人)和有钱的人(投资人)联系起来。投资者倾向于把钱给那些风险较小、更有可能还贷的人。也就是说，我们将预测借款人是否全额偿还了贷款。</p><p id="bcdc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为此，我们将使用相同的训练/测试数据创建一个随机森林模型<em class="ms">和</em>一个支持向量模型。<strong class="lt iu">最终模型将最大限度地减少预测已全额偿还贷款但实际上没有偿还的借款人数量</strong>(我们的模型选择标准)。换句话说，我们希望<strong class="lt iu">最小化我们的I型错误</strong>的大小，这与最小化假阳性的总数是一回事。</p><div class="mt mu gp gr mv mw"><a href="https://www.datadriveninvestor.com/2019/01/30/machine-learning-for-stock-market-investing/" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd iu gy z fp nb fr fs nc fu fw is bi translated">算法交易的机器学习|数据驱动的投资者</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">当你的一个朋友在脸书上传你的新海滩照，平台建议给你的脸加上标签，这是…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk ks mw"/></div></div></a></div><p id="2c5c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">该数据集包含以下特征:</p><ul class=""><li id="b0e2" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated"><strong class="lt iu"> credit.policy </strong>:如果客户符合LendingClub.com的信用核保标准，则为1，否则为0</li><li id="c317" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu">用途</strong>:贷款用途</li><li id="0502" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu">利率</strong>:贷款的利率，按比例计算</li><li id="7fc2" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu">分期付款</strong>:借款人在贷款到位的情况下所欠的每月分期付款</li><li id="a8b3" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu"> log.annual.inc </strong>:借款人自报年收入的自然日志</li><li id="0545" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu"> dti </strong>:借款人的债务收入比</li><li id="f91f" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu"> fico </strong>:借款人的fico信用评分</li><li id="906b" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu">天数:借款人拥有信用额度的天数</strong></li><li id="5bf5" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu">循环余额</strong>:借款人的循环余额</li><li id="40c6" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu">循环使用</strong>:借款人循环额度使用率</li><li id="45a5" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu"> inq.last.6mths </strong>:借款人最近6个月被债权人查询的次数</li><li id="e422" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu">拖欠2年</strong>:在过去的2年中，借款人逾期付款超过30天的次数</li><li id="4a75" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu"> pub.rec </strong>:借款人的贬损公共记录数量</li><li id="ac01" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu">未足额偿还</strong> : 1表示借款人未足额偿还贷款，0表示借款人已足额偿还贷款</li></ul><p id="ce72" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="ms">点击</em> <a class="ae ky" href="https://github.com/mokaiser/loan-borrower-classification-rf-svm" rel="noopener ugc nofollow" target="_blank"> <em class="ms">这里</em> </a> <em class="ms">获取数据集，在GitHub上看我的完整代码。</em></p><h1 id="8d8a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">导入库和数据</h1><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="13c0" class="oe la it oa b gy of og l oh oi">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>%matplotlib inline</span><span id="8afe" class="oe la it oa b gy oj og l oh oi">df = pd.read_csv('loan_data.csv')<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/1c4020134bc37739ecf351d57ad0bce5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZAzzqUEk-nMDySyc6Kbt7A.png"/></div></div></figure><h1 id="c96a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">探索性数据分析</h1><p id="64a0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">“在进行任何操作之前，先弄清楚我们在处理什么。”</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="2c5e" class="oe la it oa b gy of og l oh oi">df.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/866bf7ed4967a36c9aefab22556936d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*zTuHA1SAwDxHL6myktP-DQ.png"/></div></figure><p id="2efd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">其中:</p><ul class=""><li id="a038" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated">共14列</li><li id="3127" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">9578行</li><li id="9829" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">没有空值</li><li id="ac9b" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu">目的</strong>列属于对象dtype - &gt;提示:稍后需要转换它</li></ul><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="5961" class="oe la it oa b gy of og l oh oi">df.describe()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/e69244ae83d3ced574214cd18df609f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bTT_I9iLsu4Oqb2aN6AmzQ.png"/></div></div></figure><p id="1d61" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这是所有14个专栏的快速统计摘要。检查最大值。请注意，与其他列的最大值(<strong class="lt iu"> days.with.cr.line max = 17，639 </strong>)相比，一些列的最大值(<strong class="lt iu"> int.rate max = .21 </strong>)非常小？这是一个<strong class="lt iu">指标，表明在通过我们的模型运行数据之前，我们需要调整数据</strong>。</p><p id="a8d0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">来自<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn文档</a>:</p><blockquote class="on"><p id="63ce" class="oo op it bd oq or os ot ou ov ow mm dk translated">“标准化包括重新调整要素的比例，使其具有均值为零、标准差为一的标准正态分布的属性。”</p></blockquote><p id="1b3b" class="pw-post-body-paragraph lr ls it lt b lu ox ju lw lx oy jx lz ma oz mc md me pa mg mh mi pb mk ml mm im bi translated">简而言之，数据标准化就是当我们把我们的特征(也就是自变量，也就是预测值，也就是数字列)放在一个相似的尺度上。这就是我们如何最大限度地减少对某些功能赋予过多权重而导致结果失真的可能性。</p><h1 id="c28b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">数据清理</h1><p id="9f74" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">还记得我给你的关于<em class="ms">目的</em>列是对象数据类型的提示吗(参见探索性数据分析部分)？这意味着这是一个分类变量，我们现在需要把它转换成哑变量。如果我们不这样做，那么我们的模型就不能读取我们的数据。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="cebb" class="oe la it oa b gy of og l oh oi">purpose = pd.get_dummies(df['purpose'])<br/>purpose.head()</span></pre><p id="f67c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">其中:</p><ul class=""><li id="887c" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated"><a class="ae ky" href="https://towardsdatascience.com/the-dummys-guide-to-creating-dummy-variables-f21faddb1d40" rel="noopener" target="_blank"> pd.get_dummies </a>创建一个名为<em class="ms">目的</em>的新数据帧，由0和1组成</li><li id="d0b8" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><em class="ms">目的</em>将有一个1，这取决于贷款的目的</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/5b547d14df9dceae0bf5171a9f7c2b82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pfwkYlZq6j8oa45oJ8DaVw.png"/></div></div></figure><p id="054f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在删除原始“目的”列的同时，将原始数据帧与新创建的目的数据帧连接(也称为组合)。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="3bba" class="oe la it oa b gy of og l oh oi">df2 = pd.concat([df, purpose], axis=1)<br/>df2.drop(['purpose'], axis=1, inplace=True)<br/>df2.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/d450f00ecdb538048914484e493ce630.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fGWqdevBZQWZj-cbyNtOsA.png"/></div></div></figure><h1 id="99ab" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><em class="pe">数据预处理</em></h1><p id="08dd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="ms">请注意</em> <a class="ae ky" href="https://www.geeksforgeeks.org/python-how-and-where-to-apply-feature-scaling/" rel="noopener ugc nofollow" target="_blank"> <em class="ms">基于树的算法</em> </a> <em class="ms">(我们的随机森林模型)不受特征缩放的影响，因为它们不是基于距离的，然而，我们的SVM模型是。因为我们对两个模型使用相同的训练和测试集，所以我们仍然需要扩展我们的功能。</em></p><h2 id="de08" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">步骤1:将数据分成X和y两部分</h2><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="fc7a" class="oe la it oa b gy of og l oh oi">from sklearn.model_selection import train_test_split</span><span id="dc1f" class="oe la it oa b gy oj og l oh oi">X = df2.drop('not.fully.paid', axis=1)<br/>y = df2['not.fully.paid']</span></pre><h2 id="4d6e" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">步骤2:特征缩放</h2><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="551d" class="oe la it oa b gy of og l oh oi"><strong class="oa iu"># scaling all features - important step here! <br/></strong>from sklearn.preprocessing import StandardScaler</span><span id="890a" class="oe la it oa b gy oj og l oh oi">sc = StandardScaler()<br/>X_scaled = sc.fit_transform(X)</span></pre><h2 id="ece5" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">步骤3:将数据分为训练集和测试集</h2><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="343a" class="oe la it oa b gy of og l oh oi">X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,<br/>                                                    test_size=0.30)</span></pre><p id="009a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，我们已经扩展了我们的功能并将数据分为训练集和测试集，我们可以构建我们的随机森林模型和支持向量机模型。:)</p><h1 id="e37a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">随机森林分类器</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/315969f97d27241aab3d3b152c6af827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZkZEXTo0ns60LCoX"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@ozarkdrones?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ozark Drones</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="42a6" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">步骤1:构建、训练和预测</h2><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="1ddb" class="oe la it oa b gy of og l oh oi">from sklearn.ensemble import RandomForestClassifier</span><span id="3577" class="oe la it oa b gy oj og l oh oi">rfc = RandomForestClassifier(random_state=42)<br/>rfc.fit(X_train, y_train)<br/>rfc_pred = rfc.predict(X_test)</span></pre><h2 id="0322" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">第二步:评估(没有GridSearchCV)</h2><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="3e36" class="oe la it oa b gy of og l oh oi">from sklearn.metrics import classification_report,confusion_matrix<br/>confusion_matrix(y_test, rfc_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/984da936ca7401e2f038df8e348b6472.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*FUB3Ekbun74WgtPl31ttDw.png"/></div></figure><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="6516" class="oe la it oa b gy of og l oh oi">classification_report(y_test, rfc_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ps"><img src="../Images/665f4fa966a6136ef2e3ea6cc7b525b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aTvb2iR9jgsf0xs94w8wKQ.png"/></div></div></figure><h2 id="2e66" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">步骤3:设置GridSearchCV</h2><p id="96d0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">让我们通过测试以下内容来找到RFC的最佳参数:</p><ul class=""><li id="7c36" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated">n _估计值:10，50，100，200，300，500，800</li><li id="0d58" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">最大深度:4，5，6，7，8</li><li id="6e77" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">标准:熵、基尼系数</li></ul><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="c78c" class="oe la it oa b gy of og l oh oi">from sklearn.model_selection import GridSearchCV<br/>rfc_param_grid = {'n_estimators': [10, 50, 100, 200, 300, 500, 800],<br/>                  'max_depth': [4, 5, 6, 7, 8],<br/>                  'criterion': ['entropy', 'gini']}</span><span id="f183" class="oe la it oa b gy oj og l oh oi">rfc_grid = GridSearchCV(estimator=rfc,<br/>                        param_grid=rfc_param_grid,<br/>                        refit=True,<br/>                        verbose = 3)</span><span id="7785" class="oe la it oa b gy oj og l oh oi"><strong class="oa iu"># fitting our model with optimized parameters<br/></strong>rfc_grid.fit(X_train,y_train)</span><span id="1c4a" class="oe la it oa b gy oj og l oh oi"><strong class="oa iu"># finding our best estimators<br/></strong>optimizedRFC = rfc_grid.best_estimator_<br/>optimizedRFC</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/f87a5625f966300efa268f511835b170.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DRg7mJDjr5v2ntwRndOeJw.png"/></div></div></figure><h2 id="87e5" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">步骤4:重新运行预测并评估(使用GridSearchCV)</h2><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="1c4d" class="oe la it oa b gy of og l oh oi"><strong class="oa iu"># re-running preds<br/></strong>rfc_grid_pred = optimizedRFC.predict(X_test)</span><span id="376b" class="oe la it oa b gy oj og l oh oi"><strong class="oa iu"># re-evaluating<br/></strong>confusion_matrix(y_test, rfc_grid_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/c803ff176103e2e2fcd9dc1bb9de20b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*dNf6VSHJiiUEb3cvv9Y9HQ.png"/></div></figure><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="977d" class="oe la it oa b gy of og l oh oi">classification_report(y_test, rfc_grid_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pv"><img src="../Images/2a9bb99049748533c40915c371798fc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X_jO0RBIoSbMXLzta4kJRw.png"/></div></div></figure><h2 id="2109" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">步骤5:比较我们的1型误差的大小</h2><p id="5392" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="ms">让我们看看将GridSearchCV用于我们的随机森林分类器模型如何影响我们的准确性和假阳性总数。</em></p><p id="86c2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> RFC </strong></p><ul class=""><li id="b47b" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated">84次误报</li><li id="4a7b" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">96.1%的准确率</li></ul><p id="35c8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">优化的FC </strong></p><ul class=""><li id="8130" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated">31次误报</li><li id="eba3" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">98.6%的准确率</li></ul><h1 id="9b61" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">支持向量机</h1><h2 id="2ae2" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">步骤1:构建、训练和预测</h2><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="e21a" class="oe la it oa b gy of og l oh oi">from sklearn.svm import SVC<br/>svm = SVC()<br/>svm.fit(X_train, y_train)<br/>svm_pred = svm.predict(X_test)</span></pre><h2 id="12ae" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">第二步:评估(没有GridSearchCV)</h2><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="defb" class="oe la it oa b gy of og l oh oi">confusion_matrix(y_test, svm_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/7accd164915380d8c99d779cb9e16e21.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*yllVp2oC3vlhK78Mw6QT4g.png"/></div></figure><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="aa92" class="oe la it oa b gy of og l oh oi">classification_report(y_test, svm_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pw"><img src="../Images/b1fd4f997348517890db8053dc3b6a5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qnaXfvVoZwvrOt3YUXdWYw.png"/></div></div></figure><h2 id="8ce6" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">步骤3:设置网格搜索</h2><p id="00c8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">让我们通过测试以下内容来找到SVM的最佳参数:</p><ul class=""><li id="52d6" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated">c值:0.1，1，10</li><li id="17eb" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">伽玛值:“自动”、“缩放”</li><li id="4cb8" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">内核:' poly '，' linear '，' rbf '</li></ul><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="ebb4" class="oe la it oa b gy of og l oh oi">svm_param_grid = {'C': [0.1, 1, 10],<br/>                 'gamma': ['auto','scale'],<br/>                 'kernel': ['poly','linear','rbf']}</span><span id="bc38" class="oe la it oa b gy oj og l oh oi">svm_grid = GridSearchCV(estimator=svm,<br/>                        param_grid=svm_param_grid,<br/>                        refit=True,<br/>                        verbose=3)</span><span id="9856" class="oe la it oa b gy oj og l oh oi"><strong class="oa iu"># fitting our model with optimized parameters<br/></strong>svm_grid.fit(X_train,y_train)</span><span id="745c" class="oe la it oa b gy oj og l oh oi"><strong class="oa iu"># finding our best estimators<br/></strong>optimizedSVM = svm_grid.best_estimator_<br/>optimizedSVM</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi px"><img src="../Images/4ceef2e0acde043885c4877008f73b0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c19fVm7VNt6fjmwYXHPZ0g.png"/></div></div></figure><h2 id="558c" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">步骤4:重新运行预测并评估(使用GridSearchCV)</h2><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="9a38" class="oe la it oa b gy of og l oh oi"><strong class="oa iu"># re-running preds<br/></strong>svm_grid_pred = optimizedSVM.predict(X_test)</span><span id="32ba" class="oe la it oa b gy oj og l oh oi"><strong class="oa iu"># re-evaluating<br/></strong>confusion_matrix(y_test, svm_grid_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/fa789ed31f7622031c3f8ceed69c9bf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*twcEH8NBERmQCnJgIjthjQ.png"/></div></figure><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="43f4" class="oe la it oa b gy of og l oh oi">classification_report(y_test, svm_grid_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi py"><img src="../Images/ebbf90067b36f234b5630492628dc545.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xBREkVNrSlG-JjMeF1uN7w.png"/></div></div></figure><h2 id="cb2e" class="oe la it bd lb pf pg dn lf ph pi dp lj ma pj pk ll me pl pm ln mi pn po lp pp bi translated">步骤5:比较我们的1型误差的大小</h2><p id="24b6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="ms">让我们看看将GridSearchCV用于我们的支持向量分类器模型如何影响我们的准确性和假阳性总数。</em></p><p id="1e41" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> SVM </strong></p><ul class=""><li id="5bdd" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated">62次误报</li><li id="d5ce" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">97.1%的准确率</li></ul><p id="51a2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">优化的虚拟机</strong></p><ul class=""><li id="9beb" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated">125次误报</li><li id="070c" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">94.2%的准确率</li></ul><p id="588a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">等等，我们所谓的<em class="ms">优化过的</em>模型怎么表现得更差？<a class="ae ky" href="https://stackoverflow.com/questions/52935644/gridsearchcv-performs-worse-than-vanilla-svm-using-the-same-parameters" rel="noopener ugc nofollow" target="_blank"> GridSearchCV默认执行K重交叉验证</a>，将数据拆分为训练和验证。这意味着该模型从不使用整个数据集进行训练，而是使用未经训练的数据进行预测/验证。</p><h1 id="cd61" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="a31c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们的模型选择标准是选择最小化I型错误(也就是假阳性的数量)的模型。根据我们的数据，我们问自己<strong class="lt iu">哪种模型可以最大限度地减少预测会全额偿还贷款但实际上没有偿还的借款人数量？</strong></p><ul class=""><li id="6b4f" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated">RFC预测了84个假阳性(96.1%的准确度)</li><li id="a06b" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated"><strong class="lt iu"> OptimizedRFC预测了31个假阳性</strong> (98.6%的准确率)</li><li id="75da" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">SVM预测了62个假阳性(97.1%的准确率)</li><li id="b096" class="nl nm it lt b lu nu lx nv ma nw me nx mi ny mm nq nr ns nt bi translated">优化的SVM预测了125个假阳性<strong class="lt iu"> </strong> (94.2%的准确率)</li></ul><p id="f7ab" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">也就是说，<strong class="lt iu"> OptimizedRFC模型是我们的最终赢家，因为它具有最低的误报率和最高的准确率；因此，最大限度地减少我们的1型误差。</strong></p><h1 id="4e3e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">文档链接</h1><p id="3986" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank">sk learn . preprocessing . standard scaler</a></p><p id="39b5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html" rel="noopener ugc nofollow" target="_blank"> pandas.get_dummies </a></p><p id="8c36" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV.fit" rel="noopener ugc nofollow" target="_blank"> sklearn.model_selection。GridSearchCV </a></p><h1 id="abac" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><p id="e9a5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="https://www.quora.com/What-is-feature-scaling" rel="noopener ugc nofollow" target="_blank">什么是特征缩放</a></p><p id="435c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://www.geeksforgeeks.org/python-how-and-where-to-apply-feature-scaling/" rel="noopener ugc nofollow" target="_blank">如何以及在哪里应用特征缩放</a></p><p id="6503" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://stackoverflow.com/questions/15436367/svm-scaling-input-values" rel="noopener ugc nofollow" target="_blank">为什么缩放对于SVM分类很重要</a></p><p id="3e08" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://humansofdata.atlan.com/2018/12/data-standardization/" rel="noopener ugc nofollow" target="_blank">为什么数据标准化很重要</a></p><p id="a879" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://towardsdatascience.com/the-dummys-guide-to-creating-dummy-variables-f21faddb1d40" rel="noopener" target="_blank">创建虚拟变量的虚拟指南</a></p><p id="fbf4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://stackoverflow.com/questions/52935644/gridsearchcv-performs-worse-than-vanilla-svm-using-the-same-parameters" rel="noopener ugc nofollow" target="_blank">GridSearchCV的表现如何不如标准SVM </a></p><h1 id="39fa" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">作者注释</h1><p id="c0ad" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="ms">感谢阅读！请随时关注我的</em> <a class="ae ky" href="https://medium.com/@kaiserm" rel="noopener"> <em class="ms">中</em> </a> <em class="ms">和</em><a class="ae ky" href="https://www.linkedin.com/in/kaisermorgan" rel="noopener ugc nofollow" target="_blank"><em class="ms">LinkedIn</em></a><em class="ms">。我很乐意继续对话，听听你的想法/建议。</em></p><ul class=""><li id="79ee" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated"><em class="ms">莫</em></li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pz qa l"/></div></figure></div></div>    
</body>
</html>