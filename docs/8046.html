<html>
<head>
<title>[ML UTD 29] Machine Learning Up-To-Date — Life With Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[ML UTD 29]机器学习最新—数据生活</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/ml-utd-29-machine-learning-up-to-date-life-with-data-a176d9dcfaec?source=collection_archive---------29-----------------------#2020-12-30">https://medium.datadriveninvestor.com/ml-utd-29-machine-learning-up-to-date-life-with-data-a176d9dcfaec?source=collection_archive---------29-----------------------#2020-12-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="a917" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第29期每周简讯来自<a class="ae ko" href="https://lifewithdata.org/" rel="noopener ugc nofollow" target="_blank">生活有数据</a></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi kp"><img src="../Images/952a7e793d7796b815cf0906ea08cc0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3MoE9Sm3jQEC3SFh"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">(a) Standard Transformer (b) Reordering to make it PreLN © Switchable Gates (G) to decide whether to include a layer or not. (see Applications 2)</figcaption></figure><p id="1e37" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是来自<a class="ae ko" href="https://lifewithdata.org" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> LifeWithData </strong> </a>博客的ML UTD #29！在当今软件工程和机器学习的繁忙前线，我们帮助您将信号与噪声分离。</p><p id="260d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://lifewithdata.org" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> LifeWithData </strong> </a>致力于提供精心策划的机器学习&amp;软件工程更新，为读者指出没有多余细节的关键发展。这使得整个行业能够进行频繁、简洁的更新，而不会出现信息过载。</p></div><div class="ab cl lb lc hx ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="im in io ip iq"><h1 id="4d24" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">应用程序</h1><ul class=""><li id="ac43" class="mg mh it js b jt mi jx mj kb mk kf ml kj mm kn mn mo mp mq bi translated">应用MLOps生命周期</li><li id="b76d" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">NeurIPS 2020论文:深度学习工程师的收获</li><li id="38c2" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">移动机器学习:2020年回顾</li></ul><h1 id="5de3" class="li lj it bd lk ll mw ln lo lp mx lr ls lt my lv lw lx mz lz ma mb na md me mf bi translated">学术界</h1><ul class=""><li id="7b02" class="mg mh it js b jt mi jx mj kb mk kf ml kj mm kn mn mo mp mq bi translated">利用JAX加速[深度思维]研究</li><li id="5a62" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">Wav2vec 2.0:从原始音频学习语音结构</li><li id="2a62" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">神经科学家找到了让物体识别模型表现更好的方法</li></ul></div><div class="ab cl lb lc hx ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="im in io ip iq"><h1 id="50d9" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">应用MLOps生命周期</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi kp"><img src="../Images/e8fb09c1da4812352d65e3456745b843.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HRCmfcqnOTRrqyMj2uRY6Q.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image by Seldon. Shared under CC BY-SA 4.0 [<a class="ae ko" href="https://seldon.io/" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><blockquote class="nb nc nd"><p id="09d9" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated">团队可能很难掌握MLOps。这是一个新的领域，大多数负责MLOps项目的团队目前都是从不同的背景开始着手的。</p><p id="4428" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated">从另一个项目中复制一种方法是很诱人的。但是MLOps项目的需求可能会有很大的不同。需要的是了解每个MLOps项目的具体需求。这需要了解MLOps需求的类型以及它们是如何产生的。</p><p id="5302" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><a class="ae ko" href="https://towardsdatascience.com/applying-the-mlops-lifecycle-3b60033b7cbf" rel="noopener" target="_blank"> <em class="it"> …继续阅读</em> </a></p></blockquote><p id="2ef5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">《丛林奇兵》</p><ul class=""><li id="4b4d" class="mg mh it js b jt ju jx jy kb ni kf nj kj nk kn mn mo mp mq bi translated"><a class="ae ko" href="https://towardsdatascience.com/applying-the-mlops-lifecycle-3b60033b7cbf" rel="noopener" target="_blank">条</a></li><li id="249b" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://github.com/EthicalML/awesome-production-machine-learning" rel="noopener ugc nofollow" target="_blank">【Github】制作ML风景</a></li><li id="6baa" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">信用:<a class="ae ko" href="https://medium.com/@ryandawsonuk" rel="noopener"> @ryandawsonuk on Medium </a></li></ul></div><div class="ab cl lb lc hx ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="im in io ip iq"><h1 id="5423" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">NeurIPS 2020论文:深度学习工程师的收获</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi kp"><img src="../Images/9239fdc7fa1e2eb2147a7475ed7f6618.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eHuzby54xPGQH7aRApfP9A.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">(a) Standard Transformer (b) Reordering to make it PreLN © Switchable Gates (G) to decide whether to include a layer or not. (The image is reproduced from the pdf of the paper.)</figcaption></figure><blockquote class="nb nc nd"><p id="a79a" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><em class="it">深度学习研究的进展对于处理现实世界问题的深度学习工程师来说非常有用，因为大多数深度学习研究都是经验性的，在与现实世界数据集/任务非常相似的数据集上验证新技术和理论(ImageNet预训练权重仍然有用！).</em></p><p id="a11e" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated">但是，搅动大量的研究以获得与DL工程师相关的技术、见解和观点是耗时、有压力的，而且是最不可抗拒的。</p><p id="1561" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><em class="it"> [..]所以，我翻遍了NeurIPS 2020论文的所有题目(1900多！)并阅读了175篇论文的摘要，从以下论文中提取了DL engineer相关见解。</em></p><p id="075f" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><a class="ae ko" href="https://towardsdatascience.com/neurips-2020-papers-a-deep-learning-engineers-takeaway-4f3066523151" rel="noopener" target="_blank"> <em class="it"> …继续阅读</em> </a></p></blockquote><p id="e74d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">《丛林奇兵》</p><ul class=""><li id="86af" class="mg mh it js b jt ju jx jy kb ni kf nj kj nk kn mn mo mp mq bi translated"><a class="ae ko" href="https://towardsdatascience.com/neurips-2020-papers-a-deep-learning-engineers-takeaway-4f3066523151" rel="noopener" target="_blank">文章</a></li><li id="870b" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">信用:<a class="ae ko" href="https://prakashkagitha.medium.com/" rel="noopener">@ prakashkagitha on Medium</a>&amp;<a class="ae ko" href="https://twitter.com/neuripsconf" rel="noopener ugc nofollow" target="_blank">@ neuripsconf</a></li></ul></div><div class="ab cl lb lc hx ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="im in io ip iq"><h1 id="f457" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">移动机器学习:2020年回顾</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi nl"><img src="../Images/a115d3213a95eb6a535737ceec7d024e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UzcHy4cui-vferJyelLlSw.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image by the article’s author [<a class="ae ko" href="https://heartbeat.fritz.ai/mobile-machine-learning-2020-year-in-review-be5d1f1052a1" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><blockquote class="nb nc nd"><p id="a990" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><em class="it">不言而喻，2020年是一个艰难的尝试，是的，在多个层面上。封面图像中的皱巴巴的2020让人感觉立刻就能认出来并且很合适。</em></p><p id="f2d1" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><em class="it">但在这一切当中，从我们宇宙的小角落</em><a class="ae ko" href="http://fritz.ai/" rel="noopener ugc nofollow" target="_blank"><em class="it">Fritz AI</em></a><em class="it">看到移动机器学习世界以新的令人兴奋的方式成长和发展，令人振奋和鼓舞。</em></p><p id="f458" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated">我们看到了对设备上机器学习的大量直接投资，硬件和软件都取得了长足的进步，我们甚至在移动ML游戏中遇到了一个新玩家。</p><p id="0618" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated">为了给2020年划上一个圆满的句号，我们想总结一些移动机器学习领域最激动人心和最有趣的发展。2021年大家再见！</p><p id="33bf" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><a class="ae ko" href="https://heartbeat.fritz.ai/mobile-machine-learning-2020-year-in-review-be5d1f1052a1" rel="noopener ugc nofollow" target="_blank"><em class="it">……继续阅读</em> </a></p></blockquote><p id="0607" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">《丛林奇兵》</p><ul class=""><li id="254d" class="mg mh it js b jt ju jx jy kb ni kf nj kj nk kn mn mo mp mq bi translated"><a class="ae ko" href="https://heartbeat.fritz.ai/mobile-machine-learning-2020-year-in-review-be5d1f1052a1" rel="noopener ugc nofollow" target="_blank">条</a></li><li id="5de9" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="http://fritz.ai/" rel="noopener ugc nofollow" target="_blank">弗里茨·艾网站</a></li><li id="bb0c" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">信用:<a class="ae ko" href="https://medium.com/@austin_32493?source=post_page-----be5d1f1052a1--------------------------------" rel="noopener">@ Austin _ 32493 on Medium</a>&amp;<a class="ae ko" href="https://twitter.com/fritzlabs" rel="noopener ugc nofollow" target="_blank">@ fritzlabs</a></li></ul></div><div class="ab cl lb lc hx ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="im in io ip iq"><h1 id="9b57" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">利用JAX加速[深度思维]研究</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi nq"><img src="../Images/fa490c220cff1a294c78a52651531852.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uLpalJTnO-bZmgbxcEiPPQ.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Uh, it’s the JAX logo [<a class="ae ko" href="https://deepmind.com/blog/article/using-jax-to-accelerate-our-research" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><blockquote class="nb nc nd"><p id="3a89" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><em class="it"> DeepMind的工程师通过构建工具、扩展算法以及创建具有挑战性的虚拟和物理世界来训练和测试人工智能(AI)系统，从而加快了我们的研究。作为这项工作的一部分，我们不断评估新的机器学习库和框架。</em></p><p id="81ef" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated">最近，我们发现越来越多的项目得到了谷歌研究团队开发的机器学习框架JAX的良好服务。JAX与我们的工程理念产生了很好的共鸣，并在去年被我们的研究团体广泛采用。在这里，我们分享了与JAX合作的经验，概述了为什么我们发现它对我们的人工智能研究有用，并概述了我们正在建立的支持各地研究人员的生态系统。</p><p id="1834" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><a class="ae ko" href="https://deepmind.com/blog/article/using-jax-to-accelerate-our-research" rel="noopener ugc nofollow" target="_blank"> <em class="it"> …继续阅读</em> </a></p></blockquote><p id="6cf5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">《丛林奇兵》</p><ul class=""><li id="ec7f" class="mg mh it js b jt ju jx jy kb ni kf nj kj nk kn mn mo mp mq bi translated"><a class="ae ko" href="https://deepmind.com/blog/article/using-jax-to-accelerate-our-research" rel="noopener ugc nofollow" target="_blank">文章</a></li><li id="e5cc" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://github.com/google/jax#jax-autograd-and-xla-" rel="noopener ugc nofollow" target="_blank">【Github】JAX</a></li><li id="b58e" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://github.com/deepmind/dm-haiku" rel="noopener ugc nofollow" target="_blank">【Github】俳句</a></li><li id="ac00" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://github.com/deepmind/optax" rel="noopener ugc nofollow" target="_blank">【Github】Optax</a></li><li id="7866" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://github.com/deepmind/rlax" rel="noopener ugc nofollow" target="_blank">【Github】Rlax</a></li><li id="04e2" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://github.com/deepmind/chex" rel="noopener ugc nofollow" target="_blank">【Github】Chex</a></li><li id="948a" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://github.com/deepmind/jraph" rel="noopener ugc nofollow" target="_blank">【Github】Jraf</a></li><li id="1d4e" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">信用:<a class="ae ko" href="https://twitter.com/DeepMind" rel="noopener ugc nofollow" target="_blank">@ deep mind</a>&amp;<a class="ae ko" href="https://twitter.com/davidmbudden" rel="noopener ugc nofollow" target="_blank">@ davidmbudden</a>&amp;<a class="ae ko" href="https://twitter.com/matteohessel" rel="noopener ugc nofollow" target="_blank">@ matteohessel</a></li></ul><div class="nr ns gp gr nt nu"><a href="https://www.datadriveninvestor.com/2020/11/19/how-machine-learning-and-artificial-intelligence-changing-the-face-of-ecommerce/" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd iu gy z fp nz fr fs oa fu fw is bi translated">机器学习和人工智能如何改变电子商务的面貌？|数据驱动…</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">电子商务开发公司，现在，整合先进的客户体验到一个新的水平…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="od l"><div class="oe l of og oh od oi kv nu"/></div></div></a></div></div><div class="ab cl lb lc hx ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="im in io ip iq"><h1 id="9ecb" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">Wav2vec 2.0:从原始音频学习语音结构</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi oj"><img src="../Images/3f096d588147b5933708de3433fdceb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z_yHF8X_4ezIDGUPdWYOLw.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">A 2-D PCA plot of the learned representations across languages [<a class="ae ko" href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><blockquote class="nb nc nd"><p id="557e" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated">世界上有成千上万种语言，许多语言有几种不同的方言，这对构建高质量的语音识别技术提出了巨大的挑战。跨许多可能的领域(阅读语音、电话语音等)获取每种方言和每种语言的资源是完全不可行的。).我们的新模型wav2vec 2.0通过从未标记的训练数据中学习，使用自我监督来推动边界，从而为更多语言、方言和领域启用语音识别系统。只有一个小时的标记训练数据，wav2vec 2.0在LibriSpeech基准的100小时子集上优于之前的最先进水平-使用的标记数据少100倍。</p><p id="40d0" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><em class="it">类似于来自变压器(BERT)的双向编码器表示，我们的模型通过预测音频屏蔽部分的语音单元来训练。一个主要的区别是，语音音频是一个连续的信号，它捕捉录音的许多方面，没有清晰的词或其他单位的分段。Wav2vec 2.0通过学习25毫秒长的基本单元来解决这个问题，以便能够学习高级上下文化的表示。这些单元然后被用于描述许多不同的语音音频记录，并使wav2vec更加健壮。这使我们能够建立语音识别系统，它可以胜过最好的半监督方法，即使标记的训练数据少100倍。</em></p><p id="d356" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><em class="it"> Wav2vec 2.0是我们对机器学习模型愿景的一部分，由于自我监督学习，它更少依赖于标记数据。自我监督帮助我们提高了图像分类、视频理解和我们的内容理解系统。我们希望该算法能够为更多的语言、方言和领域带来改进的语音技术，并导致现有系统的改进。</em></p><p id="1444" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><a class="ae ko" href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/" rel="noopener ugc nofollow" target="_blank"> <em class="it"> …继续阅读</em> </a></p></blockquote><p id="d278" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">《丛林奇兵》</p><ul class=""><li id="7364" class="mg mh it js b jt ju jx jy kb ni kf nj kj nk kn mn mo mp mq bi translated"><a class="ae ko" href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/" rel="noopener ugc nofollow" target="_blank">文章</a></li><li id="adfb" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://arxiv.org/pdf/2006.11477.pdf" rel="noopener ugc nofollow" target="_blank">【论文】wav2vec-2.0 </a></li><li id="cad3" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://commonvoice.mozilla.org/" rel="noopener ugc nofollow" target="_blank"> CommonVoice基准</a></li><li id="c2f1" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://github.com/pytorch/fairseq/blob/master/examples/wav2vec/README.md" rel="noopener ugc nofollow" target="_blank">【Github】代码和预训练模型</a></li><li id="62c8" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://github.com/pytorch/fairseq" rel="noopener ugc nofollow" target="_blank">【Github】fair seq</a></li><li id="100c" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">鸣谢:<a class="ae ko" href="https://twitter.com/alex_conneau" rel="noopener ugc nofollow" target="_blank">@ Alex _ conneau</a>&amp;<a class="ae ko" href="https://scholar.google.com/citations?user=i7sxIX8AAAAJ&amp;hl=en" rel="noopener ugc nofollow" target="_blank">阿列克谢·巴耶夫斯基</a> &amp; <a class="ae ko" href="https://twitter.com/michaelauli" rel="noopener ugc nofollow" target="_blank"> @michaelauli </a></li></ul></div><div class="ab cl lb lc hx ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="im in io ip iq"><h1 id="130b" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">神经科学家找到了让物体识别模型表现更好的方法</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi ok"><img src="../Images/88a557a23e5439e501291fc0af28acea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*glw7Q8UfLBPYAfCITSFdIQ.png"/></div></div></figure><blockquote class="nb nc nd"><p id="77e8" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated">被称为卷积神经网络的计算机视觉模型可以被训练成几乎像人类一样准确地识别物体。然而，这些模型有一个明显的缺陷:对图像的非常小的改变，人类观察者几乎察觉不到，可以欺骗他们犯下惊人的错误，例如将猫分类为树。</p><p id="112e" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated">来自麻省理工学院、哈佛大学和IBM的神经科学家团队开发出了一种缓解这种脆弱性的方法，即在这些模型中添加一个新的层，旨在模拟大脑视觉处理系统的最早期阶段。在一项新的研究中，他们表明这一层大大提高了模型对这类错误的鲁棒性。</p><p id="7e7a" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><em class="it">“仅仅通过使模型更类似于大脑的初级视觉皮层，在这个单一的处理阶段，我们就看到了许多不同类型的干扰和破坏的鲁棒性方面的显著改善，”麻省理工学院博士后Tiago Marques说，他是该研究的主要作者之一。</em></p><p id="905e" class="jq jr ne js b jt ju jv jw jx jy jz ka nf kc kd ke ng kg kh ki nh kk kl km kn im bi translated"><a class="ae ko" href="https://news.mit.edu/2020/object-recognition-v1-1203" rel="noopener ugc nofollow" target="_blank"> <em class="it"> …继续阅读</em> </a></p></blockquote><p id="9a3d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">《丛林奇兵》</p><ul class=""><li id="5631" class="mg mh it js b jt ju jx jy kb ni kf nj kj nk kn mn mo mp mq bi translated"><a class="ae ko" href="https://news.mit.edu/2020/object-recognition-v1-1203" rel="noopener ugc nofollow" target="_blank">文章</a></li><li id="178c" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://youtu.be/6KBkS5qeCIE" rel="noopener ugc nofollow" target="_blank">【YouTube】文章附带的视频</a></li><li id="7fb7" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><a class="ae ko" href="https://proceedings.neurips.cc/paper/2020/hash/98b17f068d5d9b7668e19fb8ae470841-Abstract.html" rel="noopener ugc nofollow" target="_blank">【论文】模拟中枢神经系统前部的初级视觉皮层改善了[…] </a></li><li id="ad4f" class="mg mh it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">致谢:<a class="ae ko" href="https://news.mit.edu/" rel="noopener ugc nofollow" target="_blank">麻省理工学院新闻</a></li></ul></div><div class="ab cl lb lc hx ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="im in io ip iq"><h1 id="5aba" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">保持最新状态</h1><p id="28b0" class="pw-post-body-paragraph jq jr it js b jt mi jv jw jx mj jz ka kb ol kd ke kf om kh ki kj on kl km kn im bi translated">ML UTD #29到此为止。然而，在学术界和工业界，事情发生得很快！除了ML UTD，在<a class="ae ko" href="https://lifewithdata.org/" rel="noopener ugc nofollow" target="_blank"> LifeWithData </a>博客、<a class="ae ko" href="https://medium.com/@anthonyagnone" rel="noopener">Medium</a>上的文章和<a class="ae ko" href="https://twitter.com/@anthonyagnone" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上保持更新。</p></div><div class="ab cl lb lc hx ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="im in io ip iq"><h1 id="d7e4" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">不断学习</h1><div class="nr ns gp gr nt nu"><a href="https://towardsdatascience.com/tips-to-survive-and-thrive-in-the-remote-first-data-workforce-34944abddd29" rel="noopener follow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd iu gy z fp nz fr fs oa fu fw is bi translated">在远程优先的数据工作人员中生存和发展的技巧</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">提示:它不仅仅是Zoom和Github</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">towardsdatascience.com</p></div></div><div class="od l"><div class="oo l of og oh od oi kv nu"/></div></div></a></div><div class="nr ns gp gr nt nu"><a href="https://towardsdatascience.com/amazon-wants-to-make-you-an-ml-practitioner-for-free-552c46cea9ba" rel="noopener follow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd iu gy z fp nz fr fs oa fu fw is bi translated">亚马逊想让你免费成为一名人工智能从业者</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">这家科技巨头计划通过公开其长期的内部材料来提高ML的熟练度</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">towardsdatascience.com</p></div></div><div class="od l"><div class="op l of og oh od oi kv nu"/></div></div></a></div><div class="nr ns gp gr nt nu"><a href="https://towardsdatascience.com/fight-san-francisco-crime-with-fast-ai-and-deepnote-6db2b96d2a83" rel="noopener follow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd iu gy z fp nz fr fs oa fu fw is bi translated">用fast.ai和Deepnote打击旧金山犯罪</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">有了正确的ML框架和笔记本平台，您就在快车道上了</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">towardsdatascience.com</p></div></div><div class="od l"><div class="oq l of og oh od oi kv nu"/></div></div></a></div></div><div class="ab cl lb lc hx ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="im in io ip iq"><p id="abba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ne">原载于2020年12月30日</em><a class="ae ko" href="https://www.lifewithdata.org/newsletter/mlutd29" rel="noopener ugc nofollow" target="_blank"><em class="ne">https://www.lifewithdata.org</em></a><em class="ne">。</em></p><p id="1e79" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">访问专家视图— </strong> <a class="ae ko" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>