<html>
<head>
<title>Mixed-precision training for deep neural networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度神经网络的混合精度训练</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/mixed-precision-training-for-deep-neural-networks-3751f2c88883?source=collection_archive---------9-----------------------#2020-03-31">https://medium.datadriveninvestor.com/mixed-precision-training-for-deep-neural-networks-3751f2c88883?source=collection_archive---------9-----------------------#2020-03-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ed97" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">详细的解释</h2></div><p id="dc53" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated">当用大量数据训练时，eep学习模型表现得惊人地好。此外，在大多数情况下，增加我们深度神经网络的规模可以提高准确性，但这也增加了训练模型的内存需求。这里的内存需求，我指的是在每次迭代中更新的存储的可训练参数。</p><blockquote class="lk"><p id="a8a5" class="ll lm iq bd ln lo lp lq lr ls lt la dk translated">你知道吗？<br/>流行的ResNet-50架构(ResNet-152的缩小版)中的可训练参数数量接近2300万。</p></blockquote><p id="66f1" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">想知道这些参数是如何存储在内存中的吗？我们来看看他们是如何表现的。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h2 id="bbf2" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ko mp mq mr ks ms mt mu kw mv mw mx my bi translated"><a class="ae mz" href="https://en.wikipedia.org/wiki/Floating-point_arithmetic" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">浮点精度格式</strong> </a> <strong class="ak">及其表示法</strong></h2><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi na"><img src="../Images/1153c96263bbfb06c0b77119deb12fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*CoExNC6aUTCt6hVcpc_cqw.jpeg"/></div></figure><p id="55d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如你在上面看到的，我们考虑了IEEE754半精度、单精度和双精度格式。我们可以用四个整数分量来表示任意一个有限数:<br/> 1。标志2。基数3。有效数字(m) 4。指数(e)。<br/>我们取基数为2(二进制)。有了这些组件，我们可以将任何数值评估为:</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/5b109e4f08535475a28db6e3b5c2c242.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*kbfvQOmZfgLr6P0TdVOdyQ.png"/></div></figure><p id="984a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在神经网络中，不管我们使用什么框架，它都使用单精度(binary32/FP32)格式存储所有参数。让我们用一个例子更详细地看看<a class="ae mz" href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format" rel="noopener ugc nofollow" target="_blank">单精度格式</a>。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi nj"><img src="../Images/6a41ae94c8896049e7d326f791e1e424.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fx1AB7wK2vkqkM_JDReMSQ.jpeg"/></div></div></figure><p id="44e6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">符号位</strong> : 0表示正值，1表示负值。</p><div class="no np gp gr nq nr"><a href="https://www.datadriveninvestor.com/2019/01/23/deep-learning-explained-in-7-steps/" rel="noopener  ugc nofollow" target="_blank"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd ir gy z fp nw fr fs nx fu fw ip bi translated">深度学习用7个步骤解释-更新|数据驱动的投资者</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">在深度学习的帮助下，自动驾驶汽车、Alexa、医学成像-小工具正在我们周围变得超级智能…</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="oa l"><div class="ob l oc od oe oa of ng nr"/></div></div></a></div><p id="b4ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">指数位</strong>:可以表示0到255个值(8位)。指数也可以是负数，显示非常小的数值。这就是为什么指数的范围是<em class="og">有符号整数</em> (-127到127)。我们给实际的指数值加上127。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/8919d365071a46ac50032f9f3fac2ef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*nolrzlgetmnlrU14Gf6anQ.png"/></div></figure><p id="9ae1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，如果实际的指数值是-12，则表示的值将是-12+127 = 115。类似地，对于0，表示的值将是127，对于-127，表示的值将是0。值127是我们加上的偏差。指数的范围是-126到127。<br/>因此，我们可以用单精度表示的数值范围是，</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/f3767ce630e5f2217e68e52cda7e5dff.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*H8kGweDO5UX5BheudIChpQ.jpeg"/></div></figure><p id="dab5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">记住这一点很重要，我们将在后面引用这个值的范围。</p><blockquote class="lk"><p id="fa35" class="ll lm iq bd ln lo lp lq lr ls lt la dk translated">你知道吗？<br/>在单精度格式中，指数值-127(表示值全为0)和128(表示值全为1)用于表示NAN和inf值。</p></blockquote><p id="b50f" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated"><strong class="kh ir">尾数位</strong>:前23位，是规格化格式的小数点后的值。我们将通过一个例子来了解这一点。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/b0f394abfb09960d6ba05bf47a67c26c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*-8ekpLdP10pKgxTfEMXJRw.png"/></div></figure><p id="9e04" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从上面归一化的值可以看出，<br/> Sign = 0(正)<br/> m = 1，1 &lt; |2| <br/>实际指数= 1 <br/>表示指数= 1 + bias = 1 + 127 = 128(十进制)= 10000000(二进制)<br/>尾数位数= 100100100001111111010(小数点后23位)<br/>因此，在单精度</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/01129e4eade2bc1ca2d3eef661e62afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*OfJGUiRuWa5dY4aXBlawZQ.png"/></div></figure><p id="ae4e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望这个例子已经使单精度(FP32)中的值的表示非常清楚了。<br/>使用单精度格式给出了非常高的精度，但也增加了计算时间和存储参数所需的内存量。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><p id="36dc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">混合精度训练是一种方法，其中我们以降低的精度(FP16)训练深度神经网络，而不会损失精度或必须修改超参数。我们来看看半精度格式(FP16)。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/61a12e006fe6dda845864e9f64a23f57.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/1*ObI-_V-Qnx_CIpEnJOCirQ.png"/></div></figure><p id="3aa4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">符号位</strong> : 0表示正值，1表示负值。</p><p id="1026" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">指数位</strong>:与单精度格式中的8位不同，这里只有5位。它们可以代表0到31个值。正如我们在单精度格式中看到的，指数也可以是负数。这里指数的实际范围是-14到15。<br/>这里的偏差值是15。例如，如果实际指数是-4，则表示的值将是-4+15 = 11。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi om"><img src="../Images/227c4d24e614869567db5169348607dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*9Dly0TjeP7Hwnd8qkf5CGA.png"/></div></figure><p id="210b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">尾数位</strong>:我们只有10位半精度格式的尾数。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><p id="c216" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在已经讨论了关于半精度格式的更多内容，并且可以将这种格式用于所有神经网络参数(我们可以仅使用16位，而不是使用32位来表示权重)。使用半精度格式确实减少了所需的内存量，也提高了计算速度，但是正如您所看到的，与单精度格式相比，半精度的范围非常窄，因此可能会丢失一些信息。</p><p id="0de3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">混合精度训练允许使用半精度形式的重量进行训练，同时克服了与较窄范围相关的问题。让我们看看可能出现的问题以及如何解决它们。</p><p id="446d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在此之前，让我们修改一下任何深度学习模型的单个训练迭代中会发生什么。首先，我们将通过将数据输入模型来执行正向传播。在进行反向传播之前，我们将测量损耗。从反向传播步骤中获得权重梯度后，我们将使用它们通过任何优化器来更新参数。</p><p id="d376" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">优化步骤:</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi on"><img src="../Images/3633e9c5ba94264cc535a9539079618a.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*jyrriSy4aZ3PczIwf38Acg.png"/></div></figure><blockquote class="oo op oq"><p id="2b38" class="kf kg og kh b ki kj jr kk kl km ju kn or kp kq kr os kt ku kv ot kx ky kz la ij bi translated">问题1:</p></blockquote><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/1efa5e4c8b60d07c98e0e6deb64fc367.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_a3vzHTXaPxxImUtttSjZw.png"/></div></figure><p id="d3c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以上两种情况都会影响我们模型的性能。情况1将权重更新为之前的值，而情况2将权重更新为0。克服这些问题的一种方法是以单精度格式保存所有权重的副本，而不是使用FP16中的权重，我们可以在优化步骤中使用它们来更新参数。</p><blockquote class="lk"><p id="d4e4" class="ll lm iq bd ln lo lp lq lr ls lt la dk translated">你知道吗？</p><p id="8469" class="ll lm iq bd ln lo lp lq lr ls lt la dk translated">在混合精度训练中，所有张量和向前向后传播的算法都使用降低的精度(FP16)。</p></blockquote><blockquote class="oo op oq"><p id="a6ff" class="kf kg og kh b ki lu jr kk kl lv ju kn or lw kq kr os lx ku kv ot ly ky kz la ij bi translated">问题2</p></blockquote><p id="7391" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们知道FP16指数偏差使得归一化值指数的范围为[-14，15]。实际上所有的梯度值都是由小的量值决定的。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi ov"><img src="../Images/2bb327da4c89ffe7f0825f103382c2d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R7lCUOnFoQswlGS6vUADRw.png"/></div></div><figcaption class="ow ox gj gh gi oy oz bd b be z dk">Histogram of activation gradient magnitudes throughout the FP32 training of the Multibox SSD network</figcaption></figure><p id="3bf3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在大多数情况下，FP16可表示范围的大部分都没有使用。由于许多梯度值将低于FP16中的最小可表示范围，因此它们变成零。我们可以从上面的图表(贯穿多盒SSD网络的FP32训练的激活梯度幅度的直方图)中更好地理解这个问题。</p><p id="7ee2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">克服这个问题的一个简单方法就是放大渐变值，这样就可以移动它们来占据更多的FP16可表示范围。这种缩放保留了之前丢失为零的渐变值。</p><p id="abf8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">移动梯度值的一种有效方式是通过某个因子来缩放在前向传播之后不久计算的损失值。反向传播中的链式法则只是确保所有梯度值按相同的量缩放。</p><p id="6bc6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦我们计算出梯度，它们必须在优化步骤之前按相同的系数缩小，因为权重更新是以FP32格式进行的。</p><blockquote class="lk"><p id="a30a" class="ll lm iq bd ln lo lp lq lr ls lt la dk translated">你知道吗？我们必须选择比例因子，使其在梯度计算过程中不会导致溢出。当梯度超出FP16可表示的范围时，会发生溢出。</p></blockquote></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><p id="29b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我相信现在很清楚为什么我们称之为“混合精度训练”。这是因为我们在训练过程中对网络权重使用了FP32和FP16浮点表示。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi pa"><img src="../Images/9ee70261c217bc129d0faf810baeb3f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_OrFqBSKxczPIcV35RCWVg.png"/></div></div><figcaption class="ow ox gj gh gi oy oz bd b be z dk">Mixed-precision training</figcaption></figure><p id="532d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看混合精度训练的步骤:</p><p id="eeeb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1.在FP32中维护重量的主副本。<br/> 2。对于历元中的每次迭代:<br/> a .制作权重的FP16副本。<br/> b .前向传播(使用FP16权重和激活)<br/> c .损失缩放:将得到的损失乘以缩放因子<em class="og"> S <br/> d. </em>后向传播(使用FP16权重、激活及其梯度)<br/> e .缩小:将权重梯度乘以1/ <em class="og"> S <br/> f. </em>使用主副本完成FP32中的权重更新。</p><p id="8f73" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">选择合适的比例因子很重要。在上述步骤中，我们最初将比例因子S固定为一个值。根据动态损耗调整的概念，我们将首先为比例因子分配一个较大的值。随着训练的进行，如果比例损失值超过NANs指示的FP16可表示范围，我们将降低比例因子并重复此过程。</p><p id="b607" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于动态损耗缩放，我们将在反向传播之后向混合精度训练添加以下步骤:</p><p id="5b17" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果重量梯度中存在Inf或NaN(表示溢出):<br/> 1。降低比例因子S. <br/> 2。跳过权重更新，转到下一次迭代。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><p id="d8e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在已经理解了混合精度训练中涉及的概念，使用混合精度训练，我们可以使用半精度格式的权重来训练我们的模型，同时克服与之相关的问题。</p><p id="629f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢您的阅读。如果你觉得这篇文章有帮助，请鼓掌。欢迎任何意见和建议。查看以下参考资料。</p><p id="e272" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参考:</p><ol class=""><li id="2a5e" class="pb pc iq kh b ki kj kl km ko pd ks pe kw pf la pg ph pi pj bi translated">混合精度训练纸:【https://arxiv.org/pdf/1710.03740.pdf T2】</li><li id="8c2d" class="pb pc iq kh b ki pk kl pl ko pm ks pn kw po la pg ph pi pj bi translated">混合精度用户指南:<a class="ae mz" href="http://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html" rel="noopener ugc nofollow" target="_blank">http://docs . NVIDIA . com/deep learning/SDK/mixed-precision-training/index . html</a>。</li></ol><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="pp pq l"/></div></figure></div></div>    
</body>
</html>