<html>
<head>
<title>Google Has Achieved Quantum Superiority. This Could Turn into a Global Disaster</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌已经取得了量子优势。这可能会变成一场全球性的灾难</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/google-has-achieved-quantum-superiority-this-could-turn-into-a-global-disaster-6a2dfda4aa52?source=collection_archive---------14-----------------------#2020-01-27">https://medium.datadriveninvestor.com/google-has-achieved-quantum-superiority-this-could-turn-into-a-global-disaster-6a2dfda4aa52?source=collection_archive---------14-----------------------#2020-01-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0f1b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">邪恶的理由</h2></div><p id="d5de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">谷歌创造的量子计算机有史以来第一次解决了常规计算机无法解决的任务。虽然并非所有专家都认同这一成果，但毫无疑问，量子计算将导致未来的技术突破。然而，它也产生了新的不可预见的问题，包括可能出现危险的人工智能。</p><h1 id="0333" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">数量优势</h1><p id="257a" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi mb translated"><span class="l mc md me bm mf mg mh mi mj di"> G </span> oogle科学家声称，他们创造了一种量子计算设备Sycamore，其计算速度比传统计算机快1亿倍。现代超级计算机需要几千年的时间，Sycamore只需要几分钟(200秒)。这种特性被称为量子优势，它使计算机能够以令人难以置信的速度解决需要考虑大量数据的复杂问题。</p><div class="mk ml gp gr mm mn"><a href="https://www.datadriveninvestor.com/2019/01/17/the-technologies-poised-to-change-the-world-in-2019/" rel="noopener  ugc nofollow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd iu gy z fp ms fr fs mt fu fw is bi translated">2019年即将改变世界的技术|数据驱动的投资者</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">很难想象一项技术会像去年的区块链一样受到如此多的关注，但是……</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb nc mn"/></div></div></a></div><p id="9b54" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">能够运算大数据的量子计算机和人工智能之间有直接联系。任何神经网络都搜索模式，这使它能够确定，例如，图片中描绘的是什么。然而，为此，计算机被迫进行天文数字的计算。通过模拟真实的自然系统，例如像人脑这样的神经网络，情况变得复杂。随着系统的复杂性，每次计算的时间呈指数增长。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nd"><img src="../Images/be7b73d2d7c4bae0d40b930c739a853a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b3I0Xu1NRlk8HDgNoPKI-g.jpeg"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Image by <a class="ae ns" href="https://pixabay.com/users/insspirito-1851261/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1280082" rel="noopener ugc nofollow" target="_blank">Garik Barseghyan</a> from <a class="ae ns" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1280082" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="f70d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">到2008年，作为蓝色大脑项目的一部分，研究人员能够模拟一个由10，000个神经元组成的大鼠大脑皮层列。拥有8000多个处理器的蓝色基因超级计算机被用于此目的。在2011年，有可能建立一个由100个新皮质柱组成的网络，总共有100万个神经元。</p><p id="d627" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，人脑是由数亿个通过突触连接的细胞组成的。理论上，量子优势为its和更复杂的系统建模提供了机会，如superintellect。</p><h1 id="ac5c" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">比人聪明</h1><p id="0a7f" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">根据牛津哲学家尼克·博斯特罗姆的定义，超级智能(superintellect)被称为一种人工智能，它在几乎任何活动领域都比人“聪明”。超级智能的出现不可避免地带来了风险，参与人工智能和其他技术开发的数学家、哲学家和科学家试图提前计算风险。例如，剑桥大学存在风险研究中心的工作人员(其顾问是SpaceX创始人埃隆·马斯克)在2015年签署了一封公开信，敦促科学家尽最大努力不要创造人们无法控制的东西。</p><p id="d6c2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2015年，《自然》杂志发表了一篇关于谷歌旗下谷歌DeepMind创建深度Q网络的文章。这个人工智能体能够学习玩游戏(并获胜)，只接收像素和点数作为输入。换句话说，他不需要一个人来指出正确和错误的决定。此外，deep Q-network超越了所有其他算法，在49场比赛中达到了一名职业游戏玩家的水平。同样，为了生存，超智能体会利用各种外部刺激来创造自己对世界的感知，人们会发现这很难理解和研究。</p><p id="b8b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">超智力的一个假想的体现是子宫脑。它是戴森球(一种围绕恒星建造的天体工程结构)的一种形式，利用所有的光能进行计算。量子技术可以创造出更紧凑的机器。</p><p id="4d53" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据尼克·博斯特罗姆的说法，要么限制他的能力，要么以某种方式激励他追求符合人类利益的目标，以确保超级智能不会伤害人类。然而，良好的意图可能会产生致命的后果。最简单的例子，被命令增加世界幸福水平的超级智能体，将决定毁灭人类，代之以幸福思想的模拟。也可以仅使用最基本的通信信道来尽可能隔离superintellect，但即使这样也不能提供保证。</p><h1 id="525d" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">这是不可能遏制的</h1><p id="1952" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">尽管量子计算机的性能优于传统计算机，但它们并非全能。量子计算机能解决的任何问题，常规计算机都解决了，尽管需要很长时间。相反，一个常规计算机原则上无法解决的问题，对量子来说也是棘手的。这种任务包括所谓的停止问题:如果给出了某个过程的描述和输入，是否有可能确定该过程的执行是否会结束。1936年艾伦·图灵证明这个任务不能用算法解决。</p><p id="b3f6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了证明一个任务是否棘手，通常将其归结为一个停止问题。如果你能为一个新任务找到解决stop问题的算法(这是一个矛盾，因为stop问题没有解决)，它也无解。2016年，一群来自美国、澳大利亚和西班牙的科学家得出结论，遏制超智能体的问题也很棘手。</p><p id="c4eb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">他们证明了这一点:威慑问题由两个子任务组成。第一个叫做危害问题，或者R (D)函数，就是要知道D输入的R程序的执行是否会危害人类。必须记住，解决伤害问题的办法不应该伤害人类。因此，寻求解决方案应该模拟R (D)的执行，并预测其执行的后果，而不影响世界，即孤立地进行。第二个子任务是控制问题。当可靠地知道不会有伤害时，该函数触发R (D)。</p><blockquote class="nt"><p id="9d7d" class="nu nv it bd nw nx ny nz oa ob oc ld dk translated">在大众文化中，人为的理性与人类的灾难紧密联系在一起。与此同时，科学家们正在认真计算与计算技术相关的风险。</p></blockquote><p id="ef6a" class="pw-post-body-paragraph ki kj it kk b kl od ju kn ko oe jx kq kr of kt ku kv og kx ky kz oh lb lc ld im bi translated">假设有一个假设的程序，它首先执行某个程序，然后开始伤害人。因为没有办法看到第一个程序是否会结束，所以你无法预测这个程序是否危险。毕竟，如果程序永远执行，不会对人造成伤害。至于控制问题，重要的是限制与超级智能体的交互，也就是说，只使用最重要的沟通渠道。但应该记住的是，超智能根据定义是一台通用图灵机(像人一样)，也就是说，能够模拟任意图灵机的行为。不可能知道超级智能是否会伤害这些通信信道中的人，也不可能安装防止伤害的断路器。</p><h1 id="eef2" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">不可预测的属性</h1><p id="9988" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">事实上，就连机器是否拥有超智能的定义也与包容问题属于同一类问题。根据赖斯定理，人们无法预测函数中任何非平凡性质(即其他函数中不存在的性质)的存在，无论它对人类或超级智能是有害的。</p><p id="5016" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">全量子计算机有望用于应对与流行病学、社会和经济危机以及气候变化相关的重要挑战。为了最有效，它们应该配备复杂的传感器并且不受限制，因为缺乏关键数据会导致不正确甚至有害的结论。但没有办法预测在这种情况下，是否会出现一个恶意或被误解的合成思维(或智力代理)，将世界引向一场全球性的灾难。</p><p id="9e5a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当然，这并不意味着人们应该忘记量子计算机。对一个人预测其行为后果的能力来说，存在着简单的数学限制。尤其是当它涉及到人工智能等极其复杂的系统的创建时。</p><figure class="ne nf ng nh gt ni"><div class="bz fp l di"><div class="oi oj l"/></div></figure></div></div>    
</body>
</html>