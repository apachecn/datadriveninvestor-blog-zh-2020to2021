<html>
<head>
<title>Tensorflow 2.0 — from preprocessing to serving (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tensorflow 2.0 —从预处理到服务(第2部分)</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/tensorflow-2-0-from-preprocessing-to-serving-part-2-cad9e7f38a9c?source=collection_archive---------9-----------------------#2020-03-15">https://medium.datadriveninvestor.com/tensorflow-2-0-from-preprocessing-to-serving-part-2-cad9e7f38a9c?source=collection_archive---------9-----------------------#2020-03-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f4a70cd9f47d53fc92af01a2a7857aaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*78KMHVVecnTzkLbN7xW0tQ.png"/></div></div></figure><p id="5f8c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">欢迎来到tensorflow及其keras API教程的第二部分。我们将讨论深度学习的一切——从如何预处理输入数据开始，然后建模你的神经网络来编码你的数据并处理输出。</p><p id="0127" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果您继续阅读本系列的第一篇文章也是谨慎的，因为我们已经讨论了预处理，我们将从那里继续。</p><p id="2863" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在你开始阅读这篇文章及其后继者之前，你应该了解以下主题的基础知识，以便在阅读时不会感到慌张:<br/> 1。微积分<br/> 2。线性代数<br/> 3。神经网络<br/> 4。熊猫，熊猫</p><p id="dbd2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">正如您可能已经从主题中推断出的那样，这是一篇编程文章，因此它可能有助于了解一些python方面的经验。</p><p id="c153" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">建议您使用Spyder(Anaconda的代码编辑器)进行编码，因为它具有选择性执行功能，这对于理解变量转换非常有帮助。</p><div class="kw kx gp gr ky kz"><a href="https://www.datadriveninvestor.com/2019/02/21/best-coding-languages-to-learn-in-2019/" rel="noopener  ugc nofollow" target="_blank"><div class="la ab fo"><div class="lb ab lc cl cj ld"><h2 class="bd ir gy z fp le fr fs lf fu fw ip bi translated">2019年最值得学习的编码语言|数据驱动的投资者</h2><div class="lg l"><h3 class="bd b gy z fp le fr fs lf fu fw dk translated">在我读大学的那几年，我跳过了很多次夜游去学习Java，希望有一天它能帮助我在…</h3></div><div class="lh l"><p class="bd b dl z fp le fr fs lf fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="li l"><div class="lj l lk ll lm li ln jw kz"/></div></div></a></div><p id="6a60" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你没有GPU，最好在Google Colab上完成这项工作——Colaboratory是一个免费的Jupyter笔记本环境，不需要设置，完全在云中运行。</p><p id="119e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">借助Colaboratory，您可以编写和执行代码、保存和共享您的分析，以及访问强大的计算资源，所有这些都可以从浏览器中免费获得。</p><p id="547b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将在这里使用的数据集是<code class="fe lo lp lq lr b">Fashion-MNIST</code>。<code class="fe lo lp lq lr b">Fashion-MNIST</code>是一个由<a class="ae ls" href="https://jobs.zalando.com/tech/" rel="noopener ugc nofollow" target="_blank"> Zalando </a>的文章图像组成的数据集——由60，000个样本的训练集和10，000个样本的测试集组成。每个示例都是28x28灰度图像，与10个类别的标签相关联。我们打算<code class="fe lo lp lq lr b">Fashion-MNIST</code>作为原始<a class="ae ls" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST数据集</a>的直接替代，用于机器学习算法的基准测试。它共享训练和测试分割的相同图像大小和结构。</p><p id="e365" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数据集的一个范例是:</p><figure class="lu lv lw lx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lt"><img src="../Images/bf2210a29b876ae60ae7cd27906ef14a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Qres15aitKY96soz.png"/></div></div></figure><p id="e7d5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">来自时尚MNIST数据集的样本(每个类占三行)</p><p id="966d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你们可能对MNIST的手写数字数据集有过经验，但我们不会在这里使用它，因为有两个非常好的理由。MNIST的网络设计太简单了，即使你使用密集的网络，你也可以达到98%的准确率。<br/> 2。它被过度使用了，我们想要学习新的东西，而不是重复旧的内容。</p><p id="44fe" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上一次，我们已经完成了我们的预处理，并准备好输入和目标进入我们的模型。</p><p id="4984" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们做最重要的部分，即模型设计，正如我们在预处理中看到的，这个模型将输入图像，我们将它们分为10类。我们将在这里使用的模型是卷积神经网络(CNN)。</p><p id="ce2e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，我们将使用Sequential类构建模型，然后使用Keras的函数式API。</p><p id="c1e8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用顺序类是设计模型最简单的方法，您可以使用。add()方法，并继续将层堆叠在彼此之上，尽管这可能是一种幼稚的方法，因为我们希望我们的模型学习各种潜在的特性。我们将学习函数式API中的分支。</p><figure class="lu lv lw lx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ly"><img src="../Images/4a7f3f41e93869f33043c98f56c44136.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W9MDlCamLotRJBAHXFBo2A.png"/></div></div></figure><p id="180d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在让我们看看CNN中存在哪种子模块。一个典型的CNN有三个不同的组成部分。它们是卷积层、汇集层和全连接层。</p><p id="67bc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，我们深入讨论卷积层的作用。一个卷积层由许多<strong class="ka ir"> <em class="lz">内核</em> </strong>组成。卷积层中存在的这些内核(有时称为<strong class="ka ir"> <em class="lz">卷积滤波器</em> </strong>)学习图像中存在的局部特征(例如，人的眼睛看起来像什么)。卷积层学习的这种局部特征称为<strong class="ka ir"> <em class="lz">特征图</em> </strong>。然后这些特征在图像上进行卷积。该卷积操作将产生一个矩阵(有时称为<strong class="ka ir"> <em class="lz">激活图</em> </strong>)。如果卷积滤波器中表示的要素出现在输入的给定位置，则激活图会在该位置产生高值。</p><figure class="lu lv lw lx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ma"><img src="../Images/6bdd9217daba4e2777e34168f6b74419.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*G72ELUhmMoBKlqzbFhB59A.gif"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Convolution Visualized</figcaption></figure><p id="0a7c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">与显而易见的相反，Conv2D不执行卷积，而是执行互相关，这在寻找潜在特征时更有意义。</p><p id="95a8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">汇集层使CNN翻译学习的这些特征不变(例如，不管人的眼睛在[ <em class="lz"> x=10，y=10 </em>或[ <em class="lz"> x=12，y=11 </em> ]位置，汇集层的输出将是相同的)。请注意，我们讨论的是每层的轻微翻译变化。然而，聚集几个这样的层，允许我们具有更高的平移不变性。</p><p id="dae6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">ReLU或整流线性单元是我们这里使用的中间激活:</p><figure class="lu lv lw lx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mf"><img src="../Images/d3b1319ec2c0bfa143eaa313ea9ab07e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NIqXtIt-CObNHvVVGP07pw.png"/></div></div></figure><p id="9b34" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另外，为了可视化其他激活功能，您可以查看这个令人惊叹的网站<a class="ae ls" href="https://dashee87.github.io/deep%20learning/visualising-activation-functions-in-neural-networks/" rel="noopener ugc nofollow" target="_blank">https://dashee 87 . github . io/deep % 20 learning/visualizing-activation-functions-in-neural-networks/</a>。</p><p id="fb95" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">输出激活是softmax，<strong class="ka ir"> Softmax函数，一个奇妙的<em class="lz">激活函数</em>，它将数字(又名逻辑)转化为概率，其总和为1。Softmax函数输出一个向量，该向量表示一系列潜在结果的概率分布。</strong>也是用于<em class="lz">深度学习</em> <em class="lz">分类</em>任务的核心元素。</p><figure class="lu lv lw lx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mg"><img src="../Images/a3203396a29932540d317c11c59485f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_IDMoFnoJT916hhUREiFAQ.png"/></div></div></figure><p id="0527" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">要了解更多关于softmax功能的信息，请查看<a class="ae ls" href="https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d" rel="noopener">https://medium . com/data-science-boot camp/understand-the-soft max-function-in-minutes-f3a 59641 e86d</a>。</p><p id="6cd6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在批次标准化层中，我们标准化每个批次前一层的激活，即应用一个变换，使平均激活接近0，激活标准偏差接近1。</p><p id="ef98" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后，我们使用扁平化层，使我们的输入是密集层兼容。丢弃层包括在训练期间的每次更新时将输入单元的一部分<code class="fe lo lp lq lr b">rate</code>随机设置为0，这有助于防止过拟合。我们这里的利率是0.2%或20%。</p><figure class="lu lv lw lx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mh"><img src="../Images/8f34f4e30eacb5454c462bb1d7fe97c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*1ahseLaWbZfgxdZ5DR2r2w.gif"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Pooling Visualized</figcaption></figure><p id="b4cc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，我们有完全连接的层。完全连接的层负责基于激活的特征映射的集合和图像中的位置产生不同的激活模式，特征映射被激活用于图像中的位置。这是CNN视觉上的样子。</p><p id="310b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">请查看<a class="ae ls" href="https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks-e3f054dd5daa" rel="noopener" target="_blank">https://towards data science . com/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks-e 3f 054 DD 5d aa</a>以更深入地了解CNN的。</p><figure class="lu lv lw lx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mi"><img src="../Images/827882263551c0aea2e4ad85860b40e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aCXG5qVzZ7olu-6RqULuCA.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">The whole CNN visualized (credits : <a class="ae ls" href="https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks-e3f054dd5daa" rel="noopener" target="_blank">https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks-e3f054dd5daa</a>)</figcaption></figure><p id="9420" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们将使用函数式API做同样的事情</p><figure class="lu lv lw lx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/377c7842eee275c05ac3075a2edf4af7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XZmgCSK4eNM_duiCwFv6OA.png"/></div></div></figure><p id="7664" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">正如你所看到的，没有什么大的变化，但是函数式API给了你将你的层重定向到你想要的任何地方的自由。</p><p id="1e07" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里唯一的主要变化是使用GlobalMaxPooling2D代替Flatten层。GlobalMaxPooling2D块执行与MaxPooling2D块完全相同的操作，除了池大小(即，水平池系数x垂直池系数)是块的整个输入的大小，即，它为每个输入通道计算单个最大值。这是直观的，因为我们想要更突出的特征，因为它们将决定我们的输入属于哪个类别，并且该层极大地减少了我们的计算。</p><p id="7f67" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你想要更多的视频教程，请在https://www.tensorflow.org/guide/keras<a class="ae ls" href="https://www.tensorflow.org/guide/keras" rel="noopener ugc nofollow" target="_blank">查看tensorflow的核心文档进行更多的练习。</a></p><p id="8137" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">既然我们已经完成了模型设计，现在我们可以编译模型了</p><figure class="lu lv lw lx gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/538fdeaf7b6a387ea121be47c16cd21a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*sXHtl9x9olG4b_edNaU25g.png"/></div></figure><p id="c842" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们在编译时选择一个优化器。</p><p id="7e97" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在训练过程中，我们调整和改变模型的参数(权重),以尝试最小化损失函数，并使我们的预测尽可能正确。但是你具体是怎么做的呢？如何改变模型的参数，改变多少，何时改变？</p><p id="25e5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这就是优化器的用武之地。它们通过响应损失函数的输出更新模型，将损失函数和模型参数联系在一起。简单来说，优化者通过使用权重将你的模型塑造成最精确的形式。损失函数是地形的向导，告诉优化器它何时向正确或错误的方向移动。</p><p id="72da" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将使用梯度下降算法的后继算法，这里是Adam(自适应矩估计)</p><figure class="lu lv lw lx gt jr gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/82413d124f81777d6df16e4aa6a106f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*C6j75n2MaCXuk2xOUH2BQA.png"/></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Source : ML Cheatsheet</figcaption></figure><p id="2b2a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有关优化器及其变体的更多信息，请查看https://algorithmia.com/blog/introduction-to-optimizers<a class="ae ls" href="https://www.dlology.com/blog/quick-notes-on-how-to-choose-optimizer-in-keras/" rel="noopener ugc nofollow" target="_blank">https://www . dlology . com/blog/quick-notes-on-how-to-choose-optimizer-in-keras/</a>和<a class="ae ls" href="https://algorithmia.com/blog/introduction-to-optimizers" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="edac" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们现在选择损失函数。作为优化算法的一部分，必须重复估计模型当前状态的误差。这需要选择误差函数，通常称为损失函数，该函数可用于估计模型的损失，从而可以更新权重以减少下一次评估的损失。</p><p id="f747" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里我们使用“sparse _ categorical _ crossentropy”，更多信息请看<a class="ae ls" href="https://medium.com/@Joocheol_Kim/what-is-sparse-categorical-crossentropy-7bf3c5acf99e" rel="noopener">https://medium . com/@ Joocheol _ Kim/what-is-sparse-categorial-cross entropy-7 BF 3c 5 ACF 99 e</a>。</p><p id="7ba4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，如果你需要知道你自己的定制模型需要什么样的损失，请查看<a class="ae ls" href="https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/</a>。</p><p id="cdc1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，我们选择需要记录的指标，因为这是一个分类问题，我们选择准确性。</p><p id="46a3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在该训练了！</p><figure class="lu lv lw lx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mm"><img src="../Images/db3b28abb337a9b3b3a31dedeb60d66a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pE74exipaAW9bUGzbJ-RRA.png"/></div></div></figure><p id="0de5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">完成这些之后，我们就完成了模型的训练。</p><p id="5431" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">PS:如果你在本地使用GPU资源，如果cudnn初始化失败，把你所有的代码移植到colab。</p><p id="d97d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在下一篇文章中，我们将讨论神经网络的版本控制，并使用tensorflow服务将它制作成API服务。</p><p id="af11" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">请点击此链接查看完整代码:</p><div class="kw kx gp gr ky kz"><a href="https://github.com/lordtt13/Medium-Articles" rel="noopener  ugc nofollow" target="_blank"><div class="la ab fo"><div class="lb ab lc cl cj ld"><h2 class="bd ir gy z fp le fr fs lf fu fw ip bi translated">Lord TT 13/中等-物品</h2><div class="lg l"><h3 class="bd b gy z fp le fr fs lf fu fw dk translated">我的Medium Articles-Lord tt13/Medium-Articles中引用的所有代码的配套报告</h3></div><div class="lh l"><p class="bd b dl z fp le fr fs lf fu fw dk translated">github.com</p></div></div><div class="li l"><div class="mn l lk ll lm li ln jw kz"/></div></div></a></div><p id="6242" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">也请给我的个人资料看看更多的内容，如机器学习，全栈开发等几个编程主题相关。</p><figure class="lu lv lw lx gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure></div></div>    
</body>
</html>