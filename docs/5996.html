<html>
<head>
<title>Resampling Methods — The solution to small datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">重采样方法-小数据集的解决方案</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/resampling-methods-the-solution-to-small-datasets-5b9e5c390eb5?source=collection_archive---------3-----------------------#2020-10-08">https://medium.datadriveninvestor.com/resampling-methods-the-solution-to-small-datasets-5b9e5c390eb5?source=collection_archive---------3-----------------------#2020-10-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="62bf" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">介绍4种重采样方法——验证集方法、留一交叉验证(LOOCV)、K折交叉验证和自举</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c6a96203b3f4b7f7a8b4dcebfe0e10f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gD9MbAWTnTMHjLhX"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@woumz?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jaden Barton</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="cdd0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在数据科学和人工智能的世界中，数据首先被收集起来，并相应地拟合到机器学习算法中，以进行预测或分析有价值的见解。我们放入的数据被称为<em class="lv">训练数据</em>，从逻辑上讲，我们放入机器学习算法的<em class="lv">训练数据</em>越多，它的表现就越好。等等，真的这么简单吗？</p><p id="30c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">答案是否定的！通常，我们会需要另一组数据，称为<em class="lv">测试数据</em>，其目的是帮助我们测试我们的机器学习模型。这个<em class="lv">测试数据</em>在训练阶段我们的模型是看不到的，一旦我们的模型被允许在商业环境中使用，它可以帮助我们评估它们的性能。</p><p id="b371" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">嗯，另一个常见的问题出现了，我们从哪里收集这么多数据？有时，数据科学家收集大量数据来获得<em class="lv">训练</em>和<em class="lv">测试</em>数据集，在计算和金钱上都是昂贵的。本文将讨论一种叫做<strong class="lb iu">重采样</strong>的技术，它将利用<em class="lv">训练数据集</em>本身。</p><h1 id="94ac" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">验证集方法</h1><p id="edc7" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">第一种方法在概念上是最简单和最容易实现的。它包括将<em class="lv">训练数据</em>随机分成两个数据子集，<em class="lv">训练</em>和<em class="lv">确认/保持</em>集。<em class="lv">训练集</em>将用于训练机器学习算法，而<em class="lv">验证/保持集</em>用于测量算法的性能。常见的分流比是70:30、80:20甚至90:10。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/8182cb7ca1905d73612d9bdf4bbf1638.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XPpcLMZrTBq9jSCiQ_45cA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Image from An Introduction to Statistical Learning with applications in R</figcaption></figure><p id="e8fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管实现起来非常简单，但是这种方法有两个潜在的缺点。</p><ol class=""><li id="13ac" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">测试误差的估计可能变化很大，因为它取决于训练/验证数据集中包含哪些观察值</li><li id="a6ed" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">只有观察值的子集用于训练模型，这可能会导致高估测试误差，因为统计方法在训练较少的数据观察值时往往表现更差</li></ol><h1 id="0fa2" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">遗漏一项交叉验证(LOOCV)</h1><p id="4581" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">顾名思义，它包括留下一个数据观察值作为验证集，剩下的数据观察值作为训练集。假设我们有n个观察值，我们将重复n次，这将产生n个测试误差。最终的测试误差将是这n个测试误差的平均值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/b1605f19d09949007aeed19acb4ecdd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s4xIMM9sQpHLqoLANNyPFQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Image from An Introduction to Statistical Learning with applications in R</figcaption></figure><p id="9e83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与验证集方法相比，LOOCV有两个优势。</p><ol class=""><li id="991d" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">LOOCV不会过高估计测试误差，因为所有的数据观测都用于训练模型</li><li id="f16e" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">LOOCV将总是产生相同的测试误差，因为与验证集方法相比，我们不再随机分割数据集，验证集方法的测试误差将取决于我们如何分割数据集</li></ol><p id="032c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，LOOCV的最大缺点是，它有可能实现起来计算量很大。如果我们有10000个数据观测值，那么必须训练10000个模型来获得10000个不同的测试误差。</p><div class="nj nk gp gr nl nm"><a href="https://www.datadriveninvestor.com/2020/07/23/learn-data-science-in-a-flash/" rel="noopener  ugc nofollow" target="_blank"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd iu gy z fp nr fr fs ns fu fw is bi translated">一瞬间学会数据科学！？数据驱动的投资者</h2><div class="nt l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">在我之前的职业生涯中，我是一名训练有素的古典钢琴家。还记得那些声称你可以…</h3></div><div class="nu l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nv l"><div class="nw l nx ny nz nv oa ks nm"/></div></div></a></div><h1 id="748e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">k倍交叉验证</h1><p id="630c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这种方法是LOOCV的一种替代方法，它不是将数据集分成n-1个观察值和1个观察值分别作为训练集和验证集，而是将数据集随机分成k个大小相等的组/折叠。第一个折叠用作验证集，而剩余的k-1个折叠用作训练集。这个过程重复k次，测试误差是这k个模型的平均值。常见的k值是5或10。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/ea03b7a2e3d84f5ebacf0aba059d968e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*wcekqXY_kn9NetsqPjBXkA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Image from An Introduction to Statistical Learning with applications in R</figcaption></figure><p id="d709" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与前两种方法相比，K倍交叉验证在以下方面更好:</p><ol class=""><li id="6024" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">测试误差的可变性低于验证集方法和LOOCV，因为验证数据集更大</li><li id="2143" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">与验证集方法相比，所有数据点都在训练模型中使用</li><li id="452b" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">计算上比LOOCV便宜，因为它只需要训练K模型</li></ol><p id="7d47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法的一个缺点是，与LOOCV相比，它可能导致更高的训练误差，因为现在在每次迭代中使用更小的训练数据集来训练我们的模型。</p><h1 id="7048" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">拔靴带</h1><p id="51b6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">将介绍的最后一种方法是Bootstrap，这可能是概念上最复杂的方法。Bootstrap是一种统计技术，用于通过对多个小数据观测值的估计值进行平均来估计统计数据的分布(例如，均值或方差)。这听起来类似于LOOCV和K-Fold交叉验证，但是自举的实现方式是非常不同的。</p><p id="4f42" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们首先决定要执行的自举样本的数量(Z ),这在技术上类似于在K重交叉验证中选择K的想法。接下来，我们将决定每个bootstrap样本中的样本大小n，与前三种方法相比，这是全新的。一旦决定，对于每个bootstrap样本，我们将从带有替换的数据集中抽取n个观察值。这意味着可以在同一个引导样本中多次得出一个特定的观察值。有了这个包含n个观察值的bootstrap样本，我们将使用它来训练我们的模型。不在该样本中的剩余数据观察(即，袋外观察)将被用作我们的验证集。然后重复Z次，测试误差是这Z个模型的平均值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/73e030bcb11904029bb491880155ca1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*kjWb2aYYtVfRbkiF8_Ir9Q.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Image from An Introduction to Statistical Learning with applications in R</figcaption></figure><p id="b62f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与其余3种重采样方法相比，自举的两个潜在缺点如下:</p><ol class=""><li id="f83a" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">由于我们是随机选择数据观察值的，因此并非所有的数据观察值都会被选为训练数据集。尽管这可以通过潜在地增加自举样本的数量来纠正</li><li id="a502" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">与之前的3种重采样方法相比，实现起来在计算上更加复杂</li></ol><h1 id="1f00" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak">总结</strong></h1><p id="40c3" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这是否意味着自举是最好的重采样方法？影响这一点的因素有很多，其中一个我觉得很重要的因素是可用的训练数据量。如果训练数据很少，使用bootstrapping方法可以为您提供更多样本来训练您的模型，因为可以在每个样本中重复绘制观察值。</p><p id="0478" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果数据集的大小在开始时是合适的，强烈建议使用K-Fold交叉验证方法，因为它将所有数据观察值作为训练数据拟合到模型中，并且在测试误差中具有最低的方差。</p><p id="052e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于哪种重采样方法是最好的，肯定没有正确的答案，这也是为什么说哪种机器学习算法是对某些问题进行预测的最佳方法，也没有正确的答案。需要进行大量的探索才能知道哪一个是最好的，有时，最简单的方法提供了最好的解决方案。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://www.buymeacoffee.com/tankahwang"><div class="gh gi od"><img src="../Images/4bc5de35955c00939383a18fb66b41d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*9vg3-OY14aZN1UpKwIxxZg.png"/></div></a></figure><h2 id="aa19" class="oe lx it bd ly of og dn mc oh oi dp mg li oj ok mi lm ol om mk lq on oo mm op bi translated">获得专家视图— <a class="ae ky" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>