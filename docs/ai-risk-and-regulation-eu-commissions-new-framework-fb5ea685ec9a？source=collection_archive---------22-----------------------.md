# 人工智能风险与监管——欧盟委员会的新框架

> 原文：<https://medium.datadriveninvestor.com/ai-risk-and-regulation-eu-commissions-new-framework-fb5ea685ec9a?source=collection_archive---------22----------------------->

## 欧洲(欧盟)委员会发布了最新的人工智能监管框架。

![](img/e4985531cc853278f2076c408251d7e1.png)

Source: [maxkabakov](https://depositphotos.com/portfolio-1152339.html) / [depositphotos.com](http://www.depositphotos.com)

# 伴随风险而来的是监管

在医学(以及生活的每个其他领域)中开发和部署基于人工智能的工具的进展比以往任何时候都要快。因此，我们必须考虑与此类系统相关的可能风险——关于监管的问题正变得不可避免。随着人工智能驱动的系统和机器正在设定新的步伐，并为基于事实的决策过程带来新的标准，现在是时候制定模式来识别可能出现的问题，并确定如何最好地解决这些问题。

# 欧盟也参与进来

在试图为所有人工智能过程开辟一种以人为中心的方法时，欧洲议会表示打算更新欧盟现有的适当伦理原则框架。该计划预计将同时权衡欧洲的价值观和用户的需求。

[](https://www.datadriveninvestor.com/2018/04/20/what-criteria-do-venture-capitalists-consider-when-seeding-a-startup/) [## 风险投资家在给创业公司播种时会考虑什么标准？数据驱动的投资者

### 2017 年，风险投资资金攀升至十年来的最高水平。你的创业公司目前吸引风险投资的机会是…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2018/04/20/what-criteria-do-venture-capitalists-consider-when-seeding-a-startup/) 

面向[这一](https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai)目标的首个欧盟指导方针于 2019 年 4 月发布。乌尔苏拉·冯·德·莱恩(欧洲委员会当选主席)然后[宣布](https://www.europarl.europa.eu/thinktank/en/document.html?reference=EPRS_BRI(2019)640163)委员会将提出进一步的立法建议，以实现一个更加协调的欧洲方法来处理人工智能的伦理影响。基本上，他们为欧盟内部人工智能和基于人工智能的服务的设计、部署和使用推荐了一个协议。

# 为什么需要监管？

尽管人工智能提供了许多好处，但对其伦理、合法性和经济影响的担忧已经出现。一些批评家甚至担心基本人权。

例如，人工智能可能对用户的隐私权和个人数据保护权构成严重风险。当使用有偏差的数据集训练算法或系统时，它还可能增加[辨别](https://www.jstor.org/stable/10.5325/jinfopoli.8.2018.0078#metadata_info_tab_contents)水平。其他常见的恐惧包括劳动力市场就业机会的破坏、虚假信息的传播以及自主武器的制造。

通过实施以人为本的规则，欧盟将影响全球决策者制定各自的计划来有效应对这些风险。毕竟，欧盟被认为是建立人工智能全面道德框架的领跑者。

![](img/09b7136ade8311b31675e254dd88ae5f.png)

Source: [galaktika_new](https://depositphotos.com/portfolio-4230659.html) / [depositphotos.com](http://www.depositphotos.com/)

# 在欧盟，这种对话已经持续了多年。

早在 2017 年 1 月，欧洲议会就指示欧盟委员会评估人工智能的影响，并为管理机器人的民事法律提出广泛的建议。不仅为机器人工程师制定了道德规范，还导致委员会建立了一个以机器人和人工智能为中心的小组。

这个人工智能高级专家组的任务是为值得信赖的人工智能制定非约束性的道德准则。总的来说，52 名独立专家致力于如何有效地保护欧盟道德人工智能系统的发展。

他们对[实现这一](https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai)的关键要求是:

## a.人类、社会和环境福祉:

这一原则表明，所有人工智能系统都应该只用于个人的有益结果。产品或应用程序必须有助于为即将到来的挑战提供解决方案。为了更进一步，所有的系统和目标都必须由适当的当局明确定义。

## b.公平:

人工智能系统应该具有包容性和可访问性。它们的使用不应导致对个人、社区或群体的不公平歧视。不能容忍因年龄、性别、种族、性别认同或性取向而受到优待。

![](img/8738d1aa075964f627ba0cc2fd299937.png)

Source: [maxkabakov](https://depositphotos.com/portfolio-1152339.html) / [depositphotos.com](http://www.depositphotos.com/)

## c.隐私保护和安全性:

所有人工智能系统都必须尊重和维护隐私权，维护数据安全。不幸的是，当涉及到人工智能时，这是目前违反最多的伦理原则之一。这一原则旨在确保可靠的安全措施始终到位。

## d.可靠性和安全性:

人工智能系统应该朝着它们预期的目的高效地运行。这意味着它们必须具有可靠性和准确性，并且它们的结果必须是可重复的。人工智能系统的使用也不应给任何用户带来不合理的安全风险。必须采取相称的措施，以尽量减少风险。

## e.透明度和理解:

基于人工智能的系统应该具有高度的透明性。人们应该意识到他们什么时候被一种机制所吸引或影响。此外，所有关于人工智能系统的披露应及时提供，并有合理的理由。这将包括有助于受试者理解决策结果的充分信息。

## f.争议性:

用户应该能够挑战他们接触到的任何人工智能系统的影响、使用和输出。必须为用户提供一个方便的异议渠道。当一个系统影响一个人、社区、团体或环境时，这是至关重要的。

![](img/d7df7846820d04ca90cd4db46321f2bc.png)

Source: [iqoncept](https://depositphotos.com/portfolio-1005979.html) / [depositphotos.com](http://www.depositphotos.com/)

## g.问责制:

负责人工智能系统生命周期不同阶段的所有个人必须是可识别的，并对其机器的结果负责，并且应该高度启用人工监督。请注意，关于人工智能系统问责制的法律原则的应用仍在发展中。即便如此，可答性也应该被视为重中之重。

# 结论

复杂吧？监管先进技术将永远是一项进行中的巨大工作。你认为这种方法怎么样？你认为人工智能应该被监管吗？

如果您对欧盟基于人工智能的系统的监管有任何问题或想法，请联系我们或留下评论。

*如果你想看到更多这样的帖子或亲自与我联系，你可以在* [*LinkedIn*](https://www.linkedin.com/in/sohail-merchant-370aaa59/) *，*[*Twitter*](https://twitter.com/smerchantMD)*上添加我，或在下面发表评论。*

# 资源

*   (2020 年 2 月)[委员会向欧洲议会提交的报告——理事会和欧洲经济和社会委员会关于人工智能、物联网和机器人的安全和责任影响的报告](https://ec.europa.eu/info/sites/info/files/report-safety-liability-artificial-intelligence-feb2020_en_1.pdf)
*   (2020 年 2 月)[人工智能白皮书——欧洲实现卓越和信任的方法](https://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_en.pdf)

*原载于 2020 年 3 月 24 日*[*https://www . aim blog . io*](https://www.aimblog.io/2020/03/24/ai-risk-and-regulation-eu-commissions-new-framework/)*。*