<html>
<head>
<title>How Generative Adversarial Network Works</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成性对抗网络如何工作</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/how-generative-adversial-network-works-3ddce0062b9?source=collection_archive---------2-----------------------#2020-01-01">https://medium.datadriveninvestor.com/how-generative-adversial-network-works-3ddce0062b9?source=collection_archive---------2-----------------------#2020-01-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/></div><div class="ab cl jn jo hu jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ij ik il im in"><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi ju"><img src="../Images/980da50b5b8b3908a90290630181bbd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mKHnP471GoVLvUeGiTdMLg.jpeg"/></div></div></figure><p id="874e" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">生成对抗网络(GANs)据说是深度学习领域最大的发明之一。最近，面部老化应用程序变得非常受欢迎，它使用GAN的一种变体作为底层算法。此外，GANs在将低分辨率图像转换为高分辨率图像方面变得非常有用。在这篇文章中，我们将看到一个基本的生成对抗网络的构建模块。</p><h2 id="6a03" class="le lf iq bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">GANs的架构:</h2><p id="a2d8" class="pw-post-body-paragraph kg kh iq ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld ij bi translated">每个GAN有两个基本元件，即发生器和鉴别器。这两个网络可以是任何深度学习网络，如人工神经网络、卷积神经网络、长短期记忆(LSTM)。鉴别器应该在网络的末端有一个分类器。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/31ccb861aa2c2d5da0e4f45ee55ce61a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/0*Mwpzq1rqmc-2LJsx."/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">(Schematic Diagram Of A Basic GAN Architecture)</figcaption></figure><p id="ad54" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">上图总结了基本GAN的工作原理。正如我们所看到的，生成器将随机值作为输入，并产生一个输出，期望它在鉴别器看来是真实的。另一方面，鉴别器从真实图像集和鉴别器生成的图像中获取输入，并试图以正确的方式对它们进行分类，即应该能够区分哪个是真实的，哪个是伪造的。</p><h1 id="7013" class="mh lf iq bd lg mi mj mk lj ml mm mn lm mo mp mq lp mr ms mt ls mu mv mw lv mx bi translated">外行人理解甘的方式:</h1><p id="211e" class="pw-post-body-paragraph kg kh iq ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld ij bi translated">gan的发生器被期望创建看起来像真实图像的图像。然而，生成器不知道真实图像是什么样子的。因此，它接受来自鉴别器的反馈(<em class="my">因为它知道或声称知道真实图像)</em>关于如何调整参数以使其看起来真实。同时，鉴别器试图识别鉴别器产生的图像，降低其成为真实图像的概率，同时增加正确分类真实图像的概率。这种受博弈论启发的竞争性学习让这两个网络变得更加强大。</p><div class="mz na gp gr nb nc"><a href="https://www.datadriveninvestor.com/2019/03/22/fixing-photography/" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd ir gy z fp nh fr fs ni fu fw ip bi translated">修复摄影|数据驱动的投资者</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">汤姆·津伯洛夫在转向摄影之前曾在南加州大学学习音乐。作为一个…</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nl l"><div class="nm l nn no np nl nq ke nc"/></div></div></a></div><h2 id="cfaa" class="le lf iq bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">数学含义:</h2><p id="b84e" class="pw-post-body-paragraph kg kh iq ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld ij bi translated">假设z是一个噪声矢量，作为发生器的输入。在这种情况下，G(z)将是发电机的输出。此外，x是训练样本的集合，在这种情况下，D(x)是真实训练样本的鉴别器概率。类似地，D(G(z))是鉴别器的输出，它是生成的图像即伪图像的概率值。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi nr"><img src="../Images/e525f91fa087f9bb3c5aa32693ea5962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tSYvE8SyXvFSdgzi.jpeg"/></div></div></figure><p id="f245" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">最大化D(G(z))与最小化1-D(G(z))相同。我们还可以看到，鉴频器部分有两种损耗，因为它有两种输入:来自发生器的输出和实数据样本。所以损失要计算两次。因此，鉴频器的总损耗是真实数据和虚假数据造成的两个损耗之和。计算损耗后，我们可以进行所需的反向传播并调整参数。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi ns"><img src="../Images/baab3ab7616768eae7bcbc9ad4f4bb0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NODG0T5YTqIBKrS9.png"/></div></div></figure><p id="acff" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">上面的等式显示V是一个值函数，让我们调整D和g的参数。</p><p id="afaf" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">当我们对V和G都应用V函数时</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi nt"><img src="../Images/03854ec49a939d2db7973b57b77be914.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*M0Pj9Ib7GKl1zmPl.jpeg"/></div></div></figure><p id="02b6" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">因此，通过上述操作，鉴别器和发生器都变得更强，以完成它们所需的任务(<em class="my">，如为发生器欺骗鉴别器，为鉴别器辨别真假图像</em></p><p id="6842" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">在下一篇文章中，我们将看到GAN的一些很酷的应用，并从头开始构建GAN。</p><figure class="jv jw jx jy gt jz"><div class="bz fp l di"><div class="nu nv l"/></div></figure></div></div>    
</body>
</html>