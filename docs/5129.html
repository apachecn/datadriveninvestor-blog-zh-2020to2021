<html>
<head>
<title>Alluxio Deep Learning Practices — 1: Running PyTorch Framework on HDFS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Alluxio深度学习实践— 1:在HDFS上运行PyTorch框架</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/alluxio-deep-learning-practices-1-running-pytorch-framework-on-hdfs-904b5789d97?source=collection_archive---------3-----------------------#2020-09-07">https://medium.datadriveninvestor.com/alluxio-deep-learning-practices-1-running-pytorch-framework-on-hdfs-904b5789d97?source=collection_archive---------3-----------------------#2020-09-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/0d1bb2256e4b41b41fe1d27c128153e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*5vxEwWOKGkcMpl2s.png"/></div></figure><p id="fa4c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><em class="ks">作者毕然</em></p><h1 id="4460" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">背景</h1><p id="c71d" class="pw-post-body-paragraph ju jv iq jw b jx lr jz ka kb ls kd ke kf lt kh ki kj lu kl km kn lv kp kq kr ij bi translated">谷歌的TensorFlow和脸书的PyTorch是社区中两个流行的深度学习框架。虽然PyTorch相对较新，但由于其开发人员友好的体验，它已经得到了快速发展。但是，PyTorch默认不允许在<a class="ae lw" href="https://www.alibabacloud.com/products/emapreduce" rel="noopener ugc nofollow" target="_blank"> Hadoop分布式文件系统</a> (HDFS)中直接训练模型。这给许多在HDFS存储数据集的用户带来了困难。因此，对于训练模型，用户需要从HDFS导出数据或修改PyTorch的源代码以支持HDFS协议。这一复杂的过程极大地损害了用户体验。</p><p id="b688" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">相比之下，Alluxio能够将HDFS API翻译成POSIX文件系统API。这个特性将PyTorch开发人员从修改计算框架的需要中解放出来，因此极大地提高了开发效率。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/0a7947029e86c391477367056522660b.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/0*i3Zcc96z7lc4La9E.png"/></div></figure><p id="4f06" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">本文描述了如何在<a class="ae lw" href="https://www.alibabacloud.com/product/kubernetes" rel="noopener ugc nofollow" target="_blank"> Kubernetes </a>环境中验证整个工作。</p><h1 id="53f0" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">准备HDFS 2.7.2环境</h1><p id="17e1" class="pw-post-body-paragraph ju jv iq jw b jx lr jz ka kb ls kd ke kf lt kh ki kj lu kl km kn lv kp kq kr ij bi translated">如果没有可用的现有HDFS集群，请使用Helm Chart直接安装HDFS。</p><p id="3ef8" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">1)用Hadoop 2.7.2安装舵图。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="bf14" class="mh ku iq md b gy mi mj l mk ml">git clone https://github.com/cheyang/kubernetes-HDFS.git</span><span id="ed0c" class="mh ku iq md b gy mm mj l mk ml">kubectl label nodes cn-huhehaote.192.168.0.117 hdfs-namenode-selector=hdfs-namenode-0<br/>#helm install -f values.yaml hdfs charts/hdfs-k8s<br/>helm dependency build charts/hdfs-k8s<br/>helm install hdfs charts/hdfs-k8s \<br/>      --set tags.ha=false  \<br/>      --set tags.simple=true  \<br/>      --set global.namenodeHAEnabled=false  \<br/>      --set hdfs-simple-namenode-k8s.nodeSelector.hdfs-namenode-selector=hdfs-namenode-0</span></pre><p id="e2e6" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">2)检查舵图的状态。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="7aa5" class="mh ku iq md b gy mi mj l mk ml">kubectl get all -l release=hdfs</span></pre><p id="e850" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">3)使用HDFS命令行界面客户端连接到HDFS。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="4249" class="mh ku iq md b gy mi mj l mk ml">kubectl exec -it hdfs-client-f5bc448dd-rc28d bash<br/>root@hdfs-client-f5bc448dd-rc28d:/# hdfs dfsadmin -report<br/>Configured Capacity: 422481862656 (393.47 GB)<br/>Present Capacity: 355748564992 (331.32 GB)<br/>DFS Remaining: 355748515840 (331.32 GB)<br/>DFS Used: 49152 (48 KB)<br/>DFS Used%: 0.00%<br/>Under replicated blocks: 0<br/>Blocks with corrupt replicas: 0<br/>Missing blocks: 0<br/>Missing blocks (with replication factor 1): 0</span><span id="3daf" class="mh ku iq md b gy mm mj l mk ml">-------------------------------------------------<br/>Live datanodes (2):</span><span id="15b8" class="mh ku iq md b gy mm mj l mk ml">Name: 172.31.136.180:50010 (172-31-136-180.node-exporter.arms-prom.svc.cluster.local)<br/>Hostname: iZj6c7rzs9xaeczn47omzcZ<br/>Decommission Status : Normal<br/>Configured Capacity: 211240931328 (196.73 GB)<br/>DFS Used: 24576 (24 KB)<br/>Non DFS Used: 32051716096 (29.85 GB)<br/>DFS Remaining: 179189190656 (166.88 GB)<br/>DFS Used%: 0.00%<br/>DFS Remaining%: 84.83%<br/>Configured Cache Capacity: 0 (0 B)<br/>Cache Used: 0 (0 B)<br/>Cache Remaining: 0 (0 B)<br/>Cache Used%: 100.00%<br/>Cache Remaining%: 0.00%<br/>Xceivers: 1<br/>Last contact: Tue Mar 31 16:48:52 UTC 2020</span></pre><p id="7437" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">4)配置HDFS命令行界面客户端。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="9bda" class="mh ku iq md b gy mi mj l mk ml">[root@iZj6c61fdnjcrcrc2sevsfZ kubernetes-HDFS]# kubectl exec -it hdfs-client-f5bc448dd-rc28d bash<br/>root@hdfs-client-f5bc448dd-rc28d:/# cat /etc/hadoop-custom-conf<br/>cat: /etc/hadoop-custom-conf: Is a directory<br/>root@hdfs-client-f5bc448dd-rc28d:/# cd /etc/hadoop-custom-conf<br/>root@hdfs-client-f5bc448dd-rc28d:/etc/hadoop-custom-conf# ls<br/>core-site.xml  hdfs-site.xml<br/>root@hdfs-client-f5bc448dd-rc28d:/etc/hadoop-custom-conf# cat core-site.xml<br/>&lt;? xml version="1.0"? &gt;<br/>&lt;? xml-stylesheet type="text/xsl" href="configuration.xsl"? &gt;<br/>&lt;configuration&gt;<br/>  &lt;property&gt;<br/>    &lt;name&gt;fs.defaultFS&lt;/name&gt;<br/>    &lt;value&gt;hdfs://hdfs-namenode-0.hdfs-namenode.default.svc.cluster.local:8020&lt;/value&gt;<br/>  &lt;/property&gt;<br/>&lt;/configuration&gt;<br/>root@hdfs-client-f5bc448dd-rc28d:/etc/hadoop-custom-conf# cat hdfs-site.xml<br/>&lt;? xml version="1.0"? &gt;<br/>&lt;? xml-stylesheet type="text/xsl" href="configuration.xsl"? &gt;<br/>&lt;configuration&gt;<br/>  &lt;property&gt;<br/>    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;<br/>    &lt;value&gt;file:///hadoop/dfs/name&lt;/value&gt;<br/>  &lt;/property&gt;<br/>  &lt;property&gt;<br/>    &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt;<br/>    &lt;value&gt;false&lt;/value&gt;<br/>  &lt;/property&gt;<br/>  &lt;property&gt;<br/>    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;<br/>    &lt;value&gt;/hadoop/dfs/data/0&lt;/value&gt;<br/>  &lt;/property&gt;<br/>&lt;/configuration&gt;<br/>root@hdfs-client-f5bc448dd-rc28d:/etc/hadoop-custom-conf# hadoop --version<br/>Error: No command named `--version' was found. Perhaps you meant `hadoop -version'<br/>root@hdfs-client-f5bc448dd-rc28d:/etc/hadoop-custom-conf# hadoop -version<br/>Error: No command named `-version' was found. Perhaps you meant `hadoop version'<br/>root@hdfs-client-f5bc448dd-rc28d:/etc/hadoop-custom-conf# hadoop version<br/>Hadoop 2.7.2<br/>Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41<br/>Compiled by jenkins on 2016-01-26T00:08Z<br/>Compiled with protoc 2.5.0<br/>From source with checksum d0fda26633fa762bff87ec759ebe689c<br/>This command was run using /opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar</span></pre><p id="c5ea" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">5)验证HDFS上的基本文件操作。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="4b57" class="mh ku iq md b gy mi mj l mk ml"># hdfs dfs -ls /<br/>Found 1 items<br/>drwxr-xr-x   - root supergroup          0 2020-03-31 16:51 /test<br/># hdfs dfs -mkdir /mytest<br/># hdfs dfs -copyFromLocal /etc/hadoop/hadoop-env.cmd /test/<br/># hdfs dfs -ls /test<br/>Found 2 items<br/>-rw-r--r--   3 root supergroup       3670 2020-04-20 08:51 /test/hadoop-env.cmd</span></pre><p id="58b0" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">6)下载数据。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="c341" class="mh ku iq md b gy mi mj l mk ml">mkdir -p /data/MNIST/raw/<br/>cd /data/MNIST/raw/<br/>wget http://kubeflow.oss-cn-beijing.aliyuncs.com/mnist/train-images-idx3-ubyte.gz<br/>wget http://kubeflow.oss-cn-beijing.aliyuncs.com/mnist/train-labels-idx1-ubyte.gz<br/>wget http://kubeflow.oss-cn-beijing.aliyuncs.com/mnist/t10k-images-idx3-ubyte.gz<br/>wget http://kubeflow.oss-cn-beijing.aliyuncs.com/mnist/t10k-labels-idx1-ubyte.gz<br/>hdfs dfs -mkdir -p /data/MNIST/raw<br/>hdfs dfs -copyFromLocal *.gz /data/MNIST/raw</span></pre><h1 id="ff77" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">部署Alluxio</h1><p id="361e" class="pw-post-body-paragraph ju jv iq jw b jx lr jz ka kb ls kd ke kf lt kh ki kj lu kl km kn lv kp kq kr ij bi translated">1)选择一个或多个指定的节点。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="26d5" class="mh ku iq md b gy mi mj l mk ml">kubectl label nodes cn-huhehaote.192.168.0.117 dataset=mnist</span></pre><p id="0f42" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">2)创建config.yaml，特别是将节点选择器设置为指定的节点。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="23bc" class="mh ku iq md b gy mi mj l mk ml">cat &lt;&lt; EOF &gt; config.yaml<br/>image: registry.cn-huhehaote.aliyuncs.com/alluxio/alluxio<br/>imageTag: "2.2.0-SNAPSHOT-b2c7e50"<br/>nodeSelector:<br/>    dataset: mnist<br/>properties:<br/>    alluxio.fuse.debug.enabled: "false"<br/>    alluxio.user.file.writetype.default: MUST_CACHE<br/>    alluxio.master.journal.folder: /journal<br/>    alluxio.master.journal.type: UFS<br/>    alluxio.master.mount.table.root.ufs: "hdfs://hdfs-namenode-0.hdfs-namenode.default.svc.cluster.local:8020"<br/>worker:<br/>    jvmOptions: " -Xmx4G "<br/>master:<br/>    jvmOptions: " -Xmx4G "<br/>tieredstore:<br/>  levels:<br/>  - alias: MEM<br/>    level: 0<br/>    quota: 20GB<br/>    type: hostPath<br/>    path: /dev/shm<br/>    high: 0.99<br/>    low: 0.8<br/>fuse:<br/>  image: registry.cn-huhehaote.aliyuncs.com/alluxio/alluxio-fuse<br/>  imageTag: "2.2.0-SNAPSHOT-b2c7e50"<br/>  jvmOptions: " -Xmx4G -Xms4G "<br/>  args:<br/>    - fuse<br/>    - --fuse-opts=direct_io<br/>EOF</span></pre><ul class=""><li id="ec57" class="mn mo iq jw b jx jy kb kc kf mp kj mq kn mr kr ms mt mu mv bi translated">请注意，在编译期间必须指定HDFS版本。在本例中，容器映像支持HDFS 2.7.2。</li><li id="eeec" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr ms mt mu mv bi translated">alluxio . master . mount . table . root . ufs属性指定HDFS地址。</li><li id="c43e" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr ms mt mu mv bi translated">quota属性指定缓存的最大大小。有关具体配置的信息，请访问此<a class="ae lw" href="https://docs.alluxio.io/os/user/stable/en/deploy/Running-Alluxio-On-Kubernetes.html." rel="noopener ugc nofollow" target="_blank">页面</a>。</li></ul><div class="nb nc gp gr nd ne"><a href="https://www.datadriveninvestor.com/2020/06/24/disclosure-and-resolution-program-wont-prevent-physicians-from-practicing-defensive-medicine/" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd ir gy z fp nj fr fs nk fu fw ip bi translated">人工智能、深度学习和医疗实践|数据驱动的投资者</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">人工智能和深度神经学习的效用看起来可能是合法和有前途的，特别是…</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns js ne"/></div></div></a></div><p id="5ec4" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">3)安装Alluxio。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="ce65" class="mh ku iq md b gy mi mj l mk ml">wget http://kubeflow.oss-cn-beijing.aliyuncs.com/alluxio-0.12.0.tgz<br/>tar -xvf alluxio-0.12.0.tgz<br/>helm install alluxio -f config.yaml alluxio</span></pre><p id="0dad" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">4)检查Alluxio的状态，直到所有组件都处于就绪状态。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="5fe4" class="mh ku iq md b gy mi mj l mk ml">helm get manifest alluxio | kubectl get -f -<br/>NAME                     TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                                   AGE<br/>service/alluxio-master   ClusterIP   None         &lt;none&gt;        19998/TCP,19999/TCP,20001/TCP,20002/TCP   14h</span><span id="4de0" class="mh ku iq md b gy mm mj l mk ml">NAME                            DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br/>daemonset.apps/alluxio-fuse     4         4         4       4            4           &lt;none&gt;          14h<br/>NAME                            DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br/>daemonset.apps/alluxio-worker   4         4         4       4            4           &lt;none&gt;          14h</span><span id="1c8a" class="mh ku iq md b gy mm mj l mk ml">NAME                              READY   AGE<br/>statefulset.apps/alluxio-master   1/1     14h</span></pre><h1 id="b46a" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">准备PyTorch容器图像</h1><p id="0f24" class="pw-post-body-paragraph ju jv iq jw b jx lr jz ka kb ls kd ke kf lt kh ki kj lu kl km kn lv kp kq kr ij bi translated">1)准备一份文档。</p><ul class=""><li id="73ce" class="mn mo iq jw b jx jy kb kc kf mp kj mq kn mr kr ms mt mu mv bi translated">创建一个目录、一个Dockerfile文件和一个PyTorch脚本。</li></ul><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="9872" class="mh ku iq md b gy mi mj l mk ml">mkdir pytorch-mnist<br/>cd pytorch-mnist<br/>vim Dockerfile</span></pre><ul class=""><li id="a30b" class="mn mo iq jw b jx jy kb kc kf mp kj mq kn mr kr ms mt mu mv bi translated">输入以下信息:</li></ul><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="515a" class="mh ku iq md b gy mi mj l mk ml">FROM pytorch/pytorch:1.4-cuda10.1-cudnn7-devel</span><span id="4bbc" class="mh ku iq md b gy mm mj l mk ml"># pytorch/pytorch:1.4-cuda10.1-cudnn7-devel</span><span id="a9d8" class="mh ku iq md b gy mm mj l mk ml">ADD mnist.py /</span><span id="0a90" class="mh ku iq md b gy mm mj l mk ml">CMD ["python", "/mnist.py"]</span></pre><p id="417a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">2)准备一个名为mnist.py的测试代码文件。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="5ab0" class="mh ku iq md b gy mi mj l mk ml">cd pytorch-mnist<br/>vim mnist.py</span></pre><ul class=""><li id="d496" class="mn mo iq jw b jx jy kb kc kf mp kj mq kn mr kr ms mt mu mv bi translated">输入以下信息:</li></ul><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="395e" class="mh ku iq md b gy mi mj l mk ml"># -*- coding: utf-8 -*-<br/># @Author: cheyang<br/># @Date:   2020-04-18 22:41:12<br/># @Last Modified by:   cheyang<br/># @Last Modified time: 2020-04-18 22:44:06<br/>from __future__ import print_function<br/>import argparse<br/>import torch<br/>import torch.nn as nn<br/>import torch.nn.functional as F<br/>import torch.optim as optim<br/>from torchvision import datasets, transforms<br/>from torch.optim.lr_scheduler import StepLR<br/></span><span id="d7e5" class="mh ku iq md b gy mm mj l mk ml">class Net(nn.Module):<br/>    def __init__(self):<br/>        super(Net, self).__init__()<br/>        self.conv1 = nn.Conv2d(1, 32, 3, 1)<br/>        self.conv2 = nn.Conv2d(32, 64, 3, 1)<br/>        self.dropout1 = nn.Dropout2d(0.25)<br/>        self.dropout2 = nn.Dropout2d(0.5)<br/>        self.fc1 = nn.Linear(9216, 128)<br/>        self.fc2 = nn.Linear(128, 10)</span><span id="6a09" class="mh ku iq md b gy mm mj l mk ml">    def forward(self, x):<br/>        x = self.conv1(x)<br/>        x = F.relu(x)<br/>        x = self.conv2(x)<br/>        x = F.relu(x)<br/>        x = F.max_pool2d(x, 2)<br/>        x = self.dropout1(x)<br/>        x = torch.flatten(x, 1)<br/>        x = self.fc1(x)<br/>        x = F.relu(x)<br/>        x = self.dropout2(x)<br/>        x = self.fc2(x)<br/>        output = F.log_softmax(x, dim=1)<br/>        return output<br/></span><span id="98f1" class="mh ku iq md b gy mm mj l mk ml">def train(args, model, device, train_loader, optimizer, epoch):<br/>    model.train()<br/>    for batch_idx, (data, target) in enumerate(train_loader):<br/>        data, target = data.to(device), target.to(device)<br/>        optimizer.zero_grad()<br/>        output = model(data)<br/>        loss = F.nll_loss(output, target)<br/>        loss.backward()<br/>        optimizer.step()<br/>        if batch_idx % args.log_interval == 0:<br/>            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(<br/>                epoch, batch_idx * len(data), len(train_loader.dataset),<br/>                100. * batch_idx / len(train_loader), loss.item()))<br/></span><span id="dd1a" class="mh ku iq md b gy mm mj l mk ml">def test(model, device, test_loader):<br/>    model.eval()<br/>    test_loss = 0<br/>    correct = 0<br/>    with torch.no_grad():<br/>        for data, target in test_loader:<br/>            data, target = data.to(device), target.to(device)<br/>            output = model(data)<br/>            test_loss += F.nll_loss(output,<br/>                                    target,<br/>                                    reduction='sum').item()<br/>            pred = output.argmax(dim=1, keepdim=True)<br/>            correct += pred.eq(target.view_as(pred)).sum().item()</span><span id="b7dd" class="mh ku iq md b gy mm mj l mk ml">    test_loss /= len(test_loader.dataset)</span><span id="2e83" class="mh ku iq md b gy mm mj l mk ml">    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(<br/>        test_loss, correct, len(test_loader.dataset),<br/>        100. * correct / len(test_loader.dataset)))<br/></span><span id="150d" class="mh ku iq md b gy mm mj l mk ml">def main():<br/>    # Training settings<br/>    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')<br/>    parser.add_argument('--batch-size', type=int, default=64, metavar='N',<br/>                        help='input batch size for training (default: 64)')<br/>    parser.add_argument('--test-batch-size', type=int,<br/>                        default=1000,<br/>                        metavar='N',<br/>                        help='input batch size for testing (default: 1000)')<br/>    parser.add_argument('--epochs', type=int, default=14, metavar='N',<br/>                        help='number of epochs to train (default: 14)')<br/>    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',<br/>                        help='learning rate (default: 1.0)')<br/>    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',<br/>                        help='Learning rate step gamma (default: 0.7)')<br/>    parser.add_argument('--no-cuda', action='store_true', default=False,<br/>                        help='disables CUDA training')<br/>    parser.add_argument('--seed', type=int, default=1, metavar='S',<br/>                        help='random seed (default: 1)')<br/>    parser.add_argument('--log-interval', type=int, default=10, metavar='N',<br/>                        help='how many batches to wait before logging training status')</span><span id="0675" class="mh ku iq md b gy mm mj l mk ml">    parser.add_argument('--save-model', action='store_true', default=False,<br/>                        help='For Saving the current Model')<br/>    args = parser.parse_args()<br/>    use_cuda = not args.no_cuda and torch.cuda.is_available()</span><span id="3aeb" class="mh ku iq md b gy mm mj l mk ml">    torch.manual_seed(args.seed)</span><span id="bb25" class="mh ku iq md b gy mm mj l mk ml">    device = torch.device("cuda" if use_cuda else "cpu")</span><span id="316c" class="mh ku iq md b gy mm mj l mk ml">    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}<br/>    train_loader = torch.utils.data.DataLoader(<br/>        datasets.MNIST('../data', train=True, download=True,<br/>                       transform=transforms.Compose([<br/>                           transforms.ToTensor(),<br/>                           transforms.Normalize((0.1307,), (0.3081,))<br/>                       ])),<br/>        batch_size=args.batch_size, shuffle=True, **kwargs)<br/>    test_loader = torch.utils.data.DataLoader(<br/>        datasets.MNIST('../data', train=False, transform=transforms.Compose([<br/>                       transforms.ToTensor(),<br/>                       transforms.Normalize((0.1307,), (0.3081,))<br/>                       ])),<br/>        batch_size=args.test_batch_size, shuffle=True, **kwargs)</span><span id="37ef" class="mh ku iq md b gy mm mj l mk ml">    model = Net().to(device)<br/>    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)</span><span id="649a" class="mh ku iq md b gy mm mj l mk ml">    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)<br/>    for epoch in range(1, args.epochs + 1):<br/>        train(args, model, device, train_loader, optimizer, epoch)<br/>        test(model, device, test_loader)<br/>        scheduler.step()</span><span id="1cd0" class="mh ku iq md b gy mm mj l mk ml">    if args.save_model:<br/>        torch.save(model.state_dict(), "mnist_cnn.pt")<br/></span><span id="407f" class="mh ku iq md b gy mm mj l mk ml">if __name__ == '__main__':<br/>    main()</span></pre><p id="ee53" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">3)在与测试代码文件相同的目录级别创建一个定制映像。在本例中，目标容器映像是registry . cn-Shanghai . aliyuncs . com/tensor flow-samples/mnist:py torch-1.4-cuda 10.1-cud nn 7-devel。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="a7cf" class="mh ku iq md b gy mi mj l mk ml">docker build -t \<br/> registry.cn-shanghai.aliyuncs.com/tensorflow-samples/mnist:pytorch-1.4-cuda10.1-cudnn7-devel .</span></pre><p id="d4e8" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">4)将创建的图像registry . cn-Shanghai . aliyuncs . com/tensor flow-samples/mnist:py torch-1.4-cuda 10.1-cud nn 7-devel提交到在中国(杭州)地区创建的图像库。更多信息，参见<a class="ae lw" href="https://help.aliyun.com/document_detail/60743.html" rel="noopener ugc nofollow" target="_blank">基本图像操作</a>。</p><h1 id="0296" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">提交PyTorch训练任务</h1><p id="7e35" class="pw-post-body-paragraph ju jv iq jw b jx lr jz ka kb ls kd ke kf lt kh ki kj lu kl km kn lv kp kq kr ij bi translated">1)安装竞技场。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="56ad" class="mh ku iq md b gy mi mj l mk ml">$ wget http://kubeflow.oss-cn-beijing.aliyuncs.com/arena-installer-0.3.3-332fcde-linux-amd64.tar.gz<br/>$ tar -xvf arena-installer-0.3.3-332fcde-linux-amd64.tar.gz<br/>$ cd arena-installer/<br/>$ ./install.<br/>$ yum install bash-completion -y<br/>$ echo "source &lt;(arena completion bash)" &gt;&gt; ~/.bashrc<br/>$ chmod u+x ~/.bashrc</span></pre><p id="0a5c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">2)使用Arena提交一个训练任务。确保为选择器选择了dataset=mnist。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="d0bb" class="mh ku iq md b gy mi mj l mk ml">arena submit tf \<br/>             --name=alluxio-pytorch \<br/>             --selector=dataset=mnist \<br/>             --data-dir=/alluxio-fuse/data:/data \<br/>             --gpus=1 \<br/>             --image=registry.cn-shanghai.aliyuncs.com/tensorflow-samples/mnist:pytorch-1.4-cuda10.1-cudnn7-devel \<br/>             "python /mnist.py"</span></pre><p id="346f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">3)在Arena中查看训练日志。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="b037" class="mh ku iq md b gy mi mj l mk ml"># arena logs --tail=20 alluxio-pytorch<br/>Train Epoch: 12 [49280/60000 (82%)] Loss: 0.021669<br/>Train Epoch: 12 [49920/60000 (83%)] Loss: 0.008180<br/>Train Epoch: 12 [50560/60000 (84%)] Loss: 0.009288<br/>Train Epoch: 12 [51200/60000 (85%)] Loss: 0.035657<br/>Train Epoch: 12 [51840/60000 (86%)] Loss: 0.006190<br/>Train Epoch: 12 [52480/60000 (87%)] Loss: 0.007776<br/>Train Epoch: 12 [53120/60000 (88%)] Loss: 0.001990<br/>Train Epoch: 12 [53760/60000 (90%)] Loss: 0.003609<br/>Train Epoch: 12 [54400/60000 (91%)] Loss: 0.001943<br/>Train Epoch: 12 [55040/60000 (92%)] Loss: 0.078825<br/>Train Epoch: 12 [55680/60000 (93%)] Loss: 0.000925<br/>Train Epoch: 12 [56320/60000 (94%)] Loss: 0.018071<br/>Train Epoch: 12 [56960/60000 (95%)] Loss: 0.031451<br/>Train Epoch: 12 [57600/60000 (96%)] Loss: 0.031353<br/>Train Epoch: 12 [58240/60000 (97%)] Loss: 0.075761<br/>Train Epoch: 12 [58880/60000 (98%)] Loss: 0.003975<br/>Train Epoch: 12 [59520/60000 (99%)] Loss: 0.085389</span><span id="9800" class="mh ku iq md b gy mm mj l mk ml">Test set: Average loss: 0.0256, Accuracy: 9921/10000 (99%)</span></pre><h1 id="d709" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">摘要</h1><p id="870c" class="pw-post-body-paragraph ju jv iq jw b jx lr jz ka kb ls kd ke kf lt kh ki kj lu kl km kn lv kp kq kr ij bi translated">早先，在HDFS上运行PyTorch程序需要修改PyTorch适配器的代码。现在，Alluxio简化了适应，允许您快速开发和训练模型。在<a class="ae lw" href="https://www.alibabacloud.com/product/kubernetes" rel="noopener ugc nofollow" target="_blank">阿里云Kubernetes平台</a>上，前面的工作变得非常简单。我们强烈建议您尝试一下！</p><h1 id="6fe1" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">原始来源:</h1><div class="nb nc gp gr nd ne"><a href="https://www.alibabacloud.com/blog/alluxio-deep-learning-practices---1-running-pytorch-framework-on-hdfs_596532" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd ir gy z fp nj fr fs nk fu fw ip bi translated">Alluxio深度学习实践- 1:在HDFS上运行PyTorch框架</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">阿里巴巴容器服务2020年8月25日81 Google的TensorFlow和脸书的PyTorch是两个流行的深度学习…</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">www.alibabacloud.com</p></div></div><div class="nn l"><div class="nt l np nq nr nn ns js ne"/></div></div></a></div><p id="8a9d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">访问专家视图— </strong> <a class="ae lw" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="jw ir">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>