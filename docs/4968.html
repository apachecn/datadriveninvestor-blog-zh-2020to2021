<html>
<head>
<title>The Architecture and Implementation of LeNet from Scratch in Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch中LeNet的架构与实现</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/architecture-implementation-of-lenet-from-scratch-in-pytorch-709cc38c00a9?source=collection_archive---------1-----------------------#2020-09-01">https://medium.datadriveninvestor.com/architecture-implementation-of-lenet-from-scratch-in-pytorch-709cc38c00a9?source=collection_archive---------1-----------------------#2020-09-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="0968" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">重建最古老的神经网络架构。</p><h1 id="c17c" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">介绍</h1><p id="b075" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">我将在medium上发表一系列文章，涵盖大多数CNN架构，并在PyTorch和TensorFlow上实现。我相信在掌握了标准架构之后，我们将准备好为任何任务构建我们自己的定制CNN架构。</p><p id="5462" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以我从最古老的CNN架构LeNet(1998)开始。它主要是为识别手写和其他字符而开发的。</p><p id="15fc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该架构共有7层，由2组卷积层和平均池层组成，其后是平坦卷积层。之后，我们有2个密集的全连接层，分别有84个和10个输出神经元。</p><h2 id="858b" class="lo km iq bd kn lp lq dn kr lr ls dp kv jy lt lu kz kc lv lw ld kg lx ly lh lz bi translated">LeNet架构</h2><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ma"><img src="../Images/0b7ff59fe5d0a39cd832c683b21bd05d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*26Oa6s9_V6euoA2r.jpeg"/></div></div></figure><p id="b2d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上图总结了LeNet的架构，我们来分解一下各层的参数。</p><p id="7349" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种体系结构是专门为低分辨率图像设计的，例如大小为32 x 32灰度级的MNIST图像。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="ab gu cl mm"><img src="../Images/7414923bd26bd61d1f22c28fbba4691d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*2rD5uCYnAKKABEWbQDU9tQ.png"/></div></figure><h2 id="c008" class="lo km iq bd kn lp lq dn kr lr ls dp kv jy lt lu kz kc lv lw ld kg lx ly lh lz bi translated">输出通道的数量可以通过下式计算:</h2><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mn"><img src="../Images/8a53f077ad97624f220f82a04a19c3cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/0*sIY6s23_1sFar6Rp.png"/></div></div></figure><h2 id="fd70" class="lo km iq bd kn lp lq dn kr lr ls dp kv jy lt lu kz kc lv lw ld kg lx ly lh lz bi translated">学习参数的数量= [i x (f x f) x b] + b</h2><p id="cc46" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">i =卷积层中输入通道的数量<br/> f =滤波器尺寸<br/> b =偏置数量</p><h2 id="a751" class="lo km iq bd kn lp lq dn kr lr ls dp kv jy lt lu kz kc lv lw ld kg lx ly lh lz bi translated">总体计算:</h2><p id="3918" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">跨距和填充在整个网络中保持不变，<br/>因此<strong class="jp ir"> S = 1，P = 0 </strong></p><ol class=""><li id="e0fa" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk mt mu mv mw bi translated"><strong class="jp ir">输入图层形状= 32×32×1</strong></li><li id="a708" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk mt mu mv mw bi translated"><strong class="jp ir">用6个大小为(5x5)的过滤器应用conv2d后，</strong></li></ol><ul class=""><li id="a1af" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk nc mu mv mw bi translated">输出形状=((32+0–5)/1)+1 = 28</li><li id="772d" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk nc mu mv mw bi translated">学习参数的数量= ([ 1 x (5 * 5) x 1] + 1) * 6个过滤器= 156</li></ul><p id="599b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.<strong class="jp ir">应用平均大小池(2x2)后，</strong></p><ul class=""><li id="a2c4" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk nc mu mv mw bi translated">输出形状=((28+0–2)/2)+1 = 14</li><li id="9539" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk nc mu mv mw bi translated">学习参数数量=无(0)</li></ul><p id="cdd0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4.<strong class="jp ir">应用conv2d和16个大小为(5x5)的过滤器后，</strong></p><ul class=""><li id="5bac" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk nc mu mv mw bi translated">输出形状=((14+0–5)/1)+1 = 10</li><li id="7b59" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk nc mu mv mw bi translated">学习参数的数量= ([ 6 x (5 * 5) x 1] + 1) * 16个过滤器= 2416</li></ul><p id="0748" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">5.<strong class="jp ir">应用平均大小池(2x2)后，</strong></p><ul class=""><li id="70dc" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk nc mu mv mw bi translated">输出形状=((10+0–2)/2)+1 = 5</li><li id="64ff" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk nc mu mv mw bi translated">学习参数数量=无(0)</li></ul><p id="6b1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">6.<strong class="jp ir">应用conv2d和150个大小为(5x5)的过滤器后，</strong></p><ul class=""><li id="287c" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk nc mu mv mw bi translated">输出形状=((5+0–5)/1)+1 = 1</li><li id="103e" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk nc mu mv mw bi translated">学习参数的数量= ([ 16 x (5 * 5) x 1] + 1) * 120个过滤器= 48120</li></ul><p id="acfd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">7.<strong class="jp ir">应用84个神经元的线性层，</strong></p><ul class=""><li id="3824" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk nc mu mv mw bi translated">学习参数个数= (120 * 84 + 84) = 10164</li></ul><p id="f12c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">8.<strong class="jp ir">应用10个神经元的线性层，</strong></p><ul class=""><li id="bcbe" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk nc mu mv mw bi translated">学习参数个数= (84 * 10 + 10) = 850</li></ul><div class="nd ne gp gr nf ng"><a href="https://www.datadriveninvestor.com/2020/06/24/disclosure-and-resolution-program-wont-prevent-physicians-from-practicing-defensive-medicine/" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd ir gy z fp nl fr fs nm fu fw ip bi translated">人工智能、深度学习和医疗实践|数据驱动的投资者</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">人工智能和深度神经学习的效用看起来可能是合法和有前途的，特别是…</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu mk ng"/></div></div></a></div></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><h1 id="0ff5" class="kl km iq bd kn ko oc kq kr ks od ku kv kw oe ky kz la of lc ld le og lg lh li bi translated">用Pytorch实现LeNet</h1><h2 id="925e" class="lo km iq bd kn lp lq dn kr lr ls dp kv jy lt lu kz kc lv lw ld kg lx ly lh lz bi translated">导入库</h2><figure class="mb mc md me gt mf"><div class="bz fp l di"><div class="oh oi l"/></div></figure><h2 id="1131" class="lo km iq bd kn lp lq dn kr lr ls dp kv jy lt lu kz kc lv lw ld kg lx ly lh lz bi translated">模型结构</h2><figure class="mb mc md me gt mf"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="7c1d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们看到的，模型的总结与我们的计算完全吻合。</p><h2 id="8d85" class="lo km iq bd kn lp lq dn kr lr ls dp kv jy lt lu kz kc lv lw ld kg lx ly lh lz bi translated">MNIST实施:</h2><figure class="mb mc md me gt mf"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="5296" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从图中，我们看到模型在训练和测试数据上表现良好。</p><p id="58ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">损失值:</p><div class="mb mc md me gt ab cb"><figure class="oj mf ok ol om on oo paragraph-image"><img src="../Images/e8755418ee34f3b5e43a77f3de569414.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*lkLVM4GjLzD2ZU9CK2tR_A.png"/></figure><figure class="oj mf op ol om on oo paragraph-image"><img src="../Images/0fd54d608f95824bb27dbf41777de71f.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*jF_ZIOtiGuCYtthIvzMsXg.png"/><figcaption class="oq or gj gh gi os ot bd b be z dk ou di ov ow">Training and Validation Loss</figcaption></figure></div><h2 id="387e" class="lo km iq bd kn lp lq dn kr lr ls dp kv jy lt lu kz kc lv lw ld kg lx ly lh lz bi translated">我们模型的准确性:</h2><figure class="mb mc md me gt mf"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="bab1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在MNIST模型上，我们得到了96.37的良好训练精度和96.32的验证精度。</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><p id="f758" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">📌<strong class="jp ir">完整实现可在此</strong><a class="ae ox" href="https://gist.github.com/bala-codes/0f79addd101152d9d67f33ff69ab9234" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">GitHub Gist</strong></a><strong class="jp ir">或</strong> <a class="ae ox" href="https://colab.research.google.com/gist/bala-codes/0f79addd101152d9d67f33ff69ab9234/architecture-implementation-of-lenet-from-scratch-in-pytorch.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">打开Colab </strong> </a> <strong class="jp ir">。</strong></p><blockquote class="oy oz pa"><p id="4c90" class="jn jo pb jp b jq jr js jt ju jv jw jx pc jz ka kb pd kd ke kf pe kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">参考文献:</em> </strong></p></blockquote><p id="70f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[1] Yann LeCun，<a class="ae ox" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" rel="noopener ugc nofollow" target="_blank">基于梯度的学习应用于文档识别</a> (1998)。</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><p id="65a1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">文章作者:</p><p id="a464" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">巴拉克里希纳·库马尔五世</p><h2 id="7b65" class="lo km iq bd kn lp lq dn kr lr ls dp kv jy lt lu kz kc lv lw ld kg lx ly lh lz bi translated">获得专家观点— <a class="ae ox" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>