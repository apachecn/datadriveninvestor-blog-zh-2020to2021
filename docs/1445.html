<html>
<head>
<title>Context-Based Search Using Bert</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Bert的基于上下文的搜索</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/context-based-search-using-bert-8957d25feaa9?source=collection_archive---------2-----------------------#2020-03-18">https://medium.datadriveninvestor.com/context-based-search-using-bert-8957d25feaa9?source=collection_archive---------2-----------------------#2020-03-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f69d98004271f91aab4e6c0557cc039f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lijfjMWwOTsW4AKL"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">(Photo By Nicolas J Leclercq On Unsplash)</figcaption></figure><p id="b4f5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们现在是在2020年，在40年内，互联网已经给我们带来了大约15亿个网站。这比2011年印度的人口还要多。因此，通过互联网搜索是一项艰巨的任务。但是多亏了像谷歌这样的搜索引擎，必应变得简单了。为了改善搜索体验，他们使用pagerank、knowledge graph等算法(<strong class="ke ir"> <em class="la">这是一个完全不同的话题</em> </strong>)。</p><h1 id="ff8d" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">语义搜索的力量:</h1><p id="d029" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">用户使用一些我们称之为查询的术语通过这些搜索引擎进行搜索，并且基于这些查询，搜索引擎将获取一些结果。之前可以看到，这些引擎主要依靠关键字匹配来执行搜索。然而，这些基于关键字的匹配无法理解查询的上下文，并且基于它所使用的匹配关键字返回结果。然而，最近随着深度学习的进步，有可能理解查询的语义，这是一个巨大的成功。例如让我们考虑两个句子"<em class="la">是的银行损失了所有的钱"</em>和<em class="la">"恒河的河岸很漂亮"</em>这个词<strong class="ke ir">银行</strong>有两种不同的意思。但是传统的模型会为同一个单词返回相同的向量表示。伯特来救援了。它将能够理解单词的含义，并根据上下文返回向量。下图展示了语义搜索的威力</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/476f298b89990659142c47171a5fdcc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*irGXNsRu6zFAjOIg.jpg"/></div></div></figure><p id="0168" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">正如我们所看到的，使用bert后，搜索结果有了显著的改善。伯特通过理解单词<em class="la">到</em>与其他单词的关系来学习其语义。而之前的算法无法理解单词<em class="la">对</em>的重要性，并返回一个美国公民想要去巴西旅游的结果。</p><h1 id="9027" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">伯特:</h1><p id="82bc" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">来自Transformers或BERT的双向编码器被认为是自然语言处理领域的一场革命。该模型由谷歌在2018年开源。该模型同时考虑了左右上下文。这项任务是通过两种策略实现的。</p><h2 id="dcc0" class="mi lc iq bd ld mj mk dn lh ml mm dp ll kn mn mo lp kr mp mq lt kv mr ms lx mt bi translated">掩蔽语言建模:</h2><p id="3473" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">在这种技术中，我们屏蔽了大约15–20%的令牌，并让模型预测它们。这种方法有助于我们获得关于单词表征的各种统计见解。当我们想了解单词的更深层次的表达时，这种方法非常有用。</p><h2 id="ee7f" class="mi lc iq bd ld mj mk dn lh ml mm dp ll kn mn mo lp kr mp mq lt kv mr ms lx mt bi translated">下一句预测:</h2><p id="148b" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">在这种技术中，我们获取一个句子，并预测作为输入提供的下一个句子是否是原始文档中的下一个句子。在训练过程中，我们取两个句子，其中第二个句子实际上是原始文档中的下一个句子，占50%，而其余50%是任何其他随机的句子。这个方法基本上在问答模型中帮助我们。</p><h1 id="6ddb" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">如何执行语义搜索:</h1><p id="a198" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">现在我们对bert的工作有了一点了解，让我们看看如何将它应用到我们的任务中。假设我们有100个文档，当然我们会有一个查询。因此，我们将计算每个文档的嵌入，我们也将为我们的查询这样做。在计算嵌入向量之后，我们将找到查询和每个文档之间的余弦相似性。现在，基于相似性，我们将对文档进行排序，并返回前k个文档<strong class="ke ir"><em class="la"/></strong>，其中k值取决于我们的要求。</p><p id="5e92" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了实现这一点，我们将使用句子转换器库，它将帮助我们嵌入每个句子或文档。</p><pre class="me mf mg mh gt mu mv mw mx aw my bi"><span id="833d" class="mi lc iq mv b gy mz na l nb nc"><strong class="mv ir">from</strong> <strong class="mv ir">sentence_transformers</strong> <strong class="mv ir">import</strong> SentenceTransformer<br/>model = SentenceTransformer('bert-base-nli-mean-tokens')</span></pre><p id="0e32" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">上面的代码片段创建了一个对我们的句子进行编码的模型。利用这一点，我们可以计算每个句子的嵌入。</p><p id="5381" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">要将一个句子转换成它的嵌入形式，我们可以简单地使用encode方法。</p><p id="475d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了找到每个句子之间的余弦相似性，我们可以利用scipy库。</p><pre class="me mf mg mh gt mu mv mw mx aw my bi"><span id="c60b" class="mi lc iq mv b gy mz na l nb nc">from scipy.spatial.distance import cosine</span></pre><p id="2dcc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在，使用由模型为查询和文档计算的嵌入，我们将尝试找到最相似的文档并作为结果返回它们。</p><div class="nd ne gp gr nf ng"><a href="https://www.datadriveninvestor.com/2019/02/07/8-skills-you-need-to-become-a-data-scientist/" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd ir gy z fp nl fr fs nm fu fw ip bi translated">成为数据科学家所需的8项技能|数据驱动型投资者</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">数字吓不倒你？没有什么比一张漂亮的excel表更令人满意的了？你会说几种语言…</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu jw ng"/></div></div></a></div><p id="3d1c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这是语义搜索的理论概述。在下一篇文章中，我们将使用一些不同的方法，如xlnet，看看它是否工作正常。</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="nv nw l"/></div></figure></div></div>    
</body>
</html>