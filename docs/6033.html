<html>
<head>
<title>Fixing Small Photos with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用深度学习固定小照片</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/fixing-small-photos-with-deep-learning-eeae87172a1b?source=collection_archive---------7-----------------------#2020-10-09">https://medium.datadriveninvestor.com/fixing-small-photos-with-deep-learning-eeae87172a1b?source=collection_archive---------7-----------------------#2020-10-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="802c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你使用社交媒体吗？你有没有给别人发了一张照片，当你后来看的时候，你发现这张照片的质量很差？如果你能逆转这一切呢？</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/a54ca414537015ebcc48b84dbe926fe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G4s1Mskww09qAVXOZTMS2A.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk"><a class="ae le" href="https://www.prima.co.uk/leisure/news/a39405/anxious-cheetah-cubs-puppy-playdates/" rel="noopener ugc nofollow" target="_blank">Link to image</a></figcaption></figure><h1 id="bb35" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">如果</h1><p id="8ad1" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">主要目的是-&gt;获取一幅图像，并将其向上采样3倍(这意味着如果图像最初是100×100，到最后我们会得到300×300的图像)，而不会丢失任何信息。现在，如果我们决定让图像为100x100，我们可以调整它的大小，但分辨率会比以前高得多。</p><p id="9950" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将看看如何将这作为一个深度学习问题，深入研究代码，并以一篇关于该主题的论文中的一些观点作为结束。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="fe3e" class="lf lg it bd lh li mp lk ll lm mq lo lp lq mr ls lt lu ms lw lx ly mt ma mb mc bi translated">我们还能做什么</h1><p id="1bbd" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">假设你不想为此使用深度学习。那你会怎么做？你有几个选择。(这些我都不推荐)</p><ol class=""><li id="14ab" class="mu mv it js b jt ju jx jy kb mw kf mx kj my kn mz na nb nc bi translated">成为一名Photoshop高手(尽管现在连这个都使用深度学习)</li><li id="af53" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn mz na nb nc bi translated">回到过去，确保你拍了更好的照片</li><li id="af35" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn mz na nb nc bi translated">处理它</li><li id="dc0c" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn mz na nb nc bi translated">(推荐)阅读这篇文章</li></ol></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="a874" class="lf lg it bd lh li mp lk ll lm mq lo lp lq mr ls lt lu ms lw lx ly mt ma mb mc bi translated">我们能在哪里使用这个？</h1><ul class=""><li id="cc1e" class="mu mv it js b jt md jx me kb ni kf nj kj nk kn nl na nb nc bi translated">游戏！想象一下1080年的马里奥</li><li id="3673" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn nl na nb nc bi translated">Whatsapp垃圾</li><li id="ab28" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn nl na nb nc bi translated">或许更好的视频通话？我们可以不压缩和发送视频，而是拍摄一个潜在的低分辨率视频，并让它以相当高的质量出现</li><li id="6a7c" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn nl na nb nc bi translated">有一些你想升级的旧照片吗？运行它！</li></ul></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="6a53" class="lf lg it bd lh li mp lk ll lm mq lo lp lq mr ls lt lu ms lw lx ly mt ma mb mc bi translated">技术方面</h1><p id="e420" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">既然我们已经解决了这个问题。让我们进一步定义这个问题。我们将尝试从一篇<a class="ae le" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shi_Real-Time_Single_Image_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中探究。石，，等，“利用高效的亚像素卷积神经网络实现单幅图像和视频的实时超分辨率”IEEE计算机视觉和模式识别会议录。2016.</p><p id="cb1f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">目标的技术版本是这样的。假设我们有两个“空间”。一个具有高分辨率，另一个具有低分辨率。我们的网络应该学习如何将像素从低分辨率空间转换到另一个空间。高效地。</p><p id="3281" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要做到这一点，我们需要遵循标准的深度学习训练程序，并进行一些修改。(注意，总代码太长，无法在这里发布，所以你可以在我的<a class="ae le" href="https://github.com/SubhadityaMukherjee/pytorchTutorialRepo/tree/master/SuperRes" rel="noopener ugc nofollow" target="_blank">回购</a>上找到所有代码)</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="09e7" class="lf lg it bd lh li mp lk ll lm mq lo lp lq mr ls lt lu ms lw lx ly mt ma mb mc bi translated">获取数据。</h1><p id="3083" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">第一步通常是获取数据。出于我们的目的，我们可以使用<a class="ae le" href="http://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz" rel="noopener ugc nofollow" target="_blank"> BSDS300数据集</a>。只要得到它并提取它。</p><p id="587e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们需要能够加载数据。为此，我们需要一些东西。</p><ul class=""><li id="c3b2" class="mu mv it js b jt ju jx jy kb mw kf mx kj my kn nl na nb nc bi translated">我们需要检查图像是否是一个文件并加载它。我们需要执行转换。我们需要加载数据。</li><li id="8701" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn nl na nb nc bi translated">因为大部分只是标准代码，所以让我们只看新的东西</li><li id="df49" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn nl na nb nc bi translated">居中裁剪。要裁剪图像，我们需要确定一个有效的裁剪尺寸。</li></ul><pre class="kp kq kr ks gt nm nn no np aw nq bi"><span id="d2a9" class="nr lg it nn b gy ns nt l nu nv">def calculate_valid_crop_size(crop_size, upscale_factor):<br/>    return crop_size - (crop_size % upscale_factor)</span></pre><p id="94e8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以在转换管道中使用CenterCrop(crop_size)来调用它。</p><ul class=""><li id="d696" class="mu mv it js b jt ju jx jy kb mw kf mx kj my kn nl na nb nc bi translated">主数据加载器。这将使我们能够读取数据集并根据需要使用它。注意，我们实际上有<strong class="js iu">两幅</strong>图像。一个是输入图像，另一个是我们需要将其转换到的目标。我们基本上加载它们，执行所需的转换，并将它们作为一个<strong class="js iu">元组</strong>返回。这是重要的部分。和分类的主要区别。我们在主数据加载器中返回的不是一个，而是两个东西。</li><li id="18a1" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn nl na nb nc bi translated">现在我们有一对图像，一个在低分辨率空间，另一个在高分辨率空间。</li></ul><pre class="kp kq kr ks gt nm nn no np aw nq bi"><span id="b2b3" class="nr lg it nn b gy ns nt l nu nv">class DatasetFromFolder(data.Dataset):<br/>    def __init__(self, image_dir, input_transform = None, target_transform =<br/>                 None):<br/>        super(DatasetFromFolder, self).__init__()<br/><br/>        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir)<br/>                               if is_image_file(x)]<br/>        self.input_transform = input_transform<br/>        self.target_transform = target_transform<br/><br/>    def __getitem__(self, index):<br/>        input = load_img(self.image_filenames[index])<br/>        target = input.copy()<br/>        if self.input_transform:<br/>            input = self.input_transform(input)<br/>        if self.target_transform:<br/>            target = self.target_transform(target)<br/>        <br/>        return input, target<br/>    <br/>    def __len__(self):<br/>        return len(self.image_filenames)</span></pre></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="8831" class="lf lg it bd lh li mp lk ll lm mq lo lp lq mr ls lt lu ms lw lx ly mt ma mb mc bi translated">图片1</h1><p id="6f61" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">这是我们想要提升的形象。这是全尺寸的图像。如你所见，它非常小。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/ed565c904d565ab691e5514b675cc9de.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*zrgQdtjblWAZyGrTWcMCnQ.jpeg"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Small mountain</figcaption></figure></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="93c2" class="lf lg it bd lh li mp lk ll lm mq lo lp lq mr ls lt lu ms lw lx ly mt ma mb mc bi translated">创建网络</h1><p id="f9d0" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">欢迎来到深水区。我们的网络实际上很简单，因为我们使用PyTorch。我们有4个conv层，4个ReLUs和一个叫做PixelShuffle的特殊层。</p><p id="c33e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">PixelShuffle是什么？这是我们正在考虑的论文的决定性时刻。所以定义事实上PyTorch实际上已经内置了它。简单来说，这一层就是洗牌机。它取形状H(高)x W(宽)x C(通道)的张量。r(活化数),给我们一个形状为rH×rW×rC的张量。“混洗”又名子像素卷积层。这很有用，因为现在一切都是并行的。</p><div class="nx ny gp gr nz oa"><a href="https://www.datadriveninvestor.com/2020/06/24/disclosure-and-resolution-program-wont-prevent-physicians-from-practicing-defensive-medicine/" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd iu gy z fp of fr fs og fu fw is bi translated">人工智能、深度学习和医疗实践|数据驱动的投资者</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">人工智能和深度神经学习的效用看起来可能是合法和有前途的，特别是…</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="oj l"><div class="ok l ol om on oj oo ky oa"/></div></div></a></div><p id="2e86" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还需要初始化我们的权重。这样做是为了确保我们的网络有一个良好的开端。这里我们使用正交初始化。</p><pre class="kp kq kr ks gt nm nn no np aw nq bi"><span id="37c8" class="nr lg it nn b gy ns nt l nu nv">import torch<br/>import torch.nn as nn<br/>import torch.nn.functional as F<br/>import torch.nn.init as init<br/><br/># Main network<br/>class Net(nn.Module):<br/>    def __init__(self, upscale_factor):<br/>        super(Net, self).__init__()<br/>        self.relu = nn.ReLU()<br/>        self.conv1 = nn.Conv2d(1, 64, (5,5), (1,1), (2,2))<br/>        self.conv2 = nn.Conv2d(64, 64, (3,3), (1,1), (1,1))<br/>        self.conv3 = nn.Conv2d(64, 32, (3,3), (1,1), (1,1))<br/>        self.conv4 = nn.Conv2d(32, upscale_factor**2, (3,3), (1,1), (1,1))<br/>        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)<br/><br/>        self._initialize_weights()<br/><br/>    def forward(self, x):<br/>        x = self.relu(self.conv1(x))<br/>        x = self.relu(self.conv2(x))<br/>        x = self.relu(self.conv3(x))<br/>        x = self.pixel_shuffle(self.conv4(x))<br/>        return x<br/><br/>    def _initialize_weights(self):<br/>        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))<br/>        init.orthogonal_(self.conv2.weight,init.calculate_gain('relu'))<br/>        init.orthogonal_(self.conv3.weight,init.calculate_gain('relu'))<br/>        init.orthogonal_(self.conv4.weight)</span></pre></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="d5f0" class="lf lg it bd lh li mp lk ll lm mq lo lp lq mr ls lt lu ms lw lx ly mt ma mb mc bi translated">火车！</h1><p id="c9e2" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">哇，我们差不多完成一半了。现在进行主要训练。我们首先加载我们需要的所有东西，用一个升级因子导入我们的网络(也就是我们需要升级多少个x)。然后我们初始化我们的优化器。我们将在这里使用亚当，因为它的效果最好。我们还需要一个损失函数。</p><p id="49a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">好吧，如果你想一想，既然我们试图找到一个像素方面的差异，为什么不使用它呢..MSELoss。</p><p id="313b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们遵循简单的策略:批处理-&gt;推到GPU -&gt;零优化器梯度-&gt;计算损失-&gt;反推-&gt;逐步优化器。(注:如果这里有你不明白的地方，看看我的<a class="ae le" href="https://www.subhadityamukherjee.me/deconstructingdl.html" rel="noopener ugc nofollow" target="_blank">博客</a></p><pre class="kp kq kr ks gt nm nn no np aw nq bi"><span id="8afe" class="nr lg it nn b gy ns nt l nu nv">def train(args, device, train_loader,model,  epoch, optimizer, criterion):<br/>    epoch_loss = 0<br/>    device = torch.device("cuda") # Sending to GPU<br/>    for batch_idx, batch in tqdm(enumerate(train_loader, 1)):<br/>        input, target = batch[0].to(device), batch[1].to(device)<br/>        optimizer.zero_grad() # zero gradients<br/>        loss = criterion(model(input), target) # calc loss<br/>        epoch_loss += loss.item()<br/>        loss.backward() #backprop<br/>        optimizer.step()<br/><br/>        print(f"Iteration: {batch_idx}, Loss: {loss} ")<br/>    print(f"Avg epoch_loss: {epoch/len(train_loader)}")</span></pre><p id="4f77" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">测试循环与这里的非常相似，所以不需要专门讨论它。我们在模型完成训练后保存它。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="89b2" class="lf lg it bd lh li mp lk ll lm mq lo lp lq mr ls lt lu ms lw lx ly mt ma mb mc bi translated">运行它！</h1><p id="ffc6" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">现在我们有了一个很酷的模型。把它投入使用怎么样？</p><p id="a203" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了做到这一点，让我们采取一个图像，预处理，将其转换为张量。之后，我们可以加载模型，并将此图像发送到GPU。</p><pre class="kp kq kr ks gt nm nn no np aw nq bi"><span id="aa32" class="nr lg it nn b gy ns nt l nu nv">img = Image.open(opt.input_image).convert('YCbCr')<br/>y, cb, cr = img.split()<br/><br/>model = torch.load(opt.model)<br/>img_to_tensor = ToTensor()<br/>input = img_to_tensor(y).view(1, -1, y.size[1], y.size[0])<br/><br/>if opt.cuda:<br/>        model = model.cuda()<br/>        input = input.cuda()</span></pre><p id="4a43" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后我们把它通过我们的模型。我们现在得到一个奇怪的输出。为了解决这个问题，我们把它变成一个numpy数组，并执行一些操作，使我们的图像变成一个合适的图像。基本上，我们改变这些值，以便我们有一个RGB值范围内的范围。这将允许我们绘制它或做我们想做的任何事情。</p><pre class="kp kq kr ks gt nm nn no np aw nq bi"><span id="bad4" class="nr lg it nn b gy ns nt l nu nv">out = model(input)<br/>out = out.cpu()<br/>out_img_y = out[0].detach().numpy()<br/>out_img_y *= 255.0<br/>out_img_y = out_img_y.clip(0, 255)<br/>out_img_y = Image.fromarray(np.uint8(out_img_y[0]), mode='L')</span></pre><p id="17a0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在可以调整大小，并保存图像到任何我们想要的地方。</p><pre class="kp kq kr ks gt nm nn no np aw nq bi"><span id="e08a" class="nr lg it nn b gy ns nt l nu nv">out_img_cb = cb.resize(out_img_y.size, Image.BICUBIC)<br/>out_img_cr = cr.resize(out_img_y.size, Image.BICUBIC)<br/>out_img = Image.merge('YCbCr', [out_img_y, out_img_cb,<br/>                            out_img_cr]).convert('RGB')<br/><br/>out_img.save(opt.output_filename)<br/>print('output image saved to ', opt.output_filename)</span></pre><p id="7e0d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们完了。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="ea86" class="lf lg it bd lh li mp lk ll lm mq lo lp lq mr ls lt lu ms lw lx ly mt ma mb mc bi translated">输出</h1><p id="a7a2" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">这是我们运行这个模型一段时间后得到的结果。你可能会说，嘿，质量没那么好。但是想想看，这是原来的3倍，它仍然很棒。</p><p id="c496" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，如果我们把这个和我们的原始图像一样大，我们会注意到一个巨大的变化…也称为..超分辨率！！！！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi op"><img src="../Images/4a281bae3c83a57421e6d0231b5ed0a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SM6MHfDLuAZgaxPx2WdYFw.jpeg"/></div></div></figure><h1 id="a56c" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">奖金</h1><p id="f73b" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">我还转换了脚本来处理视频。:)去看看<a class="ae le" href="https://github.com/SubhadityaMukherjee/pytorchTutorialRepo/tree/master/SuperRes" rel="noopener ugc nofollow" target="_blank">回购</a></p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="951a" class="lf lg it bd lh li mp lk ll lm mq lo lp lq mr ls lt lu ms lw lx ly mt ma mb mc bi translated">论文引发的一些思考</h1><ul class=""><li id="2fc6" class="mu mv it js b jt md jx me kb ni kf nj kj nk kn nl na nb nc bi translated">超级分辨率用于医学图像、人脸识别、卫星图像</li><li id="d7cd" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn nl na nb nc bi translated">我们的目标是学习数据中隐含的冗余</li><li id="2cc1" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn nl na nb nc bi translated">学习的滤波器是比单个滤波器更好的上采样表示</li><li id="bc6a" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn nl na nb nc bi translated">使用从0.01到0.0001的可变学习率效果很好</li><li id="4938" class="mu mv it js b jt nd jx ne kb nf kf ng kj nh kn nl na nb nc bi translated">原始图像中的每个像素仅表示一次，以保持网络的效率</li></ul></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="eb06" class="lf lg it bd lh li mp lk ll lm mq lo lp lq mr ls lt lu ms lw lx ly mt ma mb mc bi translated">后续步骤</h1><p id="918b" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">谢谢你读到这里！希望你喜欢这篇文章，它能帮助你更好地理解这个话题。我真诚地建议你阅读这份报纸。这是一本容易阅读的书。超分辨率是我很久以来一直感兴趣的东西，就在今天，我发现了一个<a class="ae le" href="https://github.com/jixiaozhong/RealSR" rel="noopener ugc nofollow" target="_blank">甚至更好的网络</a>来完成这项任务。</p><p id="a424" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你喜欢这篇文章或者对以后的文章有任何反馈，请联系我们。希望你有一个伟大的一天！</p><h2 id="d2d0" class="nr lg it bd lh oq or dn ll os ot dp lp kb ou ov lt kf ow ox lx kj oy oz mb pa bi translated">访问专家视图— <a class="ae le" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>