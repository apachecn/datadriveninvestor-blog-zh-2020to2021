<html>
<head>
<title>The Essential Guide to Building a Twitter Sentiment Analysis System</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建Twitter情感分析系统的基本指南</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/the-essential-guide-to-building-a-twitter-sentiment-analysis-system-ac484d40b8a2?source=collection_archive---------2-----------------------#2020-12-02">https://medium.datadriveninvestor.com/the-essential-guide-to-building-a-twitter-sentiment-analysis-system-ac484d40b8a2?source=collection_archive---------2-----------------------#2020-12-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ae23" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在社交媒体数据分析领域，一个流行的研究领域是Twitter数据的情感分析。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8760a0c45f1bbdece89681fdc5de17fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UM7Zd0gzBQT-B70iyGiMNw.jpeg"/></div></div></figure><p id="c5d4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Twitter是世界上最受欢迎的社交媒体平台之一，每月有3.3亿活跃用户，每天发送5亿条推文。通过仔细分析这些推文的情绪——例如，无论它们是积极的、消极的还是中立的——我们可以了解很多关于人们对某些话题的感受。</p><p id="77c4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">出于各种原因，理解推文的情绪很重要:商业营销、政治、公共行为分析和信息收集只是几个例子。Twitter数据的情绪分析可以帮助营销人员了解客户对产品发布和营销活动的反应，也可以帮助政党了解公众对政策变化或公告的反应。</p><p id="7c20" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然而，Twitter数据分析并不是一项简单的任务。每秒大约有6000条推文发布。Twitter数据真多！尽管人类很容易理解一条推文的情感，但人类情感分析根本无法扩展。</p><p id="7268" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在本文中，我们将着眼于构建一个可扩展的Twitter情感分析系统，以帮助我们更好地理解机器学习在社交媒体数据分析中的作用。</p><h1 id="7a3b" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">问题:识别推文中的负面情绪</h1><p id="9259" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">在这篇文章中，我们将学习如何识别带有负面情绪的推文。为此，我们将创建一个情感分析器，以文本格式对积极和消极的推文进行分类。虽然我们将使用我们的分类器进行Twitter数据分析，但是它也可以用于分析来自其他来源的文本数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mk"><img src="../Images/bdbcc81956a6f033a17e15b8b851dab8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HfnMUXqFhcY966kq.png"/></div></div></figure><p id="a109" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">通过这篇文章，我们将了解数据集、各种文本处理和嵌入技术，然后使用机器学习模型来处理我们的数据。</p><h1 id="bcd5" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">索引</h1><ul class=""><li id="3994" class="ml mm iq kt b ku mf kx mg la mn le mo li mp lm mq mr ms mt bi translated">Twitter情感分析数据集</li><li id="a0a2" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">文本处理</li><li id="3af2" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">A.清除原始文本</li><li id="b2dc" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">B.标记化</li><li id="a7b1" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">C.堵塞物</li><li id="6ee1" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">单词嵌入技术</li><li id="c040" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">A.一袋单词</li><li id="25e3" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">B.术语频率—逆文档频率</li><li id="bee0" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">C.Word2Vec</li><li id="a2c6" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">模型</li><li id="84e0" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">性能指标</li><li id="b4f7" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">结果</li><li id="3f6f" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">摘要</li></ul><h1 id="573a" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">Twitter情感分析数据集</h1><p id="8640" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">让我们从我们的Twitter数据开始。我们将使用开源的<a class="ae mz" href="https://www.kaggle.com/ramyavidiyala/twitter-tweets-data-for-sentiment-analysis" rel="noopener ugc nofollow" target="_blank"> Twitter Tweets数据进行情感分析</a>数据集。它包含32，000条推文，其中2，000条包含负面情绪。</p><p id="6733" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个数据集的目标变量是“label ”,它将负面推文映射到1，其他任何内容映射到0。把目标变量想象成你试图预测的东西。对于我们的机器学习问题，我们将在这些数据上训练一个分类模型，以便它可以预测我们给它的任何新推文的类别。</p><p id="f69f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下图显示了数据的快照。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/ef61aa32b55a0b99401218e37d3c4cbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/0*iZAa7o5e-O_TWQu1.png"/></div></div></figure><h1 id="a4f4" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">文本处理</h1><p id="5dab" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">数据通常来自各种不同的来源，并且通常采用各种不同的格式。因此，清理原始数据是准备数据集的重要部分。然而，清理不是一个简单的过程，因为文本数据通常包含冗余和/或重复的单词。在Twitter情感分析中尤其如此，因此处理我们的文本数据是我们解决方案的第一步。</p><p id="b0b7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">文本处理的基本步骤包括:</p><ul class=""><li id="9c98" class="ml mm iq kt b ku kv kx ky la nb le nc li nd lm mq mr ms mt bi translated">A.原始数据的清理</li><li id="bf7f" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">B.标记化</li><li id="7af1" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">C.堵塞物</li></ul><h1 id="cb3c" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">A.原始数据的清理</h1><p id="933c" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">这个阶段包括删除对文本意义没有价值的单词或字符。一些标准的清洁步骤如下:</p><ul class=""><li id="a539" class="ml mm iq kt b ku kv kx ky la nb le nc li nd lm mq mr ms mt bi translated">下降箱</li><li id="f02a" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">删除提及</li><li id="700b" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">特殊字符的删除</li><li id="bb27" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">停用词的删除</li><li id="de62" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">移除超链接</li><li id="45fa" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">数字的删除</li><li id="6e39" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">删除空白</li></ul><h2 id="ab87" class="ne lo iq bd lp nf ng dn lt nh ni dp lx la nj nk lz le nl nm mb li nn no md np bi translated">下降箱</h2><p id="26a1" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">降低文本的大小写是必要的，原因如下:<br/>单词“TWEET”、“tweet”和“Tweet”都为句子添加了相同的值。降低所有单词的大小写有助于通过减少词汇量来降低维度。</p><p id="6bb1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nq nr ns nt b">def to_lower(word): <br/> result = word.lower() <br/> return result</code></p><h2 id="a51c" class="ne lo iq bd lp nf ng dn lt nh ni dp lx la nj nk lz le nl nm mb li nn no md np bi translated">删除提及</h2><p id="f3ca" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">在推文中提及是很常见的。然而，由于它们不会增加解释推文情感的价值，我们可以删除它们。提及总是以“@提及”的形式出现，所以我们可以删除以“@”开头的字符串。</p><p id="b43c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了在整个数据集上实现这一点，我们使用下面的函数。</p><p id="822b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nq nr ns nt b">def remove_mentions(word): <br/> result = re.sub(r"@\S+", "", word) <br/> return result</code></p><h2 id="3115" class="ne lo iq bd lp nf ng dn lt nh ni dp lx la nj nk lz le nl nm mb li nn no md np bi translated">特殊字符的删除</h2><p id="26ce" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">这种文本处理技术将有助于处理像“万岁”和“万岁！”这样的词同理。在这个阶段，我们去掉所有的标点符号。</p><p id="8c34" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nq nr ns nt b">def remove_special_characters(word):<br/> result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))<br/> return result</code></p><h2 id="c551" class="ne lo iq bd lp nf ng dn lt nh ni dp lx la nj nk lz le nl nm mb li nn no md np bi translated">停用词的删除</h2><p id="81ee" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">停用词是语言中经常出现的词，如“the”、“a”、“an”、“is”等。我们可以在这里删除它们，因为它们不会为我们的Twitter数据分析提供任何有价值的信息。</p><p id="f106" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nq nr ns nt b">def remove_stop_words(words):<br/> result = [i for i in words if i not in ENGLISH_STOP_WORDS]<br/> return result</code></p><h2 id="0369" class="ne lo iq bd lp nf ng dn lt nh ni dp lx la nj nk lz le nl nm mb li nn no md np bi translated">移除超链接</h2><p id="b1b6" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">现在我们可以从数据中删除URL。tweets包含URL并不罕见，但是我们不需要为我们的任务分析它们。</p><p id="b852" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nq nr ns nt b">def remove_hyperlink(word):<br/> return re.sub(r"http\S+", "", word)</code></p><h1 id="7084" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">B.标记化</h1><p id="6b8d" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">标记化是将文本分割成更小的块(称为标记)的过程。每个标记都是作为特征的机器学习算法的输入。NLTK(自然语言工具包)提供了一个用于标记数据的实用函数。</p><p id="7745" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nq nr ns nt b">from nltk.tokenize import word_tokenize<br/>tweets_data['tweet'] = tweets_data['tweet'].apply(word_tokenize)</code></p><h1 id="9e92" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">C.堵塞物</h1><p id="e9fa" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">词干提取是从单词中移除和替换后缀以获得单词的词根或基本形式的过程。这叫做‘梗’。例如，单词“满意”、“满足”和“满意”的词干是“满足”，所有这些都意味着相同的感觉。</p><p id="feaf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">波特词干分析器是一种广泛使用的词干分析技术。nltk.stem为stem“porter stemmer”提供了实用函数</p><p id="3cf2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nq nr ns nt b">from nltk.stem.porter import PorterStemmer<br/>stemmer = PorterStemmer()<br/>def stem_words(text):<br/> return " ".join([stemmer.stem(word) for word in text])<br/>tweets_data['tweet'] = tweets_data['tweet'].apply(lambda text: stem_words(text))</code></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/db58f65b2460575987400daa9867582a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*uo3mz6SXY3NljWNY.png"/></div></figure><h1 id="7b47" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">单词嵌入技术</h1><p id="e912" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">有大量文本格式的数据。对机器来说，分析文本数据是一项极其复杂的任务，因为机器很难理解文本背后的语义。在这个阶段，我们将使用单词嵌入将文本数据处理成机器可理解的格式。</p><blockquote class="nv nw nx"><p id="5da0" class="kr ks ny kt b ku kv jr kw kx ky ju kz nz lb lc ld oa lf lg lh ob lj lk ll lm ij bi translated">单词嵌入只是将文本格式的数据转换成数值(或向量)，这样我们就可以将这些向量作为机器的输入，并使用代数的概念来分析数据。</p></blockquote><p id="1384" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是，重要的是要注意，当我们执行这种转换时，可能会有数据丢失。关键是在转换和保留数据之间保持平衡。</p><p id="53b6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">说到这一步，这里有两个常用术语。</p><ul class=""><li id="b173" class="ml mm iq kt b ku kv kx ky la nb le nc li nd lm mq mr ms mt bi translated">每个文本数据点称为一个文档</li><li id="cfa5" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">一整套文档被称为语料库</li></ul><p id="bf17" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">可以使用以下技术进行文本处理:</p><ol class=""><li id="8a06" class="ml mm iq kt b ku kv kx ky la nb le nc li nd lm oc mr ms mt bi translated">一袋单词</li><li id="20e9" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm oc mr ms mt bi translated">TF-IDF</li><li id="62ad" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm oc mr ms mt bi translated">Word2Vec</li></ol><p id="84b5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，让我们更详细地探索上述每一种技术，然后决定将哪一种用于我们的Twitter情感分析模型。</p><div class="od oe gp gr of og"><a href="https://www.datadriveninvestor.com/2020/07/23/learn-data-science-in-a-flash/" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd ir gy z fp ol fr fs om fu fw ip bi translated">一瞬间学会数据科学！？数据驱动的投资者</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">在我之前的职业生涯中，我是一名训练有素的古典钢琴家。还记得那些声称你可以…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="op l"><div class="oq l or os ot op ou kp og"/></div></div></a></div><h1 id="fee1" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">A.一袋单词</h1><p id="09df" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">单词包通过使用唯一单词的字典将文档简单地转换为向量。这只需两步即可完成，如下所述。</p><h2 id="dc95" class="ne lo iq bd lp nf ng dn lt nh ni dp lx la nj nk lz le nl nm mb li nn no md np bi translated">词典的构建</h2><p id="9d99" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">以向量形式创建数据语料库中所有唯一单词的字典。假设语料库中唯一单词的数量为‘d’。所以每个单词是一个维度，因此这个字典向量是一个d维向量。</p><h2 id="258f" class="ne lo iq bd lp nf ng dn lt nh ni dp lx la nj nk lz le nl nm mb li nn no md np bi translated">向量的构建</h2><p id="4423" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">对于每个文档，比如说rᵢ，我们创建一个向量，比如说vᵢ.</p><p id="efc2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个具有d维的vᵢ可以用两种方法来构造:</p><ol class=""><li id="905a" class="ml mm iq kt b ku kv kx ky la nb le nc li nd lm oc mr ms mt bi translated">对于每个文档，根据字典构建vᵢ，使得字典中的每个单词按照该单词在文档中出现的次数来再现。</li><li id="acba" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm oc mr ms mt bi translated">对于每个文档，根据字典构建vᵢ，使得字典中的每个单词被再现为:</li></ol><ul class=""><li id="473c" class="ml mm iq kt b ku kv kx ky la nb le nc li nd lm mq mr ms mt bi translated">如果该单词存在于文档中，则为1，否则为</li><li id="87a6" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">如果文档中不存在该单词，则为0</li></ul><p id="ee28" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这种类型被称为二进制单词包。</p><p id="f0f6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们有了每个文档的向量和一个字典，其中包含来自数据语料库的一组独特的单词。这些向量可以通过，</p><ul class=""><li id="e544" class="ml mm iq kt b ku kv kx ky la nb le nc li nd lm mq mr ms mt bi translated">在d维空间中绘图或</li><li id="2343" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">计算向量之间的距离以获得相似度(<em class="ny">向量越接近，它们就越相似</em></li></ul><h1 id="e33e" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">B.术语频率—逆文档频率</h1><p id="f173" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">这里有三个要素:单词、文档、语料库。词频—逆文档频率，简称TF-IDF，使用这些元素之间的关系将文本数据转换为向量。</p><blockquote class="nv nw nx"><p id="31c9" class="kr ks ny kt b ku kv jr kw kx ky ju kz nz lb lc ld oa lf lg lh ob lj lk ll lm ij bi translated">词频指的是单词和文档之间的关系。而逆文档频率指的是单词和语料库之间的关系。</p></blockquote><h2 id="4748" class="ne lo iq bd lp nf ng dn lt nh ni dp lx la nj nk lz le nl nm mb li nn no md np bi translated">计算词频</h2><p id="0849" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">词频是单词wⱼ在文档rᵢ.中的概率计算如下。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/138a543376d86679190baf5a4eaa7e72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/0*EygLFRtbYIhMUlIR.png"/></div></figure><blockquote class="nv nw nx"><p id="8975" class="kr ks ny kt b ku kv jr kw kx ky ju kz nz lb lc ld oa lf lg lh ob lj lk ll lm ij bi translated">一个单词在评论中的高频意味着该单词在该评论中是频繁出现的。一个单词在评论中的低词频暗示该单词在该评论中是罕见的。</p></blockquote><h2 id="832d" class="ne lo iq bd lp nf ng dn lt nh ni dp lx la nj nk lz le nl nm mb li nn no md np bi translated">计算IDF</h2><p id="3829" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">逆文档频率(IDF)表示一个单词在整个语料库中出现的频率。计算如下。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/f871e9ea99c2f33b74475c69b624f2e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*BbyqWJsDNiW4s6tV.png"/></div></figure><blockquote class="nv nw nx"><p id="e212" class="kr ks ny kt b ku kv jr kw kx ky ju kz nz lb lc ld oa lf lg lh ob lj lk ll lm ij bi translated">低逆向文档频率意味着该单词在语料库中是频繁的。高逆向文档频率意味着该词在语料库中很少见。</p></blockquote><p id="f9ee" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">由于缩放，我们使用对数而不是简单的反比。术语频率是一个概率，范围在0到1之间。这个比值的倒数可以取从0到无穷大的值，并且可以偏置IDF。使用日志来解决这个问题是一个简单且被广泛接受的原因。</p><blockquote class="nv nw nx"><p id="b4d3" class="kr ks ny kt b ku kv jr kw kx ky ju kz nz lb lc ld oa lf lg lh ob lj lk ll lm ij bi translated">评论中某个词的TF-IDF = TF(词，评论)* IDF(词，语料库)。</p></blockquote><p id="59d9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在每个文档的向量形式中，我们有每个单词的TF-IDF。使用TF-IDF值将文档转换为矢量称为TF-IDF矢量化。</p><p id="32eb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">TF-IDF矢量化非常重视以下单词:</p><ul class=""><li id="c696" class="ml mm iq kt b ku kv kx ky la nb le nc li nd lm mq mr ms mt bi translated">在文档中频繁出现(来自TF)</li><li id="d6d2" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">语料库中罕见(来自IDF)</li></ul><h1 id="710a" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">C.Word2Vec</h1><p id="184d" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">在单词包和TF-IDF中，我们将<em class="ny">句子转换成向量</em>。但是在Word2Vec中，我们将<em class="ny">单词转换成矢量</em>。因此得名，word2vec！</p><p id="b2be" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Word2Vec将大型文本语料库作为其输入，并产生一个向量空间，通常具有数百个维度，语料库中的每个唯一单词都被分配给该空间中的一个对应向量。单词向量的定位是以这样的方式完成的，即语料库中具有共同上下文的单词在空间上位于更近的位置。</p><p id="9aad" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">比如从男人到女人的向量平行于国王到王后等等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/c4f6c8cc6db9f93c8d7e8e0df0b09b0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*wHQeLRpsYp2oXOne.png"/></div></figure><h1 id="e2bf" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">什么时候用什么？</h1><p id="3080" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">当谈到机器学习模型使用哪种嵌入技术时，没有明显的答案:这确实取决于用例。</p><p id="a8aa" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">单词包通常用于文档分类应用，其中每个单词的出现被用作训练分类器的特征。</p><p id="6800" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">TF-IDF被Google这样的搜索引擎用作内容的排名因素。</p><p id="f7b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">当应用程序需要大量信息(如翻译文档)时，Word2vec非常有用。</p><p id="b473" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于我们的Twitter情感分析，我们将使用“单词包”作为单词嵌入技术。Scikit学习库提供了一个“计数矢量器”函数来执行单词包。使用“计数矢量器”，我们将处理后的数据转换成矢量。</p><p id="6b9c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nq nr ns nt b">from sklearn.feature_extraction.text import CountVectorizer<br/>bow=CountVectorizer<br/>( min_df=2, max_features=100000)<br/>bow.fit(tweets_data['tweet'])<br/>tweets_processed =bow.transform(tweets_data['tweet']).toarray()</code></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/ea4e1b2dfcec416f1a5e4d0d234ed2f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1jPI5eVAvCPGYH8l.png"/></div></div></figure><h1 id="211e" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">模型拟合</h1><p id="f04c" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">逻辑回归是一种被互联网应用广泛使用的监督机器学习分类算法。这是解决分类问题最简单的算法，但效率很高。我们将利用这一点在Twitter数据分析中获得情感概率。</p><p id="4e13" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">使用sklearn.linear_model，我们可以实现逻辑回归。该模型输出输入属于该类的概率，使我们有可能对新推文中的twitter数据进行情感分析。</p><p id="3b81" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nq nr ns nt b">from sklearn.linear_model import LogisticRegression<br/>model = LogisticRegression()<br/>model.fit(tweets_train, target_train) <br/># training the model<br/>prediction = model.predict_proba(tweets_test) <br/># predicting on the test set<br/>prediction_int = prediction[:,1] &gt;= 0.3 # if prediction is greater than or equal to 0.3 then 1 else 0<br/>prediction_int = prediction_int.astype(np.int)</code></p><h1 id="981e" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">Twitter情感分析的性能指标</h1><p id="679b" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">现在我们有了一个Twitter情感分析模型，可以输出一条推文属于特定类别的概率，我们需要一些方法来判断它的性能。精确度和召回率是分类模型的两个最广泛使用的性能度量。</p><blockquote class="nv nw nx"><p id="dafe" class="kr ks ny kt b ku kv jr kw kx ky ju kz nz lb lc ld oa lf lg lh ob lj lk ll lm ij bi translated">精度是所有检索实例中相关实例的分数。它帮助我们理解结果的有用性。</p><p id="8f35" class="kr ks ny kt b ku kv jr kw kx ky ju kz nz lb lc ld oa lf lg lh ob lj lk ll lm ij bi translated">回忆是所有相关实例中相关实例的分数。回忆有助于我们理解结果的覆盖范围。</p></blockquote><p id="ff4d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">F1分数是精确度和召回率的调和平均值。</p><p id="b6ef" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">例如，考虑一个搜索查询产生30个页面，其中20个是相关的，但是结果不能显示40个其他相关的结果。在这种情况下，精度是20/30，召回率是20/60。所以，我们的F1成绩是4/9。</p><p id="3377" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">使用F1-score作为分类问题的性能指标是一个很好的选择。</p><p id="7430" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nq nr ns nt b">from sklearn.metrics import f1_score<br/>from sklearn.metrics import confusion_matrix,f1_score, precision_score,recall_score<br/>cf_matrix =confusion_matrix(target_test, prediction_int)<br/>tn, fp, fn, tp = confusion_matrix(target_test, prediction_int).ravel()<br/>print("Precision: {:.2f}%".format(100 * precision_score(target_test, prediction_int)))<br/>print("Recall: {:.2f}%".format(100 * recall_score(target_test, prediction_int)))<br/>print("F1 Score: {:.2f}%".format(100 * f1_score(target_test, prediction_int)))</code></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/b790f83b49eacec6f64cb31f175e4b35.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/0*0ynvimz0BmQ127wp.png"/></div></figure><p id="a08b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nq nr ns nt b">import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>ax= plt.subplot()<br/>#annot=True to annotate cells<br/>sns.heatmap(cf_matrix, annot=True, ax = ax,cmap='Blues',fmt='');<br/># labels, title and ticks<br/>ax.set_xlabel('Predicted labels');<br/>ax.set_ylabel('True labels');<br/>ax.set_title('Confusion Matrix');<br/>ax.xaxis.set_ticklabels(['Positive', 'Negative']); ax.yaxis.set_ticklabels(['Positive', 'Negative']);</code></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/54d8d4da712553f6c819871b24498054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/0*eWSdM49KbBZTIvTS.png"/></div></figure><h1 id="4bcb" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><p id="9680" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">F1分数为73%的模型是使用传统机器学习算法的良好模型。但是，也有改进模型的方法。我们可以使用深度学习技术(尽管这些技术很昂贵)，我们可以通过添加功能和删除拼写错误的单词来响应结果和反馈。</p><p id="2282" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">此外，请记住，这些结果是基于我们的培训数据。当将情感分析模型应用于真实世界的数据时，我们仍然必须随着时间的推移主动监控模型的性能。</p><h1 id="28d8" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">总结:Twitter情感分析技巧</h1><p id="f6de" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">在本文中，我们学习了各种文本处理和单词嵌入技术，并在经过处理的数据上实现了一个Twitter情感分析分类模型。希望这能让你了解这些社交媒体数据分析系统是如何工作的，以及准备和部署它们需要做的工作。</p><p id="b845" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">本文中提到的文本处理技术广泛应用于文本数据。然而，我们不必一直执行所有的技术。根据我们的用例仔细选择处理和嵌入步骤很重要；这将在情感分析数据中发挥重要作用。</p><p id="dc0e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在社交媒体数据分析领域，尤其是twitter数据分析领域，在过程的每一步都获得领域专家的支持通常非常重要。社交网络上的词汇通常是特定社区独有的，领域专家可以帮助您避免数据偏差并提高数据集和分析的准确性。</p><p id="6041" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">本文中所学的概念和技术可以应用于各种自然语言处理问题。除了Twitter情感分析，你还可以使用类似的技术来构建聊天机器人、文本摘要、<a class="ae mz" href="https://lionbridge.ai/articles/using-natural-language-processing-for-spam-detection-in-emails/" rel="noopener ugc nofollow" target="_blank">垃圾邮件检测</a>和语言翻译模型。</p><p id="3929" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">感谢阅读！如果你想自己试验这个自定义数据集，你可以下载<a class="ae mz" href="https://www.kaggle.com/ramyavidiyala/twitter-tweets-data-for-sentiment-analysis" rel="noopener ugc nofollow" target="_blank">数据</a>并在<a class="ae mz" href="https://github.com/RamyaVidiyala/SentimentAnalysis-Tweets" rel="noopener ugc nofollow" target="_blank"> Github </a>上查看完整代码。如果你想尝试其他Twitter数据集，这里有一个针对各种不同Twitter内容的<a class="ae mz" href="https://lionbridge.ai/datasets/top-20-twitter-datasets-for-natural-language-processing-and-machine-learning/" rel="noopener ugc nofollow" target="_blank">存储库</a>。</p><p id="073a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">之前发表于<a class="ae mz" href="https://lionbridge.ai/articles/how-to-build-a-twitter-sentiment-analysis-system/" rel="noopener ugc nofollow" target="_blank">https://lionbridge . ai/articles/how-to-build-a-Twitter-opinion-analysis-system/</a></p><h2 id="4023" class="ne lo iq bd lp nf ng dn lt nh ni dp lx la nj nk lz le nl nm mb li nn no md np bi translated">访问专家视图— <a class="ae mz" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>