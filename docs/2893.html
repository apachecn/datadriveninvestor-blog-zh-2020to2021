<html>
<head>
<title>A Review On Fast RCNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">快速递归神经网络综述</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/review-on-fast-rcnn-202c9eadd23b?source=collection_archive---------0-----------------------#2020-05-21">https://medium.datadriveninvestor.com/review-on-fast-rcnn-202c9eadd23b?source=collection_archive---------0-----------------------#2020-05-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/20a6fc8ecf7b5a47d968c993a074745f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wgu20kFzdnRuivIwIKf_mQ.png"/></div></div></figure><p id="5826" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">深度卷积网络显著提高了图像分类和目标检测的准确性。与图像分类相比，目标检测是一项更具挑战性的任务，需要更复杂的方法来解决。在快速R-CNN到来之前，大多数方法在多级管道中训练模型，速度慢且不美观。在这篇文章中，我将对Ross Girshick的论文作一个详细的评论。我们将回顾分为7个部分:</p><ol class=""><li id="810f" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated"><strong class="kd iu">现有技术(R-CNN和SPP-Net)的缺点</strong></li><li id="63a8" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><strong class="kd iu">快速RCNN架构</strong></li><li id="98b8" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><strong class="kd iu">训练</strong></li><li id="b48b" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><strong class="kd iu">检测</strong></li><li id="e554" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><strong class="kd iu">一些进一步的观察和评估</strong></li><li id="9172" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><strong class="kd iu">与现有技术结果的比较</strong></li><li id="00d7" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><strong class="kd iu">主要结果</strong></li></ol></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="709e" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">1.现有技术的缺点(R-CNN和SPP-Net)</h1><p id="7a07" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">快速R-CNN提出了一种单阶段训练算法，该算法联合学习对对象提议进行分类，并细化它们的空间位置。它是对R-CNN和SPP-Net的改进。</p><p id="6026" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">R-CNN的一些缺点是:</p><ul class=""><li id="d620" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky my lg lh li bi translated"><strong class="kd iu">训练是多级流水线:</strong>在R-CNN中，首先使用log loss对Convnet进行对象提议的微调。然后，它通过替换Soft Max使SVM适应Convnet功能。在第三阶段，训练回归变量。</li><li id="4082" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky my lg lh li bi translated">训练在空间和时间上都是昂贵的。</li><li id="f586" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky my lg lh li bi translated"><strong class="kd iu">检测也很慢。</strong></li></ul><p id="e1f1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">R-CNN的主要缺点是速度慢。这主要是因为Convnet向前传递每个对象的建议。每幅图像大约有2000个物体像。SPP-Net解决了这个问题，因为它计算整个图像的特征图，然后通过<strong class="kd iu"> ROI投影将ROI建议嵌入到这些特征图中。</strong> SPP-Net在测试时间将R-CNN加速10到100倍。由于更快的建议特征提取，训练时间也减少了3倍。即便如此，SPP-Net也有几个缺点。主要缺点是:</p><ul class=""><li id="425a" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky my lg lh li bi translated"><strong class="kd iu">训练是多级流水线。</strong></li><li id="61b1" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky my lg lh li bi translated"><strong class="kd iu">中提出的微调算法无法更新空间金字塔池之前的卷积图层。(但在R-CNN中可能)</strong></li></ul><p id="af25" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">快速R-CNN是针对R-CNN和SPPnet的缺点而提出的一种新的训练算法。一些显著的特征是:</p><ul class=""><li id="e6a1" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky my lg lh li bi translated">单级管道培训。</li><li id="2e1b" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky my lg lh li bi translated">比R-CNN、SPPnet更高的检测质量(mAP)</li><li id="ab75" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky my lg lh li bi translated">训练可以更新所有层。</li><li id="8d0a" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky my lg lh li bi translated">特征捕捉不需要磁盘空间。</li></ul><div class="mz na gp gr nb nc"><a href="https://www.datadriveninvestor.com/2020/02/10/why-encryption-is-critical-to-everyday-life/" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd iu gy z fp nh fr fs ni fu fw is bi translated">为什么加密对日常生活至关重要？数据驱动的投资者</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">你几乎每天都要输入密码，这是你生活中最基本的加密方式。然而问题是…</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nl l"><div class="nm l nn no np nl nq jz nc"/></div></div></a></div></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="df3a" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">2.快速RCNN体系结构</h1><p id="c78d" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">快速R-CNN采用一组对象提议和图像作为输入。网络将该图像通过几个卷积层和最大汇集层，并形成特征图。使用ROI投影将目标方案映射到特征图上。ROI投影就是在特征图上找到与原始图像中的坐标相对应的区域建议的坐标。我稍后会解释。</p><p id="cae6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于每个对象提议，感兴趣区域(ROI)池层将提取固定长度的特征向量，并将其通过完全连接的层。这些完全连接的层分为两个输出层:</p><ul class=""><li id="fddd" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky my lg lh li bi translated">产生K+1个类别(K个类别和1个背景类别)的软最大概率的函数</li><li id="6c40" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky my lg lh li bi translated">另一个为K个类提供边界框坐标。</li></ul><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/8c8536f3172c942fa4f04ed9a48f8189.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*scEszYqJIhJ3RKjZ2wXH8A.png"/></div></figure><p id="6270" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在进一步解释之前，最好先解释一些你需要理解的概念。</p><h2 id="2475" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated"><strong class="ak"> 2.1 ROI投影</strong></h2><p id="b508" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">在快速RCNN方法中，原始图像中的区域建议被投影到最终卷积特征图的输出上。这是投资回报池稍后使用。</p><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/e767c2ef578bb58db1181cb99f806e7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*9b1gZPuYkcUjvvr-SdOWyQ.png"/></div></figure><p id="b61f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您可能认为输入图像和生成的特征图是不同的维度。那么如何将ROI建议书从图像转化为特征图呢？</p><p id="2d5d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">别担心，我会用一个例子来解释。</p><p id="0a9c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先你需要知道<strong class="kd iu">子采样率</strong>。</p><p id="ad2e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">假设我们有一个18x18的图像。在经过一些卷积和最大池后，假设我们得到一个1x1的特征图。那么我们会说，我们将有一个1/18的子采样比。它是输出特征图与输入图像的比例。</p><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/702359eecacd1c2edafb5e05d0e8f492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*b474J2S4vZcT-DQH1Q1M3A.png"/></div></figure><p id="2718" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我再解释一个例子。在下图中，我们的输入大小为18x18，输出特征映射大小为3x3。那么我们将得到3/18 = 1/6的子采样率</p><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/223da3da2a0c0784b8779781f5a3d884.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*QBSoLMfTKzwLo-4Y_twCzg.png"/></div></figure><p id="fab8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们了解了子采样率。接下来，我们将了解这如何有助于ROI预测。假设我们的输入图像大小为688x920，特征图大小为43x58。我们有一个大小为320x128的区域提案。</p><p id="c687" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">子采样率= 58/920 = 1/16</p><p id="08aa" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">新边界框坐标= (320/16，128/16) = (20，8)</p><p id="b390" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">新边界框中心= (340/16，450/16) = (21，28)</p><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/bf0b0149c92922acd4ec4c98562fa4ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*dPHlfhhy2PlfD9Y5LHBa6w.png"/></div></figure><p id="9e9e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就是我们如何对区域提案进行投资回报预测，我想现在你已经清楚这个概念了。接下来，我们将了解投资回报池是如何实现的。</p><h2 id="7260" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated"><strong class="ak"> 2.2投资回报池</strong></h2><p id="b49b" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">通常在提案阶段，我们会生成许多区域。这是因为一旦物体在第一阶段没有被检测到，它在任何阶段都不会被分类。我们不能在召回问题上妥协。我们的网络应该具有高召回率。因此必须产生大量的建议，但它也有一些缺点。</p><ul class=""><li id="0d68" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky my lg lh li bi translated">生成大量感兴趣区域会导致性能问题。这将使得实时对象检测难以实现。</li><li id="fe0f" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky my lg lh li bi translated">我们不能一次训练完系统的所有组件。</li></ul><p id="705e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">投资回报池作为一种解决方案应运而生。RoI图层只是SPP网络中使用的空间金字塔池图层的特例，其中只有一个金字塔等级。它还加快了培训和测试过程。它需要两个输入。</p><ol class=""><li id="fa6b" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated">由深度卷积网络产生的固定大小的特征图。</li><li id="1288" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">表示感兴趣区域列表的N×5矩阵，其中N是感兴趣区域的数量。第一列表示图像索引，其余四列是该区域左上角和右下角的坐标</li></ol><p id="1243" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于输入列表中的每个感兴趣区域，它从输入要素地图中提取相应的区域，并将其缩放到某个预定义的大小(例如7x7)。缩放通过以下方式完成:</p><ol class=""><li id="a903" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated">将区域建议划分为大小相等的部分(其数量与输出的维度相同)</li><li id="c5f0" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">找出每一部分的最大值</li><li id="b1ca" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">将这些最大值复制到输出缓冲器</li></ol><p id="e96c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我通过一个例子来说明。让我们的特征图如下，ROI是特征图内的黑色方块。这里，我们将把roi缩小到2x2的大小。</p><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi om"><img src="../Images/902dc2538ee748adb152c8432ed32abb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*zlfIBgjS0P435lhJLoW8SA.png"/></div></figure><p id="0111" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="on">注意:感兴趣区域的大小不必被汇集部分的数量整除(在这种情况下，我们的RoI是7×5，我们有2×2个汇集部分)。</em></p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="3599" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">3.培养</h1><p id="2cd5" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">用反向传播训练所有网络权值是Fast-RCNN的一个重要功能。在开始之前，最好知道，</p><p id="0243" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="on">为什么SPP网无法更新空间金字塔池层以下的权重？</em> </strong></p><p id="83cb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">根本原因是当每个训练样本(即RoI)来自不同的图像时，通过SPPlayer的反向传播是非常低效的，这正是R-CNN和SPP网络被训练的方式。</p><p id="378a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在Fast-RCNN中，我们提出了一种更有效的方法，在训练中，随机梯度下降(SGD)小批量被分层采样，首先通过采样N个图像，然后通过从每个图像采样R/N个ROI。例如，当使用N= 2和R= 128时，所提出的训练方案比从128个不同图像中采样一个RoI大约快64倍(即，R-CNN和SPP网络策略)。</p><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/5652f35902a4f8d6d960f746f12e4b28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*8aw-_VwQCjy_KwD_mUArIA.png"/></div></figure><h2 id="fd2b" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated">3.1多任务损失:</h2><p id="849a" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">快速Rcnn体系结构具有两个输出层:一层预测K+1个类概率，另一层输出包围盒回归偏移，</p><p id="7df5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">tk = (tk-x，tk-y，tk-h，tk-w)</p><p id="143e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">其中tk指定相对于对象提议的不变平移和对数空间高度/宽度移动。</p><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi op"><img src="../Images/cd4f5f118470a2b0d616b969be28a9e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*R9hDmwuDDnP_LVIUWsuhsQ.png"/></div></figure><p id="067b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="on"> Lcls </em>是真实等级<em class="on"> u </em>的对数损失。<br/> Llos是边界框的损失<strong class="kd iu">。</strong>我们使用平滑L1损耗，而不是R-CNN和SPP-Net<strong class="kd iu"><br/></strong>【u≥1】中使用的L2损耗，当u≥1时等于1。(u=0是背景类)</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="33d6" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">4.侦查</h1><p id="450c" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">一旦训练了网络，检测就只是向前传递(假设对象提议是预先计算的)。该网络采用输入图像(或图像金字塔，编码为图像列表)和R对象提议列表来评分。r通常在2000左右。当使用图像金字塔时，每个RoI被分配给比例，使得缩放后的RoI最接近224像素。</p><p id="fc6a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，图像被向前传递，并且获得类别概率和包围盒预测。然后，我们对每个类独立地执行非最大值抑制，并获得最佳包围盒。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="b477" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">5.一些进一步的观察和评价</h1><h2 id="b520" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated">5.1多任务损失评估</h2><p id="24d6" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">评估了3个模型:</p><h2 id="aeba" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated">S = AlexNet或CaffeNet <br/> M =类似VGG的更宽版本S <br/> L = VGG-16</h2><p id="ed8f" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated"><em class="on">注意:我们稍后也将使用S、M、L符号</em></p><p id="8730" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在多任务丢失的情况下，与阶段式训练相比，获得更高的mAP，</p><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/886dd4046d6ec1f32f59ea0bf6f7ca56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*YwEgDNH9qoO4MKhcBeOeeA.png"/></div><figcaption class="or os gj gh gi ot ou bd b be z dk">multi task training.Obtained mAP greater than stage wise training</figcaption></figure><h2 id="dce9" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated">5.2 SVM与软最大分类</h2><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/42b3adf5380aa52083d2a39a66d35c09.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*umOXUq68avR3SwQsRoS8Aw.png"/></div></figure><p id="7dd1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">软马克斯比SVM表现更好。</p><h2 id="a5d4" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated">5.3截断奇异值分解，检测速度更快</h2><p id="da24" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">对于整幅图像分类，与conv图层相比，计算全连通图层所花费的时间较少。相反，对于检测来说，要处理的ROI的数量很大，并且将近一半的前向通过时间花费在计算完全连接的层上。通过用截短的SVD压缩它们，大的完全连接的层很容易被加速。</p><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/26191afef4ef20a39346cdf77dac54bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*p-9OIFL7ElR11_aA4jqh5A.png"/></div><figcaption class="or os gj gh gi ot ou bd b be z dk">Timing for VGG16 before and after truncated SVD.</figcaption></figure><h2 id="b65b" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated">5.4不同规模的培训</h2><p id="f417" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">我们使用了两种方法:暴力方法和图像金字塔。</p><p id="9ccb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在强力方法中，在训练和测试期间，每个图像都以预定的像素大小进行处理。网络必须从训练数据中直接学习尺度不变对象检测。</p><p id="9d32" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在多尺度训练期间，每次对图像进行采样时，都会对金字塔尺度进行随机采样，这是一种数据扩充形式。由于GPU内存限制，我们仅对较小的网络进行多尺度训练实验。</p><p id="abcb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在测试期间，用5种不同的标度测试输入图像，并获得VOC07的以下结果。</p><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/252ca1cc18a149c10cd45ba560d80442.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*akkTEkyJlYj0NeslJYH6Kw.png"/></div><figcaption class="or os gj gh gi ot ou bd b be z dk">1 scale vs 5 scale</figcaption></figure><h2 id="df61" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated">5.5精细车削层</h2><p id="532c" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">对于SPP-Net和R-CNN微调，只有完全连接的层似乎足以获得良好的精度。但是在快速RCNN的情况下，使用另一种方法。十三个卷积层被冻结，只允许完全连接的层学习。但它使平均动脉压从66.9%下降到61.4%。</p><p id="5c77" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="on">这是否意味着所有卷积层都要微调？</em> </strong></p><p id="6fe5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">简而言之，没有。在较小的网络(S和M)中，我们发现conv1是通用的，并且与任务无关。这意味着，无论我们是否微调conv1，它的性能都是一样的。对于VGG16，他们发现只需要更新conv31及以上的层(13层conv中的9层)。这改进了地图。</p><h2 id="3970" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated">5.6区域提案</h2><p id="2c33" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">提议越多越好吗？</p><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/7f27165f451325c9cb4aff8ebf2592c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*uSzngSNfaaPhq4EGK9zD4Q.png"/></div><figcaption class="or os gj gh gi ot ou bd b be z dk">VOC07 test mAP and avg recall</figcaption></figure><p id="5f85" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们发现，随着提案数量的增加，mAP先上升，然后略有下降。我们可以看到越来越多的建议并不总是增加地图。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="d37a" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated"><strong class="ak"> 6。与最先进结果的比较</strong></h1><h2 id="93c8" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated">6.1 VOC2007</h2><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oy"><img src="../Images/2fac36b5a5b756ac6f150120f9820f1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y_EEJpv_2VDcEd5pTvLMbA.png"/></div></div></figure><p id="4468" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="on">快速R-CNN: 66.9% mAP <br/>快速R-CNN在训练过程中移除了困难示例:68.1% mAP <br/>快速R-CNN带外部VOC 2012训练:70.0% mA </em> <strong class="kd iu"> <em class="on"> P </em> </strong></p><h2 id="2e44" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated">6.2 VOC2010</h2><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oz"><img src="../Images/d2668df740cbff2e46f546c64e9a7f90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m6w-Ap9-v3oCCBezrF0E0A.png"/></div></div></figure><h2 id="2b1b" class="nw lw it bd lx nx ny dn mb nz oa dp mf km ob oc mj kq od oe mn ku of og mr oh bi translated">6.3 VOC2012</h2><figure class="ns nt nu nv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pa"><img src="../Images/e352aeab5d44a45dd2271e37d4e519fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h90RwY0qETdPHHoEn0z7Yw.png"/></div></div></figure></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="86f0" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">7.主要结果</h1><p id="4acf" class="pw-post-body-paragraph kb kc it kd b ke mt kg kh ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky im bi translated">三个主要结果支持了本文的贡献:</p><p id="56b1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> 1。VOC07、2010和2012年的最新地图</strong></p><p id="029d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> 2。与R-CNN、SPPnet3相比，训练和测试速度更快。</strong></p><p id="0aa5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> 3。在VGG16中微调卷积层可以改善贴图。</strong></p><h1 id="6213" class="lv lw it bd lx ly pb ma mb mc pc me mf mg pd mi mj mk pe mm mn mo pf mq mr ms bi translated">参考</h1><ul class=""><li id="d109" class="la lb it kd b ke mt ki mu km pg kq ph ku pi ky my lg lh li bi translated"><a class="ae kz" href="https://deepsense.ai/wp-content/uploads/2017/02/1504.08083.pdf" rel="noopener ugc nofollow" target="_blank">https://deep sense . ai/WP-content/uploads/2017/02/1504.08083 . pdf</a></li><li id="25c9" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky my lg lh li bi translated"><a class="ae kz" href="https://deepsense.ai/region-of-interest-pooling-explained/" rel="noopener ugc nofollow" target="_blank">https://deepsense.ai/region-of-interest-pooling-explained/</a></li><li id="2364" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky my lg lh li bi translated"><a class="ae kz" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">https://medium . com/coin monks/review-fast-r-CNN-object-detection-a82e 172 e 87 ba</a></li><li id="7761" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky my lg lh li bi translated"><a class="ae kz" href="https://www.youtube.com/watch?v=wGa6ddEXg7w&amp;list=PL1GQaVhO4f_jLxOokW7CS5kY_J1t1T17S&amp;index=72" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=wGa6ddEXg7w&amp;list = pl 1 gqavho 4 f _ jlxookw7 cs 5ky _ j 1 t1 t 17s&amp;index = 72</a></li></ul><figure class="ns nt nu nv gt ju"><div class="bz fp l di"><div class="pj pk l"/></div></figure></div></div>    
</body>
</html>