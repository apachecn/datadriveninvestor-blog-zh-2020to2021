<html>
<head>
<title>Using Python and Sklearn’s DBSCAN to Find Core Samples of High Density</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python和Sklearn的DBSCAN寻找高密度岩心样本</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/using-python-and-sklearns-dbscan-to-find-core-samples-of-high-density-784805832874?source=collection_archive---------2-----------------------#2020-11-26">https://medium.datadriveninvestor.com/using-python-and-sklearns-dbscan-to-find-core-samples-of-high-density-784805832874?source=collection_archive---------2-----------------------#2020-11-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f9e5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">实现DBSCAN算法以查找岩心样本</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2d0821f754341ca2d1fb665ce221ba55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gxHmC9aoxpBHQs-3.jpg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">(Image from <a class="ae ky" href="https://cdn.pixabay.com/photo/2017/04/17/00/38/galaxy-2236129_960_720.jpg" rel="noopener ugc nofollow" target="_blank">Pixabay</a>)</figcaption></figure><p id="9df6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">DBS can</strong>——<strong class="lb iu">的简称，是一种基于密度的聚类算法。基于密度参数形成聚类。</strong></p><p id="99bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就DBSCAN而言，密度意味着位于给定区域内的点的数量。这些点彼此越靠近，密度就越大。</p><div class="lv lw gp gr lx ly"><a href="https://www.datadriveninvestor.com/2020/10/27/algorithms-have-rights-like-people-and-corporations/" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">算法像人和企业一样有权利？数据驱动的投资者</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">我们不会让一辆车就这么扔出去，开始开着它到处跑，而不检查一下车轮是否已经固定好…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><p id="6299" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DBSCAN算法采用2个参数；<em class="mn">ε</em>—ε，是核心点的半径，也是聚类中数据点的最小个数。</p><p id="942d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下面取自<a class="ae ky" href="https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/DBSCAN-Illustration.svg/400px-DBSCAN-Illustration.svg.png" rel="noopener ugc nofollow" target="_blank">维基百科</a>的图表中，最小点数被选为4，minPts = 4。</p><p id="9401" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">点A和所有其他红点被称为<strong class="lb iu">核心点</strong>，因为它们在其圆内至少包含4个点。点B和C是边界点，它们不是核心点，因为它们没有包含最少4个点。点N是一个<strong class="lb iu">噪声点。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/477c21c15edbd19a943f40883ee1356f.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*zgjQ948iybMJInAP.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">(Image from <a class="ae ky" href="https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/DBSCAN-Illustration.svg/400px-DBSCAN-Illustration.svg.png" rel="noopener ugc nofollow" target="_blank">Wikipedia</a>)</figcaption></figure><p id="a792" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> DBSCAN算法</strong>可以抽象为以下几个主要步骤:</p><ol class=""><li id="69c9" class="mp mq it lb b lc ld lf lg li mr lm ms lq mt lu mu mv mw mx bi translated">求一个点的ε闭包里的点数，并识别核心点。</li><li id="3c29" class="mp mq it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">在邻域中寻找<em class="mn">核</em>点的连通分量。</li><li id="8ec8" class="mp mq it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">如果每个边界点在邻域中，则将该点分配给附近的核心点簇，否则将其分配给噪声。</li></ol><p id="a1c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">密集区域内的点称为<strong class="lb iu">岩心样本</strong>。在下面的代码示例中，我们将使用Sklearn的DBSCAN来查找自生成数据的核心样本。</p><h1 id="cb27" class="nd ne it bd nf ng nh ni nj nk nl nm nn jz no ka np kc nq kd nr kf ns kg nt nu bi translated">密码</h1><p id="4a2e" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">在本文的这一部分中，我们将仔细检查代码，以找到高密度的核心样本，并从中扩展集群。</p><h2 id="b24a" class="oa ne it bd nf ob oc dn nj od oe dp nn li of og np lm oh oi nr lq oj ok nt ol bi translated">导入库和模块</h2><p id="f782" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">首先，让我们导入相关的库和模块。我们将导入<strong class="lb iu"> NumPy </strong>，Sklearn的<strong class="lb iu">度量</strong>，来自Sklearn的<strong class="lb iu"> DBSCAN </strong>算法，<strong class="lb iu"> make_blobs </strong>函数允许我们生成具有高斯分布的点的blob，以及<strong class="lb iu"> StandardScaler </strong>用于特征标准化。</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="adc9" class="oa ne it on b gy or os l ot ou">import numpy as np<br/>from sklearn.cluster import DBSCAN<br/>from sklearn import metrics<br/>from sklearn.datasets import make_blobs<br/>from sklearn.preprocessing import StandardScaler</span></pre><h2 id="8b45" class="oa ne it bd nf ob oc dn nj od oe dp nn li of og np lm oh oi nr lq oj ok nt ol bi translated">生成样本数据</h2><p id="bd32" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">接下来，我们将生成样本数据，首先创建中心，然后使用<strong class="lb iu"> make_blobs </strong>函数生成斑点，并标准化我们的特征。</p><p id="3b16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将有3个<strong class="lb iu">中心</strong>，坐标如下:(1，1)，(-1，-1)，和(1，-1)。</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="22e4" class="oa ne it on b gy or os l ot ou">centers = [[1, 1], [-1, -1], [1, -1]]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/c37d1d2efffd458372e12e6b5e731bca.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*kxrmrfR0O2H6btDn87TPWg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Generating Center Points (Image by Author)</figcaption></figure><p id="4383" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html?highlight=make%20blobs#sklearn.datasets.make_blobs" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> make_blobs </strong> </a>函数，我们将生成总共有750个点的斑点，这些点在聚类中平均分配，中心由中心数组给出，标准偏差为0.4。</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="3e05" class="oa ne it on b gy or os l ot ou">X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,<br/>                            random_state=0)</span></pre><p id="f09c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将导致NumPy数组:<strong class="lb iu"> X </strong>和<strong class="lb iu"> labels_true。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/0bbffd69b2dcfff4690221dfa469f2d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*8IzrsUYp1vrgpDlsyFZIhA.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">NumPy Array X before Feature Standardization (Image by Author)</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/0b5ed9b73260ae40a492ec381a8e2d8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*VC42p91y_ItnKQvhsMi2Ig.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><strong class="bd nf">labels_true </strong>Numpy Array storing the labels of the data points in <strong class="bd nf">X </strong>(Image by Author)</figcaption></figure><p id="9d2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将使用<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html?highlight=standard%20scaler#sklearn.preprocessing.StandardScaler" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">standard scaler()</strong></a>对<strong class="lb iu"> X. </strong>应用特征标准化。这将通过移除平均值并将其缩放至单位方差来标准化特征。</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="b38a" class="oa ne it on b gy or os l ot ou">X = StandardScaler().fit_transform(X)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/31b33e943664645a36ad75eb9a856761.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*9z0hBzRI-TupfafBKxJzwg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">NumPy Array <strong class="bd nf">X</strong> after Feature Standardization (Image by Author)</figcaption></figure><h2 id="ca5a" class="oa ne it bd nf ob oc dn nj od oe dp nn li of og np lm oh oi nr lq oj ok nt ol bi translated">计算数据库扫描</h2><p id="d779" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">一旦我们创建并标准化了我们的数据，我们将部署来自<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html?highlight=dbscan" rel="noopener ugc nofollow" target="_blank"> Sklearn </a>的DBSCAN算法，其中ε=<strong class="lb iu">0.3<em class="mn"/></strong>和<strong class="lb iu"> 10 </strong>的值作为集群中的最小样本数。</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="3044" class="oa ne it on b gy or os l ot ou">db = DBSCAN(eps=0.3, min_samples=10).fit(X)</span></pre><p id="ba73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将定义一个数组<strong class="lb iu"> core_sample_mask </strong>，它的维数与标签的维数相同。<strong class="lb iu"> core_sample_mask </strong>将是一个包含750个零(假)元素的数组。</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="8e37" class="oa ne it on b gy or os l ot ou">core_samples_mask = np.zeros_like(db.labels_, dtype=bool)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/ee70e0dcc26fb19fb1c3f8b1f6f7d34c.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*M4QQHCUyxf3gy4wwQBuurw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><strong class="bd nf">core_samples_mask</strong> array (Image by Author)</figcaption></figure><p id="206c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在对数据拟合DBSCAN模型之后，我们将计算<strong class="lb iu"> core_samples_mask。</strong></p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="96e0" class="oa ne it on b gy or os l ot ou">core_samples_mask[db.core_sample_indices_] = True</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/dddfa585d9fdc1061bffbf441902570a.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*vPLWw-BVLdnQTniSaCER-w.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><strong class="bd nf">core_samples_mask</strong> array (Image by Author)</figcaption></figure><p id="39c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将所有数据点的标签值存储在<strong class="lb iu">标签</strong>数组中。</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="1fca" class="oa ne it on b gy or os l ot ou">labels = db.labels_</span></pre><p id="3aee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">标签</strong>数组中共有4个值:0、1、2和-1。值0、1和2指的是由数据组成的3个聚类，而-1是那些核心样本点与<strong class="lb iu">中心</strong>阵列中的样本点不匹配的数据点的标签。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/efb58bf27e96b15f71e331e17c8a9f51.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*cwbQ3oud7Jn1j6ebWauP8Q.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><strong class="bd nf">labels</strong> array (Image by Author)</figcaption></figure><h2 id="0cb5" class="oa ne it bd nf ob oc dn nj od oe dp nn li of og np lm oh oi nr lq oj ok nt ol bi translated">聚类数和噪声</h2><p id="2fb0" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">现在让我们打印忽略噪声数据点形成的聚类数以及异常值的总数:</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="a746" class="oa ne it on b gy or os l ot ou">n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)<br/>n_noise_ = list(labels).count(-1)<br/>print('Estimated number of clusters: %d' % n_clusters_)<br/>print('Estimated number of noise points: %d' % n_noise_)</span></pre><p id="98d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有<strong class="lb iu"> 3 </strong>个集群和<strong class="lb iu"> 18 </strong>个异常值/噪声:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/67dfbf453bfbc6a699e567ba870ae638.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*jJsPW6I8UW-WHTNEWjzgGw.png"/></div></figure><h2 id="da45" class="oa ne it bd nf ob oc dn nj od oe dp nn li of og np lm oh oi nr lq oj ok nt ol bi translated">绘制聚类图</h2><p id="b2ee" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">最后，让我们绘制聚类结果。我们将使用<strong class="lb iu"> matplotlib </strong>来绘制集群。</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="0455" class="oa ne it on b gy or os l ot ou">import matplotlib.pyplot as plt</span><span id="3802" class="oa ne it on b gy oz os l ot ou">unique_labels = set(labels)<br/>colors = [plt.cm.Spectral(each)<br/>          for each in np.linspace(0, 1, len(unique_labels))]<br/>for k, col in zip(unique_labels, colors):<br/>    if k == -1:<br/>        # Black used for noise.<br/>        col = [0, 0, 0, 1]</span><span id="6a86" class="oa ne it on b gy oz os l ot ou">class_member_mask = (labels == k)</span><span id="c8d4" class="oa ne it on b gy oz os l ot ou">xy = X[class_member_mask &amp; core_samples_mask]<br/>    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),<br/>             markeredgecolor='k', markersize=14)</span><span id="9b5a" class="oa ne it on b gy oz os l ot ou">xy = X[class_member_mask &amp; ~core_samples_mask]<br/>    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),<br/>             markeredgecolor='k', markersize=6)</span><span id="db75" class="oa ne it on b gy oz os l ot ou">plt.title('Estimated number of clusters: %d' % n_clusters_)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/7181a1ca0232665d290f7fc5bb4f2911.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*X2Kpcr_1vmeFUA5O0w6ZXw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Clusters (Image by Author)</figcaption></figure><p id="4b81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上图所示，通过样本数据生成的数据点聚集在3个主体中。</p><p id="26d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">落在聚类之外的所有点都是异常值/噪声，因此被涂成黑色。</p><h1 id="e3c0" class="nd ne it bd nf ng nh ni nj nk nl nm nn jz no ka np kc nq kd nr kf ns kg nt nu bi translated">结论</h1><p id="1ad6" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">在本文中，我们使用了Sklearn的DBSCAN算法，这是一种对自己生成的样本数据进行无监督聚类的算法。DBSCAN聚类算法能够根据半径和半径中的最小点(我们通过代码输入)将数据点聚类在一起。</p><p id="26f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DBSCAN算法有许多应用。它用于市场研究、识别模式、分析数据和处理图像。这对于在数据集中从低密度聚类中分离高密度聚类是非常有用的，并且具有异常值检测的鲁棒性。</p><p id="501b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">希望你喜欢阅读这篇文章！😃</p><p id="e227" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">到目前为止，您是否在任何项目中使用过DBSCAN？</p><h2 id="e36c" class="oa ne it bd nf ob oc dn nj od oe dp nn li of og np lm oh oi nr lq oj ok nt ol bi translated">访问专家视图— <a class="ae ky" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>