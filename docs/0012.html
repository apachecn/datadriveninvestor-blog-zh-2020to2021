<html>
<head>
<title>Coloring Black &amp; White Images Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习给黑白图像着色</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/coloring-black-white-images-using-deep-learning-984e6f4ddf14?source=collection_archive---------1-----------------------#2020-01-02">https://medium.datadriveninvestor.com/coloring-black-white-images-using-deep-learning-984e6f4ddf14?source=collection_archive---------1-----------------------#2020-01-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/dbdcd1ccfb13cb5b806883b0c1923500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*l131x0n_GZ6ztz38q3AJ0g.jpeg"/></div></figure><p id="e885" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">你好，朋友们，</p><p id="0cea" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">几天前，在寒假期间，我去了我祖父母家，在那里我看到了我母亲童年时的黑白照片，我突然有了一个想法，想知道我们如何将这张照片着色。于是，我开始在研究论文中搜索这个主题和相关的作品。</p><div class="ks kt gp gr ku kv"><a href="https://www.datadriveninvestor.com/2019/03/22/fixing-photography/" rel="noopener  ugc nofollow" target="_blank"><div class="kw ab fo"><div class="kx ab ky cl cj kz"><h2 class="bd ir gy z fp la fr fs lb fu fw ip bi translated">修复摄影|数据驱动的投资者</h2><div class="lc l"><h3 class="bd b gy z fp la fr fs lb fu fw dk translated">汤姆·津伯洛夫在转向摄影之前曾在南加州大学学习音乐。作为一个…</h3></div><div class="ld l"><p class="bd b dl z fp la fr fs lb fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="le l"><div class="lf l lg lh li le lj js kv"/></div></div></a></div><p id="cea3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">经过几个小时的搜索，我终于找到了给这些图像着色的方法，我立即开始了这个项目的工作，经过令人筋疲力尽的6个小时，我终于得到了一个工作模型，尽管结果不如我想象的那么完美。尽管如此，我还是想写一篇关于我的项目的博客。让我们看看如何给黑白图像上色:</p><h1 id="c3a3" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">概观</h1><p id="93a9" class="pw-post-body-paragraph ju jv iq jw b jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr ij bi translated">图像彩色化是获取<strong class="jw ir">输入灰度(黑白)图像</strong>然后生成<strong class="jw ir">输出彩色图像</strong>的过程，该图像表示输入的语义颜色和色调(例如，晴朗的晴天的海洋必须是貌似“蓝色”的——它不能被模型着色为“粉红”)。</p><p id="21f4" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">以前的图像彩色化方法要么:</p><ol class=""><li id="f2b7" class="mn mo iq jw b jx jy kb kc kf mp kj mq kn mr kr ms mt mu mv bi translated">依赖于重要的人类互动和注释</li><li id="cb15" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr ms mt mu mv bi translated">产生的去饱和彩色化</li></ol><p id="18da" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">相反，我们今天将在这里使用的新方法依赖于深度学习。我们将利用卷积神经网络能够彩色化黑白图像，其结果甚至可以“愚弄”人类！</p><h1 id="fc74" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">我们开始吧</h1><figure class="nc nd ne nf gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/49aea87c9891b51e550ba22ba0e1e614.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*ZNZ9pm-c4cSvh_wwoZMejA.png"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Model Proposed By Zhang et al</figcaption></figure><p id="6eac" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们今天要介绍的技术来自张等人2016年的论文，<em class="nl">彩色图像着色</em> 。</p><p id="4ce7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">以前的黑白图像彩色化方法依赖于<em class="nl">手动人工注释</em>，并且经常产生不像真实彩色化那样“可信”的去饱和结果。</p><p id="d82c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">张等人决定通过使用卷积神经网络来解决图像彩色化的问题，以“幻觉”输入灰度图像在彩色化时的样子。</p><p id="1a0c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在，当我们得到强度作为输入，我们必须猜测颜色，我们不能使用RGB颜色空间，因为它没有关于照明的信息。因此，我们有两个选择:要么使用YCbCr色彩空间，要么使用LAB色彩空间，因为Y和L通道都编码关于照明的信息。</p><p id="5c1e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在本教程中，我们将使用LAB色彩空间，但你也可以尝试使用YCbCr空间。</p><p id="fc10" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">类似于RGB颜色空间，Lab颜色空间具有三个通道<em class="nl"/>。但是<em class="nl">与</em>RGB颜色空间不同，Lab对颜色信息的编码不同:</p><ul class=""><li id="8ae9" class="mn mo iq jw b jx jy kb kc kf mp kj mq kn mr kr nm mt mu mv bi translated"><strong class="jw ir"> <em class="nl"> L </em>通道</strong>仅对亮度进行编码</li><li id="9d94" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr nm mt mu mv bi translated"><strong class="jw ir"> <em class="nl"> a </em>通道</strong>编码绿-红。</li><li id="393f" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr nm mt mu mv bi translated">并且<strong class="jw ir"> <em class="nl"> b </em>通道</strong>编码蓝黄色</li></ul><p id="e556" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">更多信息可以参考<a class="ae nk" href="https://en.wikipedia.org/wiki/CIELAB_color_space" rel="noopener ugc nofollow" target="_blank">这篇维基百科文章</a>。</p><p id="6c48" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">由于<em class="nl"> L </em>通道仅编码强度，<strong class="jw ir">我们可以使用<em class="nl"> L </em>通道作为网络的灰度输入。</strong></p><p id="9a4f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">从那里，网络必须<strong class="jw ir">学会预测<em class="nl"> a </em>和<em class="nl"> b </em>信道。</strong>给定<strong class="jw ir">输入<em class="nl"> L </em>通道</strong>和<strong class="jw ir">预测<em class="nl"> ab </em>通道</strong>，我们就可以形成我们的<strong class="jw ir">最终输出图像。</strong></p><p id="9e4c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">整个(简化)过程可以概括为:</strong></p><ol class=""><li id="2e9b" class="mn mo iq jw b jx jy kb kc kf mp kj mq kn mr kr ms mt mu mv bi translated">将所有训练图像从RGB颜色空间转换到Lab颜色空间。</li><li id="c816" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr ms mt mu mv bi translated">将<strong class="jw ir"> <em class="nl"> L </em>通道</strong>作为网络的输入，训练网络预测<strong class="jw ir"> <em class="nl"> ab </em>通道。</strong></li><li id="acc4" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr ms mt mu mv bi translated">将输入<strong class="jw ir"> <em class="nl"> L </em>通道</strong>与预测<strong class="jw ir"> <em class="nl"> ab </em>通道组合。</strong></li><li id="c3eb" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr ms mt mu mv bi translated">将实验室图像转换回RGB。</li></ol><p id="30e5" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">更多详细信息请参考张等<a class="ae nk" href="http://richzhang.github.io/colorization/" rel="noopener ugc nofollow" target="_blank">原文</a></p><h1 id="23d7" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">用OpenCV给黑白图像着色</h1><p id="b83e" class="pw-post-body-paragraph ju jv iq jw b jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr ij bi translated">我们的colorizer脚本只需要三个导入:NumPy、OpenCV和argparse。</p><p id="fd68" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">让我们继续，<a class="ae nk" href="https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/" rel="noopener ugc nofollow" target="_blank">使用</a> <code class="fe nn no np nq b"><a class="ae nk" href="https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/" rel="noopener ugc nofollow" target="_blank">argparse</a></code> <a class="ae nk" href="https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/" rel="noopener ugc nofollow" target="_blank">来解析命令行参数。</a>该脚本要求将这四个参数直接从终端传递给脚本:</p><ul class=""><li id="9bfd" class="mn mo iq jw b jx jy kb kc kf mp kj mq kn mr kr nm mt mu mv bi translated">— image:输入黑白图像的路径。</li><li id="f577" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr nm mt mu mv bi translated">— prototxt:我们到Caffe prototxt文件的路径。</li><li id="e3e7" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr nm mt mu mv bi translated">—模型。我们通向Caffe预训练模型的道路。</li><li id="9ce3" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr nm mt mu mv bi translated">—点:NumPy聚类中心点文件的路径。</li></ul><p id="19cf" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">有了上面的四个标志和相应的参数，脚本将能够在不改变任何代码的情况下运行不同的输入。</p><pre class="nc nd ne nf gt nr nq ns nt aw nu bi"><span id="33c5" class="nv ll iq nq b gy nw nx l ny nz"># import the necessary packages</span><span id="7cbb" class="nv ll iq nq b gy oa nx l ny nz">import numpy as np<br/>import argparse<br/>import cv2</span><span id="815a" class="nv ll iq nq b gy oa nx l ny nz"># construct the argument parser and parse the arguments</span><span id="4cc6" class="nv ll iq nq b gy oa nx l ny nz">ap = argparse.ArgumentParser()<br/>ap.add_argument(“-i”, “ — image”, type=str, required=True,<br/>help=”path to input black and white image”)<br/>ap.add_argument(“-p”, “ — prototxt”, type=str, required=True,<br/>help=”path to Caffe prototxt file”)<br/>ap.add_argument(“-m”, “ — model”, type=str, required=True,<br/>help=”path to Caffe pre-trained model”)<br/>ap.add_argument(“-c”, “ — points”, type=str, required=True,<br/>help=”path to cluster center points”)<br/>args = vars(ap.parse_args())</span></pre><p id="9a11" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">让我们继续将我们的模型和聚类中心加载到内存中:</p><p id="d37f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在，我们直接从命令行参数值加载Caffe模型。OpenCV可以通过cv2.dnn.readNetFromCaffe函数读取Caffe模型。然后，将聚类中心点直接从命令行参数路径加载到点文件中。</p><p id="e8fb" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">中间几行:</p><ul class=""><li id="ac75" class="mn mo iq jw b jx jy kb kc kf mp kj mq kn mr kr nm mt mu mv bi translated">负载中心为<strong class="jw ir"> <em class="nl"> ab </em>通道</strong>用于再平衡的量化。</li><li id="a177" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr nm mt mu mv bi translated">将每个点视为<em class="nl"> 1×1 </em>卷积，并将它们添加到模型中。</li></ul><pre class="nc nd ne nf gt nr nq ns nt aw nu bi"><span id="a7e0" class="nv ll iq nq b gy nw nx l ny nz"># load our serialized black and white colorizer model and cluster<br/># center points from disk<br/>print(“[INFO] loading model…”)<br/>net = cv2.dnn.readNetFromCaffe(args[“prototxt”], args[“model”])<br/>pts = np.load(args[“points”])</span><span id="3abf" class="nv ll iq nq b gy oa nx l ny nz"># add the cluster centers as 1x1 convolutions to the model<br/>class8 = net.getLayerId(“class8_ab”)<br/>conv8 = net.getLayerId(“conv8_313_rh”)<br/>pts = pts.transpose().reshape(2, 313, 1, 1)<br/>net.getLayer(class8).blobs = [pts.astype(“float32”)]<br/>net.getLayer(conv8).blobs = [np.full([1, 313], 2.606,dtype=”float32")]</span><span id="a9b7" class="nv ll iq nq b gy oa nx l ny nz"># load the input image from disk, scale the pixel intensities to the<br/># range [0, 1], and then convert the image from the BGR to Lab color<br/># space<br/>image = cv2.imread(args[“image”])<br/>scaled = image.astype(“float32”) / 255.0<br/>lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB</span></pre><p id="2536" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在我们可以通过网络把<strong class="jw ir">输入<em class="nl"> L </em>通道</strong>传给<strong class="jw ir">预测<em class="nl"> ab </em>通道:</strong></p><p id="c929" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">L通道通过网络的前向传递发生在<strong class="jw ir">第48行和第49行</strong>(如果需要，这里是对<a class="ae nk" href="https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/" rel="noopener ugc nofollow" target="_blank"> OpenCV的</a> <code class="fe nn no np nq b"><a class="ae nk" href="https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/" rel="noopener ugc nofollow" target="_blank">blobFromImage</a></code>的复习)。</p><p id="151a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">注意，在我们调用net.forward之后，在同一行上，我们继续提取预测的ab体积。我在这里让它看起来很简单，但是如果你想了解更多细节，请参考GitHub 上张等人的文档和演示。</p><p id="0fa2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">之后是后处理部分，包括:</p><p id="b2c9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">后处理包括:</p><ul class=""><li id="5742" class="mn mo iq jw b jx jy kb kc kf mp kj mq kn mr kr nm mt mu mv bi translated">从<strong class="jw ir"> <em class="nl">原始</em> </strong>输入图像中抓取L通道(<strong class="jw ir">第58行</strong>)并将原始L通道和<strong class="jw ir"> <em class="nl">预测</em> </strong> ab通道连接在一起形成彩色化</li><li id="d31d" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr nm mt mu mv bi translated">将彩色图像从Lab色彩空间转换为RGB</li><li id="43b1" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr nm mt mu mv bi translated">剪裁任何超出范围<em class="nl">【0，1】</em>的像素亮度</li><li id="c3f8" class="mn mo iq jw b jx mw kb mx kf my kj mz kn na kr nm mt mu mv bi translated">使像素亮度回到范围<em class="nl">【0，255】</em>在预处理步骤中，我们除以255，现在我们乘以255。我还发现这种缩放和“uint8”转换并不是必需的，但它有助于代码在<strong class="jw ir"> OpenCV 3.4.x </strong>和<strong class="jw ir"> 4.x </strong>版本之间工作。</li></ul><p id="f25b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">最后，我们的原始图像和彩色图像都显示在屏幕上！</p><pre class="nc nd ne nf gt nr nq ns nt aw nu bi"><span id="2206" class="nv ll iq nq b gy nw nx l ny nz"># resize the Lab image to 224x224 (the dimensions the colorization<br/># network accepts), split channels, extract the ‘L’ channel, and then<br/># perform mean centering<br/>resized = cv2.resize(lab, (224, 224))<br/>L = cv2.split(resized)[0]<br/>L -= 50</span><span id="b60c" class="nv ll iq nq b gy oa nx l ny nz"># pass the L channel through the network which will *predict* the ‘a’<br/># and ‘b’ channel values<br/>‘print(“[INFO] colorizing image…”)’<br/>net.setInput(cv2.dnn.blobFromImage(L))<br/>ab = net.forward()[0, :, :, :].transpose((1, 2, 0))</span><span id="dc85" class="nv ll iq nq b gy oa nx l ny nz"># resize the predicted ‘ab’ volume to the same dimensions as our<br/># input image<br/>ab = cv2.resize(ab, (image.shape[1], image.shape[0]))</span><span id="8531" class="nv ll iq nq b gy oa nx l ny nz"><br/># grab the ‘L’ channel from the *original* input image (not the<br/># resized one) and concatenate the original ‘L’ channel with the<br/># predicted ‘ab’ channels<br/>L = cv2.split(lab)[0]<br/>colorized = np.concatenate((L[:, :, np.newaxis], ab), axis=2)</span><span id="dd7d" class="nv ll iq nq b gy oa nx l ny nz"># convert the output image from the Lab color space to RGB, then<br/># clip any values that fall outside the range [0, 1]<br/>colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)<br/>colorized = np.clip(colorized, 0, 1)</span><span id="3fbd" class="nv ll iq nq b gy oa nx l ny nz"># the current colorized image is represented as a floating point<br/># data type in the range [0, 1] — let’s convert to an unsigned<br/># 8-bit integer representation in the range [0, 255]<br/>colorized = (255 * colorized).astype(“uint8”)</span><span id="83fc" class="nv ll iq nq b gy oa nx l ny nz"># show the original and output colorized images<br/>cv2.imshow(“Original”, image)<br/>cv2.imshow(“Colorized”, colorized)<br/>cv2.waitKey(0)</span></pre><h1 id="1768" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">图像彩色化结果</h1><figure class="nc nd ne nf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="oc od di oe bf of"><div class="gh gi ob"><img src="../Images/83774242c9b4777fdcf4d8235d5c171d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RQj0Lf6TzjxZzUL1svPO-A.jpeg"/></div></div></figure><p id="4a03" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">不要惊慌。这是我们所期待的结果，但是我得到的结果与这种完美的结果有一点差距。</p><figure class="nc nd ne nf gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/0b7e125f00e5c23851300bb52a5394c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*r3IHMA3F5Mr7jWPfdKoeUg.jpeg"/></div></figure><p id="2d05" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这是美国作家、幽默作家、企业家、出版商和讲师马克·吐温的肖像。他被誉为“这个国家产生的最伟大的幽默作家”，威廉·福克纳称他为“美国文学之父”。</p><p id="453a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在这里，我们可以看到草和树叶被正确地染成了绿色，尽管你可以看到这些绿色融入了吐温的鞋子和手。</p><figure class="nc nd ne nf gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/28082156f471bad56807c588da10932f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*OGP0mSENNRuzDHypznULTg.jpeg"/></div></figure><p id="59eb" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在<em class="nl">左边</em>可以看到罗宾·威廉姆斯(Robin Williams)的原始输入图像，这位著名的演员和喜剧演员于~5年前去世。</p><p id="bd7d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在<em class="nl">右边</em>，你可以看到黑白彩色化模型的输出。</p><h1 id="e736" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">摘要</h1><p id="5b8e" class="pw-post-body-paragraph ju jv iq jw b jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr ij bi translated">在今天的教程中，你学习了如何使用OpenCV和深度学习给黑白图像着色。</p><p id="e212" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们今天使用的图像彩色化模型是由张等人在他们2016年的出版物《【彩色图像彩色化】中首次提出的。</p><p id="ac34" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">使用这个模型，我们能够彩色化黑白图像。</p><p id="eda8" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们的结果虽然不完美，但证明了自动给黑白图像和视频着色的合理性。</p><p id="9fdc" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">根据张等人的研究，他们的方法能够“愚弄”人类32%的时间！</p><figure class="nc nd ne nf gt jr"><div class="bz fp l di"><div class="og oh l"/></div></figure></div></div>    
</body>
</html>