<html>
<head>
<title>Web Scraping Wikipedia with BeautifulSoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用美丽的声音抓取维基百科</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/web-scraping-wikipedia-with-beautifulsoup-a5d5fe6454ee?source=collection_archive---------5-----------------------#2020-03-01">https://medium.datadriveninvestor.com/web-scraping-wikipedia-with-beautifulsoup-a5d5fe6454ee?source=collection_archive---------5-----------------------#2020-03-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/b6f9ceff4d2d9fc7ca2ea91f19a55a02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PaYGHwE_xiwVSMeOdcdgVQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/@sickle?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Sergey Pesterev</a> on <a class="ae kc" href="https://unsplash.com/s/photos/waterfall?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="5206" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">介绍</h1><p id="3478" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">想象一下，你被分配了一项任务，从互联网上提取大量数据，并需要在更短的时间内以良好的格式组织这些数据。手动浏览每个页面并获取数据会花费很多时间。有什么方法可以让我们的工作变得更简单，在结构化的格式中变得更快捷？嗯，网络抓取是答案。</p><p id="f0ae" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">互联网上有大量的信息，这是一种非结构化的格式。如果我们可以收集这些信息，并以结构化的格式进行排列，这些数据可以用于许多分析目的，也可以从数据中获得洞察力。在本教程中，我将向你展示如何从维基百科中删除数据</p><h1 id="10e4" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">什么是网页抓取？</h1><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="mi mj l"/></div></figure><p id="13ca" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">Web抓取用于从互联网中提取非结构化数据，并将其存储为结构化格式。这可以由人或机器人来完成。</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/da6eee95e55cf2af9d63266f16eb5181.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wprolPKvb-WgJYpbmCfFbw.png"/></div></div></figure><p id="10d9" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">网页抓取的一些应用包括</p><ol class=""><li id="a6dc" class="ml mm iq ld b le lz li ma lm mn lq mo lu mp ly mq mr ms mt bi translated">网络搜集可用于从网站上收集企业或个人的联系方式。</li><li id="4b69" class="ml mm iq ld b le mu li mv lm mw lq mx lu my ly mq mr ms mt bi translated">网络抓取用于从Twitter等社交媒体网站收集数据，以发现流行趋势。</li><li id="e775" class="ml mm iq ld b le mu li mv lm mw lq mx lu my ly mq mr ms mt bi translated">网络抓取用于从网站收集大量数据，并对这些数据进行分析，用于进行研发。</li></ol><h1 id="f113" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">网络抓取合法吗？</h1><p id="00e8" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">有些网站允许抓取网页，有些网站不允许。要知道一个网站是否允许网络抓取，我们需要查看网站的robots.txt文件。要找到robots.txt，我们需要输入URL并添加“/robots.txt”。例如，如果我们想放弃vizagfood.com，在URL框中输入<a class="ae kc" href="https://www.vizagfood.com/robots.txt" rel="noopener ugc nofollow" target="_blank">https://www.vizagfood.com/robots.txt</a>。在这里，我们有三个访问类别。在第一种情况下，我们可以访问所有数据，而在第二种情况下，我们不能访问数据，在最后一种情况下，我们只能访问部分数据。</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/65159feaf5a9b5a74f5a2c5ae79c0cee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*muAYhiEgz_A9pzHakivRSg.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Access types</figcaption></figure><p id="0786" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">这里的section代表不被抓取的部分。就vizagfood.com而言，robots.txt包含以下内容:</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/a2e182c0a1421c73d589570e76e15a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*JKEEn5mUL9GaPq7iv-6k_w.jpeg"/></div></figure><p id="781d" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">这意味着我们可以抓取这个网站上的所有部分。</p><h1 id="5d6b" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">网页抓取是如何工作的？</h1><p id="7482" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">当您运行代码时，会向您提到的作为输入URL的URL发送一个请求。作为对请求的响应，服务器发送数据并允许您阅读HTML页面。然后，代码解析HTML或XML页面，找到数据并提取出来。</p><h1 id="e872" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">我们要用什么工具？</h1><p id="da85" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们将使用Python模块requests和BeautifulSoup。</p><p id="d9b2" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">python模块“Requests”将允许我们发送HTTP请求来获取HTML文件。</p><p id="6cd4" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">请求文件的链接:【https://requests.readthedocs.io/en/master/ T2】</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/e189fc465b5c1bc076770b59760ccb49.png" data-original-src="https://miro.medium.com/v2/resize:fit:430/format:webp/1*0q2A6PDnxCJb0k2tiyHEQA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Requests Module</figcaption></figure><p id="4c5f" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">网络抓取最常用的库之一是“BeautifulSoup”。它用于解析HTML或XML文件。它创建有助于轻松提取数据的解析树。</p><p id="4565" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">链接到BeautifulSoup文档:<a class="ae kc" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a></p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/5651faca2d99cf9749876e65f0090178.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*GfiJGUtSNkEMyg9xR1qCjw.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">BeautifulSoup module</figcaption></figure><p id="0896" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">“urllib”模块是python的URL处理模块。它用于获取URL。这是一个包含不同模块的包，用于打开和读取文件，解析URL和解析robots.txt文件</p><h1 id="18d0" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">先决条件</h1><ul class=""><li id="2fc7" class="ml mm iq ld b le lf li lj lm nd lq ne lu nf ly ng mr ms mt bi translated">python3</li><li id="6330" class="ml mm iq ld b le mu li mv lm mw lq mx lu my ly ng mr ms mt bi translated">要求</li><li id="c68c" class="ml mm iq ld b le mu li mv lm mw lq mx lu my ly ng mr ms mt bi translated">beautifulsoup4</li></ul><h1 id="298f" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">我们来编码吧！</h1><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="nh mj l"/></div></figure><h1 id="c3b6" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">导入必要的库</h1><p id="af77" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在这里，我们导入执行Web报废所需的必要库。上面讨论了一些库，如urlib、beautiful soup(bs4 ),其余的在下面讨论。</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="ni mj l"/></div></figure><ul class=""><li id="241e" class="ml mm iq ld b le lz li ma lm mn lq mo lu mp ly ng mr ms mt bi translated">NLTK代表自然语言工具包。它包含让机器理解人类语言并以适当的响应回复人类语言的包。记号化、标点符号、字符计数和单词计数是其中的一部分。</li><li id="4c05" class="ml mm iq ld b le mu li mv lm mw lq mx lu my ly ng mr ms mt bi translated">一个<em class="nj">正则表达式</em>是一个特殊的字符序列，它可以帮助你匹配或查找其他字符串或字符串集模块“re”在Python中提供了对正则表达式的完全支持</li><li id="64a6" class="ml mm iq ld b le mu li mv lm mw lq mx lu my ly ng mr ms mt bi translated">停用词是搜索引擎已经被编程忽略的常用词(例如“the”、“a”、“an”、“in”)</li></ul><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/c203af4406b4e8ece68322da26c57a64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*6V00fNF_pDDJlzfw7LzBtw.jpeg"/></div></figure><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="ni mj l"/></div></figure><p id="e7b0" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">上面几行用于读取URL，这里soup是一个解析的HTML数据，我们将把页面内容转换成一个BeautifulSoup对象，这将允许我们解析HTML标签。然后，我们需要找出哪些HTML标签包含文章的文本。</p><div class="nl nm gp gr nn no"><a href="https://www.datadriveninvestor.com/2019/02/12/ready-or-not-the-revolution-is-upon-us/" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">不管准备好了没有，革命就在我们面前|数据驱动的投资者</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">“对于技术如何影响我们的生活和重塑经济，我们必须形成全面的全球共识……</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc jw no"/></div></div></a></div><p id="9fd8" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">为此，我们将使用谷歌浏览器中的Inspect工具。打开我们需要抓取的文章，在页面上点击右键，从下拉菜单中选择Inspect。这将显示如下所示的工具:</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/1579fc97759224391b0bd31237ec48ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*34Pq-n2sAYN312MRfqJ3mA.jpeg"/></div></div></figure><p id="65a4" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">点击上面的小箭头按钮，找到与你在页面上看到的任何内容相对应的HTML标签。当您将鼠标悬停在页面上想要选择的文本(在本例中是文章的文本)上时，您将看到哪些HTML标签用于标识该文本。</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oe"><img src="../Images/d4574c2798c8a50907cbc372ca99901e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MxRe6yrELIm_CMwJ7HjaFw.jpeg"/></div></div></figure><p id="2a56" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">当我们检查维基百科中的空间网站时，我们正在对维基百科页面执行网络抓取，所有的文本数据都存储在<p>标签中，即段落标签中。我们的目标是获取</p><p>标签中的内容并检索它。从解析后的soup对象中，我们应用“find_all”方法来获取</p><p>标签中的内容，我们将把它附加到文本中。</p></p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="ni mj l"/></div></figure><h1 id="9435" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">预处理数据</h1><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="ni mj l"/></div></figure><p id="ffbc" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们使用正则表达式过滤掉不必要的内容。这有助于我们从内容中删除数字，删除空格，也有助于将大写转换为小写。</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="ni mj l"/></div></figure><p id="5fc3" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">在“sent_tokenize”方法的帮助下，我们可以将收集到的文本转换成句子。本教程的Github库可以在这里找到:</p><div class="nl nm gp gr nn no"><a href="https://github.com/ajaymuktha/WebScraping" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">ajaymuktha/网络搜集</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">通过网络搜集从维基百科收集数据</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="of l nz oa ob nx oc jw no"/></div></div></a></div><p id="4b43" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">恭喜你！，您刚刚学会了如何从维基百科中删除数据。暂时就这样吧！我希望你喜欢这篇文章。</p><p id="2f21" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">参考:</p><div class="nl nm gp gr nn no"><a href="https://realpython.com/beautiful-soup-web-scraper-python/" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">美丽的汤:用Python——真正的Python——构建一个Web刮刀</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">在本教程中，你将走过网页抓取过程的主要步骤。你将学习如何写剧本…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">realpython.com</p></div></div><div class="nx l"><div class="og l nz oa ob nx oc jw no"/></div></div></a></div><div class="nl nm gp gr nn no"><a href="https://www.summet.com/dmsi/html/readingTheWeb.html" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">从Web读取数据:Web抓取和正则表达式</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">在这一章中，你将学习如何从网络服务器中读取数据。urllib模块允许您从…下载数据</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">www.summet.com</p></div></div><div class="nx l"><div class="oh l nz oa ob nx oc jw no"/></div></div></a></div><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oi mj l"/></div></figure></div></div>    
</body>
</html>