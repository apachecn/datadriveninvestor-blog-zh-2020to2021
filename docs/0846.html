<html>
<head>
<title>Machine Learning Project: Neural Network Learns To Play Tic-Tac-Toe</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习项目:神经网络学习玩井字游戏</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/machine-learning-project-neural-network-learns-to-play-tic-tac-toe-6ed71c159dda?source=collection_archive---------4-----------------------#2020-02-19">https://medium.datadriveninvestor.com/machine-learning-project-neural-network-learns-to-play-tic-tac-toe-6ed71c159dda?source=collection_archive---------4-----------------------#2020-02-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="288f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一个关于用Keras在Python中构建神经网络并教它玩井字游戏的机器学习项目。</h2></div><p id="be96" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">本文原载于</em> <a class="ae lc" href="https://programmerbackpack.com/python-neural-network-tutorial/" rel="noopener ugc nofollow" target="_blank"> <em class="lb">程序员背包博客</em> </a> <em class="lb">。如果你想阅读更多这类的故事，一定要访问这个博客。</em></p><p id="6ba7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">更感兴趣？在Twitter上关注我，地址是</em><a class="ae lc" href="https://twitter.com/b_dmarius" rel="noopener ugc nofollow" target="_blank"><em class="lb">@ b _ dmarius</em></a><em class="lb">，我会在那里发布每一篇新文章。</em></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/e99b53343b0f119cbb89cf5c92377d0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0XFbBdnchYAkHB4j"/></div></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk">Photo by <a class="ae lc" href="https://unsplash.com/@agkdesign?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Alex Knight</a> on <a class="ae lc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="ff8f" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">动机</h1><p id="e918" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在这篇文章中，我们将建立一个基本的神经网络来学习井字游戏。众所周知，这是一个已解决的游戏，使用神经网络有点大材小用，但这是一个搜索空间非常小的简单游戏，这是一个很好的机会，让我们可以使用神经网络，而不必太担心数据收集和清理。</p><p id="0109" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个项目的所有代码都可以在<a class="ae lc" href="https://github.com/bdmarius/nn-tic-tac-toe" rel="noopener ugc nofollow" target="_blank"> Github </a>上获得——我在这里只发布代码片段——所以你可以在那里查看(如果你这样做了，请不要忘记启动资源库，这样我就知道你喜欢这个项目了)。另外，请随时在Twitter上关注我，<a class="ae lc" href="https://twitter.com/b_dmarius" rel="noopener ugc nofollow" target="_blank"> @b_dmarius </a>，我会在那里发布每一篇新文章。</p><h1 id="d7de" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">方法</h1><p id="503a" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">我们将在命令行构建一个简单的井字游戏。我不会自己玩这个游戏，但是我会让两个电脑玩家从一系列可用的走法中随机选择来玩几千次。我们将记录玩家的每一个动作和游戏的最终结果。</p><div class="mq mr gp gr ms mt"><a href="https://www.datadriveninvestor.com/2019/03/03/editors-pick-5-machine-learning-books/" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">DDI编辑推荐:5本让你从新手变成专家的机器学习书籍|数据驱动…</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">机器学习行业的蓬勃发展重新引起了人们对人工智能的兴趣</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nc l"><div class="nd l ne nf ng nc nh ln mt"/></div></div></a></div><p id="f718" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在模拟之后，我们将把记录的数据输入一个简单的神经网络来训练我们的模型。训练完模型后，我们将让它与电脑玩家对战，首先作为玩家1，然后作为玩家2，看看结果。</p><h1 id="2444" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">游戏</h1><p id="950f" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">对于井字游戏，我选择了一个非常基本的Python实现。这部分不是这个项目中最有趣的，所以我将解释流程并在这里列出代码。您可以根据自己的项目需要对其进行调整。</p><p id="aa5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用一个简单的游戏类来保存信息和处理游戏的流程。如果没有任何玩家选择，则单元格标记为0，-1表示有X的玩家，1表示有o的玩家。每次，游戏都提供一个包含所有可用移动的列表，玩家轮流从该列表中随机选择。移动被处理，并且棋盘的当前状态被保存在我们将用于训练的历史中。游戏结束后(要么是平局，要么是一个玩家赢)，游戏结果被映射到棋盘在游戏中的每个状态。以下是我用过的符号:</p><pre class="le lf lg lh gt ni nj nk nl aw nm bi"><span id="639d" class="nn lu iq nj b gy no np l nq nr">PLAYER_X = 'X'<br/>PLAYER_O = 'O'<br/>EMPTY = ' '<br/>PLAYER_X_VAL = -1<br/>PLAYER_O_VAL = 1<br/>EMPTY_VAL = 0<br/>HORIZONTAL_SEPARATOR = ' | '<br/>VERTICAL_SEPARATOR = '---------------'<br/>GAME_STATE_X = -1<br/>GAME_STATE_O = 1<br/>GAME_STATE_DRAW = 0<br/>GAME_STATE_NOT_ENDED = 2</span></pre><p id="3bd7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是第一次移动后的训练历史。在这个游戏中，玩家X赢了(因为第一项中的-1 ),游戏中的第一步是由玩家X进行的——第3行，第2列。</p><pre class="le lf lg lh gt ni nj nk nl aw nm bi"><span id="be89" class="nn lu iq nj b gy no np l nq nr">[(-1, [[0, 0, 0], [0, 0, 0], [0, -1, 0]])]</span></pre><p id="d6cd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一整场比赛之后，历史将会是这样的:</p><pre class="le lf lg lh gt ni nj nk nl aw nm bi"><span id="5894" class="nn lu iq nj b gy no np l nq nr">[(-1, [[0, 0, 0], [0, 0, 0], [0, 1, 0]]), (-1, [[0, 0, 0], [0, -1, 0], [0, 1, 0]]), (-1, [[0, 0, 0], [1, -1, 0], [0, 1, 0]]), (-1, [[0, 0, -1], [1, -1, 0], [0, 1, 0]]), (-1, [[1, 0, -1], [1, -1, 0], [0, 1, 0]]), (-1, [[1, 0, -1], [1, -1, 0], [-1, 1, 0]]), (-1, [[1, 0, -1], [1, -1, 1], [-1, 1, 0]]), (-1, [[1, 0, -1], [1, -1, 1], [-1, 1, -1]]), (-1, [[1, 1, -1], [1, -1, 1], [-1, 1, -1]])]</span></pre><p id="b2fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">想象10000场比赛后训练数据的样子！幸运的是，我们没有钱来帮助我们。稍后你会看到我们将如何处理所有这些数据。以下是我们模拟游戏的方式:</p><pre class="le lf lg lh gt ni nj nk nl aw nm bi"><span id="46fb" class="nn lu iq nj b gy no np l nq nr">def simulate(self, playerToMove):<br/>        while (self.getGameResult() == GAME_STATE_NOT_ENDED):<br/>            availableMoves = self.getAvailableMoves()<br/>            selectedMove = availableMoves[random.randrange(0, len(availableMoves))]<br/>            self.move(selectedMove, playerToMove)<br/>            if playerToMove == PLAYER_X_VAL:<br/>                playerToMove = PLAYER_O_VAL<br/>            else:<br/>                playerToMove = PLAYER_X_VAL<br/>        # Get the history and build the training set<br/>        for historyItem in self.boardHistory:<br/>            self.trainingHistory.append((self.getGameResult(), copy.deepcopy(historyItem)))<br/>   <br/>    def simulateManyGames(self, playerToMove, numberOfGames):<br/>        playerXWins = 0<br/>        playerOWins = 0<br/>        draws = 0<br/>        for i in range(numberOfGames):<br/>            self.resetBoard()<br/>            self.simulate(playerToMove)<br/>            if i == 0:<br/>                print(self.trainingHistory)<br/>            if self.getGameResult() == PLAYER_X_VAL:<br/>                playerXWins = playerXWins + 1<br/>            elif self.getGameResult() == PLAYER_O_VAL:<br/>                playerOWins = playerOWins + 1<br/>            else: draws = draws + 1<br/>        totalWins = playerXWins + playerOWins + draws<br/>        print ('X Wins: ' + str(int(playerXWins * 100/totalWins)) + '%')<br/>        print('O Wins: ' + str(int(playerOWins * 100 / totalWins)) + '%')<br/>        print('Draws: ' + str(int(draws * 100 / totalWins)) + '%')</span></pre><p id="f0bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了评估游戏的结果，我们使用一个非常基本的方法。当然，这可以优化很多，但这不在本文的讨论范围内。以下是我使用的代码:</p><pre class="le lf lg lh gt ni nj nk nl aw nm bi"><span id="dd9c" class="nn lu iq nj b gy no np l nq nr">def getGameResult(self):<br/>        for i in range(len(self.board)):<br/>            for j in range(len(self.board[i])):<br/>                if self.board[i][j] == EMPTY_VAL:<br/>                    return GAME_STATE_NOT_ENDED<br/><br/>        # Rows<br/>        for i in range(len(self.board)):<br/>            candidate = self.board[i][0]<br/>            for j in range(len(self.board[i])):<br/>                if candidate != self.board[i][j]:<br/>                    candidate = 0<br/>            if candidate != 0:<br/>                return candidate<br/><br/>        # Columns<br/>        for i in range(len(self.board)):<br/>            candidate = self.board[0][i]<br/>            for j in range(len(self.board[i])):<br/>                if candidate != self.board[j][i]:<br/>                    candidate = 0<br/>            if candidate != 0:<br/>                return candidate<br/><br/>        # First diagonal<br/>        candidate = self.board[0][0]<br/>        for i in range(len(self.board)):<br/>            if candidate != self.board[i][i]:<br/>                candidate = 0<br/>        if candidate != 0:<br/>            return candidate<br/><br/>        # Second diagonal<br/>        candidate = self.board[0][2]<br/>        for i in range(len(self.board)):<br/>            if candidate != self.board[i][len(self.board[i]) - i - 1]:<br/>                candidate = 0<br/>        if candidate != 0:<br/>            return candidate<br/><br/>        return GAME_STATE_DRAW</span></pre><p id="2f4e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是10000场比赛后的模拟结果。在井字游戏中，作为第二个玩家似乎更容易，我们将看到这也反映在我们的神经网络模拟中。</p><p id="ba1c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb"> X胜:23% <br/> O胜:64% <br/>平局:11% </em></p><h1 id="0645" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">神经网络</h1><p id="062d" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">我们将构建一个神经网络，它将游戏棋盘状态(棋盘中每个单元格的值:-1，0，1)作为输入，并输出与每个可能的游戏结果相关的概率(X赢，O赢或平局)。从输出中，我们选择概率最高的结果作为我们的游戏结果。我们希望神经网络能够学会预测给定的棋盘状态，从而得出正确的最终结果。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/b1fd8c6f5827cc4f8e487ccfffe0990b.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*OU-cG1pscIhQgkJgecx7zA.png"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk">Neural Network Configuration</figcaption></figure><p id="fe16" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以我们的网络将有9个输入和3个输出。在输入层和输出层之间，我们有4个密集层。在尝试了许多不同的组合后，我选择了层数和尺寸。随意尝试其他组合，我相信你会得到更好的效果！下面是生成模型的代码。为此你需要安装<strong class="kh ir">张量流</strong>和<strong class="kh ir"> keras </strong>。</p><pre class="le lf lg lh gt ni nj nk nl aw nm bi"><span id="0cb0" class="nn lu iq nj b gy no np l nq nr">def __init__(self, numberOfInputs, numberOfOutputs, epochs, batchSize):<br/>        self.epochs = epochs<br/>        self.batchSize = batchSize<br/>        self.numberOfInputs = numberOfInputs<br/>        self.numberOfOutputs = numberOfOutputs<br/>        self.model = Sequential()<br/>        self.model.add(Dense(64, activation='relu', input_shape=(numberOfInputs, )))<br/>        self.model.add(Dense(128, activation='relu'))<br/>        self.model.add(Dense(128, activation='relu'))<br/>        self.model.add(Dense(128, activation='relu'))<br/>        self.model.add(Dense(numberOfOutputs, activation='softmax'))<br/>        self.model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])</span></pre><h1 id="f82b" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">训练模型</h1><p id="0765" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">我们将获得棋盘状态和最终结果，并将它们作为输入和输出提供给神经网络。我们将数据集分为80%的训练集和20%的评估集。神经网络背后的数学问题已经超出了本文的范围，但是如果您也想让我写一篇关于这方面的文章，我会很乐意的！</p><p id="c830" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们将使用这些数据对神经网络进行100个时期的训练，每批32个时期。这些数字也是实验的结果，所以你可以随时尝试新的组合。</p><pre class="le lf lg lh gt ni nj nk nl aw nm bi"><span id="537c" class="nn lu iq nj b gy no np l nq nr">def train(self, dataset):<br/>        input = []<br/>        output = []<br/>        for data in dataset:<br/>            input.append(data[1])<br/>            output.append(data[0])<br/><br/>        X = np.array(input).reshape((-1, self.numberOfInputs))<br/>        y = to_categorical(output, num_classes=3)<br/>        # Train and test data split<br/>        boundary = int(0.8 * len(X))<br/>        X_train = X[:boundary]<br/>        X_test = X[boundary:]<br/>        y_train = y[:boundary]<br/>        y_test = y[boundary:]<br/>        self.model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=self.epochs, batch_size=self.batchSize)</span></pre><h1 id="6bcc" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">预测最佳行动</h1><p id="9bfe" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">预测游戏中给定时刻的最佳行动非常简单。游戏已经为我们提供了所有可能的移动列表，因此我们可以采取每个可能的移动，将其投影到棋盘上，并通过神经网络输入棋盘状态，并记录我们感兴趣的结果(例如，如果神经网络是玩家X，我们会记录玩家X获胜的概率)。</p><p id="cab3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在网络处理完所有可能的走法后，我们选择得分最高的走法，并将其作为我们的下一步走法。</p><pre class="le lf lg lh gt ni nj nk nl aw nm bi"><span id="2689" class="nn lu iq nj b gy no np l nq nr">def predict(self, data, index):<br/>        return self.model.predict(np.array(data).reshape(-1, self.numberOfInputs))[0][index]</span></pre><p id="4eb3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是用神经网络模拟游戏的代码，一个玩家扮演另一个玩家。</p><pre class="le lf lg lh gt ni nj nk nl aw nm bi"><span id="a86c" class="nn lu iq nj b gy no np l nq nr">def simulateNeuralNetwork(self, nnPlayer, model):<br/>        playerToMove = PLAYER_X_VAL<br/>        while (self.getGameResult() == GAME_STATE_NOT_ENDED):<br/>            availableMoves = self.getAvailableMoves()<br/>            if playerToMove == nnPlayer:<br/>                maxValue = 0<br/>                bestMove = availableMoves[0]<br/>                for availableMove in availableMoves:<br/>                    # get a copy of a board<br/>                    boardCopy = copy.deepcopy(self.board)<br/>                    boardCopy[availableMove[0]][availableMove[1]] = nnPlayer<br/>                    if nnPlayer == PLAYER_X_VAL:<br/>                        value = model.predict(boardCopy, 0)<br/>                    else:<br/>                        value = model.predict(boardCopy, 2)<br/>                    if value &gt; maxValue:<br/>                        maxValue = value<br/>                        bestMove = availableMove<br/>                selectedMove = bestMove<br/>            else:<br/>                selectedMove = availableMoves[random.randrange(0, len(availableMoves))]<br/>            self.move(selectedMove, playerToMove)<br/>            if playerToMove == PLAYER_X_VAL:<br/>                playerToMove = PLAYER_O_VAL<br/>            else:<br/>                playerToMove = PLAYER_X_VAL<br/>    <br/>    def simulateManyNeuralNetworkGames(self, nnPlayer, numberOfGames, model):<br/>        nnPlayerWins = 0<br/>        randomPlayerWins = 0<br/>        draws = 0<br/>        print ("NN player")<br/>        print (nnPlayer)<br/>        for i in range(numberOfGames):<br/>            self.resetBoard()<br/>            self.simulateNeuralNetwork(nnPlayer, model)<br/>            if self.getGameResult() == nnPlayer:<br/>                nnPlayerWins = nnPlayerWins + 1<br/>            elif self.getGameResult() == GAME_STATE_DRAW:<br/>                draws = draws + 1<br/>            else: randomPlayerWins = randomPlayerWins + 1<br/>        totalWins = nnPlayerWins + randomPlayerWins + draws<br/>        print ('X Wins: ' + str(int(nnPlayerWins * 100/totalWins)) + '%')<br/>        print('O Wins: ' + str(int(randomPlayerWins * 100 / totalWins)) + '%')<br/>        print('Draws: ' + str(int(draws * 100 / totalWins)) + '%')</span></pre><p id="b33d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我们神经网络游戏的模拟结果(每个游戏10000个)。</p><blockquote class="nt nu nv"><p id="fac8" class="kf kg lb kh b ki kj jr kk kl km ju kn nw kp kq kr nx kt ku kv ny kx ky kz la ij bi translated">用神经网络模拟成X玩家:<br/> NN玩家<br/> -1 <br/> X胜:57% <br/> O胜:1% <br/>平局:40%</p><p id="d559" class="kf kg lb kh b ki kj jr kk kl km ju kn nw kp kq kr nx kt ku kv ny kx ky kz la ij bi translated">用神经网络模拟为O玩家:<br/> NN玩家<br/> 1 <br/> X胜:3% <br/> O胜:89% <br/>平局:6%</p></blockquote><p id="18b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果对我来说非常好！！在两场比赛中，神经网络都比另一个玩家赢了更多的比赛。对于第一种情况，即使神经网络只赢了57%的游戏，另一个玩家只赢了1%，其余的都是平局，这仍然是一个非常好的结果。第二场比赛的结果甚至更好，NN玩家赢得了惊人的89%的比赛，而另一个玩家只赢得了3%。所以在这两种情况下，对手都没有机会！</p><h1 id="ae58" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">结论</h1><p id="a2c9" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在本文中，我们尝试了一种简单的方法来构建一个尝试玩井字游戏的神经网络。我们只使用了一个基本模型，仍然得到了一些不错的结果。如果你想获得更好的结果，我建议尝试更复杂的模型和更多的训练数据。另外，另一个好方法是使用强化学习，但这是另一篇文章的内容。该项目的完整代码可以在Github 上找到。如果你喜欢这个项目，就开始吧。感谢阅读！</p><p id="0dca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">更感兴趣？在Twitter上关注我，地址是</em><a class="ae lc" href="https://twitter.com/b_dmarius" rel="noopener ugc nofollow" target="_blank"><em class="lb">@ b _ dmarius</em></a><em class="lb">，我会在那里发布每一篇新文章。</em></p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="nz oa l"/></div></figure></div></div>    
</body>
</html>