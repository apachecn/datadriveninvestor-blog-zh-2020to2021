<html>
<head>
<title>Best AI/ML Research Papers for NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP最佳人工智能/人工智能研究论文</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/best-ai-ml-research-papers-for-nlp-a39de074eff6?source=collection_archive---------12-----------------------#2020-12-15">https://medium.datadriveninvestor.com/best-ai-ml-research-papers-for-nlp-a39de074eff6?source=collection_archive---------12-----------------------#2020-12-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f86c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">惊人的论文…</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/090b05a3195751a3125f67dba57844f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vQeCubGwvwxhcqHv.jpg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Pic credits : Pinterest</figcaption></figure><h1 id="0d3b" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">知识密集型自然语言处理任务的检索增强生成</h1><p id="d509" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><em class="mj">作者:Patrick Lewis、Ethan Perez、Aleksandara Piktus、Fabio Petroni、Vladimir Karpukhin、Naman Goyal、Heinrich Küttler、迈克·刘易斯、Wen-tau Yih、Tim rocktschel、Sebastian Riedel、Douwe Kiela </em></p><h1 id="4a17" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">抽象—</h1><p id="7714" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">大型预训练语言模型已被证明在其参数中存储事实知识，并在下游NLP任务上进行微调时实现最先进的结果。然而，它们访问和精确操作知识的能力仍然有限，因此在知识密集型任务上，它们的性能落后于特定任务的体系结构。此外，为他们的决策提供出处和更新他们的世界知识仍然是开放的研究问题。具有对显式非参数记忆的可区分访问机制的预训练模型可以克服这个问题，但迄今为止只对提取下游任务进行了研究。我们探索了一种通用的检索增强生成(RAG)微调方法——结合预训练参数和非参数记忆的语言生成模型。我们引入RAG模型，其中参数记忆是预训练的seq2seq模型，非参数记忆是维基百科的密集向量索引，通过预训练的神经检索器访问。我们比较了两个RAG公式，一个以整个生成序列中相同的检索段落为条件，另一个可以对每个令牌使用不同的段落。我们在广泛的知识密集型NLP任务上微调和评估了我们的模型，并在三个开放域QA任务上设置了最先进的技术，优于参数seq2seq模型和特定于任务的检索和提取架构。对于语言生成任务，我们发现RAG模型比最先进的仅含参数的seq2seq基线生成更具体、多样和真实的语言。</p><p id="9728" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir"> <em class="mj">论文可以在这里找到:</em> </strong></p><p id="6d38" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><a class="ae mp" href="https://arxiv.org/pdf/2005.11401v2.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2005.11401v2.pdf</a></p><p id="7c18" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir"> <em class="mj">代码可以在这里找到:</em> </strong></p><div class="mq mr gp gr ms mt"><a href="https://github.com/huggingface/transformers" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">拥抱脸/变形金刚</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">PyTorch和TensorFlow 2.0的最新自然语言处理技术🤗变形金刚提供了成千上万的…</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">github.com</p></div></div><div class="nc l"><div class="nd l ne nf ng nc nh kp mt"/></div></div></a></div><div class="mq mr gp gr ms mt"><a href="https://github.com/deepset-ai/haystack" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">deepset-ai/haystack</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">Haystack是一个用于问答和神经搜索的端到端框架，它使您能够......在…中提问</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">github.com</p></div></div><div class="nc l"><div class="ni l ne nf ng nc nh kp mt"/></div></div></a></div></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><h1 id="fdf0" class="kv kw iq bd kx ky nq la lb lc nr le lf jw ns jx lh jz nt ka lj kc nu kd ll lm bi translated">关于高效的神经网络，计算机视觉能教给NLP什么？</h1><p id="bb2d" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">由Forrest N. Iandola，Albert E. Shaw，Ravi Krishna，Kurt W. Keutzer </p><h1 id="615a" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">抽象—</h1><p id="f7c7" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">人类每天读写数千亿条信息。此外，由于大型数据集、大型计算系统和更好的神经网络模型的可用性，自然语言处理(NLP)技术在理解、校对和组织这些消息方面取得了重大进展。因此，在无数的应用程序中部署NLP来帮助web用户、社交网络和企业是一个很好的机会。特别是，我们认为智能手机和其他移动设备是大规模部署NLP模型的重要平台。然而，今天的高度精确的NLP神经网络模型，如BERT和RoBERTa，在计算上极其昂贵，BERT-base需要1.7秒来对Pixel 3智能手机上的文本片段进行分类。在这项工作中，我们观察到，分组卷积等方法已经为计算机视觉网络带来了显著的加速，但其中许多技术尚未被NLP神经网络设计者采用。我们演示了如何用分组卷积替换自我关注层中的几个操作，我们在一个名为SqueezeBERT的新网络架构中使用了这一技术，该架构在Pixel 3上的运行速度比BERT-base快4.3倍，同时在GLUE测试集上实现了具有竞争力的准确性。</p><p id="e4c4" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir"> <em class="mj">论文可以在这里找到:</em> </strong></p><p id="976c" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">【https://arxiv.org/pdf/2006.11316v1.pdf T4】</p></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><h1 id="f94f" class="kv kw iq bd kx ky nq la lb lc nr le lf jw ns jx lh jz nt ka lj kc nu kd ll lm bi translated">FLAIR:一个易于使用的最新自然语言处理框架</h1><p id="41ba" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><em class="mj">艾伦·阿克比克、塔尼亚·博格曼、邓肯·布莱斯、卡希夫·拉苏尔、斯特凡·施韦特、罗尔·沃尔格拉夫</em></p><h1 id="8dee" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">抽象—</h1><p id="a52a" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们提出了FLAIR，这是一个NLP框架，旨在促进最先进的序列标记、文本分类和语言模型的培训和分发。该框架的核心思想是为概念上非常不同的word和document嵌入类型提供一个简单、统一的接口。这有效地隐藏了所有嵌入特定的工程复杂性，并允许研究人员毫不费力地混合和匹配各种嵌入。该框架还实现了标准模型训练和超参数选择例程，以及可以下载公开可用的NLP数据集并将其转换为数据结构以快速设置实验的数据获取模块。最后，FLAIR还附带了一个预训练模型的{ ` }模型动物园{''}，允许研究人员在他们的应用程序中使用最先进的NLP模型。本文概述了该框架及其功能。</p><p id="6a01" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir"> <em class="mj">论文可以在这里找到:</em> </strong></p><p id="c120" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><a class="ae mp" href="https://www.aclweb.org/anthology/N19-4010" rel="noopener ugc nofollow" target="_blank">https://www.aclweb.org/anthology/N19-4010</a></p><p id="82b9" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir"> <em class="mj">代码可以在这里找到:</em> </strong></p><div class="mq mr gp gr ms mt"><a href="https://github.com/zalandoresearch/flair" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">flairNLP/flair</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">最先进的自然语言处理的一个非常简单的框架。由柏林洪堡大学和朋友开发。重要的是…</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">github.com</p></div></div><div class="nc l"><div class="nv l ne nf ng nc nh kp mt"/></div></div></a></div></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><h1 id="6865" class="kv kw iq bd kx ky nq la lb lc nr le lf jw ns jx lh jz nt ka lj kc nu kd ll lm bi translated">PyText:从NLP研究到生产的无缝路径</h1><p id="ae1a" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><em class="mj">作者:Ahmed Aly、Kushal Lakhotia、赵世聪、Mrinal Mohit、Barlas Oguz、Abhinav Arora、Sonal Gupta、Christopher、Stef Nelson-Lindall、Rushin Shah </em></p><div class="mq mr gp gr ms mt"><a href="https://www.datadriveninvestor.com/2020/11/19/how-machine-learning-and-artificial-intelligence-changing-the-face-of-ecommerce/" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">机器学习和人工智能如何改变电子商务的面貌？|数据驱动…</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">电子商务开发公司，现在，整合先进的客户体验到一个新的水平…</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nc l"><div class="nw l ne nf ng nc nh kp mt"/></div></div></a></div><h1 id="7278" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">抽象—</h1><p id="5c1f" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们介绍py text——一个基于深度学习的NLP建模框架，建立在PyTorch之上。PyText解决了快速实验和大规模模型服务这两个经常发生冲突的需求。它通过为模型组件提供简单且可扩展的接口，并使用PyTorch的导出模型的功能，通过优化的Caffe2执行引擎进行推理，从而实现了这一点。我们报告了自己将实验和生产工作流迁移到PyText的经验，这使我们能够更快地迭代新的建模想法，然后无缝地将它们以工业规模发布。</p><p id="7967" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir"> <em class="mj">论文可以在这里找到:</em> </strong></p><p id="7933" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><a class="ae mp" href="https://arxiv.org/pdf/1812.08729v1.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1812.08729v1.pdf</a></p><p id="693a" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir"> <em class="mj">代码可以在这里找到:</em> </strong></p><div class="mq mr gp gr ms mt"><a href="https://github.com/facebookresearch/pytext" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">facebookresearch/pytext</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">PyText是一个基于深度学习的NLP建模框架，构建于PyTorch之上。PyText解决了经常发生冲突的…</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">github.com</p></div></div><div class="nc l"><div class="nx l ne nf ng nc nh kp mt"/></div></div></a></div></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><h1 id="d7bd" class="kv kw iq bd kx ky nq la lb lc nr le lf jw ns jx lh jz nt ka lj kc nu kd ll lm bi translated">使用OpenSeq2Seq为自然语言处理和语音识别进行混合精度训练</h1><p id="3b6b" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><em class="mj">作者:Oleksii Kuchaiev、Boris Ginsburg、Igor Gitman、Vitaly Lavrukhin、Jason Li、Huyen Nguyen、Carl Case、Paulius Micikevicius </em></p><h1 id="75f3" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">抽象—</h1><p id="0646" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们提出了openseq 2 seq——一个基于TensorFlow的工具包，用于训练序列到序列模型，其特点是分布式和混合精度训练。机器翻译和语音识别任务的基准测试表明，使用OpenSeq2Seq构建的模型提供了一流的性能，而训练时间减少了1.5-3倍。OpenSeq2Seq目前为解决包括神经机器翻译、自动语音识别和语音合成在内的广泛任务的模型提供构建块。</p><p id="ef58" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir"> <em class="mj">论文可以在这里找到:</em> </strong></p><p id="0508" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><a class="ae mp" href="https://arxiv.org/pdf/1805.10387v2.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1805.10387v2.pdf</a></p><p id="f97f" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir"> <em class="mj">代码可以在这里找到:</em> </strong></p><div class="mq mr gp gr ms mt"><a href="https://github.com/NVIDIA/OpenSeq2Seq" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">NVIDIA/OpenSeq2Seq</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">OpenSeq2Seq的主要目标是让研究人员最有效地探索各种序列间模型。的…</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">github.com</p></div></div><div class="nc l"><div class="ny l ne nf ng nc nh kp mt"/></div></div></a></div></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><p id="3b2a" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">参考文献和致谢—</p><div class="mq mr gp gr ms mt"><a href="https://arxiv.org/" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">arXiv.org</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">arXiv是一个免费的分发服务和开放存取的档案库，包含1，721，837篇学术文章，涉及领域包括…</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">arxiv.org</p></div></div></div></a></div><h2 id="b96f" class="nz kw iq bd kx oa ob dn lb oc od dp lf lw oe of lh ma og oh lj me oi oj ll ok bi translated">访问专家视图— <a class="ae mp" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>