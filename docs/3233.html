<html>
<head>
<title>Review On YOLOv3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLOv3综述</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/review-on-yolov3-faae0dd59425?source=collection_archive---------3-----------------------#2020-06-08">https://medium.datadriveninvestor.com/review-on-yolov3-faae0dd59425?source=collection_archive---------3-----------------------#2020-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="780b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们将浏览约瑟夫·雷德蒙和阿里·法尔哈迪的论文。在阅读这篇文章之前，我建议你先看一下我对<a class="ae kl" href="https://medium.com/datadriveninvestor/review-on-yolov1-3c85304b617d" rel="noopener"> <strong class="jp ir">【约洛夫1】</strong></a>和<a class="ae kl" href="https://medium.com/datadriveninvestor/review-on-yolov2-11e93c5ea3f1" rel="noopener"> <strong class="jp ir">约洛夫2 </strong> </a>的评论。</p><div class="km kn gp gr ko kp"><a href="https://www.datadriveninvestor.com/2019/01/23/deep-learning-explained-in-7-steps/" rel="noopener  ugc nofollow" target="_blank"><div class="kq ab fo"><div class="kr ab ks cl cj kt"><h2 class="bd ir gy z fp ku fr fs kv fu fw ip bi translated">深度学习用7个步骤解释-更新|数据驱动的投资者</h2><div class="kw l"><h3 class="bd b gy z fp ku fr fs kv fu fw dk translated">在深度学习的帮助下，自动驾驶汽车、Alexa、医学成像-小工具正在我们周围变得超级智能…</h3></div><div class="kx l"><p class="bd b dl z fp ku fr fs kv fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="ky l"><div class="kz l la lb lc ky ld le kp"/></div></div></a></div><p id="52ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">YOLOv3的发布对YOLOv2的改进很少。主要的两项改进是。</p><ul class=""><li id="1af3" class="lf lg iq jp b jq jr ju jv jy lh kc li kg lj kk lk ll lm ln bi translated"><strong class="jp ir">开始使用Darknet-53代替Darknet19作为主干</strong></li><li id="f353" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated"><strong class="jp ir">特征映射上采样和拼接</strong></li></ul><p id="9c00" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将文章分为5个部分:</p><ol class=""><li id="56db" class="lf lg iq jp b jq jr ju jv jy lh kc li kg lj kk lt ll lm ln bi translated"><strong class="jp ir">包围盒预测</strong></li><li id="d121" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lt ll lm ln bi translated"><strong class="jp ir">班级预测</strong></li><li id="71d2" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lt ll lm ln bi translated"><strong class="jp ir">跨尺度预测</strong></li><li id="c6e0" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lt ll lm ln bi translated"><strong class="jp ir">暗网-53 </strong></li><li id="4c35" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lt ll lm ln bi translated"><strong class="jp ir">性能</strong></li></ol><p id="0d25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们将进入更深的层次。首先我们将讨论包围盒预测</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="e5e0" class="mb mc iq bd md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">1.包围盒预测</h1><p id="b489" class="pw-post-body-paragraph jn jo iq jp b jq mz js jt ju na jw jx jy nb ka kb kc nc ke kf kg nd ki kj kk ij bi translated">这个和YOLOv2差不多。如果网络预测4个坐标<strong class="jp ir"> tx，ty，tw </strong>和<strong class="jp ir"> th </strong>，并且从图像左上角的单元偏移是<strong class="jp ir"> (cx，cy) </strong>，并且如果锚框宽度和高度是<strong class="jp ir"> pw，ph. </strong>，则预测对应于</p><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/4df20b4202a4daa6781b499cdbe011bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*C6WfCkyL72ypiqi3M6I5xg.png"/></div></figure><ul class=""><li id="11fe" class="lf lg iq jp b jq jr ju jv jy lh kc li kg lj kk lk ll lm ln bi translated">在训练中，他们使用了误差损失平方和</li><li id="6334" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">YOLOv3使用逻辑回归预测每个边界框的客观性分数。如果锚定框与地面真实框的重叠比任何其他锚定框都多，则为1。如果锚定框与地面真实框重叠，但不是最好的，那些锚定框将被忽略。他们设定的最低门槛是0.5。因此，只有一个锚定框将被分配给边界框。</li><li id="cd6b" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated"><strong class="jp ir"> k表示聚类被</strong>用来寻找锚盒</li></ul><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/f221dc07bcc83cee1003fc328a3b0632.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*K5_cJ0wy_7uOxXvrm-4rQw.png"/></div></figure></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="d69a" class="mb mc iq bd md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated"><strong class="ak"> 2。班级预测</strong></h1><ul class=""><li id="5596" class="lf lg iq jp b jq mz ju na jy nm kc nn kg no kk lk ll lm ln bi translated">对于类别预测，他们没有使用<strong class="jp ir"> softmax </strong>分类器。相反，他们使用独立的<strong class="jp ir">逻辑分类器</strong>和<strong class="jp ir">二元交叉熵损失</strong>。</li></ul></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="b197" class="mb mc iq bd md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated"><strong class="ak"> 3。跨不同尺度的预测</strong></h1><ul class=""><li id="19ce" class="lf lg iq jp b jq mz ju na jy nm kc nn kg no kk lk ll lm ln bi translated">他们从<strong class="jp ir"> 3种不同的尺度</strong>中提取预测，并将它们串联起来。为此，他们使用了<strong class="jp ir">特征金字塔网络的概念。</strong></li><li id="fc65" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">在他们对COCO的实验中，他们预测每种规模有3个盒子。因此，对于4个边界框偏移、1个对象预测和80个类别预测，张量是<strong class="jp ir">n×n×[3∫(4+1+80)】</strong>。</li><li id="5c29" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">我们从之前2层中提取特征，对其进行采样，并将其与之前某层中特征图关联起来。我们添加更多的卷积层来处理这个组合的特征图，并且获得类似的输出张量。</li><li id="1432" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">我们再次执行相同的设计来预测最终规模的盒子。因此，我们有三种不同规模的预测。</li><li id="a6bc" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">在COCO数据集上，通过k均值聚类，他们使用了这些锚盒:在COCO数据集上，9个聚类是:<strong class="jp ir"> (10×13)、(16×30)、(33×23)、(30×61)、(62×45)、(59×119)、(116×90)、(156×198)、(373×326)。</strong></li></ul></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="5b45" class="mb mc iq bd md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">4.黑暗网络53</h1><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div class="gh gi np"><img src="../Images/4c6e277a48d221d3ca76d94b6d2b3cc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*2CqozInzcKoIg6IO830y3w.png"/></div><figcaption class="nq nr gj gh gi ns nt bd b be z dk">Darknet-53</figcaption></figure><ul class=""><li id="ae84" class="lf lg iq jp b jq jr ju jv jy lh kc li kg lj kk lk ll lm ln bi translated">在YOLOv3中，<strong class="jp ir">他们使用了更深的网络Darknet-53 </strong>被使用，即53个卷积层。它也有快捷连接</li></ul><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/006d37cf0b4d1239423e61d21f69fead.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*xieaax1PoCQ69cDYHm-4sA.png"/></div><figcaption class="nq nr gj gh gi ns nt bd b be z dk">performace comparison</figcaption></figure><ul class=""><li id="c012" class="lf lg iq jp b jq jr ju jv jy lh kc li kg lj kk lk ll lm ln bi translated">Darknet-53比ResNet-101好，快1.5倍。Darknet-53的性能与ResNet-152相似，但速度快2倍。</li></ul></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="c563" class="mb mc iq bd md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">5.表演</h1><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nw nx di ny bf nz"><div class="gh gi nv"><img src="../Images/1778e72a4547950daa961001abbb9031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1YEMMI5hXMv1W74DszPaJQ.png"/></div></div></figure><ul class=""><li id="1852" class="lf lg iq jp b jq jr ju jv jy lh kc li kg lj kk lk ll lm ln bi translated">对于整体地图，yolo3表现稍差。</li><li id="f577" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">yolov 3–608在51毫秒的推理时间内获得了大约33.0%的mAP，而retina net-101–50–500在73毫秒的推理时间内仅获得了32.5%的mAP。</li></ul><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/fee6f80ebf36e26c2a5d447f504b81f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*dJ2a-CA0P-sj_cYlraKBVg.png"/></div></figure></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="5416" class="mb mc iq bd md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated"><strong class="ak">参考</strong></h1><ul class=""><li id="7bff" class="lf lg iq jp b jq mz ju na jy nm kc nn kg no kk lk ll lm ln bi translated"><a class="ae kl" href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" rel="noopener ugc nofollow" target="_blank">https://pjreddie.com/media/files/papers/YOLOv3.pdf</a></li></ul><figure class="nf ng nh ni gt nj"><div class="bz fp l di"><div class="ob oc l"/></div></figure></div></div>    
</body>
</html>