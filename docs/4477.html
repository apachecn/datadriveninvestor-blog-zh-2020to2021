<html>
<head>
<title>The Why and How of MapReduce</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么和如何使用MapReduce</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/the-why-and-how-of-mapreduce-17c3d99fa900?source=collection_archive---------0-----------------------#2020-08-10">https://medium.datadriveninvestor.com/the-why-and-how-of-mapreduce-17c3d99fa900?source=collection_archive---------0-----------------------#2020-08-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="25c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我什么时候需要使用MapReduce？我如何将我的工作转换成贴图、合并器和缩减器？</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/f6a0f5f21fa4eb5be89cfc871ff361f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3jvA_hvgkytcwH5kPxW19A.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@brookelark?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Brooke Lark</a> on <a class="ae le" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2145" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> MapReduce </strong>是一种操作大型数据集的编程技术，而<strong class="js iu"> Hadoop MapReduce </strong>是这种编程技术的具体实现。</p><p id="e1b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下是该过程的总体情况:</p><pre class="kp kq kr ks gt lf lg lh li aw lj bi"><span id="a4d1" class="lk ll it lg b gy lm ln l lo lp">Map(s) (for individual chunk of input) -&gt;<br/>     - sorting individual map outputs -&gt; <br/>Combiner(s) (for each individual map output) -&gt;<br/>     - shuffle and partition for distribution to reducers -&gt;<br/>     - sorting individual reducer input -&gt;<br/>Reducer(s) (for sorted data of group of partitions)</span></pre></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="f985" class="lx ll it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">Hadoop的MapReduce总体来说</h1><p id="2ff2" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated"><a class="ae le" href="https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" rel="noopener ugc nofollow" target="_blank"> Hadoop MapReduce </a>是一个用于编写应用程序的框架，这些应用程序可以在大型商用硬件集群(数千个节点)上以可靠、容错的方式并行处理大量数据(多TB)。</p><p id="7e22" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">典型的MapReduce作业:</p><ul class=""><li id="6002" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated">将输入数据集分割成独立的数据集</li><li id="f6b4" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated">每个单独的数据集由<strong class="js iu">映射任务</strong>并行处理<strong class="js iu"/></li><li id="5f8a" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated">然后框架<strong class="js iu">对地图的输出进行分类</strong>，</li><li id="69ef" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated">该输出然后被用作<strong class="js iu">减少任务</strong>的输入</li></ul><p id="becc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通常，作业的输入和输出都存储在文件系统中。</p><p id="cdbb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Hadoop MapReduce框架负责调度任务、监控任务以及重新执行失败的任务。</p><div class="nn no gp gr np nq"><a href="https://www.datadriveninvestor.com/2020/05/15/big-data-analytics-in-telemedicine-reshaping-the-healthcare-industry/" rel="noopener  ugc nofollow" target="_blank"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd iu gy z fp nv fr fs nw fu fw is bi translated">远程医疗中的大数据分析重塑医疗保健行业|数据驱动的投资者</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">最近，在冠状病毒疫情的推动下，远程医疗的使用出现了大爆炸。越来越…</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nz l"><div class="oa l ob oc od nz oe ky nq"/></div></div></a></div><p id="147f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通常，Hadoop的MapReduce框架和Hadoop分布式文件系统(HDFS)运行在相同的节点上，这意味着<strong class="js iu">每个节点都用于计算和存储</strong>。这种配置的<strong class="js iu">优势</strong>是可以在数据所在的节点上调度任务，从而在整个集群中实现高聚合带宽。</p><p id="ab94" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">MapReduce框架包括:</p><ul class=""><li id="0828" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated">单主<code class="fe of og oh lg b">ResourceManager</code> (Hadoop YARN)，</li><li id="1862" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated">每个集群节点一个工人<code class="fe of og oh lg b">NodeManager</code>,以及</li><li id="9c4d" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated"><code class="fe of og oh lg b">MRAppMaster</code>每次申请</li></ul><p id="3312" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">资源管理器跟踪计算资源，将它们分配给特定的任务，并跨集群调度作业。</p><p id="ccd8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了<strong class="js iu">配置MapReduce作业</strong>，应用程序至少要指定:</p><ul class=""><li id="6a72" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated">输入源和输出目的地</li><li id="e902" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated">映射和减少功能</li></ul><p id="9925" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，Hadoop的作业客户端将<strong class="js iu">作业及其配置提交</strong>给YARN，YARN负责在集群中分发作业、调度任务、监控任务，并将任务状态反馈给作业客户端。</p><p id="d7c6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">虽然Hadoop框架是用Java实现的，但是MapReduce应用不需要用Java编写。我们可以使用<code class="fe of og oh lg b"><a class="ae le" href="https://github.com/Yelp/mrjob" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">mrjobs</strong></a></code> Python包来编写可以在Hadoop或AWS上运行的MapReduce作业。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="8d81" class="lx ll it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">MapReduce作业的输入和输出</h1><p id="c6f3" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated">对于输入和输出，<strong class="js iu">数据存储在键值对</strong>中。每个键和值类必须可以被MapReduce框架序列化，因此应该实现<code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/io/Writable.html" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">Writable</strong></a></code>接口。除此之外，key类还需要实现排序机制所需的接口<code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/io/WritableComparable.html" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">WritableComparable</strong></a></code>。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="3bfd" class="lx ll it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">制图者</h1><p id="96bf" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated"><code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/Mapper.html" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">Mapper</strong></a></code>是一个将键/值对输入到一组输出键/值对的任务(这些键/值对随后被进一步的步骤使用)。输出记录不需要与输入记录的类型相同，输入对也可以映射到零个或多个输出对。</p><p id="7065" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">与给定输出键相关联的所有值随后由框架进行分组，并传递给<code class="fe of og oh lg b">Reducer</code>以确定最终输出。根据<code class="fe of og oh lg b">Reducer</code>对<code class="fe of og oh lg b">Mapper</code>输出进行分类，然后进行分割。分区总数与作业的reduce任务数相同。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="4f44" class="lx ll it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">洗牌和排序阶段</h1><p id="fb08" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated">单个映射器的输出由框架排序。</p><p id="5768" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在将数据提供给reducers之前，来自所有映射器的数据都通过一些键分组进行了分区。每个<strong class="js iu">分区</strong>包含来自一个或多个键的数据。每个分区的数据按键排序。然后将分区分配给reducers。每个reducer的输入数据都是来自一个或多个分区的数据(一般是<code class="fe of og oh lg b">1:1</code>比)。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="bf4f" class="lx ll it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">该减速器</h1><p id="6511" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated"><code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/Reducer.html" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">Reducer</strong></a></code>将共享一个关键字的一组中间值(混洗和分类阶段的输出)减少为一个更小的值组。</p><p id="3687" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在reducer阶段，为分组输入中的每个<code class="fe of og oh lg b">&lt;key, (list of values)&gt;</code>对调用reduce方法。注意<code class="fe of og oh lg b">Reducer</code>的输出没有排序。</p><p id="8797" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正确的减速器数量一般在<code class="fe of og oh lg b">0.95</code>和<code class="fe of og oh lg b">1.75</code>乘以<code class="fe of og oh lg b">&lt;no. of nodes&gt; * &lt;no. of maximum containers per node&gt;</code>之间。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="d95b" class="lx ll it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">组合器</h1><p id="3ac8" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated">我们可以选择指定一个<code class="fe of og oh lg b">Combiner</code>(称为本地缩减器)来执行中间输出的本地聚合，这有助于减少从<code class="fe of og oh lg b">Mapper</code>传输到<code class="fe of og oh lg b">Reducer</code>的数据量。在许多情况下，相同的reducer代码也可以用作合并器。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="17e8" class="lx ll it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">让我们看一个简单的例子</h1><p id="3820" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated">我们来看一个简单的统计词频的例子。考虑下面的<code class="fe of og oh lg b">mapper.py</code>文件:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/538b086c67023e36d03c04783ff2755b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tvi_4R_hXEnBt-TfusUe8g.png"/></div></div></figure><p id="26f3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以及下面的<code class="fe of og oh lg b">reducer.py</code>文件:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oj"><img src="../Images/c41ad90c684fcd287c55360d5118aa47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MeSAdw3Nbkkv-yrb1S8O0Q.png"/></div></div></figure><p id="08e7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以在本地测试它们:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/24e09449dce6774c4249353ad876107f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BNPBjTi3IcGv-oXgueioKg.png"/></div></div></figure></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="4796" class="lx ll it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">但是等等！以前的实现有一个问题…</h1><p id="7321" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated">之前的映射器代码是<strong class="js iu">内存密集型的</strong>，因为它必须维护一个字典，该字典包含每个映射器的输入块中所有唯一单词的频率。如果内存是一个问题，甚至对于涉及单个输入块的<code class="fe of og oh lg b">dict</code>，那么更好的方法是让它只打印我们遇到的每个单词(其频率为<code class="fe of og oh lg b">1</code>)。举个例子，</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/e5afdff05ab1b83868e5ac8a06df1076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GyyHSaDxA_LfrtNq_WWwfw.png"/></div></div></figure><p id="a3d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们使用具有相同输入数据的新映射器:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi om"><img src="../Images/8e4b0fe358dad905b7f2ab9f1ee36cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pxOYll9NsdkAc8caX0nNtw.png"/></div></div></figure><p id="107d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果有帮助的话，我们还可以使用一个合并器(与reducer代码相同)对每个映射器输出进行本地聚合。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi on"><img src="../Images/36f18d47f727fc0a1784f357fed2c747.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MFGjtP2EVmFzgVJI2EI1RQ.png"/></div></div></figure></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="0240" class="lx ll it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">关于<code class="fe of og oh lg b">Partitioner</code>和<code class="fe of og oh lg b">Comparator</code>的详细信息</h1><p id="32d3" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated">一个<code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/Partitioner.html" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">Partitioner</strong></a></code>对数据进行分区，这实际上是通过对“密钥空间”进行分区来实现的。</p><p id="1dde" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Partitioner控制中间映射输出的键的分区。密钥(或密钥的子集)通常通过<strong class="js iu">散列函数</strong>用于导出分区。分区总数与作业的reduce任务数相同。因此，这控制了将中间键(以及记录)发送到哪个<code class="fe of og oh lg b">m</code>归约任务进行归约。</p><p id="211d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/lib/partition/HashPartitioner.html" rel="noopener ugc nofollow" target="_blank">HashPartitioner</a></code>是默认的<code class="fe of og oh lg b">Partitioner</code>。如果您需要通过多个键对数据进行分区，您将需要使用不同的分区器(或者您的自定义分区器)。</p><p id="d118" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Hadoop有一个库类，<code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/lib/KeyFieldBasedPartitioner.html" rel="noopener ugc nofollow" target="_blank">KeyFieldBasedPartitioner</a></code>,它允许MapReduce框架基于某些关键字段而不是全部关键字段来划分地图输出。比如<code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/hadoop-streaming/HadoopStreaming.html#Hadoop_Partitioner_Class" rel="noopener ugc nofollow" target="_blank">-D mapreduce.partition.keypartitioner.options=-k1,2</a></code>。</p><p id="dbb3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以通过指定一个<code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/Job.html#setGroupingComparatorClass-java.lang.Class" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">Comparator</strong></a></code>来控制分组。</p><p id="850a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Hadoop有一个库类<code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.html" rel="noopener ugc nofollow" target="_blank">KeyFieldBasedComparator</a></code>，它提供了Unix/GNU <code class="fe of og oh lg b">sort</code>函数所提供的特性子集。比如<code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/hadoop-streaming/HadoopStreaming.html#Hadoop_Comparator_Class" rel="noopener ugc nofollow" target="_blank">-D mapreduce.partition.keycomparator.options=-k2,2nr</a></code>。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="99c1" class="lx ll it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">分布式缓存</h1><p id="abd2" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated">MapReduce框架提供的<code class="fe of og oh lg b"><a class="ae le" href="https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#DistributedCache" rel="noopener ugc nofollow" target="_blank">DistributedCache</a></code>，高效地分发大型只读文件作为应用程序所需的缓存。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="b095" class="lx ll it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">配置参数</h1><p id="7c10" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated">我们可以通过环境变量获得作业配置选项。当我们启动MapReduce应用程序时，框架会将数据分配给可用的工作人员。我们可以从脚本中访问这些数据。例如，如果我们正在运行一个映射器，那么我们可以访问关于我们正在处理的文件和幻灯片的信息。此外，我们可以获得关于我们是在运行映射器还是缩减器的信息，如果我们在映射和缩减阶段运行相同的脚本，这可能很重要。我们还可以使用以下环境变量在map或reduce阶段中访问任务id:<code class="fe of og oh lg b">mapreduce_task_id</code>、<code class="fe of og oh lg b">mapreduce_task_partition</code>。</p><p id="ac2a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae le" href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Configured_Parameters" rel="noopener ugc nofollow" target="_blank">配置的参数</a>在每个任务执行的作业配置中被本地化。在流作业的执行过程中，会转换“映射”参数的名称。圆点(<code class="fe of og oh lg b">.</code>)变成了下划线(<code class="fe of og oh lg b">_</code>)。比如<code class="fe of og oh lg b">mapreduce.job.id</code>变成了<code class="fe of og oh lg b">mapreduce_job_id</code>。在您的代码中，使用带下划线的参数名。</p><p id="69b5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">更新流媒体应用的状态:</strong></p><p id="b803" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一个<a class="ae le" href="https://hadoop.apache.org/docs/current/hadoop-streaming/HadoopStreaming.html" rel="noopener ugc nofollow" target="_blank">流进程</a>可以使用<code class="fe of og oh lg b">stderr</code>来发出状态信息。要设置状态，应将<code class="fe of og oh lg b">reporter:status:&lt;message&gt;</code>发送至<code class="fe of og oh lg b">stderr</code>。</p><h1 id="f199" class="lx ll it bd ly lz oo mb mc md op mf mg mh oq mj mk ml or mn mo mp os mr ms mt bi translated">捆绑的映射器、缩减器和分区</h1><p id="79e9" class="pw-post-body-paragraph jq jr it js b jt mu jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj my kl km kn im bi translated">Hadoop MapReduce附带了一个<a class="ae le" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/package-summary.html" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">库</strong> </a>，其中包含了常用的映射器、缩减器和分割器。</p><p id="275b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里有一些相关的有趣故事，你可能会觉得有帮助</p><ul class=""><li id="e630" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated"><a class="ae le" href="https://medium.com/@goyalmunish/distributed-data-processing-with-apache-spark-2a5e473b0cb1" rel="noopener">用Apache Spark进行分布式数据处理</a></li><li id="02e0" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated"><a class="ae le" href="https://medium.com/@goyalmunish/apache-cassandra-distributed-row-partitioned-database-for-structured-and-semi-structured-data-1dc37e72e67c" rel="noopener"> Apache Cassandra —用于结构化和半结构化数据的分布式行分区数据库</a></li></ul><p id="2ff1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">进入专家视角— </strong> <a class="ae le" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>