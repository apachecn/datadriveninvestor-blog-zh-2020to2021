<html>
<head>
<title>Handling Imbalanced Data with Basic Classifier Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用基本分类器模型处理不平衡数据</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/handling-imbalanced-data-with-basic-classifier-models-5ce3d61874f1?source=collection_archive---------1-----------------------#2020-03-25">https://medium.datadriveninvestor.com/handling-imbalanced-data-with-basic-classifier-models-5ce3d61874f1?source=collection_archive---------1-----------------------#2020-03-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2cd3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">阐述您的问题如何帮助您克服不平衡数据带来的挑战。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f1e76ac27fcbce04928e00d0b041c9c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v2EXS2aR1FS7nrQ_O7D-fQ.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@fifernando?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Fidel Fernando</a> on <a class="ae ky" href="https://unsplash.com/s/photos/scale?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="254a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">术语<em class="lv">“不平衡数据”</em>通常适用于目标变量的不同值在数据中没有被同等表示的情况。从技术上讲，大多数数据在某种程度上是不平衡的，这没什么，但目标变量组中的显著差异会使分类器模型不可靠。一个经典的例子是信用卡欺诈，其中大多数观察是合法的交易，但它是我们想要准确预测的一小部分欺诈。</p><p id="7e02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇博文中，我们将模拟一些不平衡的数据，手动检查最佳分类，然后使用逻辑回归和决策树模型分析我们可以在多大程度上接近最佳阈值。为了实现这一目标，我们将看看一些流行的选择，如过采样方法和超参数优化。</p><div class="lw lx gp gr ly lz"><a href="https://www.datadriveninvestor.com/2019/02/07/8-skills-you-need-to-become-a-data-scientist/" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd iu gy z fp me fr fs mf fu fw is bi translated">成为数据科学家所需的8项技能|数据驱动型投资者</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">数字吓不倒你？没有什么比一张漂亮的excel表更令人满意的了？你会说几种语言…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn ks lz"/></div></div></a></div><p id="0a56" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个项目的底层Python代码可以在我的<a class="ae ky" href="https://github.com/MatePocs/imbalanced_classifier" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到，如果你对编码细节感兴趣，请查看。</p><p id="1e49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有几个概念我们会用到，但不会详细解释:逻辑回归、决策树、GridSearchCV、K-Fold验证。如果你已经熟悉了这些概念，这肯定会有所帮助。这篇文章的重点是不平衡数据带来的挑战，以及我们如何应对它们。</p><h2 id="3904" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">到底是什么问题？</h2><p id="d202" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">在我们进一步探索之前，我认为澄清我们对不平衡数据的悲伤是很重要的。我相当经常看到对不平衡数据问题的介绍是这样开始的:<em class="lv">“如果你的目标变量只有1%是'是'，而其余99%的值都是'否'，那么如果你使用一个模型，天真地把一切都归类为'否'，那它就有99%的准确率。”</em>这当然是真的，但这本身不是问题。我认为在这一点上，我们有点混淆了两个不同的问题:</p><ul class=""><li id="a909" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated">准确度本身不是分类器整体性能的准确(没有双关语的意思)度量；</li><li id="78fb" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">基于某种度量，问题的基线模型可能已经非常有效了。</li></ul><p id="dce7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了恰当地提出我们的问题，我将考虑两个不同的潜在问题:</p><ul class=""><li id="79c6" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated">我们确实只对准确性感兴趣，但是不相等的大小使得我们的分类器难以优化；</li><li id="7a81" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">我们希望对具有较低代表性的组赋予较高的相对重要性，例如，即使只有1%的数据属于“是”类别，我们仍然希望准确预测其中的50%，代价是整体准确性。</li></ul><p id="ba28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这两种不同的预期结果需要不同的策略来有效解决，在开始使用任何方法之前，确定我们想要解决哪一个是很重要的。</p><h2 id="6d9f" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">几个重要术语</h2><p id="eefb" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">下面的描述是针对一个二元分类器问题(意味着你的目标变量有两个值)，这是我们将要分析的问题类型。</p><ul class=""><li id="984f" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated"><em class="lv">混淆矩阵</em>:一个2x2矩阵，包含模型做出的真阳性、真阴性、假阳性和假阴性预测的数量。4个元素的总和就是观察值的总数。排列不标准，在scikit-learn中，左上为真阴性，右下为真阳性，左下为假阴性，右上为假阳性。我们将使用scikit-learn方法。</li><li id="8a90" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><em class="lv">真正(TP) /真负(TN) </em>:实际值为正/负，模型正确预测为正/负的观测值。</li><li id="c535" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><em class="lv">假阳性(FP) /假阴性(FN) </em>:实际值为负/正，但模型错误预测为正/负的观察值。</li><li id="4c9f" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><em class="lv">准确性得分</em>:我们以前使用过这个术语，这是因为分类器模型度量定义正是您所期望的:正确预测值的比率。公式:<br/>(<em class="lv">TP</em>+<em class="lv">TN</em>)/(<em class="lv">TP</em>+<em class="lv">TN</em>+<em class="lv">FP</em>+<em class="lv">FN</em>)</li><li id="3d40" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><em class="lv">平衡准确度得分</em>:阴性和阳性观察值的正确预测比率的平均值。这个度量标准不利于在正确预测两个可能的目标值中的一个上投入太多的相对努力。公式:<br/>[<em class="lv">TP</em>/(<em class="lv">TP</em>+<em class="lv">FN</em>)+<em class="lv">TN</em>/(<em class="lv">TN</em>+<em class="lv">FP</em>)]/2</li></ul><p id="d843" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以从混淆矩阵的元素中推断出许多其他的分类器分数，更多信息请参见维基百科<a class="ae ky" href="https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers" rel="noopener ugc nofollow" target="_blank">页面。</a></p><p id="e07c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当解决上述两个不同的问题时，我们将最大化第一个问题的<code class="fe oa ob oc od b">accuracy_score</code>,第二个问题的<code class="fe oa ob oc od b">balanced_accuracy_score</code>。</p><h2 id="2880" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">数据</h2><p id="d90e" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">我们将使用两个模拟数据集。两者都由1000个“否”和100个“是”目标变量组成，称为<code class="fe oa ob oc od b">y</code>，以及一个连续的特征，我们将简称为<code class="fe oa ob oc od b">X</code>。</p><p id="5fd8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<code class="fe oa ob oc od b">Data_1</code>中，<code class="fe oa ob oc od b">X_no</code>值(属于<code class="fe oa ob oc od b">no</code>观察值的1000个<code class="fe oa ob oc od b">X</code>值)是从N(5，1)分布(期望值为5，方差为1的正态分布)中随机生成的，而<code class="fe oa ob oc od b">X_yes</code>值来自N(7，1)分布。</p><div class="kj kk kl km gt ab cb"><figure class="oe kn of og oh oi oj paragraph-image"><img src="../Images/9343758b15bbcf9395ee01bce83998c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*Mg5nHMCs-633sxQtXcYR3w.png"/></figure><figure class="oe kn of og oh oi oj paragraph-image"><img src="../Images/b6a2adc09cb55d73f10bca657cec08cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*NWF4cr2ZV3M11ENuFEt39Q.png"/></figure></div><p id="ee92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如图表所示，在<code class="fe oa ob oc od b">Data_1</code>中，<code class="fe oa ob oc od b">yes</code>观测值位于右侧，大多与<code class="fe oa ob oc od b">no</code>观测值重叠。通过查看图表，我们可以说，在7.5以上的一切都应归类为<code class="fe oa ob oc od b">yes</code>，而在<code class="fe oa ob oc od b">no</code>以下的一切到<code class="fe oa ob oc od b">accuracy_score</code>时都可能接近最佳值。</p><p id="2f1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<code class="fe oa ob oc od b">Data_2</code>中，我们从相同的<code class="fe oa ob oc od b">X_no</code>值开始，但是通过选择N(5，1/2)作为<code class="fe oa ob oc od b">X_yes</code>的分布，将<code class="fe oa ob oc od b">yes</code>观察值推到更大组的中间。然后，我们通过计算<code class="fe oa ob oc od b">X</code>值与5的绝对差值来转换对称数据，因此我们最终得到如下分布:</p><div class="kj kk kl km gt ab cb"><figure class="oe kn of og oh oi oj paragraph-image"><img src="../Images/53e6431bef32afeac7342b4b892668be.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*5alxSk4RFc1cZFl5SCDV2w.png"/></figure><figure class="oe kn of og oh oi oj paragraph-image"><img src="../Images/ec860d9a1558816c11b1c07d03f0b3af.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*qaJVivV0VGhlZ80RHlal4Q.png"/></figure></div><p id="22e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于<code class="fe oa ob oc od b">Data_2</code>，挑战将是正确预测任何<code class="fe oa ob oc od b">yes</code>值，因为目标变量为<code class="fe oa ob oc od b">no</code>的概率在我们仅有的特征<code class="fe oa ob oc od b">X</code>的任何给定范围内都较高。</p><h2 id="64c9" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">关于测试的一句话</h2><p id="3e51" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">请注意，我们不会使用验证数据，我们的目标是观察我们如何根据训练数据拟合分类器。在真实的场景中，您最终将在验证集上度量模型的性能。对于这个模拟思维实验，我认为没有必要，我们更感兴趣的是模型如何工作，以及如何处理不平衡的数据集。我们将在以后的模型选择中使用交叉验证，但不会进行独立测试。</p><h2 id="c830" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">手动计算</h2><p id="f223" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">在本节中，我们将手动计算最佳的<code class="fe oa ob oc od b">X</code>来分割数据，具体取决于我们是否希望最大化精度和平衡精度。我们称这些模型为最优模型，我们的理解是，如果我们想根据一个<code class="fe oa ob oc od b">X</code>值将数据分成两组，它们就是最优模型。有人可能会说，鉴于数据结构的简单性，一个更复杂的分类器可能会过度拟合。</p><p id="5c67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以我们只看具有一个规则的分类器，观察值将被分类，不管它们是在所选<code class="fe oa ob oc od b">X</code>的左边还是右边。这样做很简单，我们需要遍历1100个可能的<code class="fe oa ob oc od b">X</code>值，计算每次拆分的TP、TN、FP、FN值的数量，然后我们可以计算<code class="fe oa ob oc od b">accuracy_score</code>和<code class="fe oa ob oc od b">balanced_accuracy_score</code>。一旦我们有了列表，我们只需选择使分数最大化的阈值。</p><p id="e5d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于<code class="fe oa ob oc od b">Data_1</code>，这是两个分数作为<code class="fe oa ob oc od b">X</code>的函数的样子，最大值用虚线突出显示:</p><div class="kj kk kl km gt ab cb"><figure class="oe kn of og oh oi oj paragraph-image"><img src="../Images/6138dcbecf0d542e6ac6464d7c287c10.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*xz0Cd9F-TOLInoqgNJHsqA.png"/></figure><figure class="oe kn of og oh oi oj paragraph-image"><img src="../Images/4c50523e01e6db9da0612e640b64b6d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*A3t5OdrpLW-DcH1DOQ0g2Q.png"/></figure></div><p id="d9c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过选择7.30作为我们的阈值可以获得最大的准确性，因此最佳分类器将这样工作:如果X ≤ 7.30，预测<code class="fe oa ob oc od b">no</code>，否则，预测<code class="fe oa ob oc od b">yes</code>。这导致0.935 <code class="fe oa ob oc od b">accuracy_score</code>。另一方面，如果我们想要最大化平衡精度，我们应该选择5.87作为阈值，这将导致0.843 <code class="fe oa ob oc od b">balanced_accuracy_score</code>。</p><p id="208f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以在直方图和分布上绘制最佳精度和平衡精度阈值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/3bb4cd5631d750653f512d33192480ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nCtUH7q58gxPLoW9DtRrZQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/8da01f5d401759929a2285249711b83d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*obTcuERpvmyhZtwmemdLlA.png"/></div></div></figure><p id="f16e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们对<code class="fe oa ob oc od b">Data_2</code>重复同样的分析。作为阈值函数的<code class="fe oa ob oc od b">accuracy_score</code>和<code class="fe oa ob oc od b">balanced_accuracy_score</code>:</p><div class="kj kk kl km gt ab cb"><figure class="oe kn of og oh oi oj paragraph-image"><img src="../Images/c106c1863b00b309c5d5036571041f00.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*utL6U1vFlFvaL0rrJPs-3A.png"/></figure><figure class="oe kn of og oh oi oj paragraph-image"><img src="../Images/978eca83abfc2702558f0a2d30ab1c53.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*w-i7PZ7lwGJ0SnsdNFHwLA.png"/></figure></div><p id="f300" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过选择0作为阈值来获得最高的精度。这实质上意味着一切都被归类为否，这是我们能得到的最好的<code class="fe oa ob oc od b">accuracy_score</code>，0.908。在这个分类器的混淆矩阵中，我们将有1000个TP值(所有的<code class="fe oa ob oc od b">yes</code>观察值)和100个FP值(所有的<code class="fe oa ob oc od b">no</code>观察值)。我们通过选择0.64作为阈值来优化平衡精度，从而得到0.681 <code class="fe oa ob oc od b">balanced_accuracy_score</code>。请注意，阈值选择的工作方式不同，对于Data_2，我们将预测某个阈值下的观测值是<code class="fe oa ob oc od b">yes</code>。这是因为对于较低的<code class="fe oa ob oc od b">X</code>值，<code class="fe oa ob oc od b">yes</code>总体的相对概率较高。</p><p id="add6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以在直方图和分布上绘制最佳精度和平衡精度阈值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/541053869f04e0a413fe8c3348649efa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PC7pwaDpcQ0xSqkVNp01OA.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/5ca69db1e8d72a7b5bf8b5d9925b4116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VjKp_1BfnXfSeFPfTbRhoA.png"/></div></div></figure><p id="653f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所见，在<code class="fe oa ob oc od b">Data_2</code>中，不可能将<code class="fe oa ob oc od b">accuracy_score</code>提高到琐碎分类之外，琐碎分类预测一切都在<code class="fe oa ob oc od b">no</code>类别中，而不管<code class="fe oa ob oc od b">X</code>特性的值。</p><p id="ce50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们有了最佳选择，在下面的部分中，我们将看看是否可以使用逻辑回归或决策树分类器来接近它们。</p><h2 id="91ca" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">逻辑回归</h2><p id="3575" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">我们终于开始构建一个实际的分类器模型了！</p><p id="f29b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">拟合scikit-learn的基本<code class="fe oa ob oc od b">LogisticRegression</code>模型非常简单:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="34f9" class="mo mp it od b gy op oq l or os">from sklearn.linear_model import LogisticRegression</span><span id="2ca0" class="mo mp it od b gy ot oq l or os">logreg = LogisticRegression()<br/>logreg.fit(X, y)</span></pre><p id="a412" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<code class="fe oa ob oc od b">X</code>是你的特征(在我们的例子中是一维连续变量)，<code class="fe oa ob oc od b">y</code>是你的目标变量。这之后你就有了一个<code class="fe oa ob oc od b">logreg</code>对象，有一堆机会。您可以使用<code class="fe oa ob oc od b">coef_</code>和<code class="fe oa ob oc od b">intercept_</code>属性来获取模型的参数。您可以使用<code class="fe oa ob oc od b">predict</code>方法创建一个预测变量数组，如下所示:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="0ba2" class="mo mp it od b gy op oq l or os">y_prediction = logreg.predict(X)</span></pre><p id="93dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，这些都是非常基本的，如果你正在阅读如何处理不平衡的数据，你可能已经知道了。在本节中，我们将使用另外两个概念:</p><ul class=""><li id="6967" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated"><code class="fe oa ob oc od b">predict_proba</code>是一个返回两列二维数组的方法，第一列包含估计的观察概率<code class="fe oa ob oc od b">no</code>，第二列包含观察概率<code class="fe oa ob oc od b">yes</code>(因此每行两个数之和等于1)。</li><li id="b4e1" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><code class="fe oa ob oc od b">class_weight</code>是<code class="fe oa ob oc od b">LogisticRegression</code>对象的可选参数，默认值为<code class="fe oa ob oc od b">None</code>。如果我们想改变这一点，我们可以像传递字典一样传递它:<code class="fe oa ob oc od b">class_weight = {0:1, 1:3}</code>，它对<code class="fe oa ob oc od b">1</code>的权重是对<code class="fe oa ob oc od b">0</code>的权重的3倍(我们将很快讨论这意味着什么)，或者我们可以通过传递<code class="fe oa ob oc od b">class_weight = 'balanced'</code>使它自动与数据中可能结果的相对差异成比例。我想你可以看到我们的进展——我们将使用<code class="fe oa ob oc od b">class_weight</code>参数来抵消数据不平衡的影响。</li></ul><p id="6097" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们看看如果我们绘制两个逻辑回归模型的结果会发生什么。先标绘<code class="fe oa ob oc od b">Data_1</code>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/b3262527825f2f1bb5dbe6322cb49500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IfZJgmT9VGz7qI50JdGB5Q.png"/></div></div></figure><p id="aa18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">蓝色虚线表示0.5的概率。红色曲线是在所有参数保持默认的情况下，在基线中观察值为<code class="fe oa ob oc od b">yes</code>的估计概率，绿色曲线是针对我们将<code class="fe oa ob oc od b">class_weight</code>更改为<code class="fe oa ob oc od b">'balanced'</code>的模型。垂直线表示阈值，阈值以上的<code class="fe oa ob oc od b">X</code>值在相应的模型中被归类为<code class="fe oa ob oc od b">yes</code>。<code class="fe oa ob oc od b">baseline</code>模型将观察值分类为<code class="fe oa ob oc od b">yes</code>的<code class="fe oa ob oc od b">X</code>阈值是7.157，对应的<code class="fe oa ob oc od b">accuracy_score</code>是0.929(最优是0.935)，而<code class="fe oa ob oc od b">class_weight</code>模型得到的阈值是5.943，<code class="fe oa ob oc od b">balanced_accuracy_score</code>是0.837(最优是0.843)。正如我们可以看到的,<code class="fe oa ob oc od b">LogisticRegression</code>结果非常接近我们之前计算的最佳阈值，即使它们并不完全匹配，但该模型如何在没有任何调整的情况下成功应对这一点令人印象深刻。</p><p id="caee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">Data_2</code>的图表相同:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/ce614e5b5f1df55b62d0230fd26b7caa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ec766zPK-1iGY193v4Bwsw.png"/></div></div></figure><p id="b635" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">乍一看，这看起来相当糟糕。红线实际上是正确的，并导致与最佳阈值完全相同的<code class="fe oa ob oc od b">accuracy_score</code>。这似乎是一个非常琐碎的问题，最大限度地提高这种偏斜分布的准确性，所以从现在开始，我们将专注于平衡的准确性。我们用<code class="fe oa ob oc od b">class_weight</code>模型得到的<code class="fe oa ob oc od b">X</code>阈值是0.546，对应的balanced_accuracy_score是0.662(最优值是0.681)。<code class="fe oa ob oc od b">Data_2</code>与最优值的差异比<code class="fe oa ob oc od b">Data_1</code>大得多。</p><p id="e5c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在要稍微绕一下路，然后我们再用更多的模型回到逻辑回归，我们将看一个比较模型性能和最优性能的表格。</p><h2 id="143c" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">计算垂直线</h2><p id="de3f" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">如果您想知道如何使用(二进制)逻辑回归模型准确计算上图中分配给0.5概率的阈值，输出可以如下所示:</p><p id="a7df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">p = 1 / (1 + exp(-z))</code>，</p><p id="3778" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<code class="fe oa ob oc od b">p</code>是观测值为正的估计概率，<code class="fe oa ob oc od b">z</code>是类似于线性回归的公式，</p><p id="8374" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">z = intercept + sum (coefficient * corresponding feature)</code>。</p><p id="eafc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由此，在我们的一维示例中，我们得到以下公式来计算给定<code class="fe oa ob oc od b">p</code>概率的<code class="fe oa ob oc od b">X</code>值:</p><p id="f830" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">X = — [log (1 / p — 1) + intercept] / coefficient</code></p><p id="3301" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用这个函数来计算默认的<code class="fe oa ob oc od b">predict</code>函数将使用的精确阈值。</p><h2 id="960b" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">逻辑回归的其他考虑因素</h2><p id="3e5c" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">请注意，运行<code class="fe oa ob oc od b">predict</code>方法是一个<code class="fe oa ob oc od b">LogisticRegression</code>模型的基线预测，使用它，一个估计为正的概率超过50%的观察将被分类为正，其余的为负。但是你也可以调整阈值，比如说你想真正确定<code class="fe oa ob oc od b">yes</code>预测是正确的，并且想只将那些<code class="fe oa ob oc od b">yes</code>概率超过90%的观察结果归类为<code class="fe oa ob oc od b">yes</code>，你可以保存这些概率并进行一个更可控的预测，就像这样:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="031b" class="mo mp it od b gy op oq l or os">y_prob_prediction = logreg.predict_proba(X)<br/>probability_threshold = 0.9<br/>y_prediction = (y_prob_prediction[:,1] &gt; probability_threshold) * 1</span></pre><p id="2ce0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的模拟示例中，像这样选择阈值相当于手动优化。概率是<code class="fe oa ob oc od b">X</code>的单调递增/递减函数，我们可以选择我们想要使用的阈值，从<code class="fe oa ob oc od b">LogisticRegression</code>模型中计算相应的概率，并将其用作<code class="fe oa ob oc od b">probability_threshold</code>。这将使问题变得琐碎而无意义，因此在将来，我们只使用<code class="fe oa ob oc od b">predict</code>函数，因为我们希望看到不同的模型在没有任何外部指导的情况下能够多接近最佳阈值。然而，在现实生活中，这是值得一看的</p><p id="a979" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">LogisticRegression</code>也有许多可以调整的超参数，如<code class="fe oa ob oc od b">penalty</code>(确定是否应用L1或L2正则化方法)或<code class="fe oa ob oc od b">C</code>(惩罚参数)。这些可以进一步分析，但它们不会显著改变我们的结果。我们只打算在后面的决策树中进行超参数优化。</p><h2 id="7248" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">取样方法</h2><p id="1cbd" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">到目前为止，我们已经尝试在一个<code class="fe oa ob oc od b">LogisticRegression</code>模型中使用class_weights来抵消这种不平衡。当最大化<code class="fe oa ob oc od b">balanced_score_accuracy</code>时，它对<code class="fe oa ob oc od b">Data_1</code>非常有效，对<code class="fe oa ob oc od b">Data_2</code>也相对有效。在这一节中，我们将看看一个非常流行的解决不平衡数据的方法:抽样方法。采样方法是我们可以应用于不平衡数据的人工校正，以提高分类器模型的性能。</p><p id="a138" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最直接的可能是欠采样。为了对你的数据进行欠采样，你从多数类别中随机选取观察值，直到你得到一个平衡的数据。在我们的例子中，这意味着我们随机选择100个<code class="fe oa ob oc od b">y</code>为<code class="fe oa ob oc od b">no</code>的观察值，将其添加到<code class="fe oa ob oc od b">yes</code>的100个观察值中，并在这200个观察值上拟合模型。</p><p id="17af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用scikit-learn中的<code class="fe oa ob oc od b">resample</code>方法:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="b270" class="mo mp it od b gy op oq l or os">from sklearn.utils import resample</span><span id="2844" class="mo mp it od b gy ot oq l or os">data = np.concatenate((X, y.reshape(-1,1)), axis = 1)<br/>data_yes = data[data[:,1]==1]<br/>data_no = data[data[:,1]==0]</span><span id="5a50" class="mo mp it od b gy ot oq l or os">data_no_undersampled = resample(<br/>    data_no, replace = True, n_samples = len(data_yes))</span></pre><p id="15b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后从<code class="fe oa ob oc od b">data_no_undersampled</code>我们可以生成一个新的<code class="fe oa ob oc od b">X</code>和<code class="fe oa ob oc od b">y</code>来适应任何模型。欠采样的一个缺点是我们在这个过程中丢失了有价值的数据:在我们的例子中，我们简单地丢弃了90%的<code class="fe oa ob oc od b">no</code>观察值！</p><p id="4796" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与随机欠采样相反的是随机过采样，即从少数类别中随机采样多于原始大小的样本。在我们的例子中，我们将从100个可用的观察值中随机挑选<code class="fe oa ob oc od b">yes</code>个观察值，直到我们得到1000个观察值的数据。是的，这意味着相同的观察结果会在数据中出现多次，平均10次。可以使用与上述相同的重采样方法进行编码:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="fb36" class="mo mp it od b gy op oq l or os">data_yes_oversampled = resample(<br/>    data_yes, replace = True, n_samples = len(data_no))</span></pre><p id="bc29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随机过采样的一个缺点是容易导致过拟合。通过这种方法，我们增加了数据中每个观察值的数量。想象一个决策树，其中我们将单个叶子应该包含的最小观察值限制为10，我们仍然可以得到本质上适合原始数据的单个观察值的叶子。这并不是一个很好的概括。</p><p id="1c0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随机过采样的另一个缺点是，通过使用<code class="fe oa ob oc od b">class_weight</code>参数，我们很容易得到基本相同的结果。我测试了通过重复每一个<code class="fe oa ob oc od b">yes</code>观察10次，我们是否得到了与<code class="fe oa ob oc od b">class_weight</code>方法完全相同的结果，是的，我们得到了！</p><p id="76df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为替代，我们可以使用更复杂的过采样方法，SMOTE(合成少数过采样技术)。该方法为我们想要过采样的类别创建合成的新观测值。我们可以使用不平衡学习库中的<code class="fe oa ob oc od b">smote</code>方法:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="71d1" class="mo mp it od b gy op oq l or os">from imblearn.over_sampling import SMOTE</span><span id="f9a2" class="mo mp it od b gy ot oq l or os">smote = SMOTE()<br/>X_smote, y_smote = smote.fit_sample(X, y)</span></pre><p id="f5ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的一维示例中，它将简单地填充属于<code class="fe oa ob oc od b">yes</code>观测的<code class="fe oa ob oc od b">X</code>特征之间的空白，本质上创建了一个更平滑的分布。在我们最初的<code class="fe oa ob oc od b">Data_1</code>中，yes类别的前两个<code class="fe oa ob oc od b">X</code>数字是:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="d098" class="mo mp it od b gy op oq l or os">[4.78686675, 5.13065935]</span></pre><p id="6f74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SMOTE在这两点之间生成了以下数字序列:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="d700" class="mo mp it od b gy op oq l or os">[4.81446713, 4.82864615, 4.85628325, 4.94624546, 5.00124146, 5.02037642, 5.04086545, 5.12494108]</span></pre><p id="d30d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看这些采样方法在<code class="fe oa ob oc od b">Data_1</code>上是如何工作的:</p><div class="kj kk kl km gt ab cb"><figure class="oe kn of og oh oi oj paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/1ba0cc4c31731b3176a7bb7cd6949a56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*3VvhovIc-lZXpk24I-CmoA.png"/></div></figure><figure class="oe kn of og oh oi oj paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/33db403e3391ae2ac5cd608e7cbda4bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Nw7ahHHdaV0DccmOmJDkQQ.png"/></div></figure></div><p id="f3c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有趣的是我们如何得到新的随机曲线，而原来的分布是非常平滑的。在看这些图表之前，我假设我们从抽样方法中得到的分布会更接近原始分布。</p><p id="5441" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我们讨论了随机过采样的缺点，以及如何应用<code class="fe oa ob oc od b">class_weight</code>方法会产生类似的结果，我们不打算使用随机过采样。我们未来使用的4种模式:</p><ul class=""><li id="edb3" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated">基线；</li><li id="ce5c" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><code class="fe oa ob oc od b">class_weight</code>设置为<code class="fe oa ob oc od b">‘balanced’</code>；</li><li id="3d94" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">随机欠采样；</li><li id="9f99" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">击打。</li></ul><p id="2e87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经讨论了<code class="fe oa ob oc od b">LogisticRegression</code>模型的前两个，在下一节中继续讨论其他的。</p><p id="e6c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意<a class="ae ky" href="https://imbalanced-learn.readthedocs.io/en/stable/api.html" rel="noopener ugc nofollow" target="_blank">不平衡学习</a>有许多不同的过采样和欠采样方法。我最初考虑使用一种更复杂的欠采样方法，但是随机欠采样工作得很好，结果是SMOTE方法的自然对立面。</p><p id="8aad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有一点需要注意:您应该只将这些采样方法应用于您的训练数据！您可以根据修改后的训练数据来改进您的分类器，但是性能应该总是在未调整的测试数据上进行测试。在我们的模拟示例中，没有单独的测试数据，但是我们仍然要在原始的、未调整的数据上测量分类器的性能。</p><h2 id="5461" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">使用抽样方法回归逻辑回归</h2><p id="39d2" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">在本节中，我们将使用通过运行默认模型创建的新欠采样和过采样数据返回到<code class="fe oa ob oc od b">LogisticRegression</code>模型。我们将使用新创建的<code class="fe oa ob oc od b">(X_undersampled, y_undersampled)</code>和<code class="fe oa ob oc od b">(X_smote, y_smote)</code>对，而不是在原始的<code class="fe oa ob oc od b">(X, y)</code>值上安装相同的LogisticRegression对象。</p><p id="3907" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在拟合模型时，我们还可以使用<code class="fe oa ob oc od b">undersampled</code>和<code class="fe oa ob oc od b">smote</code>数据绘制两种分布的逻辑回归概率图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/c489731c7da70e7607ff4d86d4d02f59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VrxxYH30cCXkeWYWhVFLcg.png"/></div></div></figure><p id="b466" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到概率和阈值(<code class="fe oa ob oc od b">X</code>曲线与0.5概率虚线相交的值)彼此非常接近。有趣的是，<code class="fe oa ob oc od b">undersampled</code>方法产生了略高的<code class="fe oa ob oc od b">balanced_accuracy_score</code>，我们将在下一节中看到所有<code class="fe oa ob oc od b">LogisticRegression</code>模型的性能比较。</p><p id="e604" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">Data_2</code>怎么样？绘制概率图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/27989b798a24ed509970062fb2314817.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4LuFe3eor4llbvJZPbGyxQ.png"/></div></div></figure><p id="fd86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以再次看到，两条曲线和阈值非常接近，几乎看不到绿线。同样，<code class="fe oa ob oc od b">undersampled</code>方法产生的<code class="fe oa ob oc od b">balanced_accuracy_score</code>略高于<code class="fe oa ob oc od b">smote</code>方法。</p><h2 id="0411" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">逻辑回归性能总结</h2><p id="8e28" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">让我们将模型与最佳模型进行比较。我们将分别讨论旨在改进<code class="fe oa ob oc od b">accuracy_score</code>和<code class="fe oa ob oc od b">balanced_accuracy_score</code>的模型。对于<code class="fe oa ob oc od b">Data_2</code>，我们不是通过<code class="fe oa ob oc od b">accuracy_score</code>来比较模型，正如我们所讨论的，这是一个微不足道的问题。</p><p id="61e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">Data_1</code>，<code class="fe oa ob oc od b">accuracy_score</code>:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="f9cc" class="mo mp it od b gy op oq l or os"><strong class="od iu">Model             ConfusionMatrix        Threshold      Accuracy</strong></span><span id="d277" class="mo mp it od b gy ot oq l or os">optimal           [993,  7               7.3007         0.9345<br/>                   65,   35]</span><span id="5bb2" class="mo mp it od b gy ot oq l or os">logreg_baseline   [986,  14              7.1566         0.9291<br/>                   64,   36]</span></pre><p id="5a94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所见，基线<code class="fe oa ob oc od b">LogisticRegression</code>模型比最优模型表现稍差，尤其是对于<code class="fe oa ob oc od b">no</code>观测。它设置了一个较低的阈值，这意味着多1个观察值将被正确地识别为<code class="fe oa ob oc od b">yes</code>，但是应该是<code class="fe oa ob oc od b">no</code>的多7个观察值被预测为<code class="fe oa ob oc od b">yes </code>(与最优模型相比)。</p><p id="c558" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">Data_1</code>、<code class="fe oa ob oc od b">balanced_accuracy_score</code>:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="553b" class="mo mp it od b gy op oq l or os"><strong class="od iu">Model             ConfusionMatrix        Threshold      Bal.Acc.</strong></span><span id="42ed" class="mo mp it od b gy ot oq l or os">optimal           [815,  185             5.8716         0.8425<br/>                   13,   87]</span><span id="feb9" class="mo mp it od b gy ot oq l or os">logr_classweight  [834,  166             5.9429         0.8370<br/>                   16,   84]</span><span id="2ef3" class="mo mp it od b gy ot oq l or os">logr_undersampl   [841,  159             5.9653         0.8405<br/>                   16,   84]</span><span id="86f0" class="mo mp it od b gy ot oq l or os">logr_smote.       [835,  165             5.9523         0.8375<br/>                   16,   84]</span></pre><p id="5d17" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">Data_2</code>、<code class="fe oa ob oc od b">balanced_accuracy_score</code>:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="dc5f" class="mo mp it od b gy op oq l or os"><strong class="od iu">Model             ConfusionMatrix        Threshold      Bal.Acc.</strong></span><span id="a3c6" class="mo mp it od b gy ot oq l or os">optimal           [511,  489             0.6364         0.6805<br/>                   15,   85]</span><span id="cc0a" class="mo mp it od b gy ot oq l or os">logr_classweight  [583,  417             0.5460         0.6615<strong class="od iu"><br/>                 </strong>  26,   74]</span><span id="0f6c" class="mo mp it od b gy ot oq l or os">logr_undersampl   [575,  425             0.5600         0.6675<br/>                   24,   76]</span><span id="dfed" class="mo mp it od b gy ot oq l or os">logr_smote.       [581,  419             0.5482         0.6655<br/>                   25,   75]</span></pre><p id="e37d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这两个问题，表现的顺序是:<code class="fe oa ob oc od b">optimal</code>、<code class="fe oa ob oc od b">logr_undersampl</code>、<code class="fe oa ob oc od b">logr_smote</code>、<code class="fe oa ob oc od b">logr_classweight</code>。差别并不大，正如我们之前讨论的，我们只是简单地使用了<code class="fe oa ob oc od b">LogisticRegression</code>模型的<code class="fe oa ob oc od b">predict</code>功能。</p><h2 id="615d" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">决策图表</h2><p id="af16" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">在本节中，我们将查看决策树，并使用我们之前对逻辑回归模型使用的4种不同方法来查看我们与最佳阈值的接近程度:</p><ul class=""><li id="3ee5" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated">基线；</li><li id="1376" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><code class="fe oa ob oc od b">class_weight</code>设置为<code class="fe oa ob oc od b">‘balanced’</code>；</li><li id="8543" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">随机欠采样；</li><li id="b94d" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">击打。</li></ul><p id="dde4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的方法与<code class="fe oa ob oc od b">LogisticRegression</code>类似，拟合决策树非常简单:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="dbfa" class="mo mp it od b gy op oq l or os">from sklearn.linear_model import DecisionTreeClassifier</span><span id="843f" class="mo mp it od b gy ot oq l or os">dtc = DecisionTreeClassifier()<br/>dtc.fit(X, y)</span></pre><p id="11cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦你拟合了一个模型，你可以用下面的命令来可视化这个树:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="6fbc" class="mo mp it od b gy op oq l or os">from IPython.display import Image<br/>import pydotplus</span><span id="106a" class="mo mp it od b gy ot oq l or os">dot_data = export_graphviz(dtc, out_file=None,   <br/>           class_names=np.unique(y).astype('str'), <br/>           filled=True, rounded=True, special_characters=True)</span><span id="9f4a" class="mo mp it od b gy ot oq l or os">graph = pydotplus.graph_from_dot_data(dot_data)</span><span id="a91b" class="mo mp it od b gy ot oq l or os">Image(graph.create_png())</span></pre><p id="b8b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，如果你尝试运行这个模型，你会得到一个巨大的完全过度拟合的树。决策树的问题是，除非你明确地告诉他们停止，否则他们不会停止，如果他们有一个连续的变量，他们将基本上创建一个完美的匹配，但不可用的分类器。通过传递可选参数<code class="fe oa ob oc od b">max_depth</code>，您可以限制树的切割次数。在<code class="fe oa ob oc od b">Data_1</code>上运行带有<code class="fe oa ob oc od b">max_depth = 1</code>的模型，我们得到以下树:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/533ec506f72fa83cf6efbd5188aaa64c.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*zHX5D0dRqxyJ7x3c_Xv2Nw.png"/></div></figure><p id="6439" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">决策树对X= 6.533处的数据进行拆分，将它上面的一切归类为<code class="fe oa ob oc od b">yes</code>，下面的一切归类为<code class="fe oa ob oc od b">no</code>。如果我们把<code class="fe oa ob oc od b">class_weight</code>改成<code class="fe oa ob oc od b">'balanced'</code>会怎么样？我们得到下面的树:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/27cc6d7b37c7422ff03e56cd6fcc4624.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*5UMIrque7wA1U-bmvcEsfg.png"/></div></figure><p id="a718" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从这些简单的树中，还可以读出混淆矩阵，比如在第二个中，有815个<code class="fe oa ob oc od b">no</code>值和130 / 10 = 13个<code class="fe oa ob oc od b">yes</code>值预测为<code class="fe oa ob oc od b">no</code>，有185个<code class="fe oa ob oc od b">no</code>和87个<code class="fe oa ob oc od b">yes</code>值预测为<code class="fe oa ob oc od b">yes</code>。</p><p id="44b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以从树中的每个节点读取许多其他信息，最重要的是<code class="fe oa ob oc od b">gini</code>分数。在继续之前，让我们先看看这个<code class="fe oa ob oc od b">gini</code>分数意味着什么，以及如何选择分割阈值。</p><h2 id="0ede" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">关于标准的一句话</h2><p id="5f39" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">决策树使用贪婪算法来分割数据，基于两个可能得分的平均改善:<code class="fe oa ob oc od b">gini</code>和<code class="fe oa ob oc od b">entropy</code>(至少那些是<code class="fe oa ob oc od b">sklearn</code> <code class="fe oa ob oc od b">DecisionTreeClassifier</code>类中可用的两个)。当你实例化一个决策树时，你可以使用可选的<code class="fe oa ob oc od b">criterion</code>参数传递它们，缺省值是<code class="fe oa ob oc od b">gini</code>。基尼系数和熵都是衡量一组观察值“有序”程度的指标:如果大部分观察值属于某个特定的目标变量，则比观察值均匀分布在不同的目标变量中更有序。(你可以查看相应的维基百科页面，了解更多关于基尼系数和熵系数的基础数学知识。)</p><p id="030e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当决策树比较不同的数据分离时，它会计算子节点中这些分数的平均改善，并根据分离后分配给它们的样本总数进行加权。我们可以计算这个平均值作为阈值的函数，并绘制它们:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/c65c93a925c8870266b66f062426c2e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*rFMmF5tbap-KLIYM0AesEw.png"/></div></figure><p id="b5cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两条线的形状相似，它们的最小值恰好在同一个<code class="fe oa ob oc od b">X</code>。如果我们用<code class="fe oa ob oc od b">entropy</code>而不是<code class="fe oa ob oc od b">gini</code>运行基线<code class="fe oa ob oc od b">DecisionTreeClassifier</code>，我们会得到完全相同的分割(我测试过)。自然，人们不能说两个标准分数将总是导致相同的分割，但是对于这个例子，我很乐意使用默认的分数:<code class="fe oa ob oc od b">gini</code>。</p><p id="a3ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，有趣的是<code class="fe oa ob oc od b">gini</code>并没有最大化精度或平衡精度！在下图中，我们绘制了三条曲线<code class="fe oa ob oc od b">accuracy_score</code>、<code class="fe oa ob oc od b">balanced_accuracy_score</code>和<code class="fe oa ob oc od b">gini</code>，作为<code class="fe oa ob oc od b">X</code>阈值的函数，并突出显示了它们在<code class="fe oa ob oc od b">Data_1</code>的最大值/最小值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/c0aaa75326565edc10d286e0e0c011e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oak6EKVJq7BQ0wtg0Vd-WA.png"/></div></div></figure><p id="6ada" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我发现非常有趣的是，单一分割选择的阈值大致介于最佳精度/平衡精度分割之间。</p><p id="76bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，如果我们想最大限度地提高准确性，我们不能把自己限制在一个水平上，但如果我们只是让树生长，它会大量过度适应。为了平衡这两个选项，我们将不得不使用超参数优化。</p><h2 id="b67e" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">超参数优化</h2><p id="10a6" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">我们将使用scikit-learn的<code class="fe oa ob oc od b">GridSearchCV</code>来优化<code class="fe oa ob oc od b">DecisionTree</code>的超参数。首先，我们需要定义一个想要检查的参数字典，如下所示:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="a1f1" class="mo mp it od b gy op oq l or os">param_grid = {<br/>    'max_depth': [1,2,3,4,5, 10, 20],<br/>    'min_samples_leaf': [1,2,3,4,5, 10, 20],<br/>    'class_weight': [{0:1, 1: 1}, {0:1, 1: 10}]<br/>    }</span></pre><p id="5f47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我们要调整的三个参数，我们可以使用其他参数，但这些参数可能是最简单的。<code class="fe oa ob oc od b">GridSearchCV</code>将运行7*7*2 = 28种类型的树，如果我们考虑我们将使用的三重交叉验证，总共28 * 3 = 84棵树。然后，它将比较在不同类型的树上获得的分数(准确度或平衡准确度),并返回最佳估计器参数。</p><p id="9c53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在你实例化了一个<code class="fe oa ob oc od b">dtc</code> <code class="fe oa ob oc od b">DecisionTreeClassifier</code>对象之后，就像我们上面做的那样，你可以在<code class="fe oa ob oc od b">GridSearchCV</code>中把它作为一个参数传递。你可以使用所有的<code class="fe oa ob oc od b">sklearn</code>模型，但是对于这个例子，我们坚持使用<code class="fe oa ob oc od b">DecisionTree</code>的。我们将使用三重交叉验证来避免过度拟合，我们希望最终得到一个正确分离数据的树。</p><p id="6754" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法的有趣之处在于，我们无法告诉<code class="fe oa ob oc od b">DecisionTree</code>哪个阈值是理想的阈值。我们将最终得到一个<code class="fe oa ob oc od b">best_estimator_</code>，它将拥有最好的超参数，但是最终的模型将是一个简单的<code class="fe oa ob oc od b">DecisionTree</code>对象。</p><p id="061d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行<code class="fe oa ob oc od b">GridSearchCV</code>类似于运行分类器模型(在下面的例子中，我们针对<code class="fe oa ob oc od b">accuracy</code>进行了优化):</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="4c55" class="mo mp it od b gy op oq l or os">from sklearn.model_selection import GridSearchCV</span><span id="7395" class="mo mp it od b gy ot oq l or os">gscv_dt = GridSearchCV(estimator = dtc, param_grid = param_grid,     <br/>          scoring = 'accuracy', cv = 3)</span><span id="1caf" class="mo mp it od b gy ot oq l or os">gscv_dt.fit(X, y)</span></pre><h2 id="fc7a" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">使用超参数优化返回决策树</h2><p id="f0b3" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">我们将返回决策树，使用<code class="fe oa ob oc od b">GridSearchCV</code>找到最佳参数。使用GridSearchCV，我们在技术上可以有6个模型:针对3个数据、基线、<code class="fe oa ob oc od b">undersampled</code>和<code class="fe oa ob oc od b">smote</code>的精度优化/平衡精度。除此之外，为<code class="fe oa ob oc od b">accuracy_score</code>优化<code class="fe oa ob oc od b">undersampled</code>和<code class="fe oa ob oc od b">smote</code>可能没有用，但是我们可以检查一下。</p><p id="cdac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们拟合了一个<code class="fe oa ob oc od b">GridSearchCV</code>模型，我们可以使用<code class="fe oa ob oc od b">best_estimator_</code>属性重新创建选定的最佳模型:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="21d8" class="mo mp it od b gy op oq l or os">dtc = DecisionTreeClassifier(<br/>      max_depth = gscv_dt.best_estimator_.max_depth,<br/>      min_samples_leaf = gscv_dt.best_estimator_.min_samples_leaf,<br/>      class_weight = gscv_dt.best_estimator_.class_weight)</span></pre><p id="c5e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">先分析一下<code class="fe oa ob oc od b">Data_1</code>。</p><p id="ae59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们考虑未调整的基线数据。如果我们对<code class="fe oa ob oc od b">accuracy_score</code>进行优化，我们会得到这个决策树:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/9501b9943e40921b1d4d58ef70fcfdd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*bbQ4msSgDEXJf-1NDzrOlA.png"/></div></figure><p id="8cb3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好消息，树居然找到了最优分裂！人们可以从唯一的蓝色节点中扣除这一点，我们有7个假阳性和35个真阳性，这符合最优解。</p><p id="cdb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从树上，我们可以看到</p><ul class=""><li id="0657" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated">即使不改变预测，树也会继续分裂；</li><li id="5f0c" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">我们从6.533开始，与我们的第一个基线示例一样。</li></ul><p id="5ed0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们想对<code class="fe oa ob oc od b">balanced_accuracy</code>进行优化，会发生什么呢？唯一的区别是我们在上面的<code class="fe oa ob oc od b">GridSearchCV</code>对象中将<code class="fe oa ob oc od b">accuracy</code>改为<code class="fe oa ob oc od b">balanced_accuracy</code>。结果非常有趣，原来我们在第一个中尝试的第一个基线模型是平衡精度的最佳模型！在5.874分开的那个。(稍后我们将提供一个汇总表，其中总结了决策树模型的性能指标。)</p><p id="6002" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，看看取样方法，<code class="fe oa ob oc od b">undersampled</code>第一。结果再一次非常有趣，我们得到了完全相同的树，不管我们是优化了精确度还是平衡了精确度！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/96594104988766468f81417c4e69f7f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*bTbTCp_LWeWxDs7n-_kVBA.png"/></div></figure><p id="1def" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这可能是因为样本是均匀的，数据是完全平衡的。</p><p id="6886" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，<code class="fe oa ob oc od b">Data_1</code>使用<code class="fe oa ob oc od b">smote</code>方法，与<code class="fe oa ob oc od b">undersampled</code>相同的行为，我们得到完全相同的树，不管我们想要优化精度还是平衡精度。然而，树本身看起来就不那么令人愉快了:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/f932d5b185eb15b1c63b3474433ad777.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wDSjo5kVguAy8ePtZGor_A.png"/></div></div></figure><p id="2755" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有趣的是，它在左侧(橙色边上孤独的蓝色框)发现了被预测为<code class="fe oa ob oc od b">yes</code>的项目，反之亦然，在右侧(蓝色边上的橙色框)发现了被预测为<code class="fe oa ob oc od b">no</code>的项目。我们知道这可能是过度拟合的迹象，即使我们使用交叉验证，这也很容易发生。请注意，即使这是一个真实的案例，并且我们有一个测试数据，过度拟合问题也是一样的，因为我们是从拟合训练数据开始的！</p><p id="65ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在来看看<code class="fe oa ob oc od b">Data_2</code>。</p><p id="dc84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与所有其他模型一样，优化基线数据以获得准确的结果——我们无法真正构建一个分类器，我们必须将一切归类为<code class="fe oa ob oc od b">no</code>。相关的问题是:我们可以优化平衡的准确性吗？是的，事实证明，<code class="fe oa ob oc od b">class_weight</code>参数也使决策树成为可能:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/108095a61bc1e36e6dad8bd3ade11c53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3jNaT5-kM9AsA-YbGEUfOw.png"/></div></div></figure><p id="bd38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与<code class="fe oa ob oc od b">Data_1</code>类似，为<code class="fe oa ob oc od b">accuracy_score</code>或<code class="fe oa ob oc od b">balanced_accuracy</code>优化<code class="fe oa ob oc od b">Data_2</code>的<code class="fe oa ob oc od b">undersampled</code>和<code class="fe oa ob oc od b">smote</code>版本，结果得到完全相同的树。他们也表现出过度合身的迹象。我不打算在这里包括所有的图表，请参考我的<a class="ae ky" href="https://github.com/MatePocs/imbalanced_classifier" rel="noopener ugc nofollow" target="_blank"> GitHub </a>存储库以了解那些细节，并参考下一节的性能总结。</p><h2 id="bfa8" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">决策树性能摘要</h2><p id="f0b1" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">让我们将模型与最佳模型进行比较。我们将遵循与逻辑回归总结相似的结构。对于<code class="fe oa ob oc od b">Data_1</code>和<code class="fe oa ob oc od b">Data_2</code>，我们有6个不同的决策树模型，但我们只检查<code class="fe oa ob oc od b">Data_1</code>的基准决策树，因为其他模型没有针对准确性进行适当的优化。</p><p id="7c3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">Data_1</code>，<code class="fe oa ob oc od b">accuracy_score</code>:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="5cab" class="mo mp it od b gy op oq l or os"><strong class="od iu">Model             ConfusionMatrix        Threshold      Accuracy</strong></span><span id="ba92" class="mo mp it od b gy ot oq l or os">optimal           [993,  7               7.3007         0.9345<br/>                   65,   35]</span><span id="cf52" class="mo mp it od b gy ot oq l or os">dtree_baseline    [993,  7               7.309          0.9345<br/>                   65,   35]</span></pre><p id="9856" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">baseline</code>决策树模型找到了数据的最佳分割。</p><p id="fe19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">Data_1</code>，<code class="fe oa ob oc od b">balanced_accuracy_score</code>:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="f848" class="mo mp it od b gy op oq l or os"><strong class="od iu">Model             ConfusionMatrix        Threshold      Bal.Acc.</strong></span><span id="33aa" class="mo mp it od b gy ot oq l or os">optimal           [815,  185             5.8716         0.8425<br/>                   13,   87]</span><span id="1d97" class="mo mp it od b gy ot oq l or os">dtree_baseline    [815,  185             5.874          0.8425<br/>                   13,   87]</span><span id="8b8a" class="mo mp it od b gy ot oq l or os">dtree_undersampl  [797,  203             5.809          0.8385<br/>                   12,   88]</span><span id="db90" class="mo mp it od b gy ot oq l or os">dtree_smote       [821,  179             n/a            0.8505<br/>                   12,   88]</span></pre><p id="dd34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">baseline</code>决策树模型再一次找到了最优分割。<code class="fe oa ob oc od b">Undersampled</code>表现不佳，<code class="fe oa ob oc od b">smote</code>导致了更高的<code class="fe oa ob oc od b">balanced_accuracy_score</code>，但代价是过度拟合。</p><p id="13c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc od b">Data_2</code>，<code class="fe oa ob oc od b">balanced_accuracy_score</code>:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="4417" class="mo mp it od b gy op oq l or os"><strong class="od iu">Model             ConfusionMatrix        Threshold      Bal.Acc.</strong></span><span id="8701" class="mo mp it od b gy ot oq l or os">optimal           [511,  489             0.6364         0.6805<br/>                   15,   85]</span><span id="0f03" class="mo mp it od b gy ot oq l or os">dtree_baseline    [527,  473             n/a            0.7035<br/>                   12,   88]</span><span id="9746" class="mo mp it od b gy ot oq l or os">dtree_undersampl  [555,  445             n/a            0.6925<br/>                   17,   83]</span><span id="da7f" class="mo mp it od b gy ot oq l or os">dtree_smote.      [669,  331             n/a            0.7095<br/>                   25,   75]</span></pre><p id="0f68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有趣的结果是，从技术上讲，所有三个决策树模型都有更高的<code class="fe oa ob oc od b">balanced_accuracy_score</code>，但它们是以过度拟合为代价实现的。我们不能限制他们去寻找最优阈值。</p><p id="6afc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请再次注意，对单独的测试数据进行测试将是分析过度拟合的正确方法，但我认为在我们的情况下没有必要这样做。我们分析的主要结果是，我们不能总是将决策树修剪成简单的最优分裂。</p><h2 id="f8f2" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">结果摘要</h2><p id="e552" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">我们多少暗示了几次，但是没有阐明最重要的假设是他们各自组中的基线模型在准确性方面表现良好，而其他三个模型(<code class="fe oa ob oc od b">class_weight</code>、<code class="fe oa ob oc od b">undersampled</code>、<code class="fe oa ob oc od b">smote</code>)在平衡准确性方面表现良好。</p><p id="6c59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我经常看到这样的例子，用户有不平衡的数据，并开始应用采样方法，即使目标是最大限度地提高准确性。因此，接下来的转折是:让我们看看每个模型如何通过<code class="fe oa ob oc od b">Data_1</code>中的两个性能指标来表现彼此，其中两个都是有效的问题！</p><p id="cba7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下表中，两个<code class="fe oa ob oc od b">optimal_</code>模型是我们手动计算的简单分割。<code class="fe oa ob oc od b">logreg_</code>和<code class="fe oa ob oc od b">dtree_</code>型号都有四种不同的版本:</p><ul class=""><li id="d001" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated"><code class="fe oa ob oc od b">_acc</code>，为精度优化的基线(主要通过不使用<code class="fe oa ob oc od b">class_weight</code>)；</li><li id="5538" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><code class="fe oa ob oc od b">_bal_acc</code>，为平衡精度进行基线优化(主要通过使用<code class="fe oa ob oc od b">class_weight</code>)；</li><li id="9dc3" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><code class="fe oa ob oc od b">undersampled</code>，两组中只有一个这种类型的模型，对于<code class="fe oa ob oc od b">LogisticRegression</code>，我们只对相同的数据拟合一种类型的模型，对于<code class="fe oa ob oc od b">DecisionTree</code>，无论我们是针对<code class="fe oa ob oc od b">accuracy_score</code>还是<code class="fe oa ob oc od b">balanced_accuracy_score</code>进行优化，最优超参数都是相同的；</li><li id="76ea" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><code class="fe oa ob oc od b">smote</code>，每个模型组一行，原因与上述<code class="fe oa ob oc od b">undersampled</code>相同。</li></ul><p id="e676" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">讨论完之后，让我们来看看<code class="fe oa ob oc od b">Data_1</code>的汇总表:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="a0ec" class="mo mp it od b gy op oq l or os"><strong class="od iu">Model               Threshold         Accuracy        Bal.Acc.</strong><br/>optimal_acc            7.3007           <strong class="od iu">0.9345</strong>          0.6715<br/>optimal_bacc           5.8716           0.8200          <strong class="od iu">0.8425</strong><br/>logreg_acc             7.1566           0.9291          0.6730<br/>logreg_bal_acc         5.9429           0.8345          0.8370<br/>logreg_undersampl      5.9653           0.8409          0.8405<br/>logreg_smote           5.9523           0.8355          0.8375<br/>dtree_acc              7.3090           <strong class="od iu">0.9345</strong>          0.6715<br/>dtree_bal_acc          5.8740           0.8200          <strong class="od iu">0.8425</strong><br/>dtree_undersampl       5.8090           0.8045          0.8385<br/>dtree_smote               n/a           0.8264          0.8505</span></pre><p id="aec6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于准确性问题和平衡准确性问题，我认为单一决策树的结果是最稳健的。他们使用单个<code class="fe oa ob oc od b">X</code>值将数据分成两组，就像我们的最佳手动模型一样。大多数模型表现稍差，但没有一个模型在其擅长的类别中有明显的糟糕表现。<code class="fe oa ob oc od b">smote</code>模型在技术上实现了更好的平衡精度，但代价是过度拟合。</p><p id="4490" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于<code class="fe oa ob oc od b">Data_2</code>，如前所述，测量精度并不真正相关，但我们仍然可以为良好的测量创建汇总表:</p><pre class="kj kk kl km gt ol od om on aw oo bi"><span id="7a84" class="mo mp it od b gy op oq l or os"><strong class="od iu">Model               Threshold         Bal.Acc.</strong><br/>optimal_bacc           0.6364           0.6805<br/>logreg_bal_acc         0.5460           0.6615<br/>logreg_undersampl      0.5560           0.6675<br/>logreg_smote           0.5482           0.6655<br/>dtree_bal_acc             n/a           0.7035<br/>dtree_undersampl          n/a           0.6925<br/>dtree_smote               n/a           0.7095</span></pre><p id="7058" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果比预期的<code class="fe oa ob oc od b">Data_1</code>更糟，<code class="fe oa ob oc od b">Data_2</code>是一个更棘手的问题。逻辑回归模型表现相对较好，平衡精度略低于最佳手动模型。决策树模型具有更高的平衡精度，但以过度拟合为代价，而不是基于一个阈值来分离数据，它们识别出<code class="fe oa ob oc od b">yes</code>观察值随机出现的口袋。</p><h2 id="4981" class="mo mp it bd mq mr ms dn mt mu mv dp mw li mx my mz lm na nb nc lq nd ne nf ng bi translated">结论</h2><p id="5fe0" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">我想强调的第一点是，不要从这个练习或任何一个练习中得出长期的结论，这只是一个随机的例子。主要的收获是你可以用来抵消数据不平衡的可用方法，以及预先阐明问题的重要性。</p><p id="00bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话虽如此，我认为同样重要的是要注意，你不能简单地通过盲目应用<code class="fe oa ob oc od b">smote</code>抽样方法来解决每个问题，因为这是最奇特的方法，原因如下:</p><ul class=""><li id="35b3" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated">这会导致过度拟合，尤其是决策树。</li><li id="9ef3" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">如果您想最大限度地提高准确性，您可能会考虑坚持使用根据原始数据训练的更简单的模型。在<code class="fe oa ob oc od b">Data_1</code>的情况下，决策树设法将观察结果分成两组，就像我们手动做的那样。</li></ul><p id="38bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我从这个练习中吸取的另一个教训是，有时一个极度不平衡的数据可能意味着你根本无法处理它。在<code class="fe oa ob oc od b">Data_2</code>的例子中，我们根本无法建立一个好的精度分类器来击败天真的基线模型。</p><p id="cf83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就结束了我们对不平衡数据分类器的分析。我很喜欢整理这些信息，希望你会觉得有用！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pb pc l"/></div></figure></div></div>    
</body>
</html>