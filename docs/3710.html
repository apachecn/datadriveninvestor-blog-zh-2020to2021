<html>
<head>
<title>TF-IDF in Natural Language Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理中的TF-IDF</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/tf-idf-in-natural-language-processing-8db8ef4a7736?source=collection_archive---------0-----------------------#2020-07-03">https://medium.datadriveninvestor.com/tf-idf-in-natural-language-processing-8db8ef4a7736?source=collection_archive---------0-----------------------#2020-07-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/ccdab9e64ae5c83f113c02eb102c203e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wgKxsWlT3ifsZmNy-DihFQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">image:Kaggle</figcaption></figure><div class=""/><h1 id="af20" class="kc kd jf bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="ak">概述</strong></h1><p id="234e" class="pw-post-body-paragraph la lb jf lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">正如我们从我以前的文章<a class="ae ly" href="https://medium.com/@anjanimca2007/bag-of-words-in-natural-language-processing-fe996f9ae9d2" rel="noopener">单词包</a>中所知，我们通过BOW将句子转换为单词向量，BOW将单词转换为0(当单词不在句子中时)或1(当单词在句子中时)。</p><p id="7279" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc jg">单词包</strong>只是创建了一组包含句子/语料库中<strong class="lc jg">单词</strong>出现次数的向量，但它不包含重要<strong class="lc jg">单词的信息。</strong></p><p id="d9a0" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">因此，我们有另一种技术来实现的话，重要性被称为</p><blockquote class="me mf mg"><p id="b1f5" class="la lb mh lc b ld lz lf lg lh ma lj lk mi mb ln lo mj mc lr ls mk md lv lw lx ij bi translated"><strong class="lc jg"> TF-IDF </strong>意为<strong class="lc jg">术语频率和逆文档频率，</strong>是一个广泛用于信息检索(IR)或摘要的评分指标。<strong class="lc jg"> TF </strong> - <strong class="lc jg"> IDF </strong>意在反映一个术语在给定文档中的相关程度。</p></blockquote><h2 id="55a8" class="ml kd jf bd ke mm mn dn ki mo mp dp km ll mq mr kq lp ms mt ku lt mu mv ky mw bi translated"><strong class="ak">举例详细了解TF-IDF:</strong></h2><p id="b550" class="pw-post-body-paragraph la lb jf lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">让我们通过我们在“单词袋”中看到的同一个例子来理解TF-IDF</p><p id="9605" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">假设我们有下面这样的句子</p><p id="3377" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">1.他正在吃蔬菜</p><p id="edc9" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">2.她正在吃水果</p><p id="3872" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">3.两个人都在吃食物</p><p id="528d" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">在应用数据清洗技术和应用停用词后，我们将得到下面的句子单词和计数。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/d3ebdce233faa14519b87f618e4d76a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*fHXgR-q2Uy0wqCiiob5L1Q.png"/></div></figure><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/390997324cb9e11915564adb0fe23be0.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*2Y4LkwR94fMMNOLTvHlIXw.png"/></div></figure><p id="6dbc" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc jg">让我们看看计算词频(TF)的公式</strong></p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nd"><img src="../Images/40a4e3d8fe76fdaa409632c26355bfce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sea7Nis9wSuRhtE0x1lnLA.png"/></div></div></figure><p id="fa9a" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">让我们计算句子的词频</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/366dd096d8137339ea469bf54149fd4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*j0eFud1jkbywLt7zoyBrew.png"/></div></figure><p id="d441" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc jg">让我们看看计算逆文档频率(IDF)的公式</strong></p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nf"><img src="../Images/b61e81146eec6ca0e85c738c27e37d42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*33rTbQmvUh5cENS-66ZJcA.png"/></div></div></figure><p id="8f8d" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc jg">让我们计算句子中单词的逆文档频率(IDF)</strong></p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/27d6fce30db9ce6349d1082e017eaab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*qX8wOtNJB92xHlwdrjrEFQ.png"/></div></figure><p id="2c1d" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">现在计算TF-IDF，将上面生成的TF表乘以IDF</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/a35dce63d9b4379716f136c6702a4208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*ktEXNSF6anRFiwIfGXTB0Q.png"/></div></figure><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ni"><img src="../Images/aeea7281f90fb6b4522f8fd3741787a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_gjbGsHUcSJ_dEdXB0UEWw.png"/></div></div></figure><p id="3074" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">经过简化，我们得到了下面的TF * IDF矩阵表</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nj"><img src="../Images/291808d802fa50b43afef506f11ce427.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6dGHBvFnw71CXaUxEmn5EQ.png"/></div></div></figure><blockquote class="me mf mg"><p id="1cab" class="la lb mh lc b ld lz lf lg lh ma lj lk mi mb ln lo mj mc lr ls mk md lv lw lx ij bi translated">在这里，我们可以看到，在句子1(吃蔬菜)中，单词“veg”被赋予了重要性，类似地，在句子3(吃食物)中，单词“nonveg”被赋予了重要性，单词“food”被赋予了重要性，它具有某种形式的语义意义。</p><p id="95f3" class="la lb mh lc b ld lz lf lg lh ma lj lk mi mb ln lo mj mc lr ls mk md lv lw lx ij bi translated">单词“eat”不太重要，因为它经常出现在所有的句子中，可能有相同的意思，所以没有用。</p></blockquote><p id="8bda" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">现在想想我们只有三个句子，当我们有大量的段落和句子时，这将是多么有帮助。</p><p id="ccfb" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">所有输入特征将与O/P(输出特征)一起提供给模型，模型将被训练，并且可以以矩阵形式获得所有具有值的重要单词。</p><p id="0ade" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc jg"> Python代码，供参考。</strong>使用的包是来自<strong class="lc jg"> sklearn </strong>的<strong class="lc jg">tfidf矢量器</strong></p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nk"><img src="../Images/8fb494c5f93a4297a682b261f880a736.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dAObcdgudptT3c57Q7Q8dg.png"/></div></div></figure><p id="9919" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc jg">结论</strong> : TF-IDF是自然语言处理中的一种技术，用于将带有一些语义信息的词转换成向量，并对生僻词进行加权，用于各种NLP应用。还有其他先进的技术<strong class="lc jg"> Word2Vec </strong>我将在我的下一篇文章中介绍，这些技术将具有语义和单词之间的关联关系。</p><p id="d286" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">请写下您的疑问和意见，并分享您的反馈。</p><p id="9fd6" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">希望你喜欢我的文章。请鼓掌👏(50次)激励我继续写下去。</p><p id="baaa" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">想要连接:</p><p id="95fd" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">联系方式:【https://www.linkedin.com/in/anjani-kumar-9b969a39/ T4】</p><p id="398a" class="pw-post-body-paragraph la lb jf lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">如果你喜欢我在Medium上的帖子，并希望我继续做这项工作，请考虑在<a class="ae ly" href="https://www.patreon.com/anjanikumar" rel="noopener ugc nofollow" target="_blank"> <strong class="lc jg"> patreon </strong> </a>上支持我</p></div></div>    
</body>
</html>