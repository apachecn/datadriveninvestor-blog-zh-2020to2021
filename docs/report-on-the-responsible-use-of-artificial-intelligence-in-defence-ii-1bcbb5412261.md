# Raffaella Aghemo 关于国防中负责任地使用人工智能的报告(二)

> 原文：<https://medium.datadriveninvestor.com/report-on-the-responsible-use-of-artificial-intelligence-in-defence-ii-1bcbb5412261?source=collection_archive---------31----------------------->

![](img/15dc92c0027c871478a63e0cf67d4a3b.png)

Clker free vector umages pixabay

***简介***

人工智能已经成为世界大国之间，尤其是美国和中国之间竞争的焦点；本报告着重于为什么发起这些讨论，以及为什么欧盟及其成员国应该以更加一致的方式参与关于负责任地军事使用人工智能的全球对话(**第 2 章**)。然后，他概述了欧盟及其成员国如何在最佳实践方面领先，重点关注三个领域:法律合规性、道德和技术安全(**第 3 章**)。最后，总结了主要的调查结果和建议(**第 4 章**)。

正如报告所述，欧盟国家在这一领域实现共享和全球愿景的机会无疑具有以下优势:在关于人工智能治理的全球辩论中给予它们更大的权重，确保各种武装力量之间更大的互操作性，以及合作促进经济增长，共同研究该领域的新技术潜力！

美国和中国正在投资开发尖端技术，从两个角度来看，他们领先的事实可能是有问题的:如果欧盟在研发方面落后，它将面临不得不与其他国家决定的战略保持一致的严重风险，而且它可能受到与欧洲愿景格格不入的理论和原则的影响，因为它们是由美国、中国和俄罗斯等超级大国强加的！

因此，欧盟成员国需要一种积极主动的方法，而不是一种主动的方法。

在欧洲内部，战略自主的概念已经变得更加相关，因为获得技术是其最重要的方面之一，因此，国防对话将是更广泛设计的一部分。欧盟的安全政策，即 2016 年发布的全球战略或 EUGS，加强了各国之间的合作，确定了国防战略的共同原则。此外，该路线图必须与更高的技术效率相结合，但同时也要与国家层面的成本优化相结合，创建共同的项目，如由德、法、西合作开发的未来作战空中系统(FCAS )!

正如在导言中提到的，报告在这里侧重于欧盟及其成员国如何能够推进其关于负责任地军事使用人工智能的思想，确保其法律合规性、伦理可接受性和安全性。

自 2016 年以来，EDA(欧洲防务局)一直致力于负责任的人工智能的共享设计:它协调了几个涉及人工智能的研发(R&D)项目。此外，它还致力于制作:

人工智能、分类学和术语表的共同定义，以解决国家之间在概念上可能存在的概念差异；

在人工智能能够实现的广泛能力范围内，欧洲能力发展计划相关应用领域的共同愿景；

2020 年 12 月将向欧盟国防部长提交一份欧盟国防信息系统合作行动计划。

然而，这些文件尚未公开，但似乎将他们的目光转向更实用和可操作的观点，同时保持主要的人类控制，对军事人工智能的使用。

2018 年，欧洲议会通过了一项决议，禁止使用致命的自主武器，定义为“ ***没有有意义的人类控制的武器*** ”，尽管它对法律领域的国家战略几乎没有影响，即致命的军事自主系统，以至于今年 6 月，欧洲议会决定成立一个人工智能特别委员会，该委员会的任务是调查人工智能的军事应用。一位参加了斯德哥尔摩国际和平研究所主办的研讨会的欧盟专家称，欧盟成员国在人工智能军事用途方面的工作有限；事实上，根据 EDA，只有三个成员国已经制定了关于人工智能军事用途的国家战略。其中，法国是唯一一个公开其战略的国家。尽管如此，一小批国家正在寻求加强对这一主题的协调和国家反思，芬兰在 2019 年担任 EDA 理事会主席期间发表的讨论文件就是证明。该论文邀请欧盟成员国思考人工智能对欧盟未来防务的战略作用。它强调伦理考虑应该在这种反思中发挥关键作用，并概述了欧盟成员国应该作为其国家反思的一部分考虑的一些问题。

第三和最后一部分如下

版权所有

***律师***

**访问专家视图—** [**订阅 DDI 英特尔**](https://datadriveninvestor.com/ddi-intel)