<html>
<head>
<title>Deepfakes Detection by Heart Rate Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过心率预测检测深度假货</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/deepfakes-detection-by-heart-rate-prediction-d96d8843a14b?source=collection_archive---------17-----------------------#2020-12-07">https://medium.datadriveninvestor.com/deepfakes-detection-by-heart-rate-prediction-d96d8843a14b?source=collection_archive---------17-----------------------#2020-12-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="468c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">深度学习</h2><div class=""/><div class=""><h2 id="bba7" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">深度假货的心是怎么跳动的？一种基于生物信号解释残差的深度假货检测新方法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/b05ffc3284e2d82dfbbd26783d516149.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CPqbsByJkLfN99O4ts3-MQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">PPG Cells. Example frames per ω = 64 windows (<strong class="bd lh">top</strong>), and their PPG cells (<strong class="bd lh">bottom</strong>) consisting of raw PPG and PPG PSD, of a real video (<strong class="bd lh">left</strong>) and its deep fakes per generative model (<strong class="bd lh">rest</strong>). Source: <a class="ae li" href="https://arxiv.org/pdf/2008.11363.pdf" rel="noopener ugc nofollow" target="_blank">Arxiv</a></figcaption></figure><p id="ec16" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">宾汉普顿大学 和<a class="ae li" href="https://www.intel.com/content/www/us/en/homepage.html" rel="noopener ugc nofollow" target="_blank"> <em class="mf">英特尔公司</em> </a>的研究人员开发了一种通过预测心跳来识别<a class="ae li" href="https://en.wikipedia.org/wiki/Deepfake" rel="noopener ugc nofollow" target="_blank"> deepfakes </a>的模型。分类器使用<a class="ae li" href="https://en.wikipedia.org/wiki/Photoplethysmogram" rel="noopener ugc nofollow" target="_blank">光电容积描记图</a>数据来识别虚假视频。该模型中的一个重要假设是，它学习识别使用一组公开可用的架构生成的deepfakes。这限制了该模型在实际应用中的使用。</p><p id="479d" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">该方法以97.27% 的准确率<strong class="ll jd">检测出虚假视频，以93.39% </strong>的准确率<strong class="ll jd">检测出deepfakes的生成模型。</strong></p><h1 id="10bd" class="mg mh it bd lh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">DeepFakes问题</h1><p id="76ad" class="pw-post-body-paragraph lj lk it ll b lm mx kd lo lp my kg lr ls mz lu lv lw na ly lz ma nb mc md me im bi translated">deepfakes近年来越来越受欢迎。人工生成的名人视频被用于各种目的，从社交媒体图像的过滤器到政治宣传和虚假新闻。这就使得对deepfakes的识别方法的研究成为一个热门领域。</p><h1 id="ef70" class="mg mh it bd lh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">该方法背后的思想</h1><p id="91c4" class="pw-post-body-paragraph lj lk it ll b lm mx kd lo lp my kg lr ls mz lu lv lw na ly lz ma nb mc md me im bi translated">研究人员分析了来自<a class="ae li" href="https://medium.com/dev-genius/write-your-first-generative-adversarial-network-model-on-pytorch-7dc0c7c892c7" rel="noopener"> <strong class="ll jd">生成GAN模型</strong> </a>的残余物，并试图将它们与生物信号联系起来。所提出的用于对deepfake视频进行分类的框架能够识别由可用模型之一生成的虚假视频及其来源。</p><div class="nc nd gp gr ne nf"><a href="https://medium.com/dev-genius/write-your-first-generative-adversarial-network-model-on-pytorch-7dc0c7c892c7" rel="noopener follow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd jd gy z fp nk fr fs nl fu fw jc bi translated">在PyTorch上写下你的第一个生成性对抗网络模型</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">使用两个模型的例子构造生成性对抗神经网络(GANs)的详细说明…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">medium.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt lb nf"/></div></div></a></div><p id="5307" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">该模型从接收一个真实视频作为输入的几个生成网络开始。真实视频和生成的deepfakes然后被馈送到注册模块的输入端。在这个阶段，模型提取感兴趣的面部部分，这些部分跟踪光电容积描记图的生物信号。</p><p id="29a1" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">最后一个模块是一个分类器，它通过一个演示来预测视频类别。如果模型预测了一个deepfake，那么它预测了用于生成的模型的最可能的架构。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/ce57f883eaf708672d6a03dcd1bf0149.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Qs331LU_aHaA133AbWlrQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><strong class="bd lh">Method Overview</strong>. From real videos (<strong class="bd lh">a</strong>), several generators (<strong class="bd lh">b</strong>) create deep fakes with residuals specific to each model (<strong class="bd lh">c</strong>). Our system extracts face ROIs (<strong class="bd lh">d</strong>) and biological signals (<strong class="bd lh">e</strong>), to create PPG cells (<strong class="bd lh">f</strong>) where the residuals are reflected in spatial and frequency domains. Then it classifies both the authenticity and the source of any video (<strong class="bd lh">c</strong>) by training on PPG cells and aggregating window predictions (<strong class="bd lh">g</strong>). Source: <a class="ae li" href="https://arxiv.org/pdf/2008.11363.pdf" rel="noopener ugc nofollow" target="_blank">Arxiv</a></figcaption></figure><p id="d5f3" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在<a class="ae li" href="https://stats.stackexchange.com/questions/380040/what-is-an-ablation-study-and-is-there-a-systematic-way-to-perform-it" rel="noopener ugc nofollow" target="_blank">消融研究</a>中，对真实视频的检测有7.64%的增长，这证实了功率谱的主要贡献:真实视频中生物信号的时空相关性在深度赝品中没有被保留，因此在真伪检测中有用。</p><div class="nc nd gp gr ne nf"><a href="https://www.datadriveninvestor.com/2020/11/27/deep-learning-amid-increased-physician-administrative-workload/" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd jd gy z fp nk fr fs nl fu fw jc bi translated">医生管理工作量增加时的深度学习|数据驱动的投资者</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">行政工作量是我们这个时代大多数医生所经历的众多负担之一。医生，尤其是…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="no l"><div class="nv l nq nr ns no nt lb nf"/></div></div></a></div><p id="54dc" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">与利用生成器架构或最后层进行残差分类的其他源检测方法相比，作者可以容易地扩展到新的模型，而不需要模型规范或假样本的真实对应物。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/9c138fdb021caf2faf904e3c593c9555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S7_Ny1IHLz9-X-8Gp0j39w.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Ablation Study. Video source detection accuracies without reals, without PSD part of PPG cells, without biological signals, and on full frames (not only faces). Source: <a class="ae li" href="https://arxiv.org/pdf/2008.11363.pdf" rel="noopener ugc nofollow" target="_blank">Arxiv</a></figcaption></figure><h1 id="9c7d" class="mg mh it bd lh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">原始文件</h1><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h1 id="5c71" class="mg mh it bd lh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">对深度学习感兴趣？</h1><p id="48c9" class="pw-post-body-paragraph lj lk it ll b lm mx kd lo lp my kg lr ls mz lu lv lw na ly lz ma nb mc md me im bi translated"><em class="mf">如果您觉得这篇文章有帮助，请点击💚或者👏按钮或分享关于脸书的文章，这样你的朋友也可以从中受益。</em></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ny nx l"/></div></figure><p id="72be" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><strong class="ll jd">访问专家视图— </strong> <a class="ae li" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="ll jd">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>