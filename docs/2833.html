<html>
<head>
<title>The 10x designer — Smart Automation with Kubric</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">10x designer——采用Kubric的智能自动化</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/the-10x-designer-smart-automation-with-kubric-295b7de20314?source=collection_archive---------10-----------------------#2020-05-18">https://medium.datadriveninvestor.com/the-10x-designer-smart-automation-with-kubric-295b7de20314?source=collection_archive---------10-----------------------#2020-05-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/943acc96593f35dffde9e1dabf3b0f32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qE-oE5YUnZ-05ls_.jpg"/></div></div></figure><p id="7549" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在Kubric，数据科学团队的最高标准是——“我们如何减少设计师花费在繁重工作上的时间？”。我们希望消除微编辑和质量检查中的繁重工作，以便设计师可以专注于对他们真正重要的东西——设计好的内容。围绕这一点，我们创造了一套微型工具来帮助设计师真正摆脱繁重的工作。如今，这为从食品到时尚等不同客户领域的数千名创意人员提供了动力。在这篇博客中，我将谈论一个这样的功能——自动定位。</p><p id="c6b7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">概述问题</strong></p><p id="2ddb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在Kubric，我们帮助内容团队扩大产量。去年，当我们分析我们的内容制作工作流程时，我们发现一些通过Kubric制作的内容是这样初始化的(注意无头模型)</p><figure class="la lb lc ld gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi kz"><img src="../Images/da1e3ac0d3961a1ac03d173c32667558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_lLp5cntACMgKE99.png"/></div></div></figure><p id="1fa5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">用户必须花费相当多的时间对准焦点对象的中心，然后找到图像的正确比例。大约在那个时候，twitter推出了他们的<a class="ae le" href="https://blog.twitter.com/engineering/en_us/topics/infrastructure/2018/Smart-Auto-Cropping-of-Images.html" rel="noopener ugc nofollow" target="_blank">智能作物</a>，他们解决的问题和我们的非常相似。从博客中获得灵感，我们能够快速实现类似的解决方案。图像开始看起来像这样-</p><figure class="la lb lc ld gt ju gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/e1910836531620ccbff43ff007165681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*hoOWO7JKbq33DZPx.png"/></div></figure><p id="46ee" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在发布初始版本后，我们收到反馈，虽然它确实为创意提供了更好的初始化，但它只专注于图像中非常小、最显著的部分，并为我们提供了一个非常粗糙的显著区域。他们想要对自动化有更多的控制。他们想控制-</p><ul class=""><li id="1ecd" class="lg lh it kd b ke kf ki kj km li kq lj ku lk ky ll lm ln lo bi translated">边界，</li><li id="5071" class="lg lh it kd b ke lp ki lq km lr kq ls ku lt ky ll lm ln lo bi translated">控制关注哪个对象而不是整个显著区域的能力</li><li id="be9c" class="lg lh it kd b ke lp ki lq km lr kq ls ku lt ky ll lm ln lo bi translated">指定感兴趣对象的对齐方式</li></ul><p id="96ea" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">反馈帮助我们更好地了解用户需求，我们带来了增强的实现。</p><p id="da94" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">显著物体检测</strong> -</p><p id="ed90" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于初始版本，我们使用了<a class="ae le" href="https://github.com/imatge-upc/salgan" rel="noopener ugc nofollow" target="_blank"> SalGAN模型</a>，但它只为我们提供了一个非常粗糙的显著图，我们需要一个更细粒度的显著图。因此，我们决定在开源显著性数据集上训练我们自己的模型(<a class="ae le" href="https://mmcheng.net/msra10k/" rel="noopener ugc nofollow" target="_blank"> msra </a>，<a class="ae le" href="http://saliencydetection.net/dut-omron/" rel="noopener ugc nofollow" target="_blank">DUT-欧姆龙</a>)。我们使用了基于<a class="ae le" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> Unet </a>的编码器-解码器<a class="ae le" href="https://arxiv.org/abs/1801.04381" rel="noopener ugc nofollow" target="_blank"> mobilenetV2 </a>结构，使用了惊人的<a class="ae le" href="https://github.com/qubvel/segmentation_models" rel="noopener ugc nofollow" target="_blank">分段模型</a>库。我们使用焦点损失进行训练，因为类别不平衡与显著性预测的上下文相关，对于显著性预测，地面真实显著性图主要由零或接近零组成，从而产生类似的现象。该方法类似于加权二进制交叉熵，除了权重是局部调整的，并且基于预测显著性的可调伽马幂。我们跟踪像素误差作为度量，这是显著性模型的标准度量。这就是萨尔根和我们的模型之间的结果差异</p><figure class="la lb lc ld gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lu"><img src="../Images/420058d0992a203e061d097a4cf67643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pViPrnKQ1FbdGdfh.png"/></div></div></figure><p id="7376" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">新模型也快得多<strong class="kd iu"> —我们将单个cpu实例的预测时间从平均1.5秒降低到0.3秒。</strong></p><p id="d646" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于对象检测，我们目前想要处理的大多数类都出现在这个<a class="ae le" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#open-images-trained-models" rel="noopener ugc nofollow" target="_blank">开源tensorflow模型</a>中。因此，我们决定使用这个模型。</p><div class="lv lw gp gr lx ly"><a href="https://www.datadriveninvestor.com/2020/02/27/how-to-use-automation-to-get-more-out-of-your-data/" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">如何使用自动化从您的数据中获得更多价值？数据驱动的投资者</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">去年的新闻故事不停地谈论机器学习变得多么先进。电脑现在…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm jz ly"/></div></div></a></div><h1 id="8ae8" class="mn mo it bd mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk bi translated">右侧边界框</h1><p id="46dd" class="pw-post-body-paragraph kb kc it kd b ke nl kg kh ki nm kk kl km nn ko kp kq no ks kt ku np kw kx ky im bi translated">我们面临的另一个问题是，图像中有多个显著的区域/对象，我们需要决定是否要组合、拒绝多个框。为此，我们实现了以下算法-</p><ol class=""><li id="7a77" class="lg lh it kd b ke kf ki kj km li kq lj ku lk ky nq lm ln lo bi translated">看这个盒子相对于图像有多大。如果小于阈值，则拒绝该盒子。</li><li id="5c42" class="lg lh it kd b ke lp ki lq km lr kq ls ku lt ky nq lm ln lo bi translated">取最大的盒子，在这个盒子和其他盒子之间创建一个距离矩阵。</li><li id="f26b" class="lg lh it kd b ke lp ki lq km lr kq ls ku lt ky nq lm ln lo bi translated">拒绝比阈值更远的盒子，并合并剩余的盒子。</li></ol><p id="f900" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是这样做后的结果</p><figure class="la lb lc ld gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nr"><img src="../Images/4e575403813d7223b72c02d5ef28fa8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jAAPvQYaaAS_VYvR"/></div></div></figure><p id="cb92" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">计算比例和位置- </strong></p><p id="1785" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在我们得到最大边界框的坐标后，来自自动建议请求的值被用来-</p><ol class=""><li id="2afd" class="lg lh it kd b ke kf ki kj km li kq lj ku lk ky nq lm ln lo bi translated">调整图像大小，保持纵横比</li><li id="eb64" class="lg lh it kd b ke lp ki lq km lr kq ls ku lt ky nq lm ln lo bi translated">对显著图进行阈值处理，并获得边界框的坐标</li><li id="cfec" class="lg lh it kd b ke lp ki lq km lr kq ls ku lt ky nq lm ln lo bi translated">计算比例，因为我们知道对象的边界以及边界框的坐标。</li><li id="05c5" class="lg lh it kd b ke lp ki lq km lr kq ls ku lt ky nq lm ln lo bi translated">计算将对象的当前边界框移动到图像中心所需的偏移量。计算后，需要对差异进行缩放。</li></ol><p id="23f5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">部署</strong></p><p id="c39e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ML部署的主题将会有自己的博客(订阅我们的博客以便在发布时得到通知！)但是为了完整起见，我们将在这里简要介绍一下它是如何工作的。</p><p id="59da" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们的ML模型部署为独立的微服务。模型被包装在Flask API中，gunicorn作为fork前的执行器运行。我们支持同步(调用者同步等待推断并保持HTTP连接打开)和异步部署(调用者发送消息请求推断，一旦推断完成，模型API引发事件通知调用者)。同步/阻塞API对于应用程序面向用户的部分至关重要，比如我们在这里讨论的自动定位功能。另一方面，对于资产丰富这样的事情，pubsub类型的异步部署更有意义。</p><p id="f742" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们对这个API进行docker化，docker映像通过我们的CI系统作为微服务部署到我们的Kubernetes集群。这个Kubernetes集群免费为我们提供了很多东西，比如基于CPU利用率的自动伸缩、滚动部署、A/B部署等。在我们看来，像Kubernetes这样的容器编排工具是任何生产机器学习工作负载的<em class="ns">非常</em>重要的一部分。这当然要求您有一个DevOps团队来维护您的基础架构。</p><p id="d845" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">动作中的自动定位</strong></p><p id="370b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为故事板启用这个特性的请求非常简单，并且直接嵌入到我们的编辑器中。</p><p id="4f26" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是一个请求的样子-</p><figure class="la lb lc ld gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/c135739a72f943ec4f48b03dc458dbab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*y-XkWLylihP3pjKT.png"/></div></div></figure><p id="c66d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">哪里-</p><p id="38ad" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> Canvas — </strong>使用<strong class="kd iu"> contain:True </strong>参数在镜头中包含<strong class="kd iu">的hero-img所在区域的坐标。x，Y是盒子左上角的坐标，w是盒子的宽度，h是高度。</strong></p><p id="57b2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">边界— </strong>主对象所在区域的坐标。x，Y是盒子左上角的坐标，w是盒子的宽度，h是高度。</p><p id="d260" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">要关注一个特定的对象，您需要做的就是将classes参数添加到上面的请求中。可以添加多个类来重点关注！</p><figure class="la lb lc ld gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/2a8f650bd323b0b8dcc5cbd5469e699e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*54bVZ-Y5YzVvOjk2.png"/></div></div></figure><p id="cafb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您可以在创建故事板时尝试自动定位的行为-</p><figure class="la lb lc ld gt ju"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="aaa8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">结果</strong> -</p><p id="46df" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是一个视频，展示了自动定位的功能</p><figure class="la lb lc ld gt ju"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="d0b1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">虽然自动定位仍处于迭代的初级阶段，但我们对它的可能性以及它如何节省繁重的编辑工作感到兴奋。😁</p><p id="6bb4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">前往我们的<a class="ae le" href="https://docs.kubric.io/docs" rel="noopener ugc nofollow" target="_blank">文档</a>了解更多此类功能。</p><p id="8bed" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">更多有趣的博客，请前往<a class="ae le" href="https://reads.kubric.io/" rel="noopener ugc nofollow" target="_blank"> Synapse </a>。</p><p id="6438" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="ns">我们正在招人！如果你对打造下一代创新科技感到不满，一定要写信给</em><a class="ae le" href="mailto:careers@kubric.io" rel="noopener ugc nofollow" target="_blank"><em class="ns">careers @ kubric . io</em></a><em class="ns">。</em></p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="6b34" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="ns">原载于2020年5月18日</em><a class="ae le" href="https://reads.kubric.io/p/80339590-cadd-41af-81f9-f5d553b64529/" rel="noopener ugc nofollow" target="_blank"><em class="ns">https://reads . kubric . io</em></a><em class="ns">。</em></p><figure class="la lb lc ld gt ju"><div class="bz fp l di"><div class="oe nw l"/></div></figure></div></div>    
</body>
</html>