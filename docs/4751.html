<html>
<head>
<title>How Did Google Researchers Beat ImageNet While Using Fewer Resources?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌研究人员是如何在使用较少资源的情况下击败ImageNet的？</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/how-did-google-researchers-beat-imagenet-while-using-fewer-resources-267243071ee4?source=collection_archive---------4-----------------------#2020-08-22">https://medium.datadriveninvestor.com/how-did-google-researchers-beat-imagenet-while-using-fewer-resources-267243071ee4?source=collection_archive---------4-----------------------#2020-08-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b102" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">他们发明了新模型吗？请继续阅读…</h2></div><p id="e103" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了帮助我了解您<a class="ae le" href="https://forms.gle/7MfQmKhEhyBTMDUD7" rel="noopener ugc nofollow" target="_blank">请填写此调查(匿名)</a></p><p id="d735" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图像分类算法主要通过使用更多的资源(数据、计算能力和时间)而变得更好。最好的算法使用额外的<strong class="kk iu">35亿张标签图像。</strong> <a class="ae le" href="https://arxiv.org/abs/1911.04252" rel="noopener ugc nofollow" target="_blank">本文</a>，由谢启哲等人撰写。它能够击败当前的算法，同时仅使用<em class="lf">额外的<strong class="kk iu"> 300 M未标记图像</strong>(两种算法都使用相同的标记图像数据集，在其上我们分别有额外的3.5 B和300 M图像)<strong class="kk iu">。</strong>这意味着新方法使用了<strong class="kk iu"> 12倍于</strong>的较小图像，同时也不需要对这些图像进行标记。因此，它便宜很多很多倍，但效果更好。</em></p><h2 id="2c8e" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">这个团队有什么不同？</h2><p id="ff7a" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">要理解这篇论文和实验设置，请观看这个视频。</p><figure class="me mf mg mh gt mi"><div class="bz fp l di"><div class="mj mk l"/></div></figure><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/d197b3b48b52d8ceb29c5a88ca5f7543.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*7I_9xFVMpgtWbIF64NmgZg.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">An illustration from the paper showing how they trained their models</figcaption></figure><p id="0fdc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从表面上看，他们的方法似乎是标准的SSL。他们优异表现的关键在于训练前和训练中采取的步骤。无标签学生模型比老师大。该团队还将<strong class="kk iu">不同类型的噪声</strong>注入到数据和模型中，<em class="lf">确保每个学生比他们的老师学到更多类型的数据分布</em>。这与迭代训练相结合特别有效，因为这利用了不断提高的教师。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi ms"><img src="../Images/8b3fddbc28ac0951ca1414434acf1dab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oCuhNHmgOGRSAcwhPOzR0Q.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Noisy Student uses lesser extra Data still outperforms. Looks like ResNet was ended.</figcaption></figure><h2 id="029b" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">关于那噪音</h2><p id="ca9b" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi mx translated">由于我们已经在本次培训中确立了噪音的重要性，所以了解不同种类的噪音也很重要。有两大类噪声可以实现。<strong class="kk iu">模型噪音</strong>是指在训练过程中对模型进行干扰。这可以防止过度拟合，并通过允许模型从不同的“角度”评估数据，实际上可能会提高准确性和稳健性。另一种称为<strong class="kk iu">输入噪声</strong>，在这种情况下，您会向输入端注入噪声。研究人员特别使用RandAugment来实现这一点。这有两个目的，一是增加数据的多样性，二是提高预测的准确性(特别是对于真实世界的数据，这是非常嘈杂的)。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/9b2038f651ceda1324d257167c2fc765.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*OYMgca0tYkuhFQBE.gif"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Real Picture of the researchers in this paper</figcaption></figure><h2 id="5240" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">图表1:输入噪声的随机增大</h2><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi nh"><img src="../Images/62a89f01f50e3001f42b66973ab2eccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gnS0t3kHTvQFBHNH.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">The GOAT at work</figcaption></figure><p id="7b0e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">世界上有一些非常复杂的噪声函数。RandAugment不在其中。不过不要被愚弄了，这是最有效的算法之一。它以一种非常容易理解的方式工作。想象一下，有N种方法可以扭曲一幅图像。这可以是任何事情，从改变一些像素为白色，到沿轴剪切。RandAugment采用2个输入(n，m ),其中n是应用的失真数量，m是失真的幅度。它返回最终图像。失真是随机应用的，通过增加可变性来增加噪声。</p><p id="5ebb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在该图中，我们看到RandAugment在不同的幅度下仅应用了两个(固定的)变换。这三个样本已经非常不同了。不需要天才就能算出通过改变多个图像的两个值可以得到多少(答案:很多)。不应忽视数据扩充。这也确保了学生模型总是至少和老师一样大，因此需要更少</p><h2 id="1522" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">附件2:模型噪声的损失</h2><p id="cce6" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">辍学是一个过程中使用的神经网络等。它的过程非常容易描述:每次运行网络时忽略一些神经元。图片:</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi ni"><img src="../Images/271f29855451434f956c71d7870a3a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yIGb-kfxCAK0xiXipo6utA.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Standard DropOut Procedure</figcaption></figure><p id="49f6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">应用放弃是因为它停止过度拟合。通过忽略不同的单位，你改变了输出。反馈使它能够更好地概括。此外，可以实现dropout来创建来自一个网络的迷你学习者列表。通过集成，迷你学习者可以胜过父网络。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/1bb41fbada73c5e0beb13774efa075b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*sNI4UwojF0F1cZC7aWG-Nw.jpeg"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">The Mini-learner Ensemble to the parent network</figcaption></figure><h2 id="74d2" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">附件3:模型噪声的随机深度</h2><p id="e455" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi mx translated">坦率地说，我对这个概念不是很熟悉。但是，嘿，这就是谷歌的目的。对此进行解读是令人惊讶的。这可能是整篇论文中我最喜欢的东西。如果我必须重新开始只有一个记忆的生活，这将是它。现在我们已经建立了宣传…</p><p id="1a48" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随机深度包括以下步骤。</p><ol class=""><li id="4a5c" class="nk nl it kk b kl km ko kp kr nm kv nn kz no ld np nq nr ns bi translated">从非常深的网络开始</li><li id="bce9" class="nk nl it kk b kl nt ko nu kr nv kv nw kz nx ld np nq nr ns bi translated">在训练期间，对于每个小批量，随机丢弃一个层子集，并使用identity函数绕过它们。</li><li id="6fac" class="nk nl it kk b kl nt ko nu kr nv kv nw kz nx ld np nq nr ns bi translated">重复(如果需要)</li></ol><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi ny"><img src="../Images/704399f89e75a37749754f5f2b812d31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PVvbbur5XMBjwY-xiNITvQ.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Since we love visualizations</figcaption></figure><p id="d24e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这似乎非常类似于辍学。在某种程度上的确如此。可以把它想象成深度网络的放大版。但是，确实有效。<em class="lf">“它大大减少了训练时间，并显著改善了我们用于评估的几乎所有数据集的测试误差。利用随机深度，我们可以增加剩余网络的深度，甚至超过1200层，并且仍然可以在测试误差方面产生有意义的改进(在CIFAR-10上为4.91 %)。”这一点我不能否认。将很快对此进行深入研究。现在，看看这个图的绘图错误:</em></p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/7d393be7abff86461ae5efbb8631a4dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*_YrjMamOibvQETdDce2QbA.jpeg"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">See that Billy? That is Peak Performance</figcaption></figure><p id="7056" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这三种噪音都以独特的方式对训练有所贡献。这三种方法都通过增加输入的变化来增加预测的稳健性。这是它在健壮性方面区别于所有其他先进模型的地方。事实上，它们非常有效，即使没有迭代训练过程，该过程也能够改进当前的网络技术水平(更多细节请见第2部分)。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/cce19a4f9a22f34b362f10c7b7b427d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*EmRYEIleBvIsOGYjRmWPCQ.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Just applying noise has consistent improvements.</figcaption></figure><h1 id="0c4d" class="ob lh it bd li oc od oe ll of og oh lo jz oi ka lr kc oj kd lu kf ok kg lx ol bi translated">培训过程</h1><p id="0c85" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">现在我们已经了解了不同的步骤和调整是如何改进分类的，我们应该研究一些实现细节。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi om"><img src="../Images/9c8d7f5d688a1e93c9d6b79f73a51750.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*3IaQ-qqha9EDqa69u6bk4w.png"/></div></figure><p id="c565" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对我来说，训练中最重要的部分是第三步。研究人员表示<em class="lf">“具体来说，在我们的方法中，教师通过读取干净的图像来产生高质量的伪标签，而</em> <strong class="kk iu"> <em class="lf">学生需要复制那些带有增强图像的标签作为输入</em> </strong> <em class="lf">。”正如我们所见，给图像(或模型)添加噪声会极大地改变它们的外观。通过强迫学生使用增强图像，它允许模型以很高的准确性预测非常不清晰的图像。这方面的细节将在第2部分。但是现在，这里有一个例子来说明这对于预测模糊图像是多么重要。</em></p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi on"><img src="../Images/5e282ccfe17fea8cea5a41a9941e13c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HpecYS_dOEZJAMsMqInyBA.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Take my money already, you beautiful model</figcaption></figure><h1 id="9159" class="ob lh it bd li oc od oe ll of og oh lo jz oi ka lr kc oj kd lu kf ok kg lx ol bi translated">后续步骤</h1><p id="76f5" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">请在下面留下您对这篇文章的反馈。如果这对你有用，请分享并跟我来这里。</p><p id="e088" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">查看我在Medium上的其他文章。:<a class="ae le" href="https://rb.gy/oaojch" rel="noopener ugc nofollow" target="_blank">https://rb.gy/zn1aiu</a></p><p id="9602" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我的YouTube。这是一个正在进行中的工作哈哈:<a class="ae le" href="https://rb.gy/88iwdd" rel="noopener ugc nofollow" target="_blank">https://rb.gy/88iwdd</a></p><p id="c316" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在LinkedIn上联系我。我们来连线:<a class="ae le" href="https://rb.gy/m5ok2y" rel="noopener ugc nofollow" target="_blank">https://rb.gy/m5ok2y</a></p><p id="e016" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我的推特:<a class="ae le" href="https://twitter.com/Machine01776819" rel="noopener ugc nofollow" target="_blank">https://twitter.com/Machine01776819</a></p><p id="b327" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我的子任务:<a class="ae le" href="https://devanshacc.substack.com/" rel="noopener ugc nofollow" target="_blank">https://devanshacc.substack.com/</a></p><p id="6dd2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想和我一起工作，请发邮件给我:devanshverma425@gmail.com</p><p id="8b48" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">twitch现场对话:<a class="ae le" href="https://rb.gy/zlhk9y" rel="noopener ugc nofollow" target="_blank">https://rb.gy/zlhk9y</a></p><p id="ca59" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">获取我的内容更新-insta gram:<a class="ae le" href="https://rb.gy/gmvuy9" rel="noopener ugc nofollow" target="_blank">https://rb.gy/gmvuy9</a></p><p id="8ba7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">获得罗宾汉的免费股票:<a class="ae le" href="https://www.youtube.com/redirect?redir_token=QUFFLUhqa0xDdC1jTW9nSU91WXlCSFhEVkJ0emJvN1FaUXxBQ3Jtc0ttWkRObUdfem1DZzIyZElfcXVZNGlVNE1xSUc4aVhSVkxBVGtHMWpmei1lWWVKNzlDUXVJR24ydHBtWG1PSXNaMlBMWDQycnlIVXNMYjJZWjdXcHNZQWNnaFBnQUhCV2dNVERQajFLTTVNMV9NVnA3UQ%3D%3D&amp;q=https%3A%2F%2Fjoin.robinhood.com%2Ffnud75&amp;v=WAYRtSj0ces&amp;event=video_description" rel="noopener ugc nofollow" target="_blank">https://join.robinhood.com/fnud75</a></p><p id="bee6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是承诺的文件。请务必下载并阅读它，因为我已经定义了重要的定义并强调了关键部分。这会帮助你更好地理解这篇论文。</p><figure class="me mf mg mh gt mi"><div class="bz fp l di"><div class="oo mk l"/></div></figure></div></div>    
</body>
</html>