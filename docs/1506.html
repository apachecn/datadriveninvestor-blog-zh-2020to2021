<html>
<head>
<title>Reinforcement Learning Using Quantum Computing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用量子计算的强化学习</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/reinforcement-learning-using-quantum-computing-361a977c641d?source=collection_archive---------3-----------------------#2020-03-20">https://medium.datadriveninvestor.com/reinforcement-learning-using-quantum-computing-361a977c641d?source=collection_archive---------3-----------------------#2020-03-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="f253" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要理解这篇文章，你必须知道强化学习的基础，比如代理q值和目标值的概念。你脑海中可能出现的一个普遍问题是，为什么我们使用量子来训练我们的强化学习模型，你可以通过阅读整篇文章来找到答案，所以让我们在量子世界中开始你的机器学习之旅。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="ab gu cl kq"><img src="../Images/383d367a97fbfebf78e5d5862a451bbc.png" data-original-src="https://miro.medium.com/v2/format:webp/0*lQqD2CbJYkaGALBZ.png"/></div></figure><p id="b07a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">量子电路的第一个也是最重要的品质是，它比传统的神经网络需要更少的参数，这使它们有望模拟复杂的环境。对于目标网络，我采用一个冰冻湖泊的架构。</p><p id="17dd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kt" href="https://gym.openai.com/envs/FrozenLake-v0/" rel="noopener ugc nofollow" target="_blank">https://gym.openai.com/envs/FrozenLake-v0/</a></p><p id="1202" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目标电路每20步更新一次。对于经验重放，重放存储器的长度设置为80，以适应测试环境。优化过程需要计算量子测量的期望值的梯度，这可以通过相同的电路架构和略微不同的参数来进行</p><p id="e57a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在冰湖环境中，总共有16个状态。因此，它需要4个量子位来代表所有状态。我希望你们都明白量子位的意义。</p><p id="f88b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">环境方面的行动和奖励如下:</p><p id="d68b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">动作:动作空间中有四个动作。量子电路的输出是0、1、2、3，它们对应于左、下、右、上的动作</p><p id="7501" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">奖励:在这种环境下，成功实现目标的奖励为+1.0，任务失败的奖励为-0.2，即步入洞中。此外，为了鼓励代理人走最短的路径，每走一步还有0.01英镑的奖励。</p><div class="ku kv gp gr kw kx"><a href="https://www.datadriveninvestor.com/2019/02/08/machine-learning-in-finance/" rel="noopener  ugc nofollow" target="_blank"><div class="ky ab fo"><div class="kz ab la cl cj lb"><h2 class="bd ir gy z fp lc fr fs ld fu fw ip bi translated">金融中的机器学习|数据驱动的投资者</h2><div class="le l"><h3 class="bd b gy z fp lc fr fs ld fu fw dk translated">在我们讲述一些机器学习金融应用之前，我们先来了解一下什么是机器学习。机器…</h3></div><div class="lf l"><p class="bd b dl z fp lc fr fs ld fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="lg l"><div class="lh l li lj lk lg ll kr kx"/></div></div></a></div><blockquote class="lm ln lo"><p id="2124" class="jn jo lp jp b jq jr js jt ju jv jw jx lq jz ka kb lr kd ke kf ls kh ki kj kk ij bi translated"><strong class="jp ir">内存消耗上的量子优势:</strong>在基于神经网络的深度Q学习中，对于冰湖环境，参数个数将为2 × N2 + 2 × N。但有了量子电路，电路参数的数量减少到N × (3 × 2 + 1)。</p></blockquote><p id="5003" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我选择的优化是成为RMSprop，学习率= 0.01，alpha = 0.4，eps = 1，广泛应用于深度强化学习。体验回放的批量大小是5。冰湖中使用的ε-贪婪策略如下:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/85a271eb02738649de6202ce3d18fad8.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*ejRA4LbTQ7LumntiupLu1w.png"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/4c8f182d91b876c3ee5a2df013d3232f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*8YUmgtpKuw4dd4OT06kvqg.png"/></div></figure><p id="6c1a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">奖励集中在300集，所以不需要训练更多，快乐编码。</p><p id="726d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章的所有代码都在我的github上:<a class="ae kt" href="https://github.com/AFNANAMIN/AI_Freelancing/blob/master/Reinforcement_Learning_with_Quantum_Computing.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/AFNANAMIN/AI _ Freelancing/blob/master/Reinforcement _ Learning _ with _ Quantum _ computing . ipynb</a></p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="lv lw l"/></div></figure></div></div>    
</body>
</html>