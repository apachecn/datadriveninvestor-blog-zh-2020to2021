<html>
<head>
<title>Introduction to Meme Classification using PyTorch and fastText</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch和fastText的模因分类介绍</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/introduction-to-meme-classification-using-pytorch-and-fasttext-e667a81b5e0?source=collection_archive---------5-----------------------#2020-11-15">https://medium.datadriveninvestor.com/introduction-to-meme-classification-using-pytorch-and-fasttext-e667a81b5e0?source=collection_archive---------5-----------------------#2020-11-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="fd50" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated"><strong class="jt ir">简介</strong></p></blockquote><ul class=""><li id="b4d9" class="kp kq iq jt b ju jv jy jz kr ks kt ku kv kw ko kx ky kz la bi translated"><strong class="jt ir">为什么要进行模因分类？</strong></li></ul><p id="d500" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">迷因可以成为有趣的内容。但是对一个人来说很有趣的内容对另一个人来说可能是讨厌的。有些人还故意创造一个迷因，其突出目的是传播对一个社区或一个人的仇恨。</p><p id="aba3" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">因为社交媒体的内容覆盖范围不限于任何人。阅读模因在大学生的生活中是很常见的。然而，许多人在社交媒体网站上分享令人反感的模因，鼓励他们的想法。这种模因试图取笑目标个人或群体。这种迷因的想法和陈述应该被制止，否则就太晚了。许多学生阅读这样的模因，并可能接受这个想法是可以接受的。来自世界各地的数据分析师正试图解决识别这些模因的问题。</p><p id="cb6b" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">虽然迷因分类的问题可以是多类的，但为了简单起见，为了让你对如何处理视觉和语言数据有所了解，我们将首先确定给定的迷因是否是可恨的？(二元分类)</p><p id="7aa7" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">欢迎来到这个增强的领域🐱‍🚀按照时间顺序，我们在我们的研究领域应用了全球平台上一些最佳实践技术。</p><p id="51a5" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">不要再拖延了，让我们看看如何解决这个问题吧！✌</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><blockquote class="jn jo jp"><p id="0390" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated"><strong class="jt ir">数据预处理:</strong></p></blockquote><p id="ded2" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">如果你是新手，想知道事情如何🤷‍♀️使用Pytorch和FastText，我推荐你花几分钟阅读Pytorch _tutorials和fasttext _ tutorial📰极客不用担心我们有一个<a class="ae li" href="https://www.youtube.com/playlist?list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq" rel="noopener ugc nofollow" target="_blank"> PyTorch_youtube </a>📽给你的播放列表，看看吧。</p><p id="71f2" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">我们将使用由Drivendata脸书仇恨迷因挑战赛提供的数据集。该数据集仅提供给竞争对手，由于公平内容政策，尚未外包。</p><p id="b3b2" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">该数据集由8500幅图像组成，每幅图像都有一个唯一的id和一个给定的标签，以确定给定的图像是否有毒？</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lj"><img src="../Images/9325a6aa9ab400111811773b89f12d9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZeoBbpeRnsTa4cB0J-Bvtw.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk">Image taken from Facebook AI Meme Classification challenge dataset.</figcaption></figure><ul class=""><li id="5a7d" class="kp kq iq jt b ju jv jy jz kr ks kt ku kv kw ko kx ky kz la bi translated">上面是一个给定的迷因图像，为了研究这个，我们首先要从给定的图像中提取文本。我们将使用一些最好的在线OCR工具从给定的图像中抓取文本。我们也可以制作自己的OCR模型来做同样的事情。</li><li id="f8d9" class="kp kq iq jt b ju lz jy ma kr mb kt mc kv md ko kx ky kz la bi translated">数据集中给定的图像大小不同，我们将使用torchvision.transform将所有给定图像的大小调整为dim (224*224*3)，因为不同大小的图像通常难以处理。</li></ul><p id="f922" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">现在，我们必须独立处理图像和文本数据，因为解决方案不能只依赖于图像或文本。只有将两者结合起来，才能理解其背后的含义。</p><p id="75ce" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">幸运的是PyTorch已经有一个内置的数据集类，你可以通过这篇简短的<a class="ae li" href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html" rel="noopener ugc nofollow" target="_blank">教程</a>来了解这个类的架构。</p><p id="2662" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">令人惊奇不是吗？🧙‍♂️You不知道PyTorch还能提供什么！</p><p id="c02d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">我们希望数据集返回准备好用于模型输入的数据，这意味着我们需要准备:</p><ul class=""><li id="cd18" class="kp kq iq jt b ju jv jy jz kr ks kt ku kv kw ko kx ky kz la bi translated">应用<code class="fe me mf mg mh b">image_transform</code>的图像</li><li id="9da0" class="kp kq iq jt b ju lz jy ma kr mb kt mc kv md ko kx ky kz la bi translated">应用<code class="fe me mf mg mh b">text_transform</code>文本</li></ul><p id="7e33" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">上面介绍了<code class="fe me mf mg mh b">image_transform</code>，而<code class="fe me mf mg mh b">text_transform</code>将是我们的fastText模型创建的“句子向量”。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><blockquote class="jn jo jp"><p id="6d0f" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated"><strong class="jt ir">提议的方法:</strong></p></blockquote><ol class=""><li id="5e8f" class="kp kq iq jt b ju jv jy jz kr ks kt ku kv kw ko mi ky kz la bi translated">要解决这个问题，一个简单的方法是在我们的image_transform数据集上应用图像字幕，并将其转换为文本。然后应用各种NLP技术，把它当成一个情感分析问题。</li></ol><ul class=""><li id="ec99" class="kp kq iq jt b ju jv jy jz kr ks kt ku kv kw ko kx ky kz la bi translated">关于图像字幕可以参考博客:<a class="ae li" href="https://medium.com/analytics-vidhya/introduction-to-image-caption-generation-using-the-avengers-infinity-war-characters-6f14df09dbe5" rel="noopener">https://medium . com/analytics-vid hya/introduction-to-Image-caption-generation-using-the-Avengers-infinity-war-characters-6 f 14 df 09 DBE 5</a></li><li id="a9ec" class="kp kq iq jt b ju lz jy ma kr mb kt mc kv md ko kx ky kz la bi translated">进一步的情感分析可以参考使用LSTM <a class="ae li" href="https://medium.com/@sthacruz/fake-news-classification-using-glove-and-long-short-term-memory-lstm-a48f1dd605ab" rel="noopener">创建的FakeNews分类器https://medium . com/@ sthacruz/fake-news-classification-using-glove-and-long-short-term-memory-lstm-a 48 f1 DD 605 ab</a></li></ul><p id="1a5b" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">上述解决方案似乎可行和直接，但我们将创建一个多式联运模式。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/45badfda949fd4774525e3cbc1962abc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*hlUorAyYT-4uNB1zwJZKbg.png"/></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk"><em class="mk">In mid-level fusion by concatenation, input data modes pass through their respective modules after which their features are concatenated. The multimodal features are then passed through a classifier.</em></figcaption></figure><p id="3b0f" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">因此，在这种方法中，我们将从我们的image_transform和text_transform中提取特征，并将它们融合在一起，从而形成1个特征向量，并进一步将其作为输入传递给我们的神经网络分类器进行预测。</p><p id="4048" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">以上设计称为<strong class="jt ir"> <em class="js">中级concat融合。</em>T15】</strong></p><p id="4bc1" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">为了创建这种定制的融合，我们可以再次感谢PyTorch，因为它允许我们根据各自的需要创建定制的模块。参考本<a class="ae li" href="https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html" rel="noopener ugc nofollow" target="_blank">指南</a>并尝试执行。</p><ul class=""><li id="6af6" class="kp kq iq jt b ju jv jy jz kr ks kt ku kv kw ko kx ky kz la bi translated">在我们的<code class="fe me mf mg mh b">LanguageAndVisionConcat</code>架构中，我们将通过图像模型运行我们的图像数据模式，将最后一组特征表示作为输出，然后对我们的语言模式也是如此。然后，我们将连接这些特征表示，并将其视为一个新的特征向量，并通过最终的全连接图层进行分类。</li><li id="caa2" class="kp kq iq jt b ju lz jy ma kr mb kt mc kv md ko kx ky kz la bi translated">有关语言和视觉模块的定义，请参见<code class="fe me mf mg mh b">_build_model</code>方法。语言模块将使用<code class="fe me mf mg mh b">fasttext</code>嵌入作为输入，在我们的数据生成器中计算为<code class="fe me mf mg mh b">text_transform</code>(为了简单起见，我们将保持嵌入固定，尽管它们适合我们的训练数据)。语言模块的输出将来自可训练的<code class="fe me mf mg mh b">Linear</code>层，作为在训练期间微调嵌入表示的一种方式。视觉模块输入将是标准化图像，在我们的数据生成器中计算为<code class="fe me mf mg mh b">image_transform</code>，输出将是<a class="ae li" href="https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035" rel="noopener" target="_blank"> ResNet </a>模型的输出。</li></ul></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><blockquote class="jn jo jp"><p id="a2a2" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated"><strong class="jt ir">结果和讨论:</strong></p></blockquote><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi ml"><img src="../Images/671e6ee9522a9505e3dbeb03c84c311d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*98n1rlUT3Inc2jLdxmx4-Q.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk">Results gained from the above discussed architecture</figcaption></figure><ul class=""><li id="9224" class="kp kq iq jt b ju jv jy jz kr ks kt ku kv kw ko kx ky kz la bi translated"><strong class="jt ir">为什么b/w两种方法的准确性有很大差异？</strong></li></ul><p id="e144" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">这是因为我们在天真的方法中使用的图像字幕模型还没有完全开发出来，研究仍在继续以提高其准确性。到目前为止，这个模型只有70%的准确率，所以这就是为什么在将图像转换成文本时，一些预处理过的数据会丢失或不相关。</p><p id="58a1" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">但是在多模态的情况下，我们不是将一种形式转换成另一种形式，而是按照要求提取特征，并相应地进行实验，从而相对地给我们更高的准确性。</p><ul class=""><li id="6d03" class="kp kq iq jt b ju jv jy jz kr ks kt ku kv kw ko kx ky kz la bi translated">虽然有更多的实践可以产生更好的结果，但这些都有点复杂，为了理解它，你应该有基本的特征提取和多模态方法的知识来提高你的学习。</li></ul></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><blockquote class="jn jo jp"><p id="fdd7" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated"><strong class="jt ir">结论和概述</strong>:</p></blockquote><p id="5ecd" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">由于仇恨迷因问题是多模态的，即它由视觉<strong class="jt ir">和</strong>语言数据模式组成，因此访问不同的视觉和语言模型将是有用的。</p><p id="5d45" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated"><strong class="jt ir">视觉模型和实用程序。</strong> <code class="fe me mf mg mh b">torchvision</code> by <a class="ae li" href="https://pytorch.org/docs/stable/torchvision/index.html" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>由流行的数据集、模型架构(包括预训练的权重)和常见的图像变换组成。如果你用PyTorch解决计算机视觉问题，这是必不可少的。</p><p id="ca8d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated"><strong class="jt ir">语言模型和实用程序。</strong> <code class="fe me mf mg mh b">fasttext</code> by <a class="ae li" href="https://fasttext.cc/" rel="noopener ugc nofollow" target="_blank">脸书人工智能</a>让为你的数据训练嵌入变得容易。</p><p id="9a1b" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated">我们使用<code class="fe me mf mg mh b">torchvision</code>视觉模型从模因图像中提取特征，使用<code class="fe me mf mg mh b">fasttext</code>模型从属于图像的提取文本中提取特征。这些语言和视觉特征被<strong class="jt ir">用<code class="fe me mf mg mh b">torch</code>融合</strong>在一起，形成了一个多模态仇恨模因分类器。</p><p id="b56f" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated"><strong class="jt ir">对于一个人来说，检测给定的内容是否令人讨厌的准确率是80%,相对于此，我们在test_data上获得了59.81%的准确率，这是一个可接受的分数。</strong></p><blockquote class="jn jo jp"><p id="0074" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">如果你发现在实现上述实际问题的解决方案时有困难，我已经附上了github <a class="ae li" href="https://github.com/Vib-UX/Meme-Classification" rel="noopener ugc nofollow" target="_blank">链接</a>用于两种方法的相同实现。</p></blockquote><p id="e959" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kr kd ke kf kt kh ki kj kv kl km kn ko ij bi translated"><strong class="jt ir"> <em class="js">感谢您的宝贵时间🙌，请随意在下面写下任何建议…如果你觉得你获得了一些知识，别忘了鼓掌👏</em> </strong></p></div></div>    
</body>
</html>