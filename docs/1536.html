<html>
<head>
<title>Creating A Custom Data Generator In Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Keras中创建自定义数据生成器</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/creating-a-custom-data-generator-in-keras-534fd3098a58?source=collection_archive---------1-----------------------#2020-03-22">https://medium.datadriveninvestor.com/creating-a-custom-data-generator-in-keras-534fd3098a58?source=collection_archive---------1-----------------------#2020-03-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/></div><div class="ab cl jn jo hu jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ij ik il im in"><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi ju"><img src="../Images/fb0a563d26d4578ba10798b9642120b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7f-DBw08Dd8Xrigj"/></div></div><figcaption class="kg kh gj gh gi ki kj bd b be z dk">(Pic Source Unsplash)</figcaption></figure><p id="cddc" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">这是数据时代。随着大量数据的出现，有时我们对内存有很高的要求。当训练深度学习模型时，我们还需要大量数据来让模型创建任何有意义的东西。但是由于我们内存的限制，如果数据很大的话，不可能把所有的数据都加载到内存中。如果我们将所有数据都加载到内存中，很可能会耗尽内存。因此，我们不得不寻找一种替代方法，而不是将全部数据加载到内存中。</p><h1 id="de09" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">自定义数据生成器:</h1><p id="0c2d" class="pw-post-body-paragraph kk kl iq km b kn mg kp kq kr mh kt ku kv mi kx ky kz mj lb lc ld mk lf lg lh ij bi translated">如果我们加载部分数据，而不是将全部数据加载到内存中，会怎么样？所以我们会把数据分批次。并在需要时将每一批数据加载到内存中。这样我们可以节省大量的内存，剩下的部分ram可以用来训练模型。在深入研究keras的定制数据生成器之前，让我们先了解一下python生成器。</p><div class="ml mm gp gr mn mo"><a href="https://www.datadriveninvestor.com/2019/01/23/deep-learning-explained-in-7-steps/" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd ir gy z fp mt fr fs mu fu fw ip bi translated">深度学习用7个步骤解释-更新|数据驱动的投资者</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">在深度学习的帮助下，自动驾驶汽车、Alexa、医学成像-小工具正在我们周围变得超级智能…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc ke mo"/></div></div></a></div><h2 id="6be9" class="nd lj iq bd lk ne nf dn lo ng nh dp ls kv ni nj lw kz nk nl ma ld nm nn me no bi translated">Python生成器:</h2><p id="235a" class="pw-post-body-paragraph kk kl iq km b kn mg kp kq kr mh kt ku kv mi kx ky kz mj lb lc ld mk lf lg lh ij bi translated">生成器类似于python中的任何其他函数，但它没有使用<strong class="km ir"> <em class="np"> return </em> </strong>关键字，而是使用了<strong class="km ir"> <em class="np"> yield </em> </strong>关键字。<strong class="km ir"> <em class="np"> return </em> </strong>关键字终止函数并完全返回所有值，而yield关键字保存状态并从该处继续。另外需要注意的一点是yield关键字返回一个对象，该对象的值可以通过使用<strong class="km ir"> <em class="np"> next() </em> </strong>方法来访问。所以基本上这些生成器帮助我们节省了RAM，因为它不像return语句那样一次返回所有的值。下面的程序给出了一个python生成器的例子。</p><pre class="jv jw jx jy gt nq nr ns nt aw nu bi"><span id="3409" class="nd lj iq nr b gy nv nw l nx ny">def gen(n):<br/> for i in range(n):<br/>   yield i</span><span id="1308" class="nd lj iq nr b gy nz nw l nx ny">g=gen(2)</span><span id="0604" class="nd lj iq nr b gy nz nw l nx ny">print(g.__next()__)<br/>print(g.__next()__)</span></pre><p id="83da" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">在上面的代码片段中，第一条print语句输出的值是0，而第二条print语句输出的值是1。当函数产生一个值时，在保存状态之后，控制被转移到调用者。</p><p id="8075" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">现在我们对python生成器的工作原理有了一点了解，让我们创建一个定制的数据生成器。为此，我们将创建一个<strong class="km ir"> <em class="np">数据生成器</em> </strong>类，它将继承<strong class="km ir"><em class="np">keras . utils . sequence</em></strong>类。我们可以创建一个构造函数来初始化参数。让我们看看下面的代码片段。</p><pre class="jv jw jx jy gt nq nr ns nt aw nu bi"><span id="eb68" class="nd lj iq nr b gy nv nw l nx ny">def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,<br/> n_classes=10, shuffle=True):<br/> ‘Initialization’<br/> self.dim = dim<br/> self.batch_size = batch_size<br/> self.labels = labels<br/> self.list_IDs = list_IDs<br/> self.n_channels = n_channels<br/> self.n_classes = n_classes<br/> self.shuffle = shuffle<br/> self.on_epoch_end()</span></pre><p id="8d94" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">正如我们所看到的，我们已经初始化了参数，其中包括关于数据的相关信息，如批量大小、标签、通道数量、类别等。现在让我们来看看_epoch_end上的方法<strong class="km ir"> <em class="np">。</em> </strong>让我们看看同样的功能。</p><pre class="jv jw jx jy gt nq nr ns nt aw nu bi"><span id="372f" class="nd lj iq nr b gy nv nw l nx ny">def on_epoch_end(self):<br/>  self.indexes = np.arange(len(self.list_IDs))<br/>  if self.shuffle == True:<br/>    np.random.shuffle(self.indexes)</span></pre><p id="1465" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">该方法在每个历元之后更新索引。此外，shuffle=True参数可确保不同时期之间的批次不同。</p><p id="cf84" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">还可以看看下面的方法，它得到每批的历元数。</p><pre class="jv jw jx jy gt nq nr ns nt aw nu bi"><span id="d42d" class="nd lj iq nr b gy nv nw l nx ny">def __len__(self):<br/> return int(np.floor(len(self.list_IDs) / self.batch_size))</span></pre><p id="69f3" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">数据生成的核心是方法<strong class="km ir"><em class="np">_ _数据生成</em> </strong>。它生成包含数据样本的数据。看看下面的代码片段。</p><pre class="jv jw jx jy gt nq nr ns nt aw nu bi"><span id="365f" class="nd lj iq nr b gy nv nw l nx ny">def __data_generation(self, list_IDs_temp):<br/> ‘Generates data containing batch_size samples’ # X : (n_samples, *dim, n_channels)<br/> # Initialization<br/> X = np.empty((self.batch_size, *self.dim, self.n_channels))<br/> y = np.empty((self.batch_size), dtype=int)</span><span id="4635" class="nd lj iq nr b gy nz nw l nx ny"># Generate data<br/> for i, ID in enumerate(list_IDs_temp):<br/> # Store sample<br/> X[i,] = np.load(‘data/’ + ID + ‘.npy’)</span><span id="833e" class="nd lj iq nr b gy nz nw l nx ny"># Store class<br/> y[i] = self.labels[ID]</span><span id="5d58" class="nd lj iq nr b gy nz nw l nx ny">return X, keras.utils.to_categorical(y, num_classes=self.n_classes)</span></pre><p id="eb2b" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">这种方法有助于生成批量数据。作为一个参数，它接受目标批处理的id。The keras.utils.to _ categorical生成标签的一次性编码值。</p><p id="c283" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">最后，为了生成所有的数据，我们将使用下面的方法。</p><pre class="jv jw jx jy gt nq nr ns nt aw nu bi"><span id="fb02" class="nd lj iq nr b gy nv nw l nx ny">def __getitem__(self, index):<br/> ‘Generate one batch of data’<br/> # Generate indexes of the batch<br/> indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]</span><span id="5178" class="nd lj iq nr b gy nz nw l nx ny"># Find list of IDs<br/> list_IDs_temp = [self.list_IDs[k] for k in indexes]</span><span id="f1bb" class="nd lj iq nr b gy nz nw l nx ny"># Generate data<br/> X, y = self.__data_generation(list_IDs_temp)</span><span id="ece9" class="nd lj iq nr b gy nz nw l nx ny">return X, y</span></pre><p id="d98a" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">该方法使用前面代码片段的数据生成方法，并生成所需的数据批次。</p><p id="bcc9" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">下面的代码片段展示了如何实际使用它来训练我们的模型。</p><pre class="jv jw jx jy gt nq nr ns nt aw nu bi"><span id="0331" class="nd lj iq nr b gy nv nw l nx ny">import numpy as np</span><span id="e31f" class="nd lj iq nr b gy nz nw l nx ny">from keras.models import Sequential<br/>from my_classes import DataGenerator</span><span id="8a6c" class="nd lj iq nr b gy nz nw l nx ny"><br/>params = {‘dim’: (32,32,32),<br/> ‘batch_size’: 128,<br/> ‘n_classes’: 6,<br/> ‘n_channels’: 1,<br/> ‘shuffle’: True}</span><span id="8561" class="nd lj iq nr b gy nz nw l nx ny"><br/>partition = # IDs<br/>labels = # Labels</span><span id="58fd" class="nd lj iq nr b gy nz nw l nx ny"><br/>training_generator = DataGenerator(partition[‘train’], labels, **params)<br/>validation_generator = DataGenerator(partition[‘validation’], labels, **params)</span><span id="ab9d" class="nd lj iq nr b gy nz nw l nx ny"><br/>model = Sequential()<br/>[…] # Architecture<br/>model.compile()</span><span id="627e" class="nd lj iq nr b gy nz nw l nx ny"><br/>model.fit_generator(generator=training_generator,<br/> validation_data=validation_generator,<br/> use_multiprocessing=True,<br/> workers=6)</span></pre><p id="bb19" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">从上面可以看出，我们使用了<em class="np">拟合生成器</em>方法，而不是拟合方法。这在我们处理大型数据集时特别有用，因为我们不应该一次将整个数据放入ram。workers参数确保批处理是并行生成的。</p><p id="2a42" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">在领英<br/><a class="ae oa" href="https://www.linkedin.com/in/aditya-mohanty-7982451a9/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/aditya-mohanty-7982451a9/</a>联系我</p><p id="2090" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">代码可以在<a class="ae oa" href="https://github.com/mohantyaditya/Datagenerator" rel="noopener ugc nofollow" target="_blank">https://github.com/mohantyaditya/Datagenerator</a>找到。</p><h2 id="e469" class="nd lj iq bd lk ne nf dn lo ng nh dp ls kv ni nj lw kz nk nl ma ld nm nn me no bi translated">参考资料:</h2><div class="ml mm gp gr mn mo"><a href="https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd ir gy z fp mt fr fs mu fu fw ip bi translated">使用Keras的数据生成器的详细示例</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">python keras 2 fit _ generator Afshine Amidi和Shervine Amidi的大型数据集多重处理您是否曾经不得不…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">stanford.edu</p></div></div><div class="mx l"><div class="ob l mz na nb mx nc ke mo"/></div></div></a></div><figure class="jv jw jx jy gt jz"><div class="bz fp l di"><div class="oc od l"/></div></figure></div></div>    
</body>
</html>