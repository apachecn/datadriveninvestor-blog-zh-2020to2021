<html>
<head>
<title>Ensemble Learning for Deep Learning-based MRI Super Resolution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的MRI超分辨率集成学习</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/ensemble-learning-for-deep-learning-based-mri-super-resolution-2daef2491144?source=collection_archive---------23-----------------------#2020-12-28">https://medium.datadriveninvestor.com/ensemble-learning-for-deep-learning-based-mri-super-resolution-2daef2491144?source=collection_archive---------23-----------------------#2020-12-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="457f" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">在这篇文章中，集成学习的概念及其在深度学习超分辨率中的应用在论文“<a class="ae kp" href="https://arxiv.org/ftp/arxiv/papers/1907/1907.03063.pdf" rel="noopener ugc nofollow" target="_blank"> MRI超分辨率与集成学习和互补先验</a>”中作为例子进行了讨论。</p></blockquote><h2 id="9b64" class="kq kr iq bd ks kt ku dn kv kw kx dp ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">深度学习网络的集成学习</h2><p id="be76" class="pw-post-body-paragraph jq jr iq jt b ju lm jw jx jy ln ka kb kz lo ke kf ld lp ki kj lh lq km kn ko ij bi translated">我们知道深度学习模型是高度非线性的，并且通常对数据集和模型超参数中的噪声敏感。这一事实意味着，每次在特定数据集上训练神经网络时，它可能会给出轻微或高度变化的结果，即深度网络具有高方差。为了减少这种差异并建立一个性能更好的模型，我们可以结合不同较弱模型(基础学习者)的优势，并最终构建一个更强大的模型(元学习者)。这种简单但健壮的技术被称为集成学习。基础学习者可以根据他们接收的训练数据或学习者模型本身的选择而变化。有不同的方法可以用来设计元学习者，它结合了这些基础学习者的成果。</p><p id="a7e1" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">这种方法已经被许多在各种ML和<a class="ae kp" href="https://mlwave.com/kaggle-ensembling-guide/" rel="noopener ugc nofollow" target="_blank"> Kaggle比赛中获胜的参与者所采用。关于集成学习中不同技术的更多细节可以在这篇</a><a class="ae kp" href="https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205" rel="noopener" target="_blank">文章</a>中找到。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lr"><img src="../Images/d9dcc3a1b8718f06b23a5094955eac1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O52Afv5D6PQasP--5utIGA.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">A Basic Structure of Ensemble Learning</figcaption></figure><h2 id="0cb8" class="kq kr iq bd ks kt ku dn kv kw kx dp ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">磁共振成像中的超分辨率</h2><p id="59de" class="pw-post-body-paragraph jq jr iq jt b ju lm jw jx jy ln ka kb kz lo ke kf ld lp ki kj lh lq km kn ko ij bi translated">磁共振成像在医疗诊断领域发挥着主导作用，因此检索MRI扫描中的复杂细节是至关重要的。以高分辨率获取这些扫描消耗大量时间，并且需要巨大的硬件和操作成本。较长的扫描时间还会导致运动伪影，因为人们不能期望患者在整个过程中保持静止(例如:对于毫米级分辨率，20分钟或更长)。在这种情况下，一个好的<a class="ae kp" href="https://medium.com/analytics-vidhya/super-resolution-and-its-recent-advances-in-deep-learning-part-1-c6d927914d32" rel="noopener">超分辨率</a>算法可以以低得多的成本从基本MRI扫描仪上扫描的低分辨率(LR)图像生成高分辨率(HR)扫描。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/d72a9086937507f86db02b99edbc4df0.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*pZ6xFaMhgIV8osnETJ6Idw.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Resolution in slice (Z) direction is usually low compared to the in-plane (XY) direction. Ref: <a class="ae kp" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=1029417" rel="noopener ugc nofollow" target="_blank">paper</a></figcaption></figure><p id="140f" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">有时，一些医疗诊断程序需要各向同性的空间分辨率。由于直接3D采集在MRI中不可行，专家通常采集2D切片来构建体积。与体积的XY平面分辨率相比，这通常会导致z方向(切片方向)的分辨率较差。在这种情况下，从两次或更多次2D采集重建高分辨率体积的迭代超分辨率算法在切片方向上也检索到更好的纹理。</p><p id="3a14" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">现在，超分辨率是一个不适定的问题，并且不是一项容易的任务，因为对于特定的低分辨率图像，可能存在许多解决方案(超分辨率图像)。最近的进展发展了自然和医学图像领域中的各种超分辨率模型。虽然已经取得了很大的进展，但我们仍然远远没有开发出一个精确的模型。集成学习帮助我们更接近以超分辨率生成更真实的纹理的目标。在下一节中，我将详细介绍由吕青、单宏明和王戈在他们题为“集成学习和互补先验的MRI超分辨率”的论文中提出的一种方法</p><h2 id="f447" class="kq kr iq bd ks kt ku dn kv kw kx dp ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">提议的架构</h2><p id="8d08" class="pw-post-body-paragraph jq jr iq jt b ju lm jw jx jy ln ka kb kz lo ke kf ld lp ki kj lh lq km kn ko ij bi translated">由于超分辨率，估计将LR映射到HR图像域的函数的过程是一个不明确的问题。作者建议在逼近该函数时使用先验。初始下采样步骤是为下图中的训练创建一个LR数据集，而HR数据集将作为训练模型时的基础事实。本文在频域而不是图像域中进行下采样过程。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mi"><img src="../Images/a35bf347f74eab7b170cd2ef412ce759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UxOR-zbElOXmFP4_Ra1W4w.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Workflow of the SR methodology proposed in the <a class="ae kp" href="https://arxiv.org/ftp/arxiv/papers/1907/1907.03063.pdf" rel="noopener ugc nofollow" target="_blank">paper</a></figcaption></figure><p id="dbb7" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">该架构在开始时采用上采样步骤，以通过采用现有的SR模型来生成放大的图像(处理后的LR图像——图中的PLR)。由于这个原因，网络接收到的图像已经具有相当好的质量。此工作流程中使用的五种算法充当了先验的作用，它们是:-</p><p id="0345" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">(I)零插值填充(ZIP):最简单的随机共振方法</p><p id="de14" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">㈡双三次插值:一种基于插值的算法</p><p id="6294" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">㈢新的边缘定向插值(NEDI):一种基于插值的算法</p><p id="6123" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">稀疏编码:一种基于字典学习的算法</p><p id="fcd5" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">(v)调整锚定邻域回归(A+):基于字典学习的算法</p><p id="7bb3" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">这五个经处理的LR图像数据集具有与期望的HR图像的图像尺寸相等的图像尺寸，然后作为输入被发送到相应的五个<a class="ae kp" href="https://developers.google.com/machine-learning/gan/gan_structure" rel="noopener ugc nofollow" target="_blank">生成对抗网络</a> (GAN)模型。所有的gan都具有相同的架构，如下图所示。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mj"><img src="../Images/830c38eec1097a336d5dea1c048235a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NuHBkwF64mItszN9o1SDMA.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Network architecture of the GANs used in the SR methodology</figcaption></figure><p id="c4d8" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">GAN中的生成器有七个模块，每个模块由卷积层(Conv)、归一化层(LN)和激活层(ReLu)的顺序组合组成。它还具有三个跳跃连接，以实现梯度的流动，并保持LR和HR图像之间的结构相似性。鉴别器有五个类似顺序组合的块，最后有一个全局平均池层(GAP)。</p><p id="47d2" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">最后，使用卷积神经网络(CNN)将来自GAN的五个预测集合在一起，该网络的架构与GAN的生成器的架构相同。这个最终的CNN接收一个矩阵，该矩阵是连接五个预测图像矩阵的结果。</p><div class="mk ml gp gr mm mn"><a href="https://www.datadriveninvestor.com/2020/11/27/deep-learning-amid-increased-physician-administrative-workload/" rel="noopener  ugc nofollow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd ir gy z fp ms fr fs mt fu fw ip bi translated">医生管理工作量增加时的深度学习|数据驱动的投资者</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">行政工作量是我们这个时代大多数医生所经历的许多负担之一。医生，尤其是…</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb mb mn"/></div></div></a></div><h2 id="1cbe" class="kq kr iq bd ks kt ku dn kv kw kx dp ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">结果</h2><p id="a75a" class="pw-post-body-paragraph jq jr iq jt b ju lm jw jx jy ln ka kb kz lo ke kf ld lp ki kj lh lq km kn ko ij bi translated">集成学习利用由每个先验检索的特征，并将它们合并以生成质量失真更小的更好的图像。NYU fastMRI数据集用于评估该架构的性能。下图显示了五个gan的结果和执行集成学习后的最终图像。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi nc"><img src="../Images/b74efee9a6521465849790e1dcbfdd40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*75jgSf1j2gumG6TwJcF2Lw.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Input, intermediate, and output images in the SR workflow in (a) Cases 1 and (b) 2, where processed results are in the yellow boxes, LR images are in the purple boxes, HR images in the green boxes, ensemble learning results in the red boxes, and GAN predictions in the orange boxes. The processed results and GAN predictions from left to right are ZIP, BI, NEDI, SC, and A+.</figcaption></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi nd"><img src="../Images/bc8deddd09ab61f9fc1f884c933b2129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jpU4tkeRuv2Q5eEZTX2g_g.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Comparison of the proposed model with the state-of-art methods</figcaption></figure><p id="4d57" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">从主图像中截取了几个分区，以便在视觉上将提出的模型与最先进的方法进行比较，如<a class="ae kp" href="https://arxiv.org/abs/1608.00367" rel="noopener ugc nofollow" target="_blank"> FSRCNN </a>、<a class="ae kp" href="https://arxiv.org/abs/1710.01992" rel="noopener ugc nofollow" target="_blank"> LapSRN </a>、<a class="ae kp" href="https://arxiv.org/abs/1609.05158" rel="noopener ugc nofollow" target="_blank"> ESPCN </a>、<a class="ae kp" href="https://arxiv.org/abs/1511.04587" rel="noopener ugc nofollow" target="_blank"> VDSR </a>。可以观察到，在某些标记的红点处，所提出的方法生成了更清晰的细节(孔洞和裂缝),其更接近地面真实HR图像。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi ne"><img src="../Images/bb63b98dcb330e6e37ac59b6aa9dd413.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q5yi_1LmGQSqfAS2OTKENA.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Quantitative metric comparison of the proposed model with the state-of-art methods</figcaption></figure><p id="7928" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">在定量上，基于集成学习的模型比其他基于深度学习的基准方法实现了更高的结构相似性(SSIM)和峰值信噪比(PSNR)。</p><p id="2d24" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">每种SR算法都擅长保留图像特征的一些特定方面。在作者选择的算法中，ZIP、BI和NEDI保留了清晰的边缘和平滑的形状，而SC和A+保留了纹理细节。这些互补图像先验来自PLR (processed-LR)数据集，并最终在集成学习后获得的图像中观察到。</p><p id="ba1e" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">需要注意的另一点是，由于鉴别器间接控制发生器预测，训练GAN时的不稳定性会产生不同的伪像和噪声，这与目标函数控制优化问题的通用CNN不同。使用这种基于CNN的集成学习方法也可以抑制和消除这种伪影，因为数据集的大小被间接地扩大了。</p><p id="a050" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated">总之，所提出的模型结合了各个网络的能力，并通过抑制伪像和失真来生成具有清晰细节的超分辨率图像。</p><h2 id="e620" class="kq kr iq bd ks kt ku dn kv kw kx dp ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">参考资料:</h2><ol class=""><li id="0836" class="nf ng iq jt b ju lm jy ln kz nh ld ni lh nj ko nk nl nm nn bi translated"><a class="ae kp" href="https://machinelearningmastery.com/ensemble-methods-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">深度学习神经网络的集成学习方法</a></li><li id="e2c1" class="nf ng iq jt b ju no jy np kz nq ld nr lh ns ko nk nl nm nn bi translated"><a class="ae kp" href="https://arxiv.org/ftp/arxiv/papers/1810/1810.06776.pdf" rel="noopener ugc nofollow" target="_blank">通过深度学习实现超分辨率核磁共振</a></li><li id="46ab" class="nf ng iq jt b ju no jy np kz nq ld nr lh ns ko nk nl nm nn bi translated"><a class="ae kp" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=1029417" rel="noopener ugc nofollow" target="_blank">磁共振成像中的超分辨率</a></li><li id="a21f" class="nf ng iq jt b ju no jy np kz nq ld nr lh ns ko nk nl nm nn bi translated"><a class="ae kp" href="https://arxiv.org/ftp/arxiv/papers/1907/1907.03063.pdf" rel="noopener ugc nofollow" target="_blank">利用集成学习和互补先验的MRI超分辨率</a></li></ol><p id="e1ad" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kz kd ke kf ld kh ki kj lh kl km kn ko ij bi translated"><strong class="jt ir">访问专家视图— </strong> <a class="ae kp" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="jt ir">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>