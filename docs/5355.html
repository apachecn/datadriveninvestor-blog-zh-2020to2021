<html>
<head>
<title>Challenges faced while implementing the QANet Model and its solutions.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实施QANet模型面临的挑战及其解决方案。</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/challenges-faced-while-implementing-the-qanet-model-and-its-solutions-1e9d17c3b563?source=collection_archive---------7-----------------------#2020-09-16">https://medium.datadriveninvestor.com/challenges-faced-while-implementing-the-qanet-model-and-its-solutions-1e9d17c3b563?source=collection_archive---------7-----------------------#2020-09-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="0b7c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">嗨，我所有的深度学习爱好者们。</p><p id="6c49" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最近，我使用SQuAD数据集实现了问答系统的QANet模型。并在实施过程中面临许多挑战。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/3dbfbe6e50140d7d20a63159a0f126ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/1*NftmrWOWeCueIj9RNYx58A.gif"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Demo :- Question Answering system.</figcaption></figure><p id="7ce0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我不打算解释我是如何实现这个模型的。</p><p id="7038" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是我将向您介绍我解决问题和优化模型的步骤。</p><p id="9e0f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">单独解释优化过程的主要原因如下。</p><p id="6add" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1.在<em class="kx">如何使用Pytorch </em>实现QANet中有很多资料。但是，当我在实现模型时遇到一些问题时，几乎没有可用的材料来纠正这些问题，我花了很多天的时间来研究解决这个问题，但是没有一个问题是在一个地方解决的。</p><p id="f5ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.如何减少QANet模型的内存大小？</p><p id="f65d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.如何有效降低损耗值？</p><h1 id="0507" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak">QA net模型介绍</strong></h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lw"><img src="../Images/81637fb26edbe73476b139a9a0103367.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iRphCn8ur3gCTISZvxpcHA.png"/></div></div></figure><p id="90fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">QANet模型是使用<strong class="jp ir">BIDAF</strong>(<strong class="jp ir">BID</strong>directional<strong class="jp ir">A</strong>tten tion<strong class="jp ir">F</strong>low)方法的变压器版本。<br/>顾名思义，BIDAF模型主要被构建为使用不仅从上下文到问题，而且从问题到上下文的注意流机制。</p><p id="20d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在传统的问答系统中，注意力流仅用于从问题到上下文。但在这里，它是双向的。</p><p id="235f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种基线BIDAF方法最初仅被建议用于RNNs (LSTM)网络，但是为了利用变压器的计算和并行处理能力，相同的方法后来被扩展到变压器。</p><p id="f0ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">许多QANet模型在斯坦福官网的SQuAD数据集的评分板上领先，直到BERT模型的出现，基本上超越了所有其他模型。</p><p id="4598" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我使用了来自这些GITHUB链接的一些补充功能的代码。但是我基本上是从头开始写模型框架部分和其他功能的代码。</p><ol class=""><li id="d035" class="mb mc iq jp b jq jr ju jv jy md kc me kg mf kk mg mh mi mj bi translated"><a class="ae mk" href="https://github.com/galsang/BiDAF-pytorch" rel="noopener ugc nofollow" target="_blank"> <em class="kx">比达夫LSTM模型</em> </a></li><li id="1096" class="mb mc iq jp b jq ml ju mm jy mn kc mo kg mp kk mg mh mi mj bi translated"><a class="ae mk" href="https://github.com/SamLynnEvans/Transformer" rel="noopener ugc nofollow" target="_blank"> <em class="kx">变压器</em> </a></li></ol><p id="b9d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们直接进入我在实现模型时所面临的问题。</p><h1 id="5575" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">挑战1</h1><p id="5aec" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">大多数试图从研究论文中实现模型的人都经历过这种情况。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/77c0cb3f2b6ea5a5f33c309e7d2e93c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/1*U0_OQMb-Rv6OTMQY_YhZdQ.gif"/></div></figure><blockquote class="mw mx my"><p id="0706" class="jn jo kx jp b jq jr js jt ju jv jw jx mz jz ka kb na kd ke kf nb kh ki kj kk ij bi translated">“我们从哪里开始？”。</p></blockquote><p id="263a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的建议是开始为模型的基本结构编写代码，包括更大的组件，比如模型编码器、多头注意力等等..,</p><p id="24d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为这些组件指定一个对象名，并给出模型的基本结构。不要担心那些单个组件或其他子组件的代码，我们稍后会处理它。</p><p id="4e61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦模型的基本结构形成。然后开始为每个组件及其子组件编写代码，因此基本的<strong class="jp ir">自底向上的方法在这个场景中是有效的。</strong></p><h1 id="678b" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">挑战2</h1><h2 id="3839" class="nc kz iq bd la nd ne dn le nf ng dp li jy nh ni lm kc nj nk lq kg nl nm lu nn bi translated">内存不足问题</h2><p id="e76d" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">一旦我完成了编码部分，模型就用正确的尺寸正确地初始化了。</p><p id="be3e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我在模型运行时遇到了一个大问题<strong class="jp ir"> <em class="kx">内存不足</em> </strong>。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi no"><img src="../Images/88c59e3fddb021c9d42b28c6c60850a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A-lOmpjnQx7UXMK27PA-ew.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Out of Memory error</figcaption></figure><p id="e5c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">发生这个错误是因为内存的整体执行大小超过了你的RAM内存大小，<br/>当你使用像SQuAD 2.0这样的大型数据集时，这些模型会变得非常庞大。</p><blockquote class="mw mx my"><p id="cec2" class="jn jo kx jp b jq jr js jt ju jv jw jx mz jz ka kb na kd ke kf nb kh ki kj kk ij bi translated">相信我，我有一个16GB的内存在我的电脑中，但仍然“内存不足”的错误抛出。即使使用Google colab提供的GPU，我也面临着同样的问题。</p></blockquote><p id="182f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以每当我们面对这个问题时，第一步就是找出程序的哪个部分消耗了更多的内存。<br/>在这种情况下，我们确实有一个基本的想法，即由于数据集规模巨大，数据集处理可能会消耗更多内存。</p><p id="6938" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">解决这个问题最简单的方法是<strong class="jp ir">减少数据集的大小</strong>，因此我们也可以减少模型的大小。</p><p id="08ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是变压器模型通常是一个数据饥渴模型，为了让它有效地学习，我们需要给它提供更大的数据集。</p><p id="4a2d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以我决定不改变数据集的大小，而是希望减少处理的大小。</p><p id="2d0a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是万一你不确定哪个进程占用更多的RAM空间，我遵循的最简单的方法是在模型中的每个主要组件后添加一个print语句并运行程序。</p><p id="6472" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在Windows中打开任务管理器(ctrl + shift + Esc ),然后单击性能选项卡检查RAM的内存使用情况。</p><p id="b409" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由此我们可以很容易地找出哪个进程使用了更多的RAM内存，因为它会在那个特定的进程上稳步增加。</p><div class="np nq gp gr nr ns"><a href="https://www.datadriveninvestor.com/2020/07/23/learn-data-science-in-a-flash/" rel="noopener  ugc nofollow" target="_blank"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd ir gy z fp nx fr fs ny fu fw ip bi translated">一瞬间学会数据科学！？数据驱动的投资者</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">在我之前的职业生涯中，我是一名训练有素的古典钢琴家。还记得那些声称你可以…</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="ob l"><div class="oc l od oe of ob og kr ns"/></div></div></a></div><h2 id="a694" class="nc kz iq bd la nd ne dn le nf ng dp li jy nh ni lm kc nj nk lq kg nl nm lu nn bi translated">解决方案1</h2><p id="67de" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">所以第一步是把组件分成尽可能多的子模块。<br/>一旦对象或内存失去作用域，Python就会释放对象或变量的内存。<br/>所以把程序分成小函数的好处是，一旦函数的执行结束，函数内部所有的变量/对象内存都被释放。<br/>同时也提高了函数的可读性和可重用性。</p><h2 id="27bf" class="nc kz iq bd la nd ne dn le nf ng dp li jy nh ni lm kc nj nk lq kg nl nm lu nn bi translated">解决方案2:-</h2><p id="2cd1" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">在实现了解决方案1之后，几乎没有什么不同。我仍然面临着内存不足的问题。然后我开始手动释放变量的内存，这将是一个巨大的数据，但不会在程序中使用。</p><p id="9eec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了实现这个解决方案，我使用了下面的函数，</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi oh"><img src="../Images/fc2fa60444c13859992cf3a802265b03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M_HfM6ZhRwB9LuexmmVyqA.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Usage of del and gc.collect() in code as an example</figcaption></figure><p id="984f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> del和gc.collect() </strong></p><p id="c091" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> del </strong>功能将删除变量。</p><p id="3563" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> gc.collect() </strong>会释放那个被删除变量的内存。</p><blockquote class="mw mx my"><p id="1613" class="jn jo kx jp b jq jr js jt ju jv jw jx mz jz ka kb na kd ke kf nb kh ki kj kk ij bi translated">注意:- <br/>不要在模型中使用这个del和gc.collect()，这样做不仅会释放张量/变量的值，还会释放张量的梯度，<br/>导致模型具有不稳定的梯度下降，并且还会显著增加执行时间超过200%。我在这里使用过这个函数，只是在数据处理阶段。</p></blockquote><p id="876c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你想了解更多关于python中垃圾回收的知识。点击查看<a class="ae mk" href="https://stackify.com/python-garbage-collection/" rel="noopener ugc nofollow" target="_blank"/></p><p id="5a40" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我真的用了将近一周的时间来解决这个问题。相信我，用这个会让你免除很多痛苦。</p><h2 id="aedb" class="nc kz iq bd la nd ne dn le nf ng dp li jy nh ni lm kc nj nk lq kg nl nm lu nn bi translated"><strong class="ak">解决方案3:- </strong></h2><p id="64aa" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">检查具有许多迭代的过程，如果您正在处理巨大的数据集，这将导致内存增加。<br/>在这个QANet中，我们结合了预训练的单词嵌入(手套向量)和字符嵌入。</p><p id="b295" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于字符嵌入，我们使用2D卷积神经网络将其与单词嵌入相结合。所以这个2D卷积将对上下文和问题中的每一个字母进行。因此，这个2D卷积将具有最大的迭代次数和处理时间。</p><p id="fbe0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将2D CNN改为1D深度方向可分离CNN减小了模型的尺寸。<br/>我们将在下一部分讨论这种1D深度可分离CNN，因为这种解决方案也减少了执行时间并提高了性能。</p><p id="8f51" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在应用了所有这3个解决方案之后，我能够使用批量大小为50的GPU运行程序，而没有任何内存不足的错误。</p><h1 id="2019" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">挑战3</h1><h2 id="2b03" class="nc kz iq bd la nd ne dn le nf ng dp li jy nh ni lm kc nj nk lq kg nl nm lu nn bi translated">模型的执行时间很长</h2><p id="c84d" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">我使用批量为50的GPU使用Google colab运行模型。</p><p id="4d84" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是对于每100个批次，即使在使用GPU之后，也要花费近10分钟，并且几乎有1200个批次，每个批次大小为每个时期50个。</p><p id="d113" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以每个时期需要将近2个小时。Google colab一天只提供12小时的GPU运行时间。<br/>因此，即使将纪元保持为8，我也无法及时运行模型。<br/>一旦你在代码中遇到问题<br/>或者在某个地方失败，或者你想对代码进行修改，你的一整天都会被浪费掉。</p><h2 id="d198" class="nc kz iq bd la nd ne dn le nf ng dp li jy nh ni lm kc nj nk lq kg nl nm lu nn bi translated">解决方案1</h2><p id="047c" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">Pytorch为您提供了<strong class="jp ir">torch . autograded . profiler . profile()</strong>函数，该函数有助于分析模型中运行的流程，以及每个流程花费的时间和运行的次数。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi oi"><img src="../Images/b919a831354f357dd29e301a1eeac288.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JXwcWba4F_Hnpkznl-ffpQ.png"/></div></div></figure><p id="37e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过在如上所述的分析器下实现模型，我们能够发现哪个进程花费了很多时间。<br/>我们可以寻找一种替代的内存高效方式来实现相同的过程。</p><p id="691f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">例如:- </strong>正如我在之前的挑战中提到的，将2D卷积网络更改为内存高效的1D深度可分离卷积网络增加了处理时间，同时也大大减少了内存大小。</p><p id="7b64" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要了解更多关于深度可分卷积<br/>网络的信息，请点击<a class="ae mk" href="https://www.geeksforgeeks.org/depth-wise-separable-convolutional-neural-networks/" rel="noopener ugc nofollow" target="_blank">这里</a></p><p id="81b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你也可以在这里查看<strong class="jp ir">torch . autograded . profiler . profile()</strong><a class="ae mk" href="https://gist.github.com/XinDongol/fe066cb76e1c5238ecbc0cb729806410" rel="noopener ugc nofollow" target="_blank">的实现。</a></p><h2 id="92e4" class="nc kz iq bd la nd ne dn le nf ng dp li jy nh ni lm kc nj nk lq kg nl nm lu nn bi translated">解决方案2</h2><p id="cd9a" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">有时，您可能需要利用模型的准确性来平衡速度和性能。<br/>所以从这个意义上来说，我们可以减少模型的维度来减少模型的整体执行时间。</p><p id="e61d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，选择可以减少执行时间的单词和字符维数，但同时，准确性不会在很大程度上降低。</p><h1 id="77d3" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">挑战4</h1><h2 id="9966" class="nc kz iq bd la nd ne dn le nf ng dp li jy nh ni lm kc nj nk lq kg nl nm lu nn bi translated">反向推进期间每个历元损失值的波动。</h2><p id="81aa" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">应用上述解决方案后，内存和性能问题得到了解决。但是我的损失非常巨大，如下图所示。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi oj"><img src="../Images/62235204d4322cad91acb64fe7b1b374.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m1fINcXOCGIDBT_FNx-ZJA.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Higher Loss values</figcaption></figure><p id="537b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">即使在将时期增加到12个之后，损失值仍然非常高，这是不寻常的。<br/>损失值也没有减少，因为学习任何东西都更加不稳定。</p><h2 id="f56d" class="nc kz iq bd la nd ne dn le nf ng dp li jy nh ni lm kc nj nk lq kg nl nm lu nn bi translated">减少损失价值波动的解决方案:-</h2><p id="2502" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">我改变了基线BIDAF文件中给出的Adadelta优化器，用ADAM优化器<br/>代替了它，并删除了EMA(指数移动平均线)模块。波动略有减少，但差异可以忽略不计。</p><p id="c719" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以我做了很长时间的研究来找出这种行为的根源。</p><p id="4c41" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过一层一层地仔细检查代码，我能够确定代码中的问题。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi ok"><img src="../Images/94b8e53de7e8c1a3b500f568a005b4ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZnX5ku5pj2hwU37rKBXBZA.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Fully connected layer.</figcaption></figure><p id="9080" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基本上，QANet论文希望在全连接层的末端有softmax函数。<br/>但是在末尾有一个软最大值并将该值输入到交叉熵损失函数会产生反效果。</p><p id="61b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">交叉熵损失是softmax和NLL损失的组合，因此我们只需要传递来自全连接层的原始逻辑。<br/> <br/>移除softmax功能后，损耗在每个历元后开始下降，没有波动。</p><p id="91a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">唷！！！</p><h2 id="0cfe" class="nc kz iq bd la nd ne dn le nf ng dp li jy nh ni lm kc nj nk lq kg nl nm lu nn bi translated">降低巨大损失价值的解决方案:-</h2><p id="30d8" class="pw-post-body-paragraph jn jo iq jp b jq mq js jt ju mr jw jx jy ms ka kb kc mt ke kf kg mu ki kj kk ij bi translated">在逐行分析和调试代码之后，我能够在程序中找到这种行为的根本原因。</p><p id="e1a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在一个助手函数中，我从参考transformer模型代码中使用了这个函数，其中有一个模块叫做位置编码模块。</p><p id="f5cb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在该模块中，它将输入值放大维数的平方根。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi ol"><img src="../Images/6065e7333696fb4009ee1b294ec3467a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4i3OQkXIL7TEzYmtd7oOAg.png"/></div></div></figure><p id="90bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果是嵌入层，这没问题，因为嵌入层的值会很低。并且其值的增加只会提高性能。</p><p id="d759" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，当您在编码器模块中使用相同的函数时，其末端尺寸可能高达字尺寸的16倍，<br/>在我的例子中，字尺寸是100，1600的平方根是40，这对于放大来说是一个巨大的值。</p><p id="ccd6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我修改了这个函数，将这个放大限制在嵌入层，而在模型编码器层，这个将被忽略。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi gj"><img src="../Images/0f4cbb5e39248c35a6dd3290f63cade4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0LQIhaEzJBqRcHtoZpukdg.png"/></div></div></figure><p id="c152" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里提到这个代码问题的原因是，这个问题并不总是模型方面或实现方面的问题，但有时可能是由于我们可能忽略的一些基本问题。所以也要经常检查那些微小的事情，它们有时可能是更大问题的原因。</p><p id="bdd9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以在代码中做了上述修改后，我的模型开始有一个正常的损失值，如下所示，在第一个时期，这确实是一个巨大的解脱。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi om"><img src="../Images/489af633639fc6b1f05ba1977631a4c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*sATQ6is0cZIqqTfl0-5nNg.png"/></div></figure><p id="69a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在实施了上述所有解决方案后，我的EM分数达到了37.534，F1分数达到了49.802。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi on"><img src="../Images/5d8aa38b9a7d2c4b5542899c0a3053e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Yb80ZX4czELJDZCCI03_Q.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">EM and F1 score.</figcaption></figure><p id="5d54" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与基线纸相比，它仍然是平均F1和EM分数。但是基线QANet论文要求字嵌入维度值为300 <br/>并且7个堆叠编码器被用作模型编码器，而我在模型编码器中仅使用了100个维度和4个堆叠编码器。<br/>为了减少训练时间，最大上下文长度保持在150。</p><p id="02f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为实现这样一个庞大的模型需要高RAM内存的GPU，并且应该有利用更长处理时间的设施。<br/>凭借Google colab提供的12小时GPU时间，我只能实现一个更轻便的模型。</p><p id="8c5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">无论如何，这个实现背后的意图，是学习和研究如何与庞大的数据集和庞大的模型大小的变压器工作。<br/>从这个意义上说，它给了我很大的教训，将有助于我未来的努力。</p><p id="c85f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管这让我有点抓狂，而且花了几周时间才完成这个项目。</p><p id="dd44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最终结果令人满意！！！！。</p><p id="f618" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我希望我的错误和解决方案给你一个想法，在实施研究论文时会有什么期望。<br/>以及如何在实施过程中克服问题。</p><p id="ae74" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">点击这里查看我在GITHUB <a class="ae mk" href="https://github.com/iam-Raghav/QANet-QuestionAndanswering-system" rel="noopener ugc nofollow" target="_blank">中的全部代码</a></p><p id="732f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">喜欢就鼓掌，喜欢就评论。</p><p id="1e85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">和平！！！！</p><p id="c679" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">访问专家视图— </strong> <a class="ae mk" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>