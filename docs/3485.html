<html>
<head>
<title>Interview Guide to Boosting Algorithms: Part-1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">助推算法面试指南:第1部分</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/interview-guide-to-boosting-algorithms-part-1-133153714073?source=collection_archive---------3-----------------------#2020-06-20">https://medium.datadriveninvestor.com/interview-guide-to-boosting-algorithms-part-1-133153714073?source=collection_archive---------3-----------------------#2020-06-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/39a6ef98e03817f8840bec6ca0bbb9cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WuX-NkJCZ_BMpQ4k"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@officestock?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Sebastian Herrmann</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a758" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，这里有几个问题可以激发你对这个特定领域兴趣。</p><h1 id="876b" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">问题:</strong></h1><ol class=""><li id="adf1" class="mc md it ki b kj me kn mf kr mg kv mh kz mi ld mj mk ml mm bi translated"><strong class="ki iu">AdaBoost是更不容易还是更容易过度拟合？</strong></li><li id="fffc" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><strong class="ki iu">关于过度合身有哪些误解？</strong></li><li id="46bc" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><strong class="ki iu">梯度提升和AdaBoost有什么区别？</strong></li><li id="af14" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><strong class="ki iu">在什么情况/用例中，我们更喜欢XGBoost算法？</strong></li><li id="f016" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><strong class="ki iu">boosting算法在AI/ML的世界里适合什么位置？</strong></li></ol><p id="6737" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就看上面的问题，然后思考一分钟。</p><p id="d096" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一直读到最后，你会自己找到答案。</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ms"><img src="../Images/4b5c0900c114a7b120a595e97df7f2e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iuh_cuffNUAp9TqB"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@garybpt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Gary Butterfield</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="39e1" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">指导您阅读本文的目录:</h1><ul class=""><li id="46ba" class="mc md it ki b kj me kn mf kr mg kv mh kz mi ld mx mk ml mm bi translated"><strong class="ki iu">升压简介</strong></li><li id="0c03" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated"><strong class="ki iu">弱可学性的强度</strong></li><li id="f3d2" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated"><strong class="ki iu">Boosting算法的中心思想</strong></li><li id="b8d6" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated"><strong class="ki iu">AdaBoost是更少还是更容易过拟合？</strong></li><li id="1203" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated"><strong class="ki iu">关于过度合身的一些误解</strong></li><li id="bf4b" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated"><strong class="ki iu">梯度提升和AdaBoost有什么区别？</strong></li></ul><h1 id="175f" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">助推简介:</strong></h1><p id="55f4" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">Boosting是一种提高任何给定学习算法准确性的通用方法。</p><h1 id="feec" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">弱可学性的强度:</strong></h1><p id="0d02" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">一个概念类是可学习的(或强可学习的),如果给定对未知概念的实例源的访问，学习者能够以很高的概率输出除了任意小部分实例之外对所有实例都是正确的假设。</p><p id="be2d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果学习者能够提出一个仅比随机猜测稍好一点的假设，那么这个概念类就是弱可学的。</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nb"><img src="../Images/f99858638bc98c8e392578aad49a2b8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OOGrtfnuLDKxpDhU"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@priscilladupreez?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Priscilla Du Preez</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="63f5" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak"> PAC学习:</strong></h1><p id="29d6" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">一个概念类是PAC可学习的要求是非常严格的。</p><p id="9b34" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">学习算法必须适用于类中的所有目标概念、所有输入分布以及精度和置信度(δ)参数的任何设置。</p><div class="nc nd gp gr ne nf"><a href="https://www.datadriveninvestor.com/2020/03/04/on-artificial-intelligence-and-surveillance-capitalism/" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd iu gy z fp nk fr fs nl fu fw is bi translated">人工智能和监督资本主义|数据驱动的投资者</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">大科技，总是现在:人工智能推动的大科技，已经使购物，搜索，在你的…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt jz nf"/></div></div></a></div><h1 id="d0df" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">Boosting算法的中心思想:</strong></h1><p id="e0f1" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">推进方法的中心思想如下。</p><p id="7b45" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最初，我们可以使用弱学习算法，该算法给出的假设比随机猜测的性能稍好。</p><p id="b541" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以重复运行这个弱学习算法，尽管它可能返回相同的假设。</p><p id="454e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，如果我们修改分布，使得已经返回的假设不再有效，即，在新的分布下，它具有正好1/2的误差，那么弱学习算法需要为我们提供不同的假设。</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/93a7d57dc00d93a323444ba5d0bb647e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Yj1SJY9AaUOsOQhD"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@freegraphictoday?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">AbsolutVision</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="19e4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过重复这样做，我们可以结合几个假设，产生一个误差较小的假设。</p><p id="7426" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所有升压算法都利用这种高级方法。</p><h1 id="f17a" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">AdaBoost是更少还是更容易过拟合？</strong></h1><p id="9af9" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">在实际经验中，AdaBoost对过拟合非常鲁棒，而LPBoost(线性规划助推)更是如此(因为目标函数需要弱学习器的稀疏组合，这是一种能力控制的形式)。影响它的主要因素有:</p><ul class=""><li id="8853" class="mc md it ki b kj kk kn ko kr nv kv nw kz nx ld mx mk ml mm bi translated">“弱”学习器的“优势”:如果你使用非常简单的弱学习器，比如决策树桩(1级决策树)，那么算法就不容易过度拟合。每当你尝试使用更复杂的弱学习器(如决策树或甚至超平面)时，你会发现过度拟合发生得更快。</li><li id="306f" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated">数据中的噪声水平:AdaBoost特别容易在噪声数据集上过度拟合。在这种设置中，正则化形式(RegBoost、AdaBoostReg、LPBoost、QPBoost)是优选的。</li><li id="07b9" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated">数据的维数:我们知道，一般来说，我们在高维空间中会经历更多的过拟合(“维数灾难”)，AdaBoost在这方面也会受到影响，因为它只是分类器的线性组合，而分类器本身也会受到该问题的影响。是否和其他分类器一样倾向，很难确定。</li></ul><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ny"><img src="../Images/73a25f9f17208204d76f76e15874b62d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PTn8AV2aEMO_Ogsd"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@glenncarstenspeters?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Glenn Carstens-Peters</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><ul class=""><li id="95f7" class="mc md it ki b kj kk kn ko kr nv kv nw kz nx ld mx mk ml mm bi translated">当然，我们可以使用启发式方法，如验证集或k-fold交叉验证来设置停止参数(或不同变体中的其他参数)，就像您对任何其他分类器所做的那样。</li></ul><h1 id="1d16" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">关于过度合身的一些误解:</strong></h1><p id="5f34" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">就过拟合而言，AdaBoost优于随机森林被错误地解释为。</p><p id="f5eb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">事实上，根据理论(看Breiman的原始随机森林论文)，随机森林对过拟合是绝对免疫的，只要它的弱分类器不对数据过拟合。</p><h1 id="5287" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">渐变增强和AdaBoost有什么区别？</strong></h1><ul class=""><li id="29bf" class="mc md it ki b kj me kn mf kr mg kv mh kz mi ld mx mk ml mm bi translated">两种方法都使用一组弱学习者。</li><li id="51c2" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated">他们试图把这些弱学习者变成强学习者。</li></ul><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nz"><img src="../Images/721f11b1e8dde0e161cc0238a734f1e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pkwAKlTn5nebuiW_"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@kellysikkema?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Kelly Sikkema</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><ul class=""><li id="db0c" class="mc md it ki b kj kk kn ko kr nv kv nw kz nx ld mx mk ml mm bi translated">梯度推进在学习过程中产生学习者。</li><li id="7a4d" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated">它建立第一个学习器来预测样本的值/标签，并计算损失(第一个学习器的结果和真实值之间的差异)。</li><li id="b426" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated">它将建立第二个学习器来预测第一步之后的损失。该步骤继续学习第三个、第四个…直到某个阈值。</li></ul></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><ul class=""><li id="ee0a" class="mc md it ki b kj kk kn ko kr nv kv nw kz nx ld mx mk ml mm bi translated">AdaBoost要求用户指定一组弱学习器(或者，它会在真正的学习过程之前随机生成一组弱学习器)。</li><li id="6372" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated">它将学习如何添加这些学习者的权重，以成为一个强大的学习者。</li><li id="a8d4" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated">每个学习器的权重是通过它对样本的预测是否正确来学习的。</li><li id="43e0" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mx mk ml mm bi translated">如果一个学习者错误地预测了一个样本，那么这个学习者的权重就会降低一点。它将重复这样的过程，直到收敛。</li></ul><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oh"><img src="../Images/41c244eeffe512032ea344e2100a1dea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ofP5pn13Czy0KXT_"/></div></div></figure><p id="3cb9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请继续关注第二部分。继续读。</p><h1 id="c2cc" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">你的下一步是什么？</h1><blockquote class="oi oj ok"><p id="ace5" class="kg kh ol ki b kj kk kl km kn ko kp kq om ks kt ku on kw kx ky oo la lb lc ld im bi translated">如果你喜欢这篇文章，点击下面的推荐会很有帮助！<br/>关注我上 <a class="ae kf" href="https://twitter.com/imPraveenPareek" rel="noopener ugc nofollow" target="_blank"> <em class="it">推特</em> </a> <em class="it">，</em><a class="ae kf" href="https://www.linkedin.com/in/praveenpareek/" rel="noopener ugc nofollow" target="_blank"><em class="it">LinkedIn</em></a><em class="it">，</em> <a class="ae kf" href="https://medium.com/@praveen.pareek" rel="noopener"> <em class="it">中</em> </a></p><p id="fb17" class="kg kh ol ki b kj kk kl km kn ko kp kq om ks kt ku on kw kx ky oo la lb lc ld im bi translated"><strong class="ki iu"> <em class="it">看我以前的帖子:</em> </strong> <a class="ae kf" href="https://medium.com/datadriveninvestor/variational-autoencoders-part-1-368bbc3d8aa" rel="noopener"> <strong class="ki iu"> <em class="it">变分自动编码器:Part-1 </em> </strong> </a></p></blockquote><div class="nc nd gp gr ne nf"><a href="https://medium.com/datadriveninvestor/variational-autoencoders-part-1-368bbc3d8aa" rel="noopener follow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd iu gy z fp nk fr fs nl fu fw is bi translated">可变自动编码器:第1部分</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">它们已经成为复杂分布的无监督学习的最流行的方法之一。他们尝试…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">medium.com</p></div></div><div class="no l"><div class="op l nq nr ns no nt jz nf"/></div></div></a></div><p id="d6d1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">访问专家视图— </strong> <a class="ae kf" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>