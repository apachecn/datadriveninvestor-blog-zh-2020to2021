<html>
<head>
<title>Cruising through the basics of Polynomial Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">浏览多项式回归的基础知识</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/cruising-through-the-basics-of-polynomial-regression-a533fe177ca9?source=collection_archive---------7-----------------------#2020-01-17">https://medium.datadriveninvestor.com/cruising-through-the-basics-of-polynomial-regression-a533fe177ca9?source=collection_archive---------7-----------------------#2020-01-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="6d01" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">多项式回归</strong>是线性回归的一种形式，其中自变量x和因变量y之间的关系被建模为一个<em class="kl">n次</em>多项式。多项式回归拟合x的值和y的相应条件均值之间的非线性关系，表示为E(y |x)。我假设读者对线性回归有清楚的了解。我不会深入研究数学，而是试图给你一个用Python进行多项式回归的亲身体验。</p><p id="88ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们用基本的数据集来解释这个概念。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/4509667a195e774a05363bfc92bcefc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*__5iyG2aCqw_dz9oQ5gxWg.png"/></div></figure><p id="e85d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦数据和必需的库一起被导入，我们将在图表上看一下，以便更好地理解这种关系</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ku"><img src="../Images/f339b8edfc400e53e6174723b24b46b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*4qdQfAa6svCyu7ckjpjB9g.png"/></div></figure><p id="ac0c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">哇哦。现在让我们试着拟合一个线性回归，然后用散点图将其可视化。在plt.plot()中输入参数时要小心。第二个参数是包含我们预测点的y坐标的向量</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi kv"><img src="../Images/33ba47dedc056afcd1a99c9cd1f3852b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*5L92NKBkjnDdNUXvMYW1bg.png"/></div></figure><p id="f3eb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在上图中，数据点用红点表示，预测用蓝线表示。从上图可以看出，预测是不正确的。很多红点远离蓝线。</p><div class="kw kx gp gr ky kz"><a href="https://www.datadriveninvestor.com/2019/03/03/editors-pick-5-machine-learning-books/" rel="noopener  ugc nofollow" target="_blank"><div class="la ab fo"><div class="lb ab lc cl cj ld"><h2 class="bd ir gy z fp le fr fs lf fu fw ip bi translated">DDI编辑推荐:5本让你从新手变成专家的机器学习书籍|数据驱动…</h2><div class="lg l"><h3 class="bd b gy z fp le fr fs lf fu fw dk translated">机器学习行业的蓬勃发展重新引起了人们对人工智能的兴趣</h3></div><div class="lh l"><p class="bd b dl z fp le fr fs lf fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="li l"><div class="lj l lk ll lm li ln ks kz"/></div></div></a></div><p id="7d77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们通过创建一个非线性模型来解决这个问题，这样红点就更接近预测值(蓝线)。因此，为了建立这个模型，我们创建了一个新类，它将为我们提供一些工具，在回归方程中集成一些多项式项。该类在预处理库中。创建这个类之后，我们的下一步是创建一个对象，在本例中是poly_reg。这将使我们能够将我们的原始特征集转换成由多项式项组成的新特征集。多项式次数的大小作为参数传递给PolynomialFeatures类。</p><p id="a406" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦创建了对象poly_reg，我们就使用它来拟合原始数据点(X ),并将其转换为一组新的特征(X_poly ),该特征由额外的多项式项(在这种情况下只有一项)组成。可以看到，除了多项式项之外，还自动添加了一列1。那是偏见！</p><p id="2bc0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在创建了新的特征矩阵之后，我们在转换后的特征上拟合线性回归模型。</p><p id="0b11" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">附上图片的主要目的是让你练习代码，而不是复制粘贴它。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lo"><img src="../Images/4bbecd656561cbb3968d7e9ded7ddd71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lu39AYIshiHNLKxplrn5xg.png"/></div></div></figure><p id="4967" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以我们的回归模型差不多准备好了。让我们编写代码来可视化我们的预测。我们必须对上面为线性回归编写的绘图代码进行一些修改。我希望你没弄错！查看代码，只将lin_reg更改为lin_reg2没有帮助，因为lin_reg2仍然是线性回归类的对象，我们需要将转换后的功能集作为参数传递。让我们运行代码来看看结果！</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/c10d3b1081f5e06afd8c39339a1200ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*kmoZqebH9-mU3xFvu-7SjQ.png"/></div></figure><p id="c2d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这表明在线性回归中，蓝色曲线比蓝色线更接近。这可以通过增加多项式的次数来做得更好。试试增加到3！你会看到，在这种情况下，预测会变得更好，并尝试用4度。更高的度数可能会导致过度拟合。</p><p id="8b56" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你想让曲线看起来更加平滑和连续，我们需要在代码中做一些细微的改变。我们使用numpy中的一个range函数，它包含所有级别(下限和上限)以及递增的步长。这给了我们向量，我们需要矩阵，所以我们使用numpy中的reshape函数来获得X_grid矩阵。好，让我们执行代码来得到平滑的曲线。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lu"><img src="../Images/b44c12acd7eb68b4cd1a36d2f118246d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x7GM-C-o8Qp5iOfuhoMDzA.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk">Smoothed Curve</figcaption></figure><p id="990b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以清楚地看到，数据点更靠近蓝线，模型的表现比前一个更好。</p><p id="d216" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将用线性和多项式回归模型来结束我的预测</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/9592844eb01e9d893d0317bb26fb69ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*B4NHES3sZFg-0_doLJccOA.png"/></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk">Predicted Values</figcaption></figure><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div></div>    
</body>
</html>