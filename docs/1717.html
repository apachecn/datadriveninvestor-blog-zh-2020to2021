<html>
<head>
<title>Spring into Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">突然进入线性回归</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/spring-into-linear-regression-17cf2c0813f8?source=collection_archive---------13-----------------------#2020-03-29">https://medium.datadriveninvestor.com/spring-into-linear-regression-17cf2c0813f8?source=collection_archive---------13-----------------------#2020-03-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e4c8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种常见算法的数学和代码</h2></div><p id="7fb2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">大家好！在上周的博客中(<a class="ae lb" href="https://medium.com/datadriveninvestor/nevertheless-she-solved-math-problems-cebd680d77bd" rel="noopener">尽管如此，她解决了数学问题</a>)，我宣布我将开始写数据科学主题背后的数学。今天的话题是<strong class="kh ir">线性回归</strong>。<em class="lc">我们开始吧。</em></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/f9d167d2149d07fc0fb7632ae1086e1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*j2fcZnjeAhidFt-ZL3lT9A.jpeg"/></div></figure></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><p id="a682" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我假设我们大多数人都见过一个非常简单的1D线性回归方程</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/6c0651ea394040c3783f5ddfeafb2032.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*OPcplj7gKdByCBplV8lbng.png"/></div></figure><p id="64c5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="lc"> x </em>为自变量，<em class="lc"> y </em>为因变量，<em class="lc"> w </em>为回归线的斜率，<em class="lc"> b </em>为直线的<em class="lc"> y </em>截距。下图显示了一些数据点及其回归线的示例。数据点的坐标形式为(<em class="lc"> x </em>，<em class="lc"> y </em>)。回归线也称为最佳拟合线，在本例中为<em class="lc"> y </em> = 1.09 + 2.23 <em class="lc"> x </em>(其中<em class="lc"> w </em> = 2.23，b  = 1.09)。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/fbc207f6882379360717d432c15d0fec.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*5tcq_6wdfR9zB6BG98refw.png"/></div></figure><p id="9bea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于数据科学的应用，可以将<em class="lc"> x </em>视为特征值，<em class="lc"> y </em>为预测值，<em class="lc"> w </em>为特征的权重<em class="lc"> x </em>和<em class="lc"> b </em>为偏差项。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/d0dfa30c6de3a2188b3857dafd997812.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*el8T2sz3qnto9zslplvoEw.png"/></div></figure><p id="6e12" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的例子中，想想鸢尾花的花瓣宽度和花瓣长度之间的关系。从图中，这些特征似乎具有线性关系，我们可以使用回归线从宽度预测花瓣的长度。</p></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><p id="9c74" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们更进一步。与其在数据空间中是线性的(只有一个特征对应于一个预测值)，不如让我们将思维转移到一个方程，它是参数(回归系数，<em class="lc"> w </em>)和预测变量，<em class="lc"> x </em>的<a class="ae lb" href="https://en.wikipedia.org/wiki/Linear_combination" rel="noopener ugc nofollow" target="_blank">线性组合。</a></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/41a8688d707f05f2bfcac2e0c008b2ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/1*JCDOQcIDlPOnIGZK9Iac3Q.png"/></div></figure><p id="f856" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，这看起来不像线的典型几何解释。在上面的例子中，我们只需要图表上的一个轴(水平轴)来对应每个数据点的预测分量。在这里，你可以有几个，这就是为什么这是(有时)被称为多元线性回归。顺便说一下，我们只能看到两个特征(上式中的<em class="lc"> x1 </em>和<em class="lc"> x2 </em>)，因为我们需要一个第三轴作为函数的输出(<em class="lc"> y </em>)。</p><div class="lw lx gp gr ly lz"><a href="https://www.datadriveninvestor.com/2020/02/19/five-data-science-and-machine-learning-trends-that-will-define-job-prospects-in-2020/" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd ir gy z fp me fr fs mf fu fw ip bi translated">将定义2020年就业前景的五大数据科学和机器学习趋势|数据驱动…</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">数据科学和ML是2019年最受关注的趋势之一，毫无疑问，它们将继续发展…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn lj lz"/></div></div></a></div><p id="a295" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看一个用Python编写的多元线性回归的简单例子。因为是春天，所以我用的是经典教科书数据集，虹膜数据集。</p></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h1 id="7d8f" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">关于数据</h1><p id="4b58" class="pw-post-body-paragraph kf kg iq kh b ki ni jr kk kl nj ju kn ko nk kq kr ks nl ku kv kw nm ky kz la ij bi translated">如果你没听说过教材Iris dataset，可以从Kaggle【链接<a class="ae lb" href="https://www.kaggle.com/uciml/iris" rel="noopener ugc nofollow" target="_blank">此处</a>下载。该数据集自1936年以来一直存在，并被用作分类的标准教科书示例。它包括三种鸢尾，每种有50个样本，以及每种花的一些特性。我想看看我们能否用一个线性模型来拟合这个数据集。</p><h1 id="7383" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">过程</h1><ol class=""><li id="d82f" class="nn no iq kh b ki ni kl nj ko np ks nq kw nr la ns nt nu nv bi translated">导入必要的模块，读取数据，并查看示例:</li></ol><pre class="le lf lg lh gt nw nx ny nz aw oa bi"><span id="9ce4" class="ob mr iq nx b gy oc od l oe of">import pandas as pd<br/>import seaborn as sns<br/>import statsmodels.api as sm<br/>from sklearn.linear_model import LinearRegression</span><span id="964c" class="ob mr iq nx b gy og od l oe of">df = pd.read_csv(“data/IRIS.csv”)<br/>df.sample(10)</span></pre><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/3c948436a8379f395a9bfa2c987eae8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*1cB3AscbsibIwsdzg512KA.png"/></div></figure><p id="7aeb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.在数据中寻找相关性</p><pre class="le lf lg lh gt nw nx ny nz aw oa bi"><span id="abec" class="ob mr iq nx b gy oc od l oe of">df.corr()</span></pre><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/7031fd69d2b925029b16a224b51eadde.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*xWATeStOBR2tYQWSZyzAVw.png"/></div></figure><p id="7bc5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从相关矩阵可以看出，花瓣_宽度和花瓣_长度，以及萼片_长度和花瓣_长度都是高度相关的。顺便说一下，我们可以在关联热图中看到这一点。</p><pre class="le lf lg lh gt nw nx ny nz aw oa bi"><span id="bf8e" class="ob mr iq nx b gy oc od l oe of"># Use the .heatmap method to depict the relationships visually!</span><span id="a611" class="ob mr iq nx b gy og od l oe of">sns.heatmap(df.corr());</span></pre><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/6ba07c9b37cdefda1b266735716125e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*O93_nrnMi5SwhikMLDz3ZQ.png"/></div></figure><p id="f734" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.使用统计模型创建线性回归模型</p><pre class="le lf lg lh gt nw nx ny nz aw oa bi"><span id="92b0" class="ob mr iq nx b gy oc od l oe of"># Multiple Regression in StatsModels</span><span id="035f" class="ob mr iq nx b gy og od l oe of">x = df[['sepal_length','petal_width']]</span><span id="0cbc" class="ob mr iq nx b gy og od l oe of"># Our model needs an intercept so we add a column of 1s<br/>predictors = sm.add_constant(x) </span><span id="9c2d" class="ob mr iq nx b gy og od l oe of">model = sm.OLS(y, predictors).fit()</span><span id="bcbe" class="ob mr iq nx b gy og od l oe of"># print the parameters of our model<br/>model.params</span></pre><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/f707ed0e95419739744e810050c78527.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*rVZw7FV-YD55QIUTSfPjfg.png"/></div></figure><p id="9a27" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于这个等式:</p><pre class="le lf lg lh gt nw nx ny nz aw oa bi"><span id="f38b" class="ob mr iq nx b gy oc od l oe of">line = f'Regression line: y = {model.params[0]:.2f} + {model.params[1]:.2f}x1 + {model.params[2]:.2f}x2'<br/>line</span></pre><p id="7c29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">回归线为:<em class="lc"> y = -1.50 + 0.54x1 + 1.74x2 </em>其中<em class="lc"> x1 </em>和<em class="lc"> x2 </em>分别为萼片_长度和花瓣_宽度的独立值，权重和偏差四舍五入到小数点后两位。</p></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><p id="8d78" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">4.我们可以使用scikit-learn创建相同的线性回归模型(没有数据的训练测试分割)。</p><pre class="le lf lg lh gt nw nx ny nz aw oa bi"><span id="38c2" class="ob mr iq nx b gy oc od l oe of">lr = LinearRegression()<br/>lr.fit(x, y);<br/>sepal_length, petal_width = lr.coef_<br/>const = lr.intercept_</span><span id="470e" class="ob mr iq nx b gy og od l oe of">line = f'Regression line: y = {const:.2f} + {sepal_length:.2f}x1 + {petal_width:.2f}x2'<br/>line</span></pre><p id="e0f2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">线还是<em class="lc"> y = -1.50 + 0.54x1 + 1.74x2. </em></p></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><p id="0385" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么，如果这两个模块给出相同的线性回归线，为什么有多个包而不是一个？答案在于每个人的意图。</p><ul class=""><li id="19b1" class="nn no iq kh b ki kj kl km ko ol ks om kw on la oo nt nu nv bi translated">根据API(链接<a class="ae lb" href="https://www.statsmodels.org/stable/index.html" rel="noopener ugc nofollow" target="_blank">这里是</a>)，statsmodels <em class="lc">“是一个Python模块，它提供了用于许多不同统计模型的估计的类和函数，以及用于进行统计测试和统计数据探索的类和函数。”</em>它遵循传统的统计模型，重点是分析数据。事实上，您可以使用statsmodels来打印汇总统计数据，这些统计数据可用于确定哪个特性具有统计显著性。</li></ul><pre class="le lf lg lh gt nw nx ny nz aw oa bi"><span id="2bbf" class="ob mr iq nx b gy oc od l oe of">model.summary()</span></pre><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi op"><img src="../Images/2ab208f95956838830920df4f9e9b36d.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*0mORzjr6nwO9uEOrcexEhg.png"/></div></figure><ul class=""><li id="473a" class="nn no iq kh b ki kj kl km ko ol ks om kw on la oo nt nu nv bi translated">作为比较，scikit-learn(文档<a class="ae lb" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" rel="noopener ugc nofollow" target="_blank">此处为</a>)遵循机器学习传统，强调训练测试分割预测的模型选择。一旦您分析了数据，这对于构建最终模型非常有用。</li></ul></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><p id="6022" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">各位，这就是我今天的全部内容！以下是这篇文章的一些要点:</p><ul class=""><li id="af80" class="nn no iq kh b ki kj kl km ko ol ks om kw on la oo nt nu nv bi translated">尽管多元线性回归方程在几何上看起来不是一条直线，但它是数学家所说的预测因子和权重的线性组合。</li><li id="444b" class="nn no iq kh b ki oq kl or ko os ks ot kw ou la oo nt nu nv bi translated">有两个计算线性回归模型的python包:statsmodels和scikit-learn。statsmodels适用于探索和分析数据，而scikit-learn则用于使用机器学习进行预测。两者都使用普通线性回归的原理。</li></ul><p id="bd2a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一如既往，在评论里聊！</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="ov mp l"/></div></figure></div></div>    
</body>
</html>