# 什么是可解释的人工智能，它是为了什么？

> 原文：<https://medium.datadriveninvestor.com/what-is-explainable-ai-and-what-is-it-for-1748881192e7?source=collection_archive---------4----------------------->

![](img/833f76b240743a62b62ae05ec8e01e05.png)

Image from mc.ai

我相信在我们的时代，已经没有必要再写 AI 的存在和重要性了。尤其是在机器学习方面，系统做出的预测、建议和决策越来越普遍。我将在本文中准确地阐述这一点，这一点与人工智能对其算法的影响有关。

首先，有必要指出，对于一个 ML 模型所能影响的结果，有不同的临界水平。影响最小也可能是最常见的例子是购买建议。如果一个系统推荐一个不符合消费者特征的产品，影响是很小的。也许结果只是一个麻烦。

[](https://www.datadriveninvestor.com/2019/02/19/artificial-intelligence-trends-to-watch-this-year/) [## 今年值得关注的 5 大人工智能趋势|数据驱动的投资者

### 预计 2019 年人工智能将取得广泛的重大进展。从谷歌搜索到处理复杂的工作，如…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2019/02/19/artificial-intelligence-trends-to-watch-this-year/) 

然而，还有其他层次的人工智能影响，这是荒谬的关键。这些建议包括金融投资、自动驾驶汽车以及诊断或健康治疗决策等。人工智能系统建议，如果一个人进行了一次不幸的投资，失去了他或她的储蓄，这将是一件可怕的事情。然而，更糟糕的是，后果会威胁到人们的健康或生命。

目前，人工智能算法产生的结果实际上是一个黑盒，主要是最复杂的那些。结果，无论是以预测、建议还是决策的形式，通常都是由算法生成，然后应用到现实生活中，而没有任何批判性的分析。*开始受到质疑的是，这种算法究竟是如何得出结果的*，*它的规则是什么，包括与责任和道德观念相对应的偏差或参数。*

现实生活中的一个典型例子，几乎是*的陈词滥调*，是著名的伦理困境:电车冲向五个绑在铁轨上的人。有一个绕道，可以通过杠杆启动，到火车可以跟随的地方，那里只有一个人被绑在铁轨上。困境是，你会让火车转向吗？这样做，你可以救五个人，只有一个人会死。然而，在那种情况下，你会导致那个人的死亡。这听起来像是一个强加的例子，但它是说明性的，与上下文相关。

> 另一个案例，现在被视为人工智能的结果:如果无人驾驶汽车意外地在前面看到一位老年女士和一位推着婴儿车的母亲正在过马路，该怎么办？该决定将允许仅偏离其中之一。救那位女士还是救那位带着孩子的母亲。算法应该采取什么行动？放过谁？

让我们进一步看一个当前的例子。

在冠状病毒爆发日益严重的情况下，如果一个人工智能算法预测到一场全球流行病的高概率，并在第一批病例中建议一种积极的实验性治疗，这将使这些人的生命处于危险之中，这是可以接受的吗？冒着少数人的生命危险去阻止成千上万人的死亡？

> AI (XAI) 上来试着思考这样的情况。简而言之，这是一个新的研究领域，它主张人工智能模型应该透明，并让人类理解和审核它们的结果。

对于每个临界级别，应根据可能的后果采用相应的透明度级别。换句话说，主要目标是让人类知道影响算法结果的参数和偏差，并在必要时进行干预，以避免更糟糕的后果。 *XAI 与其说是技术，不如说是治理过程。*
毫无疑问，随着 AI 的日益无处不在，必须朝着这个方向迈出步伐。或许我们已经过了这个小时了。