<html>
<head>
<title>Stock Price Prediction Using Recurrent Neural Network(Artificial Intelligence)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用递归神经网络(人工智能)的股票价格预测</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/stock-price-prediction-using-recurrent-neural-network-artificial-intelligence-ffe6ac1bd344?source=collection_archive---------4-----------------------#2020-08-19">https://medium.datadriveninvestor.com/stock-price-prediction-using-recurrent-neural-network-artificial-intelligence-ffe6ac1bd344?source=collection_archive---------4-----------------------#2020-08-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="852c" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">递归神经网络导论</h1><blockquote class="kl km kn"><p id="2813" class="ko kp kq kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">R <strong class="kr ir"> <em class="iq">当前神经网络(RNN) </em> </strong> <em class="iq">是一种</em> <a class="ae ln" href="https://www.geeksforgeeks.org/tag/neural-network/" rel="noopener ugc nofollow" target="_blank"> <em class="iq">神经网络</em> </a> <em class="iq">，其中来自前一步骤的</em> <strong class="kr ir"> <em class="iq">输出被作为输入馈送到当前步骤</em> </strong> <em class="iq">。在传统的神经网络中，所有的输入和输出都是相互独立的，但在需要预测句子的下一个单词时，需要前面的单词，因此需要记住前面的单词。于是RNN出现了，它借助一个隐藏层解决了这个问题。RNN最主要也是最重要的特点是</em> <strong class="kr ir"> <em class="iq">隐藏状态</em> </strong> <em class="iq">，它记住了一个序列的一些信息。</em></p></blockquote><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/32855fc38f81c857ddc4008f9d915413.png" data-original-src="https://miro.medium.com/v2/resize:fit:342/format:webp/0*WwcOtGn_ZA9ArRpZ.jpg"/></div></figure><p id="5677" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz lw lb lc ld lx lf lg lh ly lj lk ll lm ij bi translated"><strong class="kr ir"><em class="kq">→计算当前状态的公式:</em> </strong></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/9a532b6b4729c0baec905551ba4cbac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:358/format:webp/0*Rrc8LkHvidcprBU4.png"/></div></figure><p id="ddb4" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz lw lb lc ld lx lf lg lh ly lj lk ll lm ij bi translated">其中:</p><pre class="lp lq lr ls gt ma mb mc md aw me bi"><span id="cacd" class="mf jo iq mb b gy mg mh l mi mj">ht -&gt; current state<br/>ht-1 -&gt; previous state<br/>xt -&gt; input state</span></pre><p id="7880" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz lw lb lc ld lx lf lg lh ly lj lk ll lm ij bi translated"><strong class="kr ir">→应用激活功能的公式(tanh): </strong></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mk"><img src="../Images/bae7de57b325f202bcc969e1102c7abd.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/0*KRwdtCuGjQ_BLRCN.png"/></div></div></figure><p id="ad3f" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz lw lb lc ld lx lf lg lh ly lj lk ll lm ij bi translated">其中:</p><pre class="lp lq lr ls gt ma mb mc md aw me bi"><span id="355c" class="mf jo iq mb b gy mg mh l mi mj">whh -&gt; weight at recurrent neuron<br/>wxh -&gt; weight at input neuron</span></pre><p id="723e" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz lw lb lc ld lx lf lg lh ly lj lk ll lm ij bi translated"><strong class="kr ir">→产量计算公式:</strong></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/d78134504025f964a3e25d34655a1b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/0*PffDrL_UYlmAbQN2.png"/></div></figure><p id="fa74" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz lw lb lc ld lx lf lg lh ly lj lk ll lm ij bi translated">其中:</p><pre class="lp lq lr ls gt ma mb mc md aw me bi"><span id="c5b0" class="mf jo iq mb b gy mg mh l mi mj">Yt -&gt; output<br/>Why -&gt; weight at output layer</span></pre><h2 id="6e19" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">递归神经网络的基本工作流程如下</h2><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi nb"><img src="../Images/26bf45120c2bec068a87a713f8a8b8ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AxruKU7GM9JpjzdH.png"/></div></div></figure><blockquote class="kl km kn"><p id="1fe4" class="ko kp kq kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="iq"> h0是网络的初始隐藏状态。通常，它是一个零向量，但也可以有其他值。一种方法是将关于数据的假设编码到网络的初始隐藏状态中。例如，对于确定名人讲话的音调的问题，该人过去讲话的音调可以被编码到初始隐藏状态中。另一种技术是将初始隐藏状态作为可训练参数。尽管这些技术给网络增加了很少的细微差别，但是将隐藏状态向量初始化为零通常是有效的选择。</em></p></blockquote><p id="2de5" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz lw lb lc ld lx lf lg lh ly lj lk ll lm ij bi translated"><strong class="kr ir">各循环单元的工作:</strong></p><ol class=""><li id="014d" class="nc nd iq kr b ks kt kw kx lw ne lx nf ly ng lm nh ni nj nk bi translated">取输入前一个隐藏状态向量和当前输入向量。注意，因为隐藏状态和当前输入被视为向量，所以向量中的每个元素被放置在与其他维度正交的不同维度中。因此，当每个元素与另一个元素相乘时，仅当所涉及的元素非零并且这些元素处于相同维度时，才给出非零值。</li><li id="2f1c" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm nh ni nj nk bi translated">将隐藏状态向量按元素乘以隐藏状态权重，并类似地执行当前输入向量和当前输入权重的按元素乘法。这产生了参数化的隐藏状态向量和当前输入向量。</li><li id="eb9e" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm nh ni nj nk bi translated">注意，不同向量的权重存储在可训练权重矩阵中。执行两个参数化向量的向量加法，然后计算元素双曲正切以生成新的隐藏状态向量。</li></ol><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi nq"><img src="../Images/b2a5e20ab037780118fafeb6085988f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*E29J1brodxOO466R.png"/></div></div></figure><p id="7cef" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz lw lb lc ld lx lf lg lh ly lj lk ll lm ij bi translated">在递归网络的训练期间，网络还在每个时间步长生成输出。该输出用于使用梯度下降来训练网络。</p><p id="409e" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz lw lb lc ld lx lf lg lh ly lj lk ll lm ij bi translated">因此，通过时间的反向传播与典型的反向传播的唯一不同之处在于，每个时间步长的误差被求和以计算总误差。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi nr"><img src="../Images/2720770b881852c611d828e0872eae7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*30L98-2qYf0jnbr8.png"/></div></div></figure><p id="353c" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz lw lb lc ld lx lf lg lh ly lj lk ll lm ij bi translated">尽管基本的递归神经网络相当有效，但它也有一个严重的问题。对于深层网络，反向传播过程会导致以下问题</p><ul class=""><li id="de61" class="nc nd iq kr b ks kt kw kx lw ne lx nf ly ng lm ns ni nj nk bi translated"><strong class="kr ir">消失梯度:</strong>当梯度变得非常小并趋于零时，就会出现这种情况。</li><li id="ae95" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm ns ni nj nk bi translated"><strong class="kr ir">爆炸梯度:</strong>当梯度由于反向传播而变得过大时，就会出现这种情况。</li></ul><h1 id="1db9" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">通过RNN进行培训</h1><ol class=""><li id="11dd" class="nc nd iq kr b ks nt kw nu lw nv lx nw ly nx lm nh ni nj nk bi translated">输入的单个时间步长被提供给网络。</li><li id="d3b8" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm nh ni nj nk bi translated">然后使用一组当前输入和先前状态计算其当前状态。</li><li id="64db" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm nh ni nj nk bi translated">当前ht变为下一时间步的ht-1。</li><li id="dc3a" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm nh ni nj nk bi translated">可以根据问题进行尽可能多的时间步骤，并加入来自所有先前状态的信息。</li><li id="17fa" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm nh ni nj nk bi translated">一旦所有时间步骤完成，最终的当前状态用于计算输出。</li><li id="d0f4" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm nh ni nj nk bi translated">然后将输出与实际输出(即目标输出)进行比较，产生误差。</li><li id="46da" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm nh ni nj nk bi translated">然后将误差反向传播到网络以更新权重，从而训练网络(RNN)。</li></ol><h1 id="7488" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">递归神经网络的优势</h1><ol class=""><li id="8c94" class="nc nd iq kr b ks nt kw nu lw nv lx nw ly nx lm nh ni nj nk bi translated">一个RNN人能记住所有的信息。它之所以在时间序列预测中有用，只是因为它还具有记住以前输入的功能。这叫做长短期记忆。</li><li id="7f1a" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm nh ni nj nk bi translated">递归神经网络甚至与卷积层一起使用，以扩展有效像素邻域。</li></ol><p id="a478" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz lw lb lc ld lx lf lg lh ly lj lk ll lm ij bi translated"><strong class="kr ir">递归神经网络的缺点</strong></p><ol class=""><li id="b9fb" class="nc nd iq kr b ks kt kw kx lw ne lx nf ly ng lm nh ni nj nk bi translated">梯度消失和爆炸问题。</li><li id="88ec" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm nh ni nj nk bi translated">训练RNN是一项非常艰巨的任务。</li><li id="a4d3" class="nc nd iq kr b ks nl kw nm lw nn lx no ly np lm nh ni nj nk bi translated">如果使用tanh或relu作为激活函数，它不能处理很长的序列。</li></ol><h1 id="1295" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">亚马逊公司的股票价格预测</h1><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ny"><img src="../Images/9eba84e3dbb63557da52982bcaa0f200.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1__5YsU98ctyOmme"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk">Photo by <a class="ae ln" href="https://unsplash.com/@bryanangelo?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Bryan Angelo</a> on <a class="ae ln" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><blockquote class="kl km kn"><p id="e96e" class="ko kp kq kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">基于递归神经网络</p><p id="02d0" class="ko kp kq kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">编码部分…</p></blockquote><h1 id="d9e3" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">数据要求</h1><p id="6ace" class="pw-post-body-paragraph ko kp iq kr b ks nt ku kv kw nu ky kz lw od lc ld lx oe lg lh ly of lk ll lm ij bi translated">我们使用亚马逊股票价格数据集<strong class="kr ir">、</strong>，我们的任务是根据提供的数据，使用递归神经网络预测特定时间段的股票价格</p><h2 id="4111" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→导入库</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><h2 id="2629" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→加载数据集</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><h2 id="219d" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→使用matplotlib可视化数据</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi oi"><img src="../Images/05c5159a00fef686d3bae8ebdc9c34ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yD5vsbXCRXxCr6vAUGgR4w.png"/></div></div></figure><h2 id="47cf" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→了解我们用于训练数据的行数</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><pre class="lp lq lr ls gt ma mb mc md aw me bi"><span id="03ec" class="mf jo iq mb b gy mg mh l mi mj">1736</span></pre><h2 id="63fa" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→缩放数据</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><pre class="lp lq lr ls gt ma mb mc md aw me bi"><span id="8de6" class="mf jo iq mb b gy mg mh l mi mj">array([[1.01670545e-03],<br/>       [5.18191392e-04],<br/>       [5.50990279e-04],<br/>       ...,<br/>       [9.79016559e-01],<br/>       [9.74752964e-01],<br/>       [9.86031778e-01]])</span></pre><h2 id="e8b3" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→创建训练数据</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><h2 id="49c6" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→建立长期短期模型</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><h2 id="39fa" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→编译模型</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><h2 id="5c72" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→训练模型</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><pre class="lp lq lr ls gt ma mb mc md aw me bi"><span id="bcc2" class="mf jo iq mb b gy mg mh l mi mj">"1616/1616 [==============================] - 68s 42ms/step - loss: 5.2229e-04"<br/>&lt;tensorflow.python.keras.callbacks.History at 0x7f0177fde208&gt;</span></pre><h2 id="c1d7" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→创建测试数据</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><h2 id="b199" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→获得预测价格值</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><h2 id="3979" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→评估</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><pre class="lp lq lr ls gt ma mb mc md aw me bi"><span id="a1e8" class="mf jo iq mb b gy mg mh l mi mj">40.22249227075533</span></pre><h2 id="77f1" class="mf jo iq bd jp mq mr dn jt ms mt dp jx lw mu mv kb lx mw mx kf ly my mz kj na bi translated">→可视化亚马逊股票价格的预测值</h2><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi oi"><img src="../Images/d3890510b2a7f165d09aa6d727df8005.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JsGD1hr1KPDGFJGR-tfowA.png"/></div></div></figure><h1 id="97ee" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="3e44" class="pw-post-body-paragraph ko kp iq kr b ks nt ku kv kw nu ky kz lw od lc ld lx oe lg lh ly of lk ll lm ij bi translated">因此，我们建立了一个(RNN)使用长短期模型来预测股票，我们在测试数据上获得了很高的准确率，我希望这篇文章对你有用。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi oj"><img src="../Images/a6b46433802e2815bea27f9f17a73130.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TNCSDz927wZL-hwk"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk">Stock Prices</figcaption></figure><blockquote class="kl km kn"><p id="7be0" class="ko kp kq kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">通过长短期记忆模型使用递归神经网络预测股票价格是使用python和机器学习来完成的。</p></blockquote></div></div>    
</body>
</html>