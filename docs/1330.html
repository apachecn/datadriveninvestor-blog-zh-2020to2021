<html>
<head>
<title>Reinforcement Learning for Options Trading</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">期权交易的强化学习</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/reinforcement-learning-for-options-trading-765c84d0d97d?source=collection_archive---------0-----------------------#2020-03-13">https://medium.datadriveninvestor.com/reinforcement-learning-for-options-trading-765c84d0d97d?source=collection_archive---------0-----------------------#2020-03-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="87b7" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">金融中的人工智能</h2><div class=""/><div class=""><h2 id="6ba7" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">q学习+ Black-Scholes =最优期权价格</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/9e3baf8ca84db70bf1fa4fb8d2a677b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*eGjYY9NZfT7Yy2VY3ZRt5w.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Image Credit: Financial Times</figcaption></figure><p id="95d6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">人工智能正在对金融的许多领域产生影响，尤其是交易领域。多种多样的人工智能子领域，如深度学习、强化学习和自然语言处理，目前正被用于预测股票走势。强化学习交易代理试图通过试错来学习股票价格。通过将Q学习(一种强化学习算法)与Black-Scholes模型(一种传统的期权定价模型)相结合，我们可以创建一个Q学习Black Scholes (QLBS)模型来确定最优期权价格。</p><p id="7727" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在本文中，我将回顾期权、Black-Scholes模型和Q学习，然后展示一个欧式看跌期权的Q学习Black-Scholes模型的实现。</p><p id="10b4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="lw">注:点击</em> <a class="ae lx" href="#aced" rel="noopener ugc nofollow"> <em class="lw">此处</em> </a> <em class="lw">如果想直奔QLBS模式的实现(链接在手机app中不起作用)</em></p><h1 id="0dd6" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">解释的选项</h1><p id="67c6" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">期权是一种衍生证券，这意味着它们的价值取决于股票或商品等其他资产的价格。例如，一份股票的期权合约通常代表100股基础股票。期权合约的价格被称为溢价。本质上，该合同允许持有人在合同到期时或到期前以预先确定的价格(称为执行价格)购买或出售一定数量的基础资产。此外，持有人没有义务购买或出售，所以他们也可以让合同到期。</p><p id="9693" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">两种主要的期权是看涨期权和看跌期权；前者允许持有者以规定的价格购买资产，后者允许持有者以规定的价格出售资产。买家可以用看涨期权进行投机，用看跌期权进行对冲。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/45ad7457ba0bd09427b7896a6d86f958.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Xm8LNLLmuPFS3lE2ACev9w.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Image credit: Gatsby</figcaption></figure><p id="eb67" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了更好地理解这一点，我们来看一个真实世界的例子。假设苹果股票的交易价格是每股200美元。你认为股票可能在下个月涨到210美元以上，以每份合约0.67美元的价格买入210美元的看涨期权。如果价格在合同到期日之前或到期日上涨超过210美元，你以210美元买入股票，如果股票下跌或没有上涨超过210美元，你只损失67美元的溢价(0.67 x 100股)。相反，假设你已经持有苹果股票，并认为价格可能下跌，导致你以每份合同0.63美元的价格买入190美元的看跌期权。如果在合约到期日之前或到期日，股价跌破190美元，你以190美元卖出股票获利，如果股价没有下跌，你只损失63美元的溢价(0.63 x 100股)。既然我们理解了期权，让我们继续讨论布莱克-斯科尔斯模型。</p><h1 id="61fc" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">布莱克-斯科尔斯模型</h1><p id="dfc9" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">布莱克-斯科尔斯方程，可能是金融学中最著名的方程，提供了第一个广泛使用的期权定价模型。当前股票价格、期权的执行价格、预期利率、到期时间和波动性(价格波动的量度)都被用作计算期权理论价值的输入。由经济学家费希尔·布莱克、迈伦·斯克尔斯和罗伯特·默顿于1973年提出的这个等式影响巨大，以至于为斯科尔斯和默顿赢得了1997年的诺贝尔经济学奖(布莱克不幸在获得这一荣誉之前去世)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mw"><img src="../Images/3d55a4919f08d72030a179082b19ba62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E0TRiL1bK9MIJzU_xzLxwQ.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Image Credit: KhanAcademy</figcaption></figure><p id="d2fe" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在上图中，C是买入期权价格，N(d1)是对应于买入期权delta(资产价格变化与其衍生产品价格相应变化的比率)的正态分布，N(d2)是对应于买入期权到期时行使的概率的正态分布。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/d053f7f09ce48e09a7a35b34cbcb526a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*1_DIpW0DFsvnLTaqvBCF0g.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Black-Scholes for put option</figcaption></figure><p id="f682" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了简洁起见，我将把重点放在布莱克-斯科尔斯方程所做的假设以及它的局限性上，而不是它背后的实际数学。如果你想更深入的了解布莱克-斯科尔斯，看<a class="ae lx" href="https://www.khanacademy.org/economics-finance-domain/core-finance/derivative-securities/black-scholes/v/introduction-to-the-black-scholes-formula" rel="noopener ugc nofollow" target="_blank">这个</a>。</p><h2 id="02c2" class="nb lz iq bd ma nc nd dn me ne nf dp mi lj ng nh mk ln ni nj mm lr nk nl mo iw bi translated">假设</h2><ul class=""><li id="4a55" class="nm nn iq lc b ld mq lg mr lj no ln np lr nq lv nr ns nt nu bi translated">期权是欧式的(只能在到期时行使，不能在到期前行使)</li><li id="979b" class="nm nn iq lc b ld nv lg nw lj nx ln ny lr nz lv nr ns nt nu bi translated">在期权有效期内不支付股息。</li><li id="1794" class="nm nn iq lc b ld nv lg nw lj nx ln ny lr nz lv nr ns nt nu bi translated">市场是有效的(市场运动无法预测)。</li><li id="42a8" class="nm nn iq lc b ld nv lg nw lj nx ln ny lr nz lv nr ns nt nu bi translated">购买期权没有交易成本。</li><li id="644e" class="nm nn iq lc b ld nv lg nw lj nx ln ny lr nz lv nr ns nt nu bi translated">已知且恒定的无风险利率和基础资产的波动性。</li><li id="0922" class="nm nn iq lc b ld nv lg nw lj nx ln ny lr nz lv nr ns nt nu bi translated">标的资产的正态分布回报。</li></ul><h2 id="74c7" class="nb lz iq bd ma nc nd dn me ne nf dp mi lj ng nh mk ln ni nj mm lr nk nl mo iw bi translated">限制</h2><ul class=""><li id="def4" class="nm nn iq lc b ld mq lg mr lj no ln np lr nq lv nr ns nt nu bi translated">不适用于美国期权(可在到期前行使)</li><li id="151b" class="nm nn iq lc b ld nv lg nw lj nx ln ny lr nz lv nr ns nt nu bi translated">波动性在现实生活中是波动的</li><li id="b562" class="nm nn iq lc b ld nv lg nw lj nx ln ny lr nz lv nr ns nt nu bi translated">存在交易成本</li><li id="40d3" class="nm nn iq lc b ld nv lg nw lj nx ln ny lr nz lv nr ns nt nu bi translated">无风险利率在现实生活中并不总是恒定的</li></ul><p id="aa14" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">很好，现在我们对Black-Scholes有了一个大致的了解，在开始实施QLBS模型之前，我们将回顾一下Q学习。</p><h1 id="8103" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">q学习</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi oa"><img src="../Images/50d0de0b9d9e38c4ff7da8b85974ba54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2rmKGjZOv5pGkLLVt-EuMA.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Image Credit: <a class="ae lx" href="http://incompleteideas.net/book/bookdraft2017nov5.pdf" rel="noopener ugc nofollow" target="_blank">Reinforcement Learning:An Introduction</a></figcaption></figure><p id="9cd2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在强化学习中，目标是回报最大化。代理执行一个动作来从一个状态转换到下一个状态，并且在每个状态中采取的动作给代理一个奖励。例如，想象一个场景，一只狗和它的主人。在家里(环境)，狗(代理人)在主人命令它坐下(状态)时跑来跑去(动作)，不接受任何款待(奖励)。在下一个状态中，如果主人命令狗坐下，它会坐下(因为跑步没有给食物)并接受食物。本质上，狗通过反复试验来学习。</p><div class="ob oc gp gr od oe"><a href="https://www.datadriveninvestor.com/2019/02/19/artificial-intelligence-trends-to-watch-this-year/" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd ja gy z fp oj fr fs ok fu fw iz bi translated">今年值得关注的5大人工智能趋势|数据驱动的投资者</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">预计2019年人工智能将取得广泛的重大进展。从谷歌搜索到处理复杂的工作，如…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="on l"><div class="oo l op oq or on os ku oe"/></div></div></a></div><p id="c8dd" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">Q-learning是一种强化学习算法，目标是学习最优策略(策略告诉代理在什么情况下采取什么行动)。状态x动作的维度Q表具有初始化为零的值。然后，代理选择一个动作，观察一个奖励，并进入一个新的状态，更新Q，即在每个时间t在一个状态中采取的动作的“质量”。下面是算法。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi ot"><img src="../Images/8158f216e8d6c35136cec40d2a5d026c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nOkIED37J38hIvuc1MMihw.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Image Credit: <a class="ae lx" href="https://en.wikipedia.org/wiki/Q-learning" rel="noopener ugc nofollow" target="_blank">Wikipedia</a></figcaption></figure><p id="79af" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">学习率通常在所有时间t内都是恒定的，它决定了从0(代理没有学习到新信息)到1(代理只考虑最近的信息)新信息覆盖旧信息的程度。此外，折扣系数决定了未来奖励的重要性，范围从0(仅当前奖励重要)到1(优先考虑长期奖励)。</p><p id="f76a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">代理可以通过两种方式与环境交互。一种方式是利用，代理使用Q表作为参考，并选择具有最高值的动作。然而，Q-table以全零开始，所以有时必须随机选择动作。这就是探索，当代理随机选择一个行动，而不是基于最大未来回报选择。epsilon值设置您希望代理探索而不是利用的时间百分比。</p><p id="c8b9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">最后，是时候进入Q学习和Black -Scholes的交叉点了！</p><h1 id="aced" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">q学习+布莱克-斯科尔斯</h1><p id="3868" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">当Q-learning和Black-Scholes结合时，我们的QLBS模型使用交易数据来自主学习最优期权价格和最优对冲。在模型的实现中，我们将使用欧式看跌期权。在实现QLBS模型之前，我们还将实现经典的Black-Scholes公式来比较两者的结果。为了避免这篇文章变得不必要的长，我将省略图形代码，直接展示图形；你仍然可以点击<a class="ae lx" href="https://colab.research.google.com/drive/1wa2puOkPuUt5LHdQBbyLJtQi6qYTYEC0" rel="noopener ugc nofollow" target="_blank">这里</a>查看完整代码(该项目是Coursera的<a class="ae lx" href="https://www.coursera.org/learn/reinforcement-learning-in-finance" rel="noopener ugc nofollow" target="_blank">金融强化学习</a>课程中的一个练习)。</p><h1 id="1836" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">进口</h1><p id="3509" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">首先，我们进行必要的进口。</p><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="686d" class="nb lz iq ov b gy oz pa l pb pc">import numpy as np<br/>import pandas as pd<br/>from scipy.stats import norm<br/>import random<br/>import time<br/>import matplotlib.pyplot as plt<br/>import sys</span></pre><h1 id="f68e" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">蒙特 卡罗模拟</h1><p id="4ac4" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">在导入之后，我们将为价格的蒙特卡罗模拟设置参数。蒙特卡洛模拟用于模拟由于随机变量的存在而不可预测的过程中不同结果的概率(如股票价格变动)。</p><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="46dd" class="nb lz iq ov b gy oz pa l pb pc">S0 = 100      # initial stock price<br/>mu = 0.05     # drift<br/>sigma = 0.15  # volatility<br/>r = 0.03      # risk-free rate<br/>M = 1         # maturity</span><span id="522d" class="nb lz iq ov b gy pd pa l pb pc">T = 24        # number of time steps<br/>N_MC = 10000  # number of paths</span><span id="ce34" class="nb lz iq ov b gy pd pa l pb pc">delta_t = M / T                # time interval<br/>gamma = np.exp(- r * delta_t)  # discount factor</span></pre><h1 id="42d6" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">布莱克-斯科尔斯模拟</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi pe"><img src="../Images/2d7894265d668121814c0a70f4b92bf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XA73NQTp_sw0q2fvTn3MCg.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Images from Coursera: Reinforcement Learning in Finance</figcaption></figure><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="b972" class="nb lz iq ov b gy oz pa l pb pc">np.random.seed(42)</span><span id="dd2c" class="nb lz iq ov b gy pd pa l pb pc"># stock price<br/>S = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))<br/>S.loc[:,0] = S0</span><span id="2a35" class="nb lz iq ov b gy pd pa l pb pc"># standard normal random numbers<br/>RN = pd.DataFrame(np.random.randn(N_MC,T), index=range(1, N_MC+1), columns=range(1, T+1))</span><span id="74ef" class="nb lz iq ov b gy pd pa l pb pc">for t in range(1, T+1):<br/>    S.loc[:,t] = S.loc[:,t-1] * np.exp((mu - 1/2 * sigma**2) * delta_t + sigma * np.sqrt(delta_t) * RN.loc[:,t])</span><span id="121a" class="nb lz iq ov b gy pd pa l pb pc">delta_S = S.loc[:,1:T].values - np.exp(r * delta_t) * S.loc[:,0:T-1]<br/>delta_S_hat = delta_S.apply(lambda x: x - np.mean(x), axis=0)</span><span id="9829" class="nb lz iq ov b gy pd pa l pb pc"># state variable<br/>X = - (mu - 1/2 * sigma**2) * np.arange(T+1) * delta_t + np.log(S)   # delta_t here is due to their conventions</span></pre><p id="3fbb" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这是一些股票价格和状态变量路径的样子。</p><div class="kp kq kr ks gt ab cb"><figure class="pf kt pg ph pi pj pk paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><img src="../Images/c4c24223ea9bda461d59a178ee483272.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*MCAc9JEgNwFmkt87QwkvuQ.png"/></div></figure><figure class="pf kt pl ph pi pj pk paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><img src="../Images/3fc609c6897316932e9f459afaa13226.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*Jq5sTc2lYH1NnohNU0OzpQ.png"/></div></figure></div><h1 id="8036" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">最终收益</h1><p id="2443" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">最终收益是投资者在期权策略到期时获得的金额。我们将定义一个函数来计算欧式看跌期权的最终收益。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/fc828515bbee4eae4fa889ed0113c382.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*as8SUZqkzGgUUUb74juzbw.png"/></div></figure><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="d440" class="nb lz iq ov b gy oz pa l pb pc">def terminal_payoff(ST, K):<br/>    # ST   final stock price<br/>    # K    strike<br/>    payoff = max(K - ST, 0)<br/>    return payoff</span></pre><h1 id="21df" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">样条基函数</h1><p id="767a" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">样条函数是由多项式函数分段构造的函数。B样条函数是最大可微的插值基函数，我们可以用它来表示状态变量x。</p><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="ef1d" class="nb lz iq ov b gy oz pa l pb pc">!pip install bspline<br/>import bspline<br/>import bspline.splinelab as splinelab</span><span id="8f48" class="nb lz iq ov b gy pd pa l pb pc">X_min = np.min(np.min(X))<br/>X_max = np.max(np.max(X))<br/>print('X.shape = ', X.shape)<br/>print('X_min, X_max = ', X_min, X_max)</span><span id="c092" class="nb lz iq ov b gy pd pa l pb pc">p = 4            # order of spline (as-is; 3 = cubic, 4: B spline?)<br/>ncolloc = 12</span><span id="87e8" class="nb lz iq ov b gy pd pa l pb pc">tau = np.linspace(X_min,X_max,ncolloc)  <br/># These are the sites to which we would like to interpolate</span><span id="d774" class="nb lz iq ov b gy pd pa l pb pc"># k is a knot vector that adds endpoints repeats as appropriate for a spline of order p<br/># To get meaninful results, one should have ncolloc &gt;= p+1<br/>k = splinelab.aptknt(tau, p) <br/>                             <br/># Spline basis of order p on knots k<br/>basis = bspline.Bspline(k, p)        <br/>        <br/>f = plt.figure()<br/># B   = bspline.Bspline(k, p)     # Spline basis functions <br/>print('Number of points k = ', len(k))<br/>basis.plot()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi pn"><img src="../Images/37fc948858347f2cbf84da1102f28485.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BtuAnofAmAPlb5xFqCQTBQ.png"/></div></div></figure><h1 id="4b33" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">数据矩阵</h1><p id="25f4" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">现在我们用特征值做数据矩阵；这里的特征是数据点处的基函数值，输出是维数为num_tSteps x num_MC x num_basis的3D数组。</p><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="495e" class="nb lz iq ov b gy oz pa l pb pc">num_t_steps = T + 1<br/>num_basis =  ncolloc # len(k) #</span><span id="4862" class="nb lz iq ov b gy pd pa l pb pc">data_mat_t = np.zeros((num_t_steps, N_MC,num_basis ))<br/>print('num_basis = ', num_basis)<br/>print('dim data_mat_t = ', data_mat_t.shape)</span><span id="13af" class="nb lz iq ov b gy pd pa l pb pc"># fill it <br/>for i in np.arange(num_t_steps):<br/>    x = X.values[:,i]<br/>    data_mat_t[i,:,:] = np.array([ basis(el) for el in x ])</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi po"><img src="../Images/b7b386518b8dee537b533324484d884a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*sWqm87e7tCy0wQ7Tzzs4DQ.png"/></div></figure><h1 id="5717" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">QLBS的动态规划解决方案</h1><p id="e4ff" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">简单解释一下，马尔可夫决策过程(MDP)包含一组可能的世界状态S、一组可能的动作A、一个实值奖励函数R(s，A)以及每个状态下每个动作效果的描述T。贝尔曼最优方程可以提供一个最优策略来求解每个MDP。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi pp"><img src="../Images/ab8245d2a15e40a7fcac4ab65a9f38bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5NhLYkZL1VK2un9BfXP5qA.png"/></div></div></figure><h1 id="f880" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">定义期权执行和风险规避参数</h1><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="a650" class="nb lz iq ov b gy oz pa l pb pc">risk_lambda = 0.001 <em class="lw"># risk aversion</em><br/>K = 100             <em class="lw"># option stike</em></span></pre><h1 id="8ae0" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">计算最佳行动的系数</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi pq"><img src="../Images/01d78f33eb26a5822441525c0aca3144.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GIsuVjdej13yCBJrKMJUJg.png"/></div></div></figure><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="ca5c" class="nb lz iq ov b gy oz pa l pb pc"># functions to compute optimal hedges<br/>def function_A_vec(t, delta_S_hat, data_mat, reg_param):<br/>    X_mat = data_mat[t, :, :]<br/>    num_basis_funcs = X_mat.shape[1]<br/>    this_dS = delta_S_hat.loc[:, t]<br/>    hat_dS2 = (this_dS ** 2).values.reshape(-1, 1)<br/>    A_mat = np.dot(X_mat.T, X_mat * hat_dS2) + reg_param * np.eye(num_basis_funcs)<br/>    return A_mat<br/>   <br/>        <br/>def function_B_vec(t, Pi_hat, delta_S_hat=delta_S_hat, S=S, data_mat=data_mat_t, gamma=gamma, risk_lambda=risk_lambda):<br/>    tmp = Pi_hat.loc[:,t+1] * delta_S_hat.loc[:, t]<br/>    X_mat = data_mat[t, :, :]  # matrix of dimension N_MC x num_basis<br/>    B_vec = np.dot(X_mat.T, tmp)<br/>    return B_vec</span></pre><h1 id="df24" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">计算最佳对冲和投资组合价值</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi pr"><img src="../Images/ca7b6c69cc4d044848e59aee261f899a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m3LCer78A35oXXUhn6Bh2Q.png"/></div></div></figure><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="1cd2" class="nb lz iq ov b gy oz pa l pb pc"># portfolio value<br/>Pi = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))<br/>Pi.iloc[:,-1] = S.iloc[:,-1].apply(lambda x: terminal_payoff(x, K))</span><span id="bd28" class="nb lz iq ov b gy pd pa l pb pc">Pi_hat = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))<br/>Pi_hat.iloc[:,-1] = Pi.iloc[:,-1] - np.mean(Pi.iloc[:,-1])</span><span id="9d55" class="nb lz iq ov b gy pd pa l pb pc"># optimal hedge<br/>a = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))<br/>a.iloc[:,-1] = 0</span><span id="89f7" class="nb lz iq ov b gy pd pa l pb pc">reg_param = 1e-3 # free parameter<br/>for t in range(T-1, -1, -1):<br/>    A_mat = function_A_vec(t, delta_S_hat, data_mat_t, reg_param)<br/>    B_vec = function_B_vec(t, Pi_hat, delta_S_hat, S, data_mat_t, gamma, risk_lambda)<br/>    # print ('t =  A_mat.shape = B_vec.shape = ', t, A_mat.shape, B_vec.shape)<br/>    <br/>    # coefficients for expansions of the optimal action<br/>    phi = np.dot(np.linalg.inv(A_mat), B_vec)<br/>    <br/>    a.loc[:,t] = np.dot(data_mat_t[t,:,:],phi)<br/>    Pi.loc[:,t] = gamma * (Pi.loc[:,t+1] - a.loc[:,t] * delta_S.loc[:,t])<br/>    Pi_hat.loc[:,t] = Pi.loc[:,t] - np.mean(Pi.loc[:,t])<br/>    <br/>a = a.astype('float')<br/>Pi = Pi.astype('float')<br/>Pi_hat = Pi_hat.astype('float')</span></pre><div class="kp kq kr ks gt ab cb"><figure class="pf kt ps ph pi pj pk paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><img src="../Images/c0add519c7a918d46022f42824672f04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*4QIZ_s6kdPFpCrcJmT2D3A.png"/></div></figure><figure class="pf kt ps ph pi pj pk paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><img src="../Images/c785627391571a4faacd2cfad0b0da3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*FTlyTLe0nb5adSQRkKrs9A.png"/></div></figure></div><h1 id="64d7" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">计算所有路径的奖励</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi pt"><img src="../Images/eff776d84b3e95a0b28357df6756ba07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YaAvAzkKwfoAEi1t_NKyQg.png"/></div></div></figure><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="d1bf" class="nb lz iq ov b gy oz pa l pb pc"># Compute rewards for all paths<br/># reward function<br/>R = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))<br/>R.iloc[:,-1] = - risk_lambda * np.var(Pi.iloc[:,-1])</span><span id="d5b1" class="nb lz iq ov b gy pd pa l pb pc">for t in range(T):<br/>    R.loc[1:,t] = gamma * a.loc[1:,t] * delta_S.loc[1:,t] - risk_lambda * np.var(Pi.loc[1:,t])<br/>  <br/># plot 10 paths<br/>plt.plot(R.T.iloc[:, idx_plot])<br/>plt.xlabel('Time Steps')<br/>plt.title('Reward Function')<br/>plt.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi pu"><img src="../Images/4d1468b90992fca277e56652242754d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6vGtqJDLxucNHLOAZVQjtg.png"/></div></div></figure><h1 id="2ae1" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">计算最佳Q函数</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi pv"><img src="../Images/5a362edebd9379e7af813c7885addc02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v84Cwm3UV_vB41DjPh2YLg.png"/></div></div></figure><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="4f86" class="nb lz iq ov b gy oz pa l pb pc">def function_C_vec(t, data_mat, reg_param):<br/>    X_mat = data_mat[t, :, :]<br/>    num_basis_funcs = X_mat.shape[1]<br/>    C_mat = np.dot(X_mat.T, X_mat) + reg_param * np.eye(num_basis_funcs)<br/>    return C_mat<br/>   <br/>def function_D_vec(t, Q, R, data_mat, gamma=gamma):<br/>    X_mat = data_mat[t, :, :]<br/>    D_vec = np.dot(X_mat.T, R.loc[:,t] + gamma * Q.loc[:, t+1])<br/>    return D_vec</span></pre><p id="6a75" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在我们可以调用这些函数来得到最优的Q函数</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi pw"><img src="../Images/35024ff06880fea76fc7b31e029e20eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*17QPpSr756Rhz4wQC28HmA.png"/></div></div></figure><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="2bba" class="nb lz iq ov b gy oz pa l pb pc"># Q function<br/>Q = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))<br/>Q.iloc[:,-1] = - Pi.iloc[:,-1] - risk_lambda * np.var(Pi.iloc[:,-1])</span><span id="306a" class="nb lz iq ov b gy pd pa l pb pc">reg_param = 1e-3<br/>for t in range(T-1, -1, -1):<br/>    C_mat = function_C_vec(t,data_mat_t,reg_param)<br/>    D_vec = function_D_vec(t, Q,R,data_mat_t,gamma)<br/>    omega = np.dot(np.linalg.inv(C_mat), D_vec)<br/>    <br/>    Q.loc[:,t] = np.dot(data_mat_t[t,:,:], omega)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi px"><img src="../Images/c6e508475c4a7a2e69e00046e0cf0e9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JKTDlsbCjBwRmeQIqwCSRg.png"/></div></div></figure><h1 id="4955" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">比较</h1><p id="6670" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">让我们将QLBS价格与Black-Scholes公式给出的欧式看跌价格进行比较。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi py"><img src="../Images/4a3eb609415504a1660cfcedd40c95a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*cfghUzNS25gE2trG3n_AzQ.png"/></div></figure><pre class="kp kq kr ks gt ou ov ow ox aw oy bi"><span id="48c9" class="nb lz iq ov b gy oz pa l pb pc"># The Black-Scholes prices<br/>def bs_put(t, S0=S0, K=K, r=r, sigma=sigma, T=M):<br/>    d1 = (np.log(S0/K) + (r + 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)<br/>    d2 = (np.log(S0/K) + (r - 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)<br/>    price = K * np.exp(-r * (T-t)) * norm.cdf(-d2) - S0 * norm.cdf(-d1)<br/>    return price</span><span id="b4f7" class="nb lz iq ov b gy pd pa l pb pc">def bs_call(t, S0=S0, K=K, r=r, sigma=sigma, T=M):<br/>    d1 = (np.log(S0/K) + (r + 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)<br/>    d2 = (np.log(S0/K) + (r - 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)<br/>    price = S0 * norm.cdf(d1) - K * np.exp(-r * (T-t)) * norm.cdf(d2)<br/>    return price</span></pre><div class="kp kq kr ks gt ab cb"><figure class="pf kt pz ph pi pj pk paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><img src="../Images/b6f8ecf965f36483c06cb48c4d3bbcb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*bweU8ulPnaRwpf-9eWeRPQ.png"/></div></figure><figure class="pf kt qa ph pi pj pk paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><img src="../Images/f9ad507b346bc1b7eccf9815a291d089.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*DT2jV7nD1J5-oqw4-jHgMQ.png"/></div></figure></div><p id="6689" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这里，我们可以看到QLBS看跌价格比Black-Scholes看跌价格高0.4。鉴于期权价格在大多数路径中大幅下跌，我们可以看到QLBS看跌期权价格明显优于Black-Scholes看跌期权价格。</p><h1 id="9a5f" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">摘要</h1><p id="00db" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">作为参考，下面是我们在整个项目中绘制的各种图表。在欧式看涨期权上测试QLBS与BS，并试图找出Q学习如何应用于美式看涨/看跌期权，这将是非常有趣的。再一次，如果你想看的话，我在这里链接了项目<a class="ae lx" href="https://colab.research.google.com/drive/1wa2puOkPuUt5LHdQBbyLJtQi6qYTYEC0" rel="noopener ugc nofollow" target="_blank">的全部代码。</a></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi qb"><img src="../Images/803eb5f61d2ee1fdebeff6dd0b5dfeb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TX7yUPZC1WCS11ukLjcpAg.png"/></div></div></figure><p id="a79a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">咻，今天到此为止！</p><h1 id="95af" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">参考</h1><p id="fed2" class="pw-post-body-paragraph la lb iq lc b ld mq ka lf lg mr kd li lj ms ll lm ln mt lp lq lr mu lt lu lv ij bi translated">[1] Coursera，<a class="ae lx" href="https://www.coursera.org/learn/reinforcement-learning-in-finance" rel="noopener ugc nofollow" target="_blank">金融中的强化学习</a></p><p id="87ad" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[2]伊戈尔·哈尔珀林，<a class="ae lx" href="https://arxiv.org/abs/1801.06077#clicktoread" rel="noopener ugc nofollow" target="_blank">QLBS Q-Learner Goes NuQLear:拟合Q迭代、逆RL、期权组合(2018) </a>、arXiv</p><p id="6759" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[3]詹姆斯·陈，<a class="ae lx" href="https://www.investopedia.com/terms/o/option.asp" rel="noopener ugc nofollow" target="_blank">期权</a>，Investopedia</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qc qd l"/></div></figure></div></div>    
</body>
</html>