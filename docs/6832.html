<html>
<head>
<title>Web Scraping for Data Scientists</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向数据科学家的网络搜集</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/web-scraping-for-data-scientists-6f179c23d667?source=collection_archive---------5-----------------------#2020-11-12">https://medium.datadriveninvestor.com/web-scraping-for-data-scientists-6f179c23d667?source=collection_archive---------5-----------------------#2020-11-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="483a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">足够的现成CSV文件；以现实生活的方式研究数据科学。</em></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/101b2bea75a10610b03a338f3c6c5e9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*t8cBozo_QF5IcQEntsjyRA.jpeg"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://unsplash.com/photos/1bjsASjhfkE" rel="noopener ugc nofollow" target="_blank">Michael Dziedzic on Unsplash</a></figcaption></figure><p id="55f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如维基百科所描述的，<em class="kl"/><strong class="jp ir"><em class="kl">网页抓取</em> </strong> <em class="kl">，</em> <strong class="jp ir"> <em class="kl">网页采集</em> </strong> <em class="kl">或</em> <strong class="jp ir"> <em class="kl">网页数据提取</em> </strong> <em class="kl">是一种复制的形式，其中从网页上收集并复制特定的数据，通常将其复制到中央本地数据库或电子表格中，以供以后检索或分析。”</em></p><p id="fba6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">TL；DR；</strong>下面是代码的GitHub链接:<a class="ae ky" href="https://github.com/SteveKola/articles_based_projects/blob/main/Web%20Scraping%20for%20Data%20Scientists/scraper.ipynb" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/Steve kola/articles _ based _ projects/blob/main/Web % 20 scraping % 20 for % 20 data % 20 scientists/scraper . ipynb</a></p><p id="f3e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们的数据科学工作流中，大多数时候我们不会有一个CSV文件，用丝带绑着，等着我们去探索。我们必须从数据库中查询数据，从API中消费数据，等等。另一种获取数据的方式是通过网络抓取，这在非程序员看来是一种黑暗的艺术，因为这是一个程序自己探索互联网和收集数据的能力。如果您是It新手，这听起来可能有点陌生，但它是最符合逻辑、最容易访问的数据源之一。</p><p id="93e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为一名数据科学家，大多数项目的第一步是获得一个适当的相关数据集。在这方面，网络抓取是一个必不可少的工具，因为它让你几乎可以无限制地访问互联网上的信息宝库。常言道，“数据是新的石油”，网络就像盛产石油的沙特阿拉伯。</p><p id="5ff5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请记住，一些网站不希望任何人抓取他们的网站，当网站格式改变时，你可能需要更新你的网页抓取工具。</p><p id="537e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本教程中，我们将通过抓取尼日利亚数据科学网站<a class="ae ky" href="https://www.datasciencenigeria.org/2020-bootcamp-attendees/" rel="noopener ugc nofollow" target="_blank">https://www.datasciencenigeria.org/2020-bootcamp-attendees/</a>上的2020年人工智能训练营参与者名单，并将其保存在CSV文件中，来浏览网络抓取的基本组成部分。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi kz"><img src="../Images/8713751ee12d4859c463654727a76b82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WPXmNdJXBkFBSAo45Keb5A.png"/></div></div></figure><p id="c65a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们在这里可以看到，桌子上的每一行(attendee)都有序列号、训练营ID、姓名、性别和他/她所属的AI社区。我们的目标是为每个参与者检索这些信息。</p><p id="8d27" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用Python请求库来完成这项任务。<strong class="jp ir"> <em class="kl">请求</em> </strong>被广泛认为是人类的<em class="kl">HTTP</em>，它使检索网站变得相当轻松。如果您想了解使用请求的概况，请随时查看位于<a class="ae ky" href="https://requests.readthedocs.io/en/master/user/quickstart/" rel="noopener ugc nofollow" target="_blank">https://requests.readthedocs.io/en/master/user/quickstart/</a>的快速指南。</p><ul class=""><li id="057e" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">因此，第一步是通过导入所需的库(稍后我们可能会导入其他库)来准备我们的Jupyter笔记本，正如我们在下面的代码片段中所做的；</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/a2ed9dff96af71d8b059718605c5ebbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*nmNhuokor-ADaFROZ8vkwQ.png"/></div></figure><ul class=""><li id="eb64" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">数据的URL是https://www.datasciencenigeria.org/2020-bootcamp-attendees/的。让我们运行一个快速测试，确保我们可以检索到网页。</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/c8616c39f5c4e66c99e9676d19f64e34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*QFJUJBsP5I4TGddD_DFzLw.png"/></div></figure><ul class=""><li id="02db" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">这段代码调用站点，检索信息，并将其存储在<em class="kl"> r </em>对象中。我们可以从<em class="kl"> r </em>对象中检索很多属性，但是我们现在只想要内容。我们可以在下面的截图中看到输出；</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi lp"><img src="../Images/d3512359b29ac32f067932043038a6da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cGLVo9R5ZRnNrlO7YbY4dQ.png"/></div></div></figure><p id="7eec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一步是检查页面元素，看看如何解析页面数据；</p><ul class=""><li id="883c" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">在Chrome中打开DSN网页，右键单击页面上的任意位置。</li><li id="b43b" class="le lf iq jp b jq lq ju lr jy ls kc lt kg lu kk lj lk ll lm bi translated">你应该看到<em class="kl">检查。</em>点击它。页面现在应该是这样的；</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi lv"><img src="../Images/5b3b317da23acd67faf033273875df07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fRsH7U-6uwGv8jJlxboytQ.png"/></div></div></figure><ul class=""><li id="b2d2" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">在我们刚刚打开的工具中，左上角有一个带箭头的正方形。点击该按钮，然后点击页面上名为<em class="kl"> 1 </em>的<em class="kl">序列号</em>。它应该如下所示:</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/8e3c509cf46fa91b063bbaf892359401.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*owRGNPaznPj8hvslomq4aA.png"/></div></figure><ul class=""><li id="6231" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">从这里我们可以看到，该行的数据在一个表中(我们有一个table，在我们的present标签上有thead、tbody和tr标签),第一个<em class="kl"> td </em>包含S/N，第二个包含参加者的Bootcamp ID，第三个包含参加者的姓名，第四个包含参加者的性别，第五个包含参加者所属的AI社区。</li></ul><p id="2eee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们开始构建代码来测试我们对数据的解析。我们将使用一个名为<strong class="jp ir"> BeautifulSoup </strong>的库来解析HTML。BeautifulSoup是一个流行的、易于使用的Python HTML解析库。如果您还没有pip，可以安装它。虽然它预装了Anaconda，但是如果您在conda环境中，就不必担心这个问题。它的文件可以在https://www.crummy.com/software/BeautifulSoup/bs4/doc/找到。</p><ul class=""><li id="bee0" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">首先，我们只需将页面内容传递给<em class="kl"> BeautifulSoup </em>类，如下所示；</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/016f1c0957c51d86ae5c4c0ef68de8b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*TdO70didWxpkFZvdeC99NQ.png"/></div></figure><ul class=""><li id="6b23" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">现在我们可以使用我们创建的这个<em class="kl"> soup </em>对象开始解析这个表。让我们试着在网页上检索包含参与者数据的<em class="kl"> tr </em>标签。</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/fc7c5f33deb71aa5c0a3862e122959cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*wH1BUr-XIlGXnF_dQc--3g.png"/></div></figure><ul class=""><li id="a02a" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">我们在前面的代码中所做的是选择所有包含<em class="kl">行</em>作为其名称一部分的<em class="kl">tr</em>。这些是包含我们想要的数据的文件。</li><li id="3976" class="le lf iq jp b jq lq ju lr jy ls kc lt kg lu kk lj lk ll lm bi translated">接下来，让我们看看下面这段代码的输出；</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi lz"><img src="../Images/e5a1258441a12c66f8e49fa043a94fdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GGmetkY9AYm4MDsDnDpKgQ.png"/></div></div></figure><ul class=""><li id="9ca9" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">注意，我们有一个包含所有我们想要的<em class="kl"> tr </em>标签的Python列表。让我们通过检查列表的长度来确认；</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/01fc94090e6c8d1612c8c27da3374efd.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*WPlzNxGwWa08cdzODU07xQ.png"/></div></figure><ul class=""><li id="077e" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">考虑到我们有479名训练营参加者+一个标题行，这完全有意义。</li></ul><h2 id="4aee" class="mb mc iq bd md me mf dn mg mh mi dp mj jy mk ml mm kc mn mo mp kg mq mr ms mt bi translated">提取单个数据点</h2><p id="e5c8" class="pw-post-body-paragraph jn jo iq jp b jq mu js jt ju mv jw jx jy mw ka kb kc mx ke kf kg my ki kj kk ij bi translated">现在我们已经有了所有参与者数据的<em class="kl">tr</em>，我们需要提取每个参与者的个人数据点。</p><p id="2ffb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些都是我们想要瞄准的点；</p><ul class=""><li id="8faa" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">与会者的序列号。</li><li id="19d2" class="le lf iq jp b jq lq ju lr jy ls kc lt kg lu kk lj lk ll lm bi translated">与会者的训练营ID。</li><li id="730a" class="le lf iq jp b jq lq ju lr jy ls kc lt kg lu kk lj lk ll lm bi translated">与会者的姓名。</li><li id="ada0" class="le lf iq jp b jq lq ju lr jy ls kc lt kg lu kk lj lk ll lm bi translated">与会者的性别。</li><li id="0c67" class="le lf iq jp b jq lq ju lr jy ls kc lt kg lu kk lj lk ll lm bi translated">与会者的AI社区。</li></ul><p id="f537" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从第一行开始:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi mz"><img src="../Images/1eb6d644f4708529e7b96084ab6f543a.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*1BDzQaPBMdm96JbA5fncXg.png"/></div></div></figure><p id="9618" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">前面的代码给出了以下输出:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi na"><img src="../Images/f708d59321cf8f31c02127aeda2fb7ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OwRgCpY4804d5YWkHT1EIQ.png"/></div></div></figure><p id="506b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，第一行包含标题。我们可能应该从第二行开始寻找我们的数据。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nb"><img src="../Images/f188ee433ef2e837d59a1a9383803c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EWF30GaRT1doCw9CUDytyg.png"/></div></div></figure><p id="0f13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">耶！第二行包含我们需要的所有数据点。下一步是开始我们的解析，分别针对它们。</p><p id="c38c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们首先解析出我们的S/N列。我们可以用另一个<em class="kl"> select </em>语句来实现，如下所示:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/824dada77a150e9df853b7de5609b9c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*rgXvFtu8ivspi1bF1svXfQ.png"/></div></figure><p id="7571" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这正是我们所希望的。我们现在可以继续检索与会者的其他数据点。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/ee56ff4e303125a9471e4d0f4099ae7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*LWAtzF6WvzTFHIZ8xqlfYQ.png"/></div></figure><p id="5b2a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在已经得到了我们想要的所有数据。现在让我们把它们放在一个循环中，这样我们就可以从每一行中提取数据，并保存到一个列表中。</p><p id="3a3e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在下面的代码中，我们将取出每行的所有数据点；</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/eb43f2bb048ba19f262a42a09fbd6164.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*lcCUIxjDSt1zpAFzSOy2bg.png"/></div></figure><p id="d7f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们解包我们在前面的代码中做了什么。我们知道页面上有480行包含Bootcamp参与者，所以我们为创建了一个<em class="kl">循环，遍历每个参与者并提取数据，然后将所有参与者添加到<em class="kl"> table_list。</em></em></p><p id="2bd0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将用下面的<em class="kl">打印</em>语句来验证:<em class="kl"> table_list。</em>这会产生以下输出:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nf"><img src="../Images/54fe20f661d922f353cfc424eb37b32a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X-LhyqAlDVRr9zGZDw1z8g.png"/></div></div></figure><p id="da92" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是刮痧！恭喜你走到这一步。</p><h2 id="6bdf" class="mb mc iq bd md me mf dn mg mh mi dp mj jy mk ml mm kc mn mo mp kg mq mr ms mt bi translated">为将来的分析整理我们的数据</h2><p id="7f46" class="pw-post-body-paragraph jn jo iq jp b jq mu js jt ju mv jw jx jy mw ka kb kc mx ke kf kg my ki kj kk ij bi translated">现在我们有了数据，下一步是将它移到一个熊猫数据框架中，这样我们就可以更容易地使用它。我们还会将它保存在一个CSV文件中，以供将来使用。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/9f777c2c227fefc996fbacbe97912b27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*JaTI--U5i2UOysIwLu2E8w.png"/></div></figure><p id="4e25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们通过调用<em class="kl">boot camp _ participants . head()</em>来检查我们的数据</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/3b893f9a8cb2241779b380696be2c77d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*grdThsN7-XSuzG7QUrtkBw.png"/></div></figure><p id="f072" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">维奥拉。现在我们的数据看起来很像我们在Kaggle和Zindi的现成csv文件上调用的<em class="kl"> pd.read_csv() </em>。</p><p id="9cdc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后一步是保存在CSV文件中，以供将来分析。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/3342b12dbe86ba8fd88f1844d6be06e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*xtW1eE7IZ3YjhsvXBzvm4g.png"/></div></figure><p id="933e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这样，我们就有了对网络抓取的第一次介绍。我希望我们能继续从更多的网站上下载更多的数据。</p><p id="87fc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">谢谢你走到这一步！如果你在抓取网页的过程中遇到任何问题，请不要犹豫，通过<a class="ae ky" href="https://twitter.com/steveddev" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和<a class="ae ky" href="https://www.linkedin.com/in/steven-kolawole-80/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。请将此分享给任何需要网络抓取入门的人。</p><p id="904b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">刮的开心！</p></div></div>    
</body>
</html>