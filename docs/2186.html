<html>
<head>
<title>Types of Distance Metrics and Using User Defined Distance metrics in Scikit’s KNN Algorithm:</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">距离度量的类型以及在Scikit的KNN算法中使用用户定义的距离度量:</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/types-of-distance-metrics-and-using-user-defined-distance-metrics-in-scikits-knn-algorithm-9d159dfa4391?source=collection_archive---------2-----------------------#2020-04-18">https://medium.datadriveninvestor.com/types-of-distance-metrics-and-using-user-defined-distance-metrics-in-scikits-knn-algorithm-9d159dfa4391?source=collection_archive---------2-----------------------#2020-04-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/238f85b838cd193b166fcbe95a9fecc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_DOTmuIGzo7WWFEPCsncAg.jpeg"/></div></div></figure><p id="7459" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">KNN算法是数据科学中最常用和最重要的算法之一。这是一个<strong class="kd iu">监督分类</strong>算法，这意味着我们输入算法的数据被标记，我们使用它们来根据它们的相似性对数据进行分类。该算法首先测量每个点到<strong class="kd iu"> k个最近点</strong>的距离，并分配最近点的标签。它用于图像、物种等的分类。</p><p id="af4d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">KNN算法最重要的部分是它使用的距离度量。谢天谢地，scikit允许我们调整这一部分。距离度量标准如此之多，让我们讨论五种广泛使用的距离度量标准。</p><blockquote class="kz la lb"><p id="5672" class="kb kc lc kd b ke kf kg kh ki kj kk kl ld kn ko kp le kr ks kt lf kv kw kx ky im bi translated">如果你想<strong class="kd iu">马上实现你自己的距离度量</strong>，跳到最后一部分！</p></blockquote><h1 id="5eba" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">距离度量:</h1><p id="bd64" class="pw-post-body-paragraph kb kc it kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">在我们开始讨论距离度量之前，让我们为有效的距离函数设置一些基本规则。距离函数必须满足的条件是</p><ul class=""><li id="88d0" class="mj mk it kd b ke kf ki kj km ml kq mm ku mn ky mo mp mq mr bi translated"><strong class="kd iu">非负性</strong> : d(x，y) &gt; = 0。距离必须始终大于0。</li><li id="df0b" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">恒等式</strong> : d(x，y) = 0当且仅当x == y。</li><li id="c786" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">对称性</strong> : d(x，y) = d(y，x)。</li><li id="eace" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">三角形不等式</strong> : d(x，y) + d(y，z) &gt; = d(x，z)。</li></ul><p id="6577" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">好了，现在我们来讨论一下距离度量。</p><div class="mx my gp gr mz na"><a href="https://www.datadriveninvestor.com/2020/02/19/cognitive-computing-a-skill-set-widely-considered-to-be-the-most-vital-manifestation-of-artificial-intelligence/" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd iu gy z fp nf fr fs ng fu fw is bi translated">认知计算——一套被广泛认为是……</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">作为它的用户，我们已经习惯了科技。这些天几乎没有什么是司空见惯的…</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no jz na"/></div></div></a></div><h2 id="43c7" class="np lh it bd li nq nr dn lm ns nt dp lq km nu nv lu kq nw nx ly ku ny nz mc oa bi translated">1.闵可夫斯基距离:</h2><p id="5cb2" class="pw-post-body-paragraph kb kc it kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">闵可夫斯基距离用于度量赋范向量空间中的距离。这意味着，我们可以将一个数据点表示为空间中的一个向量，其长度是可以计算的。向量的范数就是向量的长度。</p><p id="e39a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">向量x的范数||x||必须满足这些条件:</p><p id="637a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">1.<strong class="kd iu">零矢量</strong>的长度为零。</p><p id="3636" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">2.标量因子(正)乘以一个矢量，只改变大小而不改变方向。</p><p id="c876" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">3.保持三角形不相等。</p><p id="352b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">公式如下:</strong></p><figure class="oc od oe of gt ju gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/cd4534882579e277bb956c9db852966b.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*y8DBZmfab1IjxE62UmcYJw.png"/></div><figcaption class="og oh gj gh gi oi oj bd b be z dk">The formula of Minkowski distance</figcaption></figure><p id="8ea8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当p = 1时，公式给出<strong class="kd iu">曼哈顿距离:</strong></p><figure class="oc od oe of gt ju gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/ee2bd0d5c0fb3bab9b99779991e9c60f.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*HR5x_37NAZspL5S9FWDNUg.png"/></div></figure><p id="083d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">距离是用一个<strong class="kd iu"> <em class="lc">差的绝对总和。</em> </strong></p><p id="641a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当p = 2时，它给出了<strong class="kd iu">欧几里德距离:</strong></p><figure class="oc od oe of gt ju gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/667aa403237d61bce8718e9b12088adc.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*o5aNV-pZBWGa60iVpb188Q.png"/></div></figure><p id="4d07" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这个公式是基于勾股定理的。</p><p id="8009" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当p = ∞，我们得到<strong class="kd iu">切比雪夫距离:</strong></p><figure class="oc od oe of gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi om"><img src="../Images/c39cf889fdd7980b24b959c242a8638a.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*qDa50u9MpoKkY1EWKWPRVg.png"/></div></div></figure><p id="ef7a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="lc">注意:</em> </strong> <em class="lc">当使用这些距离度量时，</em> <strong class="kd iu"> <em class="lc">归一化</em> </strong> <em class="lc">非常重要，因为这种距离度量对单个属性中的极端差异很敏感</em></p><h2 id="1484" class="np lh it bd li nq nr dn lm ns nt dp lq km nu nv lu kq nw nx ly ku ny nz mc oa bi translated">2.汉明距离:</h2><p id="e2d5" class="pw-post-body-paragraph kb kc it kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">汉明距离给出了两个二进制字符串之间的相似性。例如</p><p id="40bf" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi">11011001 ⊕ 10011101 = 01000100</p><p id="5c13" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">汉明距离，d(11011001，10011101) = 2。</p><p id="e0b1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最小的汉明距离代表最接近的值。汉明距离对于测量数据串特别有用。我们可以在<strong class="kd iu">分类数据</strong>上使用这个，并且查看两个字符串是否相等，即查看“Hamming”和“Hanning”是否相同。</p><p id="3e4c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一个简单的方法是设置公式=<strong class="kd iu">| x-y |⁰.</strong>因此，当差异为0时，值将为0，表示它们相似。任何其他提高到0的数都是1，因此值为1意味着它们不相同。</p><h2 id="f384" class="np lh it bd li nq nr dn lm ns nt dp lq km nu nv lu kq nw nx ly ku ny nz mc oa bi translated">3.堪培拉距离:</h2><p id="eb7a" class="pw-post-body-paragraph kb kc it kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">堪培拉度量类似于曼哈顿距离。区别在于，两个对象的变量之间的绝对差在求和之前除以绝对变量值的和。这是曼哈顿距离的加权版本。它对零附近的变化非常敏感。当我们处理具有大量变量的高维空间中的数据时，这个特性变得非常有用。</p><figure class="oc od oe of gt ju gh gi paragraph-image"><div class="gh gi on"><img src="../Images/351327a4d9d89e11eb7939498c84b988.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*Q719DDOg0rn3c8uY6VeDHw.png"/></div></figure><h2 id="8570" class="np lh it bd li nq nr dn lm ns nt dp lq km nu nv lu kq nw nx ly ku ny nz mc oa bi translated">4.Jaccard距离:</h2><p id="c914" class="pw-post-body-paragraph kb kc it kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">假设两个数据点是两个集合，你想测量它们有多相似。Jaccard距离度量的一个好选择。它测量两个集合中的公共元素与两个集合中所有元素的数量。更多的公共元素意味着两个对象应该是相似的。分数越高，两个数据点越相似。</p><figure class="oc od oe of gt ju gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ba758847558254988af86a174e43be1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*Yovw5m6wIGAA_G3zZlD4Sw.png"/></div></figure><p id="b33c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这种度量的一些用例是识别剽窃、文档之间的相似性等。</p><h2 id="d583" class="np lh it bd li nq nr dn lm ns nt dp lq km nu nv lu kq nw nx ly ku ny nz mc oa bi translated">5.余弦相似性和距离:</h2><p id="4efc" class="pw-post-body-paragraph kb kc it kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">余弦相似性试图通过测量两个向量之间的余弦来测量两个向量的相似性。余弦给出邻边和斜边的比值。当角度= 0时，余弦= 1。当两个向量之间的角度为0时，它们位于彼此之上。当值= 1时，表示两个向量相似。较低的值意味着它们具有较低的相似性。</p><figure class="oc od oe of gt ju gh gi paragraph-image"><div class="gh gi op"><img src="../Images/6b9c77f3227e2e7643685e84f4cb4007.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*qM1kF4elK87YsdXJ0Qw9iw.png"/></div></figure><p id="97a6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">余弦距离= 1 —余弦相似度。</strong>我们可以用上面的公式来计算距离。</p><blockquote class="kz la lb"><p id="3d5d" class="kb kc lc kd b ke kf kg kh ki kj kk kl ld kn ko kp le kr ks kt lf kv kw kx ky im bi translated">对于大多数用例来说，这应该已经足够了。但是什么时候应该使用哪种度量标准呢？</p></blockquote><p id="5fda" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">没有一种特定的距离度量在所有情况下都适用，也没有一种特定的距离度量在任何时候都适用于特定的问题。这都是关于试错。所以，用最适合你的吧！</p><p id="4d4f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是一篇漂亮的<a class="ae oq" href="https://arxiv.org/pdf/1708.04321.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>，探讨了数据集上不同的距离度量，并对它们进行了比较。</p><h1 id="d0b8" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">使用Scikit的KNN算法自定义用户定义的距离度量:</h1><p id="67a5" class="pw-post-body-paragraph kb kc it kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">Scikit已经允许您从一系列距离度量中进行选择。请参考此<a class="ae oq" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html" rel="noopener ugc nofollow" target="_blank">页</a>查看您想要使用的指标是否可用。但是如果你需要使用一个没有在上面的链接中列出的距离度量，你可以这样做:</p><h2 id="d9d6" class="np lh it bd li nq nr dn lm ns nt dp lq km nu nv lu kq nw nx ly ku ny nz mc oa bi translated">步骤1:定义函数:</h2><p id="bcae" class="pw-post-body-paragraph kb kc it kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">我已经决定实现我上面提到的论文中的Hassant距离。该函数必须返回传递给它的每对向量的距离分数。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="fcda" class="np lh it os b gy ow ox l oy oz"><strong class="os iu">def hassant_distance(v1, v2):<br/>    total = 0<br/>    for xi, yi in zip(v1, v2):<br/>        min_val = min(xi, yi)<br/>        max_val = max(xi, yi)<br/>        if min_val &gt;= 0:<br/>            total += 1 - (1 + min_val)/(1 + max_val)<br/>        else:<br/>            total += 1 - (1 + min_val + abs(min_val))/(1 + max_val + abs(max_val))<br/>    return total</strong></span></pre><h2 id="7d70" class="np lh it bd li nq nr dn lm ns nt dp lq km nu nv lu kq nw nx ly ku ny nz mc oa bi translated">步骤2:将度量参数中的函数名传递给模型构造函数:</h2><p id="0349" class="pw-post-body-paragraph kb kc it kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">我用的是sklearn . neighborsclassifier .我从kaggle上下载了音乐数据集。目标是根据音乐类型的属性对其进行正确分类。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="e73b" class="np lh it os b gy ow ox l oy oz">import pandas as pd<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors<br/>from sklearn.metrics import accuracy_score, classification_report</span><span id="31eb" class="np lh it os b gy pa ox l oy oz">#Read the data in<br/>music_data = pd.read_csv("..\Datasets\Tmusic_data.csv")</span><span id="b14d" class="np lh it os b gy pa ox l oy oz">#Specify the target<br/>X = music_data.drop("class", axis = 1)<br/>Y = music_data["class"]</span><span id="0164" class="np lh it os b gy pa ox l oy oz">#Split the data into train and test sets<br/>Xtrain, Xtest, y_train, y_test = train_test_split(X, Y, random_state = 0, train_size = 0.7)</span><span id="2325" class="np lh it os b gy pa ox l oy oz">#Standardize the data <br/>scaler = preprocessing.StandardScaler().fit(Xtrain)<br/>Xtrain = scaler.transform(Xtrain)<br/>Xtest = scaler.transform(Xtest)</span><span id="568e" class="np lh it os b gy pa ox l oy oz"><strong class="os iu">#train the algorithm<br/>knn = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree', metric = hassant_distance) <br/>knn.fit(Xtrain, y_train)</strong></span><span id="f342" class="np lh it os b gy pa ox l oy oz">#test<br/>y_pred = knn.predict(Xtest)</span><span id="a459" class="np lh it os b gy pa ox l oy oz">print(accuracy_score(y_test, y_pred))</span><span id="b8e6" class="np lh it os b gy pa ox l oy oz">0.75</span></pre><p id="e62f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们得到了75%的准确率。你可以尝试不同的指标，看看你是否能得到更好的分数。</p><p id="155f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">注意:<em class="lc"> </em> </strong> <em class="lc">如果我们选择</em><em class="lc">KD _ tree算法，这个自定义函数不起作用。除此之外，你很棒。</em></p><figure class="oc od oe of gt ju"><div class="bz fp l di"><div class="pb pc l"/></div></figure></div></div>    
</body>
</html>