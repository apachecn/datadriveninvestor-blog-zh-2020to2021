<html>
<head>
<title>Learning Stable Graphs from Heterogeneous Confounded Environments</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从异质混杂环境中学习稳定图</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/learning-stable-graphs-from-heterogeneous-confounded-environments-99710e1bd36e?source=collection_archive---------20-----------------------#2020-11-09">https://medium.datadriveninvestor.com/learning-stable-graphs-from-heterogeneous-confounded-environments-99710e1bd36e?source=collection_archive---------20-----------------------#2020-11-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/f0694e5d91ec32781206eb340247880c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*_K19HPBSfIQ7rrgk.png"/></div></figure><p id="5e0d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><em class="ks">下载“</em><a class="ae kt" href="https://resource.alibabacloud.com/whitepaper/cloud-knowledge-discovery-on-kdd-papers_2592" rel="noopener ugc nofollow" target="_blank"><em class="ks">【KDD论文云知识发现】</em> </a> <em class="ks">”白皮书，探索12篇KDD论文和12位阿里巴巴专家的知识发现。</em></p><p id="86dc" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><em class="ks">作者:何越，，马建新，，，，俞宗怡</em></p><h1 id="9327" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">背景</h1><p id="5b31" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">图可以用来描述事物之间的普遍关系，这些关系可以编码成参数化的图结构，例如邻接矩阵。基于专家的图形合成方法需要昂贵的手动收集的信息。很难在广泛的生产和日常生活环境中部署合成图。这推动了数据驱动的图形生成算法的研究。数据驱动的图形生成算法旨在构建一个能够最好地描述输入数据生成过程的图形。例如，在推荐场景中，输入数据可以是买家的购物记录，产品网络图表达了项目之间的关系强度。数据驱动算法严重依赖于数据的条件独立性假设。这个假设规定训练场景和测试场景具有相同的数据分布。如果不满足这一假设，图形性能会显著下降。事实上，独立性假设是非常脆弱的。数据采样过程受到时间和空间的限制。比如网购人群中，女性通常比男性占比更大，年轻人比老年人占比更大。基于这一事实得出的图表显示，年轻女性比其他群体更受青睐。因此，提高图结构的泛化性能是有意义的。</p><h1 id="df18" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">挑战</h1><p id="15fe" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">通过学习因果图，我们可以直接捕捉到事物之间不变的因果关系，以保证稳定性。然而，因果图的学习需要高度复杂的计算，并且很难将学习过程应用于大型网络。此外，因果图是一种有向无环图(DAG ),不能描述广泛的、基于场景的循环结构。图结构包含复杂的高阶非线性关系。这使得很难直接在原始图结构空间(如邻接矩阵)中纠正偏差。另外，用于生成图结构的输入数据是高维稀疏的，比如set数据类型。本文介绍了SGL，一种用于在异构混杂环境中学习稳定的通用图结构的方法。</p><h1 id="1e35" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">模型</h1><p id="312a" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">为了适应更一般的场景，我们假设输入数据是集合类型的，它是高维稀疏的。集合数据记录的生成可以看作是向一个空集逐个添加元素直到该集合饱和的过程。对于第m个数据环境，将每个元素IkIk添加到给定集合s的概率等于该集合的条件生成概率p(m)(Ik|s)p(m)(Ik|s)。显然，pm (I_k│s) pm (I_k│s)与图结构G(m)G(m)中包含的元素关系有关，可以表示为:</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/00d06fcd07bccfaf7f0c2181a190343f.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/0*_O5I44J6C7qF_GJw.png"/></div></figure><p id="91b3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在各种异构环境中，由于采样偏差，条件生成概率是有偏差的。假设环境选择是随机的。每个环境的概率空间平均起来就是一个无偏环境的估计。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/05c0d234a55b42c477814d66f91ccc9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:410/format:webp/0*Dy667KNsufzTSfXm.png"/></div></figure><p id="c83a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">图结构充满了高阶的非线性关系。这使得很难在图结构的参数空间(邻接矩阵)中直接消除偏差。但是，如果我们可以建立从图结构到条件生成概率的映射，并在生成概率空间中平衡这些偏差，我们就可以间接地纠正这些偏差。</p><h1 id="de2a" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">基于图的稀疏集生成</h1><p id="3a1d" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">按照前面的思路，首先要做的是建立从图结构到条件生成概率的映射。假设存在不同的有偏数据环境，我们可以首先使用基于联合出现频率的方法在每个环境中创建初始图，每个点代表一个集合中的一个元素。SGL框架由两个模块组成。第一个模块是图形卷积神经网络，它将初始图形的结构特征嵌入到输出元素表示中。通过汇集一个集合的所有元素表示，我们可以获得这个集合的特征向量。特征向量被传递到第二模块，元素级变分自动编码器(E-VAE)。该模块重构真实数据并学习集合生成概率。我们可以通过用编码器处理集合的特征向量来获得隐藏空间分布。我们还可以从编码向量中抽取一个隐藏向量，并结合每个元素的表示对该隐藏向量进行解码。这导致每个元素的强度被包括在集合中。然后，我们将所有元素的强度投影到概率空间，以输出集合生成概率。假设输入集是饱和的。我们可以重建原始数据来学习环境中的条件生成概率空间。换句话说，我们要对真实样本的输出概率应用条件。在我们添加新的采样元素后，我们保持集合不变，以最大化真实样本的出现概率。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi md"><img src="../Images/451b01d1c82fcf7ab9c526e0a0759f36.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/0*iAqrp9rTBNdH7gZn.png"/></div></figure><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi me"><img src="../Images/e4ca1bf5dde610623b54ebc2fe9916b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*64KveUuzuQvYGAq9.png"/></div></figure><p id="4579" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">考虑到数据集的稀疏性，我们使用负对数似然函数作为优化模型学习的目标函数。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/e3d7d7b4eead5b59724289b7ab521457.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/0*v3oJ7zbAzSglaJxy.png"/></div></figure><p id="de63" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们还优化了E-VAE中隐藏分布和预定义正态分布之间的Kullback-Leibler (KL)散度，如下所示:</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/a60f68ba9293221f009f3f00e49a0364.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/0*KWQR7MJdf9Eo-c8y.png"/></div></figure><h1 id="1009" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">学习稳定的图形结构</h1><p id="92fe" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">通过训练在每个环境中共享相同参数的图卷积网络和E-VAEs，我们可以获得在不同环境中相同输入集的条件生成概率。假设我们正在初始化一个无偏数据环境的图形结构。我们可以优化这个图的结构，使得这个图输出的无偏环境的生成概率是所有有偏环境的生成概率的平均值。这可以产生稳定的图形结构。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/4cc0c4529e3fe1e08961814592bdf161.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/0*uP2f4xJZ3aqk9nqK.png"/></div></figure><p id="b108" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">考虑到各部分之间的相互作用，我们联合优化了GCNs、E-VAEs和稳定图结构的邻接矩阵。经过SGD框架的优化，该模型适用于更大尺寸的图形。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/646b58706f5ae9f9cd18571942217142.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/format:webp/0*c-gzGAn_XPvuKg0J.png"/></div></figure><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi me"><img src="../Images/32c9dfd4dc909b3ebeb983ed71a72048.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*mDABf8of6pyWVFSR.png"/></div></figure><h1 id="aaac" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">实验</h1><p id="fac0" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">为了验证模型的有效性，我们分别在模拟数据和真实数据上进行了实验。在模拟数据实验中，我们使用有偏随机行走来生成在两种环境中具有不同数据分布的行走路径。随机漫步使用p_0(零阶相关性，如用户的优先偏好)、p_1(元素的一阶相关性)和p_2(元素的二阶相关性)来控制两个环境之间的差异程度。分布差异与P0、P1和p2的值成正比。然后，我们使用每个环境中的训练数据来创建基于联合出现频率的图表。这样，我们获得了两个具有不同隐含关系的图。</p><p id="16de" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">分别为这两种环境创建了频率图G1和G2。我们的基线模型应用了等式GA=(G1+G2)/2，并将两种环境的数据均匀且成比例地混合，以构成频率图GC。基于G1、G2和训练数据，我们学习了稳定的图结构GS。</p><p id="cfbb" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">为了测试不同图结构的稳定性，我们设计了一个集合预测任务。首先，我们将测试集分为目标元素和剩余的已知元素。给定从图结构学习的元素表示和测试集的已知元素，我们的目标是从所有候选节点中选择目标元素，也就是说，选择与该集的剩余元素最接近的元素。然后，我们以0:10、1:9、…、10:0的比例混合两种环境的测试数据，得到11个测试组。我们收集了从不同图结构中学习到的元素表示的统计数据。我们使用元素表示之间的平均COS距离来测量具有不同数据分布的多个测试组中的预测准确性。为了保证实验的公平性，我们使用相同的GCN来学习不同图形的元素表示。</p><p id="ab08" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">根据以下结果，图内关系在单个环境中的适用性随着另一个环境中数据的增加而降低。当计算每个环境中的图的线性平均值时，不考虑图内非线性关系。通过混合各种环境中的数据来进行图形合成的方法不能避免传统图形合成方法中固有的模型偏差。这种方法也不能解决零阶相关性问题，例如用户先前偏好之间的差异。可以使用稳定的图形结构来实现具有最小标准偏差的最佳预测精度。原因是这个图可以平衡不同测试环境中高阶、非线性关系的偏差。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi me"><img src="../Images/66a4907b8a96a709fdc452bf83d3c91e.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*_DSvbpydXl7sED1x.png"/></div></figure><p id="7640" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">真实数据实验在两种场景下进行:用户人群之间的差异和各种产品之间的暴露差异。第一种情况涉及不同用户群的不同比例。第二种情况涉及主导产品在不同环境中的不同流行程度。针对用户人群的差异，我们将男性和女性用户分为两种环境。对于各种产品之间的曝光差异，我们首先确定了热门产品。然后，我们根据每条记录中受欢迎产品的比例是否超过50%，将所有购物记录分为受欢迎-占主导地位的环境和不受欢迎-占主导地位的环境。用于验证基线模型和预测任务的实验与模拟数据实验相同。</p><p id="e7e2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">实验结果表明，不同环境下的预测难度不同。女性的购物行为比男性更容易预测。这可能是因为女性比男性对高度相关的产品更感兴趣。此外，对于包含许多热门产品的购物记录，预测更容易。这可能是因为热门产品之间的相关性更高。SGL可以从不同的环境中学习更多的通用信息，以达到最佳的预测率。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi me"><img src="../Images/9eeda3ce0bd8e7ada065426d976b896b.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*T61jtqNy04lOwfmZ.png"/></div></figure><h1 id="b7fb" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">摘要</h1><p id="c1a2" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">我们提出了SGL学习框架，从异质混杂环境中学习稳定的图结构。通过基于图生成稀疏数据，该框架建立了从图结构到生成概率空间的映射。然后平衡生成概率空间中的有偏信息，以纠正图的结构偏差。实验表明，该方法能够提高图结构的稳定性，为实际问题提供有效的解决方案。</p><h1 id="d788" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">参考</h1><p id="2bcc" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">[1]拉达·阿达米克和埃坦·阿达。2003.网上的朋友和邻居。社会网络25，3 (2003)，211–230。亚历山大·博伊切夫斯基、亚历山大·施库尔、丹尼尔·zügner和斯蒂芬·günnemann.2018.Netgan:通过随机漫步生成图形。arXiv预印本arXiv:1803.00816 (2018)。<br/> [3]彼得·bühlmann、乔纳斯·彼得斯、简·欧内斯特等人2014。CAM:因果可加模型、高维序搜索和惩罚回归。统计年鉴42，6 (2014)，2526–2556。[4]阿布舍克·古普塔、科林·德文、刘宇轩、彼得·阿比勒和谢尔盖·莱文。2017.用强化学习学习不变特征空间转移技能。arXiv预印本arXiv:1703.02949 (2017)。<br/> [5]基洛·古普塔、穆昆德·耶拉汉卡·拉古普拉萨德和潘克胡里·库马尔。[未注明]。一种用于协同过滤的混合变分自动编码器。([未注明])。<br/> [6]姜波、张紫妍、、、。2019.基于图学习的半监督学习-卷积网络。IEEE计算机视觉和模式识别会议论文集。11313–11320.<br/> [7]迪耶德里克·P·金玛和马克斯·韦林。2013.自动编码变分贝叶斯。arXiv预印本arXiv:1312.6114 (2013)。</p><p id="6057" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><em class="ks">本文观点仅供参考，不一定代表阿里云官方观点。</em></p><h1 id="8bdb" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">原始来源:</h1><div class="mi mj gp gr mk ml"><a href="https://www.alibabacloud.com/blog/learning-stable-graphs-from-heterogeneous-confounded-environments_596746" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd ir gy z fp mq fr fs mr fu fw ip bi translated">从异质混杂环境中学习稳定图</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">Alibaba Clouder年10月15日142下载《KDD论文中的云知识发现》白皮书，探索12…</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">www.alibabacloud.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz js ml"/></div></div></a></div></div></div>    
</body>
</html>