<html>
<head>
<title>Intro to K-Nearest Neighbours (KNN) — Machine Learning 101</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">K近邻(KNN)介绍—机器学习101</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/k-nearest-neighbours-knn-a9f8ba09cb8b?source=collection_archive---------13-----------------------#2020-12-31">https://medium.datadriveninvestor.com/k-nearest-neighbours-knn-a9f8ba09cb8b?source=collection_archive---------13-----------------------#2020-12-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/32e064c9fae8ceb1896a5d92ae3dc035.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*WQmkAPKje9-1Lenh-Fs0Xw.png"/></div></figure><p id="810b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">k近邻或KNN是基本的机器学习模型之一。它简单、直观、有用。</p><h1 id="bdb2" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated"><strong class="ak">你应该知道的术语:</strong></h1><blockquote class="lq lr ls"><p id="a622" class="ju jv lt jw b jx jy jz ka kb kc kd ke lu kg kh ki lv kk kl km lw ko kp kq kr ij bi translated"><strong class="jw ir"> <em class="iq">分类:</em> </strong> <em class="iq">分类器是指在给定一些数据的情况下，用机器学习的方法给一个未知的案例分配一个标签。它是</em> <a class="ae lx" href="https://en.wikipedia.org/wiki/Supervised_learning#:~:text=Supervised%20learning%20is%20the%20machine,a%20set%20of%20training%20examples." rel="noopener ugc nofollow" target="_blank"> <em class="iq">监督学习</em> </a> <em class="iq">的一种形式。</em></p><p id="89ec" class="ju jv lt jw b jx jy jz ka kb kc kd ke lu kg kh ki lv kk kl km lw ko kp kq kr ij bi translated"><strong class="jw ir"> <em class="iq">回归:</em> </strong> <em class="iq">回归是一种将数值/连续输出分配给输入的方法。在回归中，每个单独的输入被映射到一个单独的输出。它是</em> <a class="ae lx" href="https://en.wikipedia.org/wiki/Supervised_learning#:~:text=Supervised%20learning%20is%20the%20machine,a%20set%20of%20training%20examples." rel="noopener ugc nofollow" target="_blank"> <em class="iq">监督学习</em> </a> <em class="iq">的一种形式。</em></p><p id="ccc6" class="ju jv lt jw b jx jy jz ka kb kc kd ke lu kg kh ki lv kk kl km lw ko kp kq kr ij bi translated"><strong class="jw ir"><em class="iq">K:</em></strong><em class="iq">K-最近邻(KNN)中的K是指参与多数表决的邻居数量，用于测试或未知情况的分类</em></p><p id="ac16" class="ju jv lt jw b jx jy jz ka kb kc kd ke lu kg kh ki lv kk kl km lw ko kp kq kr ij bi translated"><strong class="jw ir"> <em class="iq">邻居:</em> </strong> <em class="iq">邻居是指用于KNN分类的数据集中的数据点</em></p></blockquote><h1 id="8efa" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">什么是KNN:(K-最近邻)</h1><p id="1edc" class="pw-post-body-paragraph ju jv iq jw b jx ly jz ka kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr ij bi translated">KNN是一种受监督的机器学习模型，可用于分类或回归。KNN利用来自K个邻居的<strong class="jw ir">多数票</strong>进行分类。K的值可以是任何给定的奇数。(1,3,5,…)</p><p id="3e7e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">KNN模型的分类或回归过程可以简化为三个步骤:</p><ol class=""><li id="b8a1" class="md me iq jw b jx jy kb kc kf mf kj mg kn mh kr mi mj mk ml bi translated">选择K</li><li id="4cf7" class="md me iq jw b jx mm kb mn kf mo kj mp kn mq kr mi mj mk ml bi translated">识别K个最近邻居</li><li id="723f" class="md me iq jw b jx mm kb mn kf mo kj mp kn mq kr mi mj mk ml bi translated"><strong class="jw ir"> <em class="lt"> (a)分类:</em> </strong>输出K近邻的众数(最频繁标签)<strong class="jw ir"> <em class="lt"> (b)回归:</em> </strong>输出K近邻的均值(平均值)</li></ol><p id="70d8" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">KNN可用于多变量或单变量问题。</p><h1 id="e667" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">如何选择K:</h1><p id="f02a" class="pw-post-body-paragraph ju jv iq jw b jx ly jz ka kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr ij bi translated">选择K是一个能真正影响KNN模型有效性的过程。因此，知道如何选择k很重要。</p><p id="80e9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">重要的是要知道，没有特定的统计方法来选择k。一些方法包括:</p><blockquote class="lq lr ls"><p id="a259" class="ju jv lt jw b jx jy jz ka kb kc kd ke lu kg kh ki lv kk kl km lw ko kp kq kr ij bi translated"><em class="iq">随机初始化K的值并参考精度度量来识别最佳K </em></p><p id="70c2" class="ju jv lt jw b jx jy jz ka kb kc kd ke lu kg kh ki lv kk kl km lw ko kp kq kr ij bi translated"><em class="iq">使用公式:</em> <strong class="jw ir"> K = sqrt(N) </strong> <em class="iq">其中N是训练数据集中的数据点数</em></p></blockquote><p id="5caa" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">请记住，较高的K值会导致较低的方差和较高的偏差。相反，较小的K导致较高的方差和较低的偏差。换句话说，较高的K值可能导致过度拟合，而较低的K值可能导致拟合不足。</p><h1 id="ffe3" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">如何计算距离:</h1><p id="df6a" class="pw-post-body-paragraph ju jv iq jw b jx ly jz ka kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr ij bi translated">有许多不同的方法来寻找KNN模型的距离。一些受欢迎的包括:</p><blockquote class="lq lr ls"><p id="9a6a" class="ju jv lt jw b jx jy jz ka kb kc kd ke lu kg kh ki lv kk kl km lw ko kp kq kr ij bi translated"><strong class="jw ir">欧几里德距离</strong></p></blockquote><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/8923414f1ed27cb7e8f4db8fd876107e.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*spw0VvsbzKDQhctdOtAv5g.png"/></div></figure><p id="49d9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这种方法利用勾股定理(A + B = C)来计算一维或多维距离。</p><blockquote class="lq lr ls"><p id="00a8" class="ju jv lt jw b jx jy jz ka kb kc kd ke lu kg kh ki lv kk kl km lw ko kp kq kr ij bi translated"><strong class="jw ir">曼哈顿距离</strong></p></blockquote><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/7e75f10f2750751d238fbe5eafef3632.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*cD3uVDzEF4JizjtVVgEPfA.png"/></div></figure><p id="7bfb" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">曼哈顿距离公式假设两点之间的距离等于它们的绝对差之和。</p><h1 id="7dc7" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">优点:</h1><ul class=""><li id="0622" class="md me iq jw b jx ly kb lz kf mx kj my kn mz kr na mj mk ml bi translated">KNN简单明了，易于理解和实现</li><li id="a1e9" class="md me iq jw b jx mm kb mn kf mo kj mp kn mq kr na mj mk ml bi translated">KNN并不真正需要传统意义上的“训练”</li><li id="14cf" class="md me iq jw b jx mm kb mn kf mo kj mp kn mq kr na mj mk ml bi translated">KNN不强调假设</li><li id="5fe8" class="md me iq jw b jx mm kb mn kf mo kj mp kn mq kr na mj mk ml bi translated">KNN可以快速适应新数据</li><li id="6a08" class="md me iq jw b jx mm kb mn kf mo kj mp kn mq kr na mj mk ml bi translated">该算法可用于回归和分类</li></ul><h1 id="d743" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">缺点:</h1><ul class=""><li id="4613" class="md me iq jw b jx ly kb lz kf mx kj my kn mz kr na mj mk ml bi translated">KNN算法计算量大且速度慢</li><li id="f205" class="md me iq jw b jx mm kb mn kf mo kj mp kn mq kr na mj mk ml bi translated">KNN的效率与特征的数量成反比</li><li id="4c71" class="md me iq jw b jx mm kb mn kf mo kj mp kn mq kr na mj mk ml bi translated">使用公共距离(例如欧几里德距离)KNN要求同质输入(例如这个值的增加与另一个值成比例)</li><li id="6dd5" class="md me iq jw b jx mm kb mn kf mo kj mp kn mq kr na mj mk ml bi translated">缺少值时，KNN无法正常运行</li><li id="4839" class="md me iq jw b jx mm kb mn kf mo kj mp kn mq kr na mj mk ml bi translated">离群值对KNN的影响尤其大</li></ul><div class="nb nc gp gr nd ne"><a href="https://www.datadriveninvestor.com/2020/11/19/how-machine-learning-and-artificial-intelligence-changing-the-face-of-ecommerce/" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd ir gy z fp nj fr fs nk fu fw ip bi translated">机器学习和人工智能如何改变电子商务的面貌？|数据驱动…</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">电子商务开发公司，现在，整合先进的客户体验到一个新的水平…</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns js ne"/></div></div></a></div><h1 id="3801" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">从零开始制作KNN:(python)</h1><p id="ac42" class="pw-post-body-paragraph ju jv iq jw b jx ly jz ka kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr ij bi translated">让我们用python创建一个KNN框架！</p><h2 id="1dac" class="nt kt iq bd ku nu nv dn ky nw nx dp lc kf ny nz lg kj oa ob lk kn oc od lo oe bi translated">第一步:</h2><p id="427e" class="pw-post-body-paragraph ju jv iq jw b jx ly jz ka kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr ij bi translated">用python实现欧几里德距离公式</p><pre class="ms mt mu mv gt of og oh oi aw oj bi"><span id="b7cd" class="nt kt iq og b gy ok ol l om on">import math</span><span id="56c5" class="nt kt iq og b gy oo ol l om on">def euclidian_distance(a, b):<br/> distances = []<br/> for i in range(len(a)):<br/>  distances.append((a[i] - b[i])**2)<br/> return math.sqrt(sum(distances))</span></pre><h2 id="31a5" class="nt kt iq bd ku nu nv dn ky nw nx dp lc kf ny nz lg kj oa ob lk kn oc od lo oe bi translated">第二步:</h2><p id="2d1a" class="pw-post-body-paragraph ju jv iq jw b jx ly jz ka kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr ij bi translated">找到K个最近的邻居</p><pre class="ms mt mu mv gt of og oh oi aw oj bi"><span id="95b8" class="nt kt iq og b gy ok ol l om on">def find_neighbours(self):<br/>  #predict a single input<br/>  self.dist = []<br/>  for i in range(len(self.X)):<br/>   self.dist.append(['X', euclidian_distance(self.input,self.X[i])])<br/>  for i in range(len(self.Y)):<br/>   self.dist.append(['Y', euclidian_distance(self.input,self.Y[i])])<br/>  self.dist.sort(key=lambda x: x[1])</span></pre><h2 id="8332" class="nt kt iq bd ku nu nv dn ky nw nx dp lc kf ny nz lg kj oa ob lk kn oc od lo oe bi translated">第三步:</h2><p id="e310" class="pw-post-body-paragraph ju jv iq jw b jx ly jz ka kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr ij bi translated">从单个给定输入生成预测</p><pre class="ms mt mu mv gt of og oh oi aw oj bi"><span id="e6d2" class="nt kt iq og b gy ok ol l om on">def predict(self):<br/>  self.knn = []<br/>  self.model_type<br/>  #if regression, return mean of knn<br/>  if self.model_type == 'regression':<br/>   for i in range(n_neighbours):<br/>    self.knn.append(self.dist[i][1])<br/>   return sum(self.knn)/len(self.knn)<br/>  #if classifcation, return mode of knn<br/>  if self.model_type == 'classification':<br/>   self.knn = [i[0] for i in self.dist]</span><span id="7cc1" class="nt kt iq og b gy oo ol l om on">for i in range(n_neighbours):<br/>    self.knn.append(self.dist[i][0])<br/>   dict_items = [i[0] for i in self.knn]<br/>   return max(set(dict_items), key = dict_items.count)</span></pre><h2 id="3693" class="nt kt iq bd ku nu nv dn ky nw nx dp lc kf ny nz lg kj oa ob lk kn oc od lo oe bi translated">第四步:</h2><p id="48ac" class="pw-post-body-paragraph ju jv iq jw b jx ly jz ka kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr ij bi translated">使用先验函数，迭代多个输入并生成预测</p><pre class="ms mt mu mv gt of og oh oi aw oj bi"><span id="2166" class="nt kt iq og b gy ok ol l om on">def NearestNeighbours(n_neighbours, X, Y, input, model_type):<br/> preds = []<br/> for i in range(len(input)):<br/>  selected_input = input [i]<br/>  model = KNN_model(n_neighbours,X,Y,selected_input, model_type)<br/>  model.find_neighbours()<br/>  preds.append(model.predict())<br/> return preds</span></pre><h2 id="97c9" class="nt kt iq bd ku nu nv dn ky nw nx dp lc kf ny nz lg kj oa ob lk kn oc od lo oe bi translated">完整代码:</h2><pre class="ms mt mu mv gt of og oh oi aw oj bi"><span id="cb8c" class="nt kt iq og b gy ok ol l om on">import math<br/>from collections import Counter</span><span id="8251" class="nt kt iq og b gy oo ol l om on">def euclidian_distance(a, b):<br/> #implementation of euclidian distance formula between points a and b<br/> distances = []<br/> for i in range(len(a)):<br/>  distances.append((a[i] - b[i])**2)<br/> return math.sqrt(sum(distances))</span><span id="db8c" class="nt kt iq og b gy oo ol l om on">class KNN_model():<br/> def __init__(self,n_neighbours,X,Y,input, model_type):<br/>  self.n_neighbours = n_neighbours<br/>  self.X = X<br/>  self.Y = Y<br/>  self.input = input<br/>  self.model_type = model_type<br/> def find_neighbours(self):<br/>  #predict a single input<br/>  self.dist = []<br/>  for i in range(len(self.X)):<br/>   self.dist.append(['X', euclidian_distance(self.input,self.X[i])])<br/>  for i in range(len(self.Y)):<br/>   self.dist.append(['Y', euclidian_distance(self.input,self.Y[i])])<br/>  self.dist.sort(key=lambda x: x[1])</span><span id="a39f" class="nt kt iq og b gy oo ol l om on">def predict(self):<br/>  self.knn = []<br/>  self.model_type<br/>  #if regression, return mean of knn<br/>  if self.model_type == 'regression':<br/>   for i in range(n_neighbours):<br/>    self.knn.append(self.dist[i][1])<br/>   return sum(self.knn)/len(self.knn)<br/>  #if classifcation, return mode of knn<br/>  if self.model_type == 'classification':<br/>   self.knn = [i[0] for i in self.dist]</span><span id="8e61" class="nt kt iq og b gy oo ol l om on">for i in range(n_neighbours):<br/>    self.knn.append(self.dist[i][0])<br/>   dict_items = [i[0] for i in self.knn]<br/>   return max(set(dict_items), key = dict_items.count)<br/>   <br/>#defining key information<br/>n_neighbours = 1<br/>X = [[2,2],[2,2]]<br/>Y = [[1,1],[1,1],[1,1]]<br/>input = [[0,0],[0,0]]</span><span id="fefc" class="nt kt iq og b gy oo ol l om on">def NearestNeighbours(n_neighbours, X, Y, input, mode_type):<br/> preds = []<br/> <br/> for i in range(len(input)):<br/>  selected_input = input [i]<br/>  model = KNN_model(n_neighbours,X,Y,selected_input, mode_type)<br/>  model.find_neighbours()<br/>  preds.append(model.predict())<br/> return preds</span><span id="d0ea" class="nt kt iq og b gy oo ol l om on">predictions = NearestNeighbours(n_neighbours, X, Y, input,'classification')<br/>#print predictions<br/>print(predictions)</span></pre><p id="8bac" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">获取专家视图— <a class="ae lx" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="jw ir">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>