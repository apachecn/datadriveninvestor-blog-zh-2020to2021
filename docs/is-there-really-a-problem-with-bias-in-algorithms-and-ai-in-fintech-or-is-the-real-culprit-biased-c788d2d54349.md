# FinTech 真的是算法和 AI 有偏差的问题，还是真正的罪魁祸首是数据有偏差？

> 原文：<https://medium.datadriveninvestor.com/is-there-really-a-problem-with-bias-in-algorithms-and-ai-in-fintech-or-is-the-real-culprit-biased-c788d2d54349?source=collection_archive---------7----------------------->

## 检察官和监管者如何把事情搞得更糟

![](img/8de044fc402c469e20bbdf36e64fa119.png)

各位系好安全带。因为在 Tech on Reg 播客的第五集，我们将对算法偏差和人工智能这一紧迫问题展开自己的调查。

再次提醒…以防你错过第一集:[ [第一集](https://podcasts.apple.com/us/podcast/the-bias-in-ai-isnt-so-artificial/id1483479206?i=1000453459856)和[人工智能中的偏见不是人为的。](https://medium.com/datadriveninvestor/bias-in-a-i-isnt-artificial-5350c3940dac) ]

这是很少有人真正关心或谈论的话题之一，直到他们发现自己在金融机构的审查过程中被拒绝贷款或信用额度，特别是当他们发现这个过程严重依赖于算法和机器人。然后，名人开始使用 Twitter。每个人都会失去它。

为了更深入地了解这个复杂多变的问题，我们有幸请到了罗恩·谢夫林。他是 Cornerstone Advisors 金融科技研究部的董事总经理，也是该公司战略研究工作的负责人。此外，谢夫林是《福布斯》的定期撰稿人和专栏作家，也是这个话题备受追捧的专家。

碰巧的是，由于两起高调的案件，对算法和人工智能固有偏见的指控正受到关注，这两起案件都涉及知名公司。(当然，这些问题并不新鲜。)

首先，我们有一个鲜为人知的案例 [UnitedHealth Group Inc .及其健康服务平台 Optum，](https://www.bizjournals.com/twincities/news/2019/10/29/unitedhealth-algorithm-accused-of-racial-bias-gets.html)被指控使用有问题的风险算法，偏向白人患者而非黑人患者。然后，我们有高度推文和谈论的苹果卡和高盛的情况，据称提供更有利的信贷条件，男性比女性，或者更具体地说，丈夫比妻子。

[](https://www.datadriveninvestor.com/2019/02/19/artificial-intelligence-trends-to-watch-this-year/) [## 今年值得关注的 5 大人工智能趋势|数据驱动的投资者

### 预计 2019 年人工智能将取得广泛的重大进展。从谷歌搜索到处理复杂的工作，如…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2019/02/19/artificial-intelligence-trends-to-watch-this-year/) 

在纽约州金融服务部发起的全面正式的调查中，联合健康公司和苹果信用卡公司都受到了不利的影响。

我们先来深入了解一下 Apple Card 的案例。正如我的客人谢夫林所说，苹果卡案件激怒了消费者，让纽约的检察官们口吐白沫，因为毫无疑问，我们这里存在这样或那样的大问题。

> “这是一个烂摊子，”谢夫林说。“绝对是一片混乱。”

Apple Card 的故事爆发了，因为著名的丹麦程序员和 Ruby on Rails web 开发框架的创建者 David Heinemeier Hansson 在 Twitter 上抱怨说，尽管他的配偶 Jamie Hansson 拥有更好的信用评分，但她的信用额度增加申请却被苹果通过与高盛的合作拒绝了。

汉森声称，当他打电话询问发生了什么事情时，他与非常友好和礼貌的代表进行了交谈，但他们所能提供的解释是归咎于算法。

接下来，他们提出在没有获得更多财务信息的情况下，通过提高汉森夫人的信用额度来解决问题。“这当然引起了一场大风暴，”谢夫林说。“史蒂夫·沃兹尼亚克自己也发了一条推文，(声称)他的信用额度是他妻子的 10 倍。”

现在，许多人认为，与普通工薪阶层的抱怨相反，那些权势人物的推文引发了纽约监管机构的正式调查。

> “这(整个情况)不仅提出了关于偏见和算法的问题，还提出了一系列其他问题，”谢夫林说。“我不确定苹果卡没有联名账户这一点是否得到了很好的理解。妻子和丈夫必须分别申请。也不清楚这些人分别给了沃兹尼亚克和他的妻子什么信息。很有可能 Ruby on Rails 这个家伙把他的收入记为 100 万美元，而他的妻子可能说她一年只赚 5 万美元。因此，他们共同纳税和住在共同财产区的事实对申请来说并不重要。”

说得好，谢夫林。但我必须稍微反驳一下这种自动反射式的辩护，因为虽然我们可能不知道沃兹尼亚克和他妻子的收入问题的答案，但汉森和他的妻子确实披露了联合纳税申报单和共同资产。诸如此类的细节让整个情况变得更加混乱和可疑。

更糟糕的是，苹果信用卡公司的官员是如何根据一个电话投诉，毫不迟疑地提出增加汉森夫人的信用额度的。

当客户不得不拿起电话抱怨，而没有任何额外数据时，公司的回应类似于:哦，我们的错。这里还有一点信用。拜托，你能不能不要向监管机构投诉？

> 谢夫林说:“那件事太迟了。”。“很明显，纽约会监控推特，看看谁会抱怨什么。因此，这也提出了一个问题，即监管机构是否应该采取这种行动，你知道，这似乎是基于几个相对高调的人在推特上的膝跳反应。”

当然，最根本的答案应该是否定的。我们的监管机构不应该根据每一条推特和推特风暴就开始调查。对于监管机构来说，监控社交媒体以了解公司和消费者可能面临的问题未必是一件坏事，但一条推文不应该在没有任何进一步信息的情况下对一家公司展开调查，因为消费者投诉的孤立账户从来没有这样做过。

我早就警告过你，这个话题会给你带来很大的刺激。

幸运的是，在本周的播客中，我和谢夫林继续深入探讨了这个问题，这确实需要一些相当大的曲折。

请听这一集，听听我们对为什么责怪算法和质疑人工智能科学可能是一个大错误的看法，因为问题往往会被纳入数据本身。毕竟，算法和人工智能的好坏取决于输入系统的信息。有时，这些信息被坏的或不完整的数据或从一开始就以有偏见的方式收集的数据所破坏。

> “人工智能本身没有偏见，只有数据有偏见，”谢夫林说。“不是 AI 本身需要监管，甚至可以监管。因为数据本身就是问题的根源。”

我不确定我是否百分之百同意这个观点。但是你可以自己听听我的反驳。

我们还解决了算法是否能够或应该帮助解决社会中的固有偏见的问题，如收入不平等和性别歧视，方法是对算法进行调整，以考虑一些因素，如一个人被认为工资太低或拥有 Y 染色体而不是 x 染色体。

此外，我们还探索监管机构不仅如何开展调查，还探索他们是否受过专业培训，手头是否有适当的资源来彻底和负责任地调查依赖于算法和人工智能科学的金融科技案件。谁来支付持续的教育和培训费用？当过分热心的律师和检察官介入时会发生什么，我们会不会不可避免地以一个反动的、考虑不周的规章制度的迷宫而告终？

现在说还为时过早。

最后，谢夫林和我提出了最大的问题:联合健康和苹果信用卡调查会导致更多的监管甚至更多的监督吗？

我是说…可能吧。【T0:】

[达拉·塔可夫斯基。](https://www.linkedin.com/in/dara-chevlin-tarkowski/)企业家、作家、演说家、母亲|打造新事物；联合创始人[@ actuate law](https://actuatelaw.com/)\[@ quointec](http://quointec.com/)