<html>
<head>
<title>COVID-19 Detection in X-ray Images with Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Pytorch检测X射线图像中的新冠肺炎</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/covid-19-detection-in-x-ray-images-with-pytorch-5c5602b4658f?source=collection_archive---------1-----------------------#2020-03-27">https://medium.datadriveninvestor.com/covid-19-detection-in-x-ray-images-with-pytorch-5c5602b4658f?source=collection_archive---------1-----------------------#2020-03-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="889a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">放射诊断和成像中的人工智能</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/d7bc6325c51767d3f57db2a73173c7d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*ffCnI1dmkREAQGxAEUGSRg.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Pic: Which lungs belong to COVID-19 patients?</figcaption></figure><p id="3e35" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">昨天，我被周围的人问到一个问题:“我们有可能用X射线图像预测新冠肺炎吗？我立刻上网冲浪，发现世界上有几个团体正在为此而努力。</p><ul class=""><li id="b2aa" class="ln lo iq kt b ku kv kx ky la lp le lq li lr lm ls lt lu lv bi translated">一组中国研究人员在“arxiv.org”上发表了一篇论文，标题为“<a class="ae lw" href="https://arxiv.org/ftp/arxiv/papers/2002/2002.09334.pdf" rel="noopener ugc nofollow" target="_blank">深度学习系统筛查冠状病毒疾病2019肺炎</a>”。他们的深度学习模型能够实现86.7%的总体准确率，将CT图像分类为新冠肺炎、甲型流感病毒性肺炎或健康病例。</li><li id="b070" class="ln lo iq kt b ku lx kx ly la lz le ma li mb lm ls lt lu lv bi translated">约瑟夫·保罗·寇恩、保罗·莫里森和蓝岛正试图建立一个包含新冠肺炎、中东呼吸综合征、非典和急性呼吸窘迫综合征病例的<a class="ae lw" href="https://github.com/ieee8023/covid-chestxray-dataset?fbclid=IwAR3yCPo_e55khIvhhqDdPhCI6OMCLXjZKEziNnUzZWC9_h3NkyhqdjTqD5c" rel="noopener ugc nofollow" target="_blank">开放数据库</a>，这些病例都有胸部x光或CT图像。</li><li id="0e48" class="ln lo iq kt b ku lx kx ly la lz le ma li mb lm ls lt lu lv bi translated">Adrian Rosebrock发表了一篇关于“pyimagesearch”的教程，演示了使用Keras、TensorFlow和深度学习在X射线图像中检测<a class="ae lw" href="https://www.pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">新冠肺炎的分步指南。他成功地实现了新冠肺炎和非新冠肺炎X射线图像之间90%的分类模型总体准确性。</a></li></ul><p id="5c98" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个故事的贡献包括演示我实现的方法，以实现由Adrian Rosebrock使用深度学习框架Pytorch提供的图像数据集训练的100%的整体模型准确性。</p><h1 id="44c2" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">下载数据集</h1><p id="c9c8" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">首先，我在“pyimagesearch”上通过输入我的电子邮件地址下载了阿德里安教程(<a class="ae lw" href="https://www.pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://www . pyimagesearch . com/2020/03/16/detecting-新冠肺炎-in-x-ray-images-with-keras-tensor flow-and-deep-learning/</a>)中的数据集，以下载数据集和源代码。接下来，我通过“pyimagesearch”发送到我邮箱的链接下载了它们。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/e7d2b4a984167fd33d0930b248fdd06e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a3Oqi1SI6RcxUbYSZNNqvg.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Pic: Key in your email address to get the dataset.</figcaption></figure><p id="d369" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在名为“数据集”的文件夹中，有两个子文件夹名为“covid”和“normal”。每个子文件夹包含25幅图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ne"><img src="../Images/526f9f604852728a88f7cb1be8c1027a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vP1IDPNJl3G3UZ31SX9FOA.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Pic: The images that are stored in “normal” sub-folder.</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nf"><img src="../Images/0917433be523d9e388fbf768ad7c36b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z5-t3sgqjjzGNh667nDLrg.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Pic: The images that are stored in “covid” sub-folder.</figcaption></figure><h1 id="74f8" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">导入库</h1><p id="77f6" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">这个项目中使用的库包括Torch、Torchvision、Sklearn、PIL、Matplotlib、Numpy、Os、Time和Random。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="bb8e" class="nl md iq nh b gy nm nn l no np"># Import essential libraries<br/>from sklearn.metrics import accuracy_score, classification_report, confusion_matrix<br/>from sklearn.model_selection import train_test_split<br/>from PIL import Image<br/>import torchvision<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import torch<br/>import os<br/>import time<br/>import random<br/>%matplotlib inline</span></pre><h1 id="6113" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">准备数据集</h1><p id="8969" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">我准备了数据集，将图像的所有名称和标签分别存储为带有变量名“img_name”和“label”的列表。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="2d61" class="nl md iq nh b gy nm nn l no np">path="dataset/"<br/>img_name=[]<br/>label=[]<br/>for root, directories, files in os.walk(path):<br/>    for file in files:<br/>        img_name.append(root+"/"+file)<br/>        label.append(root.split("/")[-1])</span></pre><h1 id="1df4" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">研究数据集</h1><p id="dd36" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">通过观察数据集，我得到了一些信息:</p><ol class=""><li id="106f" class="ln lo iq kt b ku kv kx ky la lp le lq li lr lm nq lt lu lv bi translated">所有的图像大小不一样，这意味着它们的高度和宽度不一样。</li><li id="acd0" class="ln lo iq kt b ku lx kx ly la lz le ma li mb lm nq lt lu lv bi translated">所有图像的纵横比都不是1: 1。如果我们将图像调整为固定的比例(224像素宽和224像素高)，可能会导致整体模态精度下降。</li><li id="c2d3" class="ln lo iq kt b ku lx kx ly la lz le ma li mb lm nq lt lu lv bi translated">所有图像的缩放比例不同。在图像中，一些肺看起来很大，一些肺看起来很小。</li></ol><p id="1f5c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我画了一个箱线图，显示了图像的高度和宽度在整个图像数据集中的分布。标签“1”代表宽度，标签“2”代表高度。观察到一些异常值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/3b752951bc69ca9cf0676978e454fd0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*1z9pvCT1lT0wjKqauKgy0Q.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Pic: The boxplot of widths and heights of all the images in the dataset.</figcaption></figure><h1 id="fbe0" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated"><strong class="ak">分割数据集</strong></h1><p id="dac6" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">我把数据集拆分成test_size = 0.2，random_state=50的训练和测试，并使用Sklearn库分层。可以自由改变random_state的值，以观察使用不同的random_state值得到的结果是否一致。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="5499" class="nl md iq nh b gy nm nn l no np">train_img_name, val_img_name, train_label, val_label = train_test_split(img_name, label, test_size=0.2, random_state=50, stratify=label)</span></pre><h1 id="7565" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">扩充数据集</h1><p id="3511" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">在Adrian准备的教程中，他通过仅实现random_rotation=15度的设置来增强图像。除了random_rotation之外，我还将random_zooming_ratio的设置固定在0.7到1.3的范围内，以通过减少所有图像之间不同缩放比例的影响来确保分类器更加健壮。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="c222" class="nl md iq nh b gy nm nn l no np">train_Aug = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224)),                                 torchvision.transforms.RandomRotation((-20, 20)),                                          torchvision.transforms.RandomAffine(0, translate=None, scale=[0.7, 1.3], shear=None, resample=False, fillcolor=0),                                            torchvision.transforms.ToTensor()])<br/>test_Aug = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224)),                                           torchvision.transforms.ToTensor()])</span></pre><h1 id="f516" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">准备数据加载器</h1><p id="da22" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">我准备了两个数据加载器，一个是加载训练图像的训练加载器，另一个是加载测试图像的测试加载器。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="9a6b" class="nl md iq nh b gy nm nn l no np">class CustomDatasetFromImages(torch.utils.data.Dataset):<br/>    def __init__(self, img_name, label, transforms=None): <br/>        self.image_arr = np.asarray(img_name)<br/>        self.label_arr = np.asarray(label)<br/>        self.data_len = len(img_name)<br/>        self.transforms = transforms<br/>    def __getitem__(self, index):<br/>        single_img_name = self.image_arr[index]<br/>        img_array = Image.open(single_img_name).convert('RGB')<br/>        if self.transforms is not None:<br/>            img_array = self.transforms(img_array)<br/>        image_label = self.label_arr[index]<br/>        return (single_img_name, img_array, image_label)<br/>    def __len__(self):<br/>        return self.data_len</span><span id="8d8c" class="nl md iq nh b gy ns nn l no np">train_set=CustomDatasetFromImages(train_img_name, train_label, transforms=train_Aug)<br/>test_set=CustomDatasetFromImages(val_img_name, val_label, transforms=test_Aug)<br/>trainloader= torch.utils.data.DataLoader(train_set, batch_size=64, num_workers=2,shuffle=True) <br/>testloader= torch.utils.data.DataLoader(test_set, batch_size=64, num_workers=2, shuffle=False)</span></pre><h1 id="eee8" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">初始化模型架构</h1><p id="fc2c" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">我开始用ResNet18对图像建模，因为图像只有黑白的。如果ResNet18被证明是欠拟合的，那么在后面的实验中只会考虑引入更深的网络。我使用Pytorch提供的默认预训练体重。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="a9f3" class="nl md iq nh b gy nm nn l no np">model = torchvision.models.resnet18(pretrained=True)</span></pre><p id="e258" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我把ResNet 18最后一层的输出节点的编号改成了2。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="ac4b" class="nl md iq nh b gy nm nn l no np">model.fc = torch.nn.Linear(512, len(unique_class))</span></pre><h1 id="44e8" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">配置超参数</h1><p id="be91" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">我用的损失函数是交叉熵损失。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="511a" class="nl md iq nh b gy nm nn l no np">criterion = torch.nn.CrossEntropyLoss()</span></pre><p id="eea2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我使用的优化器是Adam，初始学习率=0.001，权重衰减=0.0005。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="e0b3" class="nl md iq nh b gy nm nn l no np">optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)</span></pre><p id="1ac6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我使用的学习率调度器是ReduceLROnPlateau，因子=0.1，耐心=10。这意味着，如果在训练过程中，训练损失在10个时期内不再连续减少，则学习率将变为其初始值的0.1倍。即:改变前= 0.001，改变后=0.0001。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="61a6" class="nl md iq nh b gy nm nn l no np">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, eps=1e-06)</span></pre><h1 id="b627" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">训练和评估模型</h1><p id="f5f9" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">在定义了模型架构和所有超参数之后，现在可以用训练图像来训练模型，并用测试图像来评估模型。我设定的纪元总数是50。保存包含模型权重的模型，该模型权重实现最低的验证损失，然后是最高的验证准确度。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nt"><img src="../Images/5d94cd812773c98824e698911999e2bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*odIImS4C9Fhd6-jJJ-uQxw.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Pic: The Training Loss, Training Accuracy, Testing Loss and Testing Accuracy in Epoch 1–5.</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nu"><img src="../Images/33e16a6b751b34e7eeaec31764a91d5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4xVy_ZL0N7AF39VqadxabA.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Pic: The Training Loss, Training Accuracy, Testing Loss and Testing Accuracy in Epoch 26–30.</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nv"><img src="../Images/a703707ead549d5f4e33e375182db269.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ozOd5M05g6um6iUsYToD2A.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Pic: The Training Loss, Training Accuracy, Testing Loss and Testing Accuracy in Epoch 46–50.</figcaption></figure><h1 id="32b9" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">讨论</h1><p id="2d1c" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">包含最佳结果的模型来自纪元50。准确性得分、分类报告和混淆矩阵如下图所示。整个建模过程耗时95.91秒，建模过程运行在高规格的GPU上。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/a646818bdb72939d621cbf2affd489a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*anJCRGx9nFHCW-V-Hhaq5A.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Fig: The best result (from epoch-50).</figcaption></figure><p id="cbf9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">10张测试图像的结果如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nx"><img src="../Images/871731d021eb162eb9532c7412fe9c9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lGlUHcGIQbns90EkUzNj0w.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ny"><img src="../Images/6db76b8982c4f91fd19f989539d9850c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTUkZMPJHFR5vQCoRodmKg.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nz"><img src="../Images/c7fa805f3138232b74597f0d5f981584.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XzWJlYmkh8sSJfqYu5naXA.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi oa"><img src="../Images/da4bd1443ac700f981b962f96087ae67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qKkyxjsy9MTOi3F5-UbnaQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ob"><img src="../Images/24768a8ddf04fe356b3feb0b364107bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xgu0lDkTrrxkNMKqWo6ETA.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Pic: The result of the 10 testing images.</figcaption></figure><h1 id="8e14" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">最后的话:</h1><p id="439d" class="pw-post-body-paragraph kr ks iq kt b ku mu jr kw kx mv ju kz la mw lc ld le mx lg lh li my lk ll lm ij bi translated">通过添加random_zooming_ratio的数据扩充设置，模型被设法从90% (9幅图像被正确预测，已由Adrian完成)提高到100% (10幅图像被正确预测)。</p><div class="oc od gp gr oe of"><a href="https://www.datadriveninvestor.com/2020/02/12/has-general-ai-exceeded-the-intellectual-capacity-of-humans/" rel="noopener  ugc nofollow" target="_blank"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd ir gy z fp ok fr fs ol fu fw ip bi translated">AI将军是否已经超过了人类的智力容量？数据驱动的投资者</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">不仅在游戏中，而且在劳动力市场上，机器都比人类聪明。在今天的许多领域，使用…</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="oo l"><div class="op l oq or os oo ot kl of"/></div></div></a></div><h1 id="4593" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated"><strong class="ak">参考文献:</strong></h1><ul class=""><li id="a506" class="ln lo iq kt b ku mu kx mv la ou le ov li ow lm ls lt lu lv bi translated">Adrian Rosebrock，<a class="ae lw" href="https://www.pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">使用Keras、TensorFlow和深度学习在X射线图像中检测新冠肺炎</a>。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ox oy l"/></div></figure></div></div>    
</body>
</html>