<html>
<head>
<title>How Do I Use Azure API in Object Detection?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在对象检测中使用Azure API？</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/how-do-i-use-azure-api-in-object-detection-ac8b6d34c7d8?source=collection_archive---------2-----------------------#2020-09-12">https://medium.datadriveninvestor.com/how-do-i-use-azure-api-in-object-detection-ac8b6d34c7d8?source=collection_archive---------2-----------------------#2020-09-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="b59e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这篇博客是系列文章的第一篇。我们将在每个博客中讨论物体检测的一些部分。其他零件请点击此处:</p><p id="c10f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">想知道这些关于深度学习的大肆宣传是关于什么的吗？作为一名从业者，您如何利用它来为您的组织增加价值？这一系列的博客文章将帮助你理解什么是物体检测。需要关注的关键绩效指标是什么？如何利用最先进的方法在更短的时间内简洁地完成工作。</p><h1 id="da74" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">大纲:</h1><p id="f5cd" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">1.理解问题<br/> 2。使用Azure API进行对象检测<br/> 3。深度学习模型概述</p><h1 id="058e" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">先决条件:</h1><p id="9e2e" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">1.<a class="ae lr" href="https://www.aegissofttech.com/machine-learning-development-services.html" rel="noopener ugc nofollow" target="_blank">机器学习服务知识</a> <br/> 2。关于Web APIs及其工作的知识<br/> 3。关于绩效指标的介绍性知识</p><h1 id="5ff8" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">什么是物体检测？</h1><p id="bf48" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">简而言之，对象检测就是输出包围盒以及表示包围在这些包围盒中的对象的类别标签。单个图像中可以有多个对象，如椅子、手提包、桌子、笔记本电脑等。多个对象可以是相同类型的，比如两个瓶子或不同类型的。它们也可以彼此重叠。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/6f902f8d5d4dc21a12d9a505e3343684.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*uQ4XkRJZkF6hgCfXG0s_tA.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk"><em class="me">Image URL: </em><a class="ae lr" href="https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg/330px-Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg" rel="noopener ugc nofollow" target="_blank"><em class="me">https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg/330px-Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg</em></a></figcaption></figure><h1 id="d4d6" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">对象检测与图像分割:</h1><p id="f3fa" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">目标检测不同于图像分割，因为在图像分割中，我们试图获得或标记精确的像素。通常，我们想要标记每个像素，这表示它是对象的一部分，比如手提包。因此，在对象检测中，我们更关心边界框，而在图像分割中，我们更关心像素。像UNets这样在像素级上工作的算法本质上是耗时的。这种算法试图构建一个像素图，比如说所有这些像素都属于笔记本电脑。因为我们希望物体检测更快，所以我们在这里使用边界框。</p><p id="4a40" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们知道什么是输入，什么是输出，对吗？简单地说，图像是输入，输出是边界框。有多种方式来表示一个边界框:比如使用高度和宽度。对于每个包围盒，我们想知道它里面的物体是什么。</p><h1 id="e366" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak">使用Azure API进行对象检测:</strong></h1><p id="a90d" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">我们将在Azure API的帮助下以自己的方式工作，因为它不会向你收取一个周末的费用，而Google Compute会向你收取信用卡费用，而许多读者可能没有信用卡。请记住，这里我假设您了解Web-API的基础知识以及它们是如何工作的。我不打算从底层细节来解释它们是如何工作的。</p><p id="243a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你只是在谷歌上搜索“azure object detection python”。你得到的第一个搜索结果是关于如何做的<a class="ae lr" href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-detection" rel="noopener ugc nofollow" target="_blank">代码集</a>。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/49c60b966db9037d63c2d38233e2de58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*jr9NJu5l_5ZSblKR8QIfdg.png"/></div></figure><p id="78be" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图片网址:<a class="ae lr" href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/images/windows-kitchen.jpg" rel="noopener ugc nofollow" target="_blank">https://docs . Microsoft . com/en-us/azure/cognitive-services/computer-vision/images/windows-kitchen . jpg</a></p><p id="c9c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你通读文档，你会看到，有一个图像作为输入，JSON作为输出返回，这是目前每个API使用的几乎相同的格式。</p><p id="5311" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><pre> <br/> &lt;代码&gt; <br/> { <br/>【物体】:<br/> { <br/>【矩形】:{<br/>【x】:730，<br/>【y】:66，<br/>【w】:135，<br/>【h】:85<br/>}，<br/>【物体】:【厨房用具】，<br/>【置信度】:0.501 <br/> }，<br/>{<br/><br/> <br/>{<br/>" rectangle ":{<br/>" x ":654，<br/> "y":0，<br/> "w":584，<br/> "h":473 <br/> }，<br/> "object":"person "，<br/>" confidence ":0.855<br/>}<br/>，<br/>" request id ":" a 7 FDE 8 FD-cc18–4f5f-99d 3–899</pre></p><p id="d4ec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们试着理解JSON的输出:我们可以看到返回的对象实际上是一个数组，其中包含几个子对象。这些部分表示模型从输入图片中检测到的可能对象。我们可以看到，对于边界框(大多是矩形)，我们返回中心坐标、高度和宽度。此外，对于正在进行的预测，它将返回置信度值，该值是解释模型对该预测正确的置信度的概率。置信度值的范围是从0到1。你甚至可以看到，物体的层次结构，比如一台笔记本电脑，也被预测为一台计算机，这在现实世界中是真实的。</p><h1 id="06bb" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak">Azure API的局限性:</strong></h1><p id="62fa" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">如果你经历一些限制:</p><p id="8918" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">1)它不能检测小于图像总面积5%的物体。</p><p id="39ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2)此外，堆叠在一起的物体有点难以识别。</p><p id="2511" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3)不能区分品牌或产品名称。</p><p id="e707" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后一点，有一个与<a class="ae lr" href="https://www.aegissofttech.com/en-au/microsoft-crm-development-services.html" rel="noopener ugc nofollow" target="_blank">微软<br/> dynamics 365 consultants </a>完全不同的API，让我们去参观一下。</p><div class="mg mh gp gr mi mj"><a href="https://www.datadriveninvestor.com/2020/03/29/microsoft-having-an-edge-over-chrome/" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd iu gy z fp mo fr fs mp fu fw is bi translated">数据驱动的投资者|微软比Chrome有“优势”</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">简史我从来不是浏览器的粉丝，确切地说，我只是一个浏览器的粉丝，Chrome。这是我的…</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="ms l"><div class="mt l mu mv mw ms mx ly mj"/></div></div></a></div><h1 id="5938" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak">计算机视觉API-2.0 </strong></h1><p id="cec1" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">我们的对象检测功能是分析图像API的一部分。现在，假设您了解基于Web的API，以及localhost如何向服务器发送一些请求，并根据一些请求变量/参数返回一些输出。如果你只要求一个对象，当没有指定时，它将只给你其他的，其他有效的特征类型，如成人内容、品牌、颜色、面孔、名人、地标等。也会被归还。您还可以指定希望输出使用的语言。比如说英语、汉语、日语、西班牙语等。</p><p id="65cc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你也可以看看下面给出的JSON，可以看到类似于我们上面看到的，这个描述了输入图像中存在的几种类型的对象，并以一定的置信度对其进行预测。此外，我们可以看到最终出现在输入图像中的对象的边界框。</p><p id="9f89" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><pre> <br/> &lt;代码&gt; <br/> { <br/>【类别】:【<br/> { <br/>【姓名】:【摘要_】，<br/>【分数】:0.00390625 <br/> }，<br/> { <br/>【姓名】:【人物_】，<br/>【分数】:0.83984375，<br/>【详细】:{ <br/>【名人】:<br/> { <br/>。 <br/>"置信度":0.9978346<br/>}<br/>]<br/>}<br/>}<br/>，<br/>"成人":{ <br/> "isAdultContent": false，<br/> "isRacyContent": false，<br/>" adultScore ":0.0934349000453949，<br/>" racyScore ":0.06868649195 <br/>【描述】:{ <br/>【标签】:[ <br/>【人】，<br/>【人】，<br/>【户外】，<br/>【窗】，<br/>，【眼镜】，<br/>，<br/>【字幕】:[ <br/> { <br/>【正文】:《坐在长椅上的塞特亚·纳德拉》，<br/>【信心】:0.48293603002174444 <br/>【高度】:250 <br/> } <br/> } <br/>，<br/>【颜色】:{<br/>" dominantcolorsforeground ":"棕色"，<br/>" dominantcolorbeground ":"棕色"，<br/> "dominantColors": [ <br/>"棕色"，<br/>"黑色"<br/> ]，<br/>"重音颜色":" 873B59 "，<br/></pre></p><p id="1c03" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">像FAANG这样的巨头在他们的文档中提供代码。您可以在Python语言的代码部分看到，我们将订阅密钥作为请求头的一部分提供。您还可以看到我们讨论过的作为请求一部分的几个参数。你必须在视觉特征部分指定它是一个物体，一张脸，还是别的什么东西。然后是另一段代码，说我们首先建立一个HTTPS连接。您将返回字节流数据。如果你想打印它，你可以使用:<strong class="js iu">print(JSON . dumps(response . JSON()))</strong></p><p id="a241" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><pre><code><br/># # # # # # # # # # # # # # Python 2.7 # # # # # # # # # # # #<br/>导入httplib，urllib，base64 <br/> <br/> headers = { <br/> #请求头<br/>' Content-Type ':' application/JSON '，<br/>' Ocp-Apim-Subscription-Key ':' { Subscription Key } '，<br/>}<br/><br/>params = urllib . urlenode({<br/>#请求参数<br/>' vishttps connection(' westcentralus . API . cognitive . Microsoft . com ')<br/>conn . request(" POST "，"/vision/v2.0/analyze？%s" % params，" {body} "，headers)<br/>response = conn . getresponse()<br/>data = response . read()<br/>print(data)<br/>conn . close()<br/>Exception as e:<br/>print("[Errno { 0 }]{ 1 }"。format(e.errno，e . strerror))<br/><br/># # # # # # # # # # # # # # # # # # # # # # # # #<br/><br/># # # # # # # # # # # # # # Python 3.2 # # # # # # # # # # # #导入http.client，urllib.request，urllib.parse，urllib.error，base64<br/><br/>headers = {<br/># Request headers<br/>【Content-Type】:‘application/JSON’，【T38%s" % params，" {body} "，headers)<br/>response = conn . getresponse()<br/>data = response . read()<br/>print(data)<br/>conn . close()<br/>Exception as e:<br/>print("[Errno { 0 }]{ 1 }"。format(e.errno，e . strerror))<br/><br/># # # # # # # # # # # # # # # # # # # # #<br/>/code&gt;<br/>&lt;/pre&gt;</code></pre></p><p id="45ed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你有兴趣看完整的代码，请访问<a class="ae lr" href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/quickstarts/python-analyze" rel="noopener ugc nofollow" target="_blank">这个</a>。</p><h1 id="6e06" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak">绩效指标:</strong></h1><p id="49af" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">我们如何衡量一个算法好不好？有几个术语你应该可以轻松使用:</p><p id="49be" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">1) <strong class="js iu">地面真理:</strong>是绝对真理；通常由人类标记或给予。它将是一个由人在被要求时画出的有边界的盒子。在机器学习行话中，用…</p><p id="d8c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2) <strong class="js iu">预测:</strong>是机器/模型做出的预测。在机器学习行话中，用…</p><p id="67f8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您想知道机器预测与人工注释的接近程度。你会做什么？我们将把这两个矩形也称为包围盒，并会计算一些所谓的交集或IoU。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi mf"><img src="../Images/2ccfb9ffae2f6ccbe992f3cd95e6b7d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*JOea1hphEQF1Khhdn4V7tg.png"/></div></div></figure><p id="ead1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">那么，理想的情况应该是怎样的呢？当两个边界框彼此完全重叠时，的值将为1。最坏的情况是什么？当两个边界框完全不重叠时，即交叉点= 0。结果，IoU将为0。使用的常见阈值是，如果，那么您的预测被称为阳性(在二元分类设置的情况下)。它有时也被称为50%。现在，这是一个边界框的表现。当我们在同一个图像中有多个对象时，也会有许多边界框。那又怎样？</p><p id="98a9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们说的是预测矩形是否与地面真实矩形重叠50%或更多。矩形重叠问题转化为<a class="ae lr" href="https://en.wikipedia.org/wiki/Binary_classification" rel="noopener ugc nofollow" target="_blank">二元分类问题</a>。但是对于多个对象，我们有一个<a class="ae lr" href="https://en.wikipedia.org/wiki/Multiclass_classification" rel="noopener ugc nofollow" target="_blank">多类分类问题</a>。现在，对于每个班级(椅子，人，..)，我们将计算所有同类对象的平均精度，这可以使用精度曲线下的<a class="ae lr" href="http://pages.cs.wisc.edu/~boyd/aucpr_final.pdf" rel="noopener ugc nofollow" target="_blank">区域来计算。</a></p><p id="4401" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">计算出每个类的平均精度后，取所有类的平均值，就会得到mean-average-precision()。许多研究论文都有符号表示我们正在计算。不要把它和统计学中的<a class="ae lr" href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation" rel="noopener ugc nofollow" target="_blank">图</a>(最大后验概率)混淆。</p><h1 id="3396" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak">深度学习模型概述:</strong></h1><p id="6ec3" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">到目前为止，我们已经介绍了一个非深度学习的人如何利用可用的API，而不用担心算法的东西来执行对象检测。现在，我们将转向算法部分。如您所见，我们的输入是图像或视频。我们可以将视频分解成一系列图像，然后交给模特，这样就完全没问题了。现在，输出是多少？我们需要边界框和相关的对象类标签。我们将利用<a class="ae lr" href="http://cocodataset.org/" rel="noopener ugc nofollow" target="_blank"> COCO </a>数据集进行理解。它包含80个类别标签和几千张图片。因此，这是一个相当大的数据集，非常适合于图像分割和对象检测等任务。</p><p id="c95d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，主要的权衡是速度与速度，这里的速度基本上是指给定一个输入算法的图像，它能以多快的速度输出。它可以用毫秒或每秒帧数来衡量。因此，如果算法处理图像的速度为50毫秒，大约等于20帧/秒。因为，1秒= 1000毫秒，因此每秒20幅图像。人类以24 fps看世界。对于无人驾驶汽车这样的系统，只有一点时间来识别其他车辆和车道，实时人脸检测系统只有一点时间来识别进入者，速度非常关键。在其他地方，平均精度非常重要。比如，医疗诊断和光学字符识别(OCR ),在这些领域，我们不能以牺牲更快的结果为代价犯太多的错误。</p><p id="0b31" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了更好，像R-CNN，快速R-CNN和更快R-CNN这样的算法，以基于金字塔网络的FRCN为特色。这些算法的更快版本可以更快地完成任务，因为从根本上说，它们不是为此而设计的。然后，我们有像单镜头检测和RetinaNet这样的算法。此外，像<a class="ae lr" href="https://medium.com/@amrokamal_47691/yolo-yolov2-and-yolov3-all-you-want-to-know-7e3e92dc4899" rel="noopener"> YOLO v1 (2015)、YOLO v2/ YOLO 9000 </a>(之所以这么叫是因为它可以识别Imagenet数据集上的9000个对象)和最近一个在阵容中的算法是YOLO v3(2018年4月)。出于同样的目的，还有其他30多种算法。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/6d6f30f78f086bcd5a25a9d6ae6bf214.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*jKHYhkHc0LFFPWoJeywqbg.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk"><em class="me">Source: </em><a class="ae lr" href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" rel="noopener ugc nofollow" target="_blank"><em class="me">https://pjreddie.com/media/files/papers/YOLOv3.pdf</em></a></figcaption></figure><p id="fd3b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，查看基准测试映像，我们可以看到YOLO v3根据它所处理的映像的大小有三种变体。YOLO-320-基本上说输入图像的大小是320x320。我们的目标是获得更高和更少的时间。我们可以看到，YOLO v3的速度非常快，性能非常好。输入图像越小，处理时间就越短。而当输入图像的尺寸较大时，需要更多的时间，但是有更多的机会正确检测较小的对象。因此，在YOLO v3提供的变体中进行选择，取决于您希望检测多小的物体。YOLO v3是一个真正伟大的架构，它集合了各种其他模型的优点。</p><p id="cbf3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在下一篇博文中，我们将看看YOLOv3成为物体检测领域最佳模型之一的架构和调整。直到那时，<strong class="js iu">快乐学习</strong>！</p><p id="8663" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">访问专家视图— </strong> <a class="ae lr" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>