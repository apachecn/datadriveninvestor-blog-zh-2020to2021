<html>
<head>
<title>Tokenization Explained Token by Token</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">符号化逐个符号地解释</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/tokenization-explained-token-by-token-b76df5d61112?source=collection_archive---------12-----------------------#2020-05-22">https://medium.datadriveninvestor.com/tokenization-explained-token-by-token-b76df5d61112?source=collection_archive---------12-----------------------#2020-05-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="67f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">分成更小的部分</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/1e7481506a88193ac02436cfaf6c1147.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4x-icmfyf8QDl7Bwmhf94g.png"/></div></div></figure><p id="0c99" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">标记化是将大量文本分成称为<strong class="jp ir">标记</strong>的较小部分的过程。令牌是Doc对象的基本构造块。一切有助于我们理解文本意义的东西都来自于记号以及它们之间的关系。</p><p id="ccef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它本质上是将一个短语、句子、段落或整个文本文档分割成更小的单元，如单个单词或术语。这些更小的单元中的每一个都被称为令牌。</p><h1 id="512a" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">令牌的类型-</h1><blockquote class="lv lw lx"><p id="73a4" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">前缀:开头的字符</p><p id="b002" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">后缀:结尾字符</p><p id="b914" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">中缀:中间的字符</p><p id="dd4c" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">例外:特殊情况规则，用于在应用标点符号规则时将字符串拆分成几个记号或防止记号被拆分</p></blockquote><h1 id="5ff2" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">标记化</h1><p id="a959" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">创建Doc对象的第一步是将输入的文本分解成组成部分或“标记”。</p><pre class="km kn ko kp gt mh mi mj mk aw ml bi"><span id="4c0c" class="mm ky iq mi b gy mn mo l mp mq"><em class="ly"># Import spaCy and load the language library</em><br/><strong class="mi ir">import</strong> <strong class="mi ir">spacy</strong><br/>nlp = spacy.load('en_core_web_sm')</span><span id="38ab" class="mm ky iq mi b gy mr mo l mp mq"><em class="ly"># Create a Doc object and explore tokens</em><br/>doc = nlp(mystring)<br/><br/><strong class="mi ir">for</strong> token <strong class="mi ir">in</strong> doc:<br/>    print(token.text, end=' | ')</span><span id="c91e" class="mm ky iq mi b gy mr mo l mp mq">OUTPUT-<br/>" | We | 're | moving | to | L.A. | ! | " |</span></pre><p id="7a4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，标记是原始文本的一部分。也就是说，我们没有看到任何词干或词条(单词的基本形式)的转换，我们也没有看到任何关于组织/地点/金钱等的内容。标记是Doc对象的基本构建块——帮助我们理解文本含义的一切都是从标记及其相互关系中派生出来的。</p><h1 id="1d1d" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">前缀和后缀</h1><p id="941f" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">spaCy将隔离那些不<em class="ly">不</em>构成单词整体部分的标点符号。句末的引号、逗号和标点符号将被赋予各自的符号。但是，作为电子邮件地址、网站或数值的一部分存在的标点符号将作为令牌的一部分保留。</p><pre class="km kn ko kp gt mh mi mj mk aw ml bi"><span id="277e" class="mm ky iq mi b gy mn mo l mp mq">doc2 = nlp(u"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!")<br/><br/><strong class="mi ir">for</strong> t <strong class="mi ir">in</strong> doc2:<br/>    print(t)<br/></span><span id="0644" class="mm ky iq mi b gy mr mo l mp mq">OUTPUT-<br/>We<br/>'re<br/>here<br/>to<br/>help<br/>!<br/>Send<br/>snail<br/>-<br/>mail<br/>,<br/>email<br/>support@oursite.com<br/>or<br/>visit<br/>us<br/>at<br/>http://www.oursite.com<br/>!</span></pre><p id="7c6e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有趣的是,“蜗牛邮件”中的感叹号、逗号和连字符都被赋予了自己的符号，但电子邮件地址和网站都被保留了下来。</p><h1 id="14c7" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">例外</h1><p id="9f17" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">作为已知缩写的一部分存在的标点符号将作为标记的一部分保留</p><pre class="km kn ko kp gt mh mi mj mk aw ml bi"><span id="a92f" class="mm ky iq mi b gy mn mo l mp mq">doc4 = nlp(u"Let's visit St. Louis in the U.S. next year.")<br/><br/><strong class="mi ir">for</strong> t <strong class="mi ir">in</strong> doc4:<br/>    print(t)<br/> </span><span id="1fc2" class="mm ky iq mi b gy mr mo l mp mq">Output-</span><span id="e70f" class="mm ky iq mi b gy mr mo l mp mq">Let<br/>'s<br/>visit<br/>St.<br/>Louis<br/>in<br/>the<br/>U.S.<br/>next<br/>year<br/>.</span></pre><p id="403a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里,“圣”和“美国”的缩写都保留了下来。</p><h1 id="b3fc" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">令牌可以通过索引位置和切片来检索</h1><p id="4256" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">停驻对象可以被认为是对象令牌列表。因此，可以通过索引位置来检索各个标记，并且可以通过切片来检索标记的范围:</p><pre class="km kn ko kp gt mh mi mj mk aw ml bi"><span id="a776" class="mm ky iq mi b gy mn mo l mp mq">doc5 = nlp(u'It is better to give than to receive.')<br/><br/><em class="ly"># Retrieve the third token:</em><br/>doc5[2]</span><span id="c55d" class="mm ky iq mi b gy mr mo l mp mq">Output-</span><span id="e6a9" class="mm ky iq mi b gy mr mo l mp mq">better</span></pre><h1 id="0472" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">命名实体</h1><p id="ea7e" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated"><em class="ly">超越了令牌，命名实体</em>增加了另一层上下文。语言模型认为某些单词是组织名称，而其他单词是位置，还有一些组合与金钱、日期等有关。通过doc对象的ents属性可以访问命名实体。</p><pre class="km kn ko kp gt mh mi mj mk aw ml bi"><span id="f564" class="mm ky iq mi b gy mn mo l mp mq">doc8 = nlp(u'Apple to build a Hong Kong factory for $6 million')</span><span id="9a12" class="mm ky iq mi b gy mr mo l mp mq"><strong class="mi ir">for</strong> token <strong class="mi ir">in</strong> doc8:<br/>    print(token.text, end=' | ')</span><span id="f9c6" class="mm ky iq mi b gy mr mo l mp mq">print('<strong class="mi ir">\n</strong>----')</span><span id="a83c" class="mm ky iq mi b gy mr mo l mp mq"><strong class="mi ir">for</strong> ent <strong class="mi ir">in</strong> doc8.ents:<br/>    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))</span><span id="6f7a" class="mm ky iq mi b gy mr mo l mp mq">OUTPUT-</span><span id="44e2" class="mm ky iq mi b gy mr mo l mp mq">Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | <br/>----<br/>Apple - ORG - Companies, agencies, institutions, etc.<br/>Hong Kong - GPE - Countries, cities, states<br/>$6 million - MONEY - Monetary values, including unit</span></pre><p id="0981" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意两个令牌如何组合形成实体“香港”，三个令牌如何组合形成货币实体:` $ 600万'</p><h1 id="d7b2" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">名词块</h1><p id="6734" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">与Doc.ents类似，Doc.noun_chunks是另一个对象属性。名词组块是“基本名词短语”——以一个名词为中心的扁平短语。你可以把名词块想象成一个名词加上描述这个名词的单词——例如一个<em class="ly">“独眼、独角、飞翔、紫色的食人族”</em>就是一个很长的名词块</p><pre class="km kn ko kp gt mh mi mj mk aw ml bi"><span id="e9cb" class="mm ky iq mi b gy mn mo l mp mq">doc9 = nlp(u"Autonomous cars shift insurance liability toward manufacturers.")<br/><br/><strong class="mi ir">for</strong> chunk <strong class="mi ir">in</strong> doc9.noun_chunks:<br/>    print(chunk.text)</span><span id="4ccd" class="mm ky iq mi b gy mr mo l mp mq">Output-<br/>Autonomous cars<br/>insurance liability<br/>manufacturers</span></pre><h1 id="d4c6" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">内置可视化工具</h1><p id="71e5" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">spaCy包括一个名为<strong class="jp ir"> displaCy </strong>的内置可视化工具。displaCy能够检测你是否在一个Jupyter笔记本中工作，并将返回可以立即在单元格中呈现的标记。导出笔记本时，可视化效果将以HTML格式包含在内。</p><h1 id="6749" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">可视化依赖解析</h1><pre class="km kn ko kp gt mh mi mj mk aw ml bi"><span id="ff7b" class="mm ky iq mi b gy mn mo l mp mq"><strong class="mi ir">from</strong> <strong class="mi ir">spacy</strong> <strong class="mi ir">import</strong> displacy<br/><br/>doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')<br/>displacy.render(doc, style='dep', jupyter=<strong class="mi ir">True</strong>, options={'distance': 110})</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ms"><img src="../Images/4168bb2a78382a7fd0233e20f134047e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qtYRjcyWLSd_QwSK-rUbow.png"/></div></div></figure><h1 id="1acc" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">可视化实体识别器</h1><pre class="km kn ko kp gt mh mi mj mk aw ml bi"><span id="08b4" class="mm ky iq mi b gy mn mo l mp mq">doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.')<br/>displacy.render(doc, style='ent', jupyter=<strong class="mi ir">True</strong>)</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mt"><img src="../Images/458f24953301b73d322e6757abbcdf2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uNrH2ySyH9D_RPYPt0W7GA.png"/></div></div></figure><h1 id="64a9" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">结论</h1><p id="d777" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">自然语言处理用于构建诸如文本分类、智能聊天机器人、情感分析、语言翻译等应用。为了达到上述目的，理解文本中的模式变得至关重要。这些记号对于寻找这种模式非常有用，并且被认为是词干化和词汇化的基本步骤。</p></div></div>    
</body>
</html>