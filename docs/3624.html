<html>
<head>
<title>Machine Learning for Fake Job Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于虚假工作检测的机器学习</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/machine-learning-for-fake-job-detection-6e89d8e5c963?source=collection_archive---------2-----------------------#2020-06-29">https://medium.datadriveninvestor.com/machine-learning-for-fake-job-detection-6e89d8e5c963?source=collection_archive---------2-----------------------#2020-06-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2fbb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">虚假工作检测模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/eaa720adaea4d2cbb35bb0842d2f2f4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HdI-8wph0XW816WtzUOykw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://pixabay.com/users/mohamed_hassan-5229782/" rel="noopener ugc nofollow" target="_blank">mohamed_hassan</a>/Pixabay</figcaption></figure><p id="0550" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习模型有很多用例。文本分析是自然语言处理的一个分支，它提供了允许机器学习算法应用于分类模型的文本数据的方法。模式存在于数据中，我们通常无法一直检测到，但是使用分析工具，我们能够检测到这些存在的模式。使用机器学习，这些模式甚至变得更容易和可扩展，我们可能每天都会遇到的一个典型例子是垃圾邮件分类器。</p><p id="866c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文将带您了解如何使用编码来表示文本数据，然后将这些数据输入到机器学习模型中。这方面的数据可以从<a class="ae ky" href="https://www.kaggle.com/shivamb/real-or-fake-fake-jobposting-prediction/download" rel="noopener ugc nofollow" target="_blank">这里</a>下载；</p><p id="ff4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一步是做一点探索性的数据分析。这是为了让我们熟悉数据集。我们加载数据集并调用所需的库；</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="8e21" class="ma mb it lw b gy mc md l me mf">library(tidytext)<br/>library(tidyverse)<br/>library(tidygraph)<br/>library(tm)<br/>library(SnowballC)<br/>library(randomForest)<br/><br/>#Read in the dataset<br/>posting &lt;- read.csv("fake_job_postings.csv")<br/></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mg"><img src="../Images/4bd227706199f7bbf6125726569933bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7zNW0tzd528d2xRD88RTlA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">A snippet of the data</figcaption></figure><p id="7070" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦数据被加载，我们将可视化每个行业的职位数量。注t <strong class="lb iu"> <em class="mh">帽子欺诈一栏的0代表真实工作，1代表虚假工作</em> </strong>。</p><div class="mi mj gp gr mk ml"><a href="https://www.datadriveninvestor.com/2020/02/19/five-data-science-and-machine-learning-trends-that-will-define-job-prospects-in-2020/" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd iu gy z fp mq fr fs mr fu fw is bi translated">将定义2020年就业前景的五大数据科学和机器学习趋势|数据驱动…</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">数据科学和ML是2019年最受关注的趋势之一，毫无疑问，它们将继续发展…</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz ks ml"/></div></div></a></div><p id="d5b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据欺诈栏可视化虚假和真实工作中的工作发布的顶级行业；</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="6283" class="ma mb it lw b gy mc md l me mf">posting %&gt;% <br/>  group_by(fraudulent) %&gt;% <br/>  count(industry) %&gt;% <br/>  arrange(desc(n)) %&gt;%<br/>  top_n(10) %&gt;% <br/>  mutate_if(is.character, list(~na_if(.,""))) %&gt;% <br/>  mutate(total = paste(round(100*n/sum(n), 1), "%", sep = "")) %&gt;% <br/>  filter(fraudulent == 1)%&gt;% <br/>  ggplot(., aes(reorder(industry, n), n, fill = industry)) +<br/>  geom_bar(stat = "identity", show.legend = F) +<br/>  coord_flip() + <br/>  geom_text(aes(label = total), color = "black", size = 4) +<br/>  labs(title = "Fake Posts", subtitle = "Count by Industry",<br/>       x = 'Industry') + theme_classic()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/ef08729e5a8e2c6f3482e307472e019b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*oBlsNg0qoOV0-scUVKJrbQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Prevalent industries in Fake Job Posts</figcaption></figure><p id="c201" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可视化真实职位的顶级行业；</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/cda40bc18bf49bc804293b692516093c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*1LzVJ-S3t5q8R-jOLOpWpQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Prevalent industries in Real Job Posts</figcaption></figure><p id="a39b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，在这两种情况下，更大比例的工作没有指定他们的行业，因此这不是一个很好的衡量标准来判断工作通知是真是假。</p><p id="c9ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看一看每种工作岗位类型的工作要求，即真实或虚假，我们挖掘以找到一些信息；</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="e14f" class="ma mb it lw b gy mc md l me mf">#Job Requirements<br/>posting %&gt;% <br/>  group_by(fraudulent) %&gt;% <br/>  count(required_experience) %&gt;% <br/>  mutate(percentage = paste(round(100*n/sum(n), 1), "%", sep = "")) %&gt;% <br/>  mutate_if(is.character, list(~na_if(.,""))) %&gt;% <br/>  ggplot(., aes(reorder(required_experience, n), log(n), fill = factor(fraudulent))) +<br/>  geom_bar(stat = "identity") +<br/>  geom_text(aes(label = percentage)) +<br/>  labs(x = "Job Requirement", title = "Jobs Requirement") +<br/>  scale_fill_discrete(name = "Dose", labels = c("Not Fake", "Fake")) +<br/>  coord_flip() +<br/>  theme_classic()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/85f666e458ae4b5f27c8c38c5bbd62ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*zpSEzTTlnu0n05QUA8Xriw.png"/></div></figure><p id="b4d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">取一个记录值，以便更好地观察轴线。从这里我们还可以看到，更大比例的实际工作没有具体说明他们的教育要求。</p><p id="13d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检查有公司标识的工作职位类别。有趣的是，你会发现大多数有实际工作岗位的公司都没有标识，而假岗位则相反。也许是为了确保它们看起来是真的？我的意思是，任何可疑的企业都想掩盖他们的踪迹，因此，需要这个标志。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/11858b23fe6d2ffbf623e70f3d3c9d69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*9wkrPvgiFqsjMHY6addOgw.png"/></div></figure><p id="0f35" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从这里开始，我们继续进行实际的预处理过程，这样我们就可以将数据输入到机器学习算法中。</p><h2 id="5c9f" class="ma mb it bd nd ne nf dn ng nh ni dp nj li nk nl nm lm nn no np lq nq nr ns nt bi translated">数据预处理/清理</h2><p id="e7a1" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">我们将首先删除停用词、标点符号、超链接和其他不需要的词。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="cbea" class="ma mb it lw b gy mc md l me mf">#Data Cleaning<br/>corpus &lt;- Corpus(VectorSource(posting$description))</span><span id="abb6" class="ma mb it lw b gy nz md l me mf">inspect(corpus[1:5])</span><span id="d0f8" class="ma mb it lw b gy nz md l me mf">#Convert to lower cast<br/>corpus &lt;- tm_map(corpus, tolower)</span><span id="4f3c" class="ma mb it lw b gy nz md l me mf">#Remove Punctuationa and inspect<br/>corpus &lt;- tm_map(corpus, removePunctuation)</span><span id="bc0e" class="ma mb it lw b gy nz md l me mf">inspect(corpus[1:5])</span><span id="b36a" class="ma mb it lw b gy nz md l me mf">#Remove stopwords<br/>corpus &lt;- tm_map(corpus, removeWords, stopwords(kind = "en"))</span><span id="b27b" class="ma mb it lw b gy nz md l me mf">#Stem document<br/>corpus &lt;- tm_map(corpus, stemDocument)</span></pre><p id="3221" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将创建一个清理数据的术语文档矩阵，这是一个主要的预处理阶段</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="1309" class="ma mb it lw b gy mc md l me mf">#Create document frequency<br/>freq &lt;- DocumentTermMatrix(corpus)<br/>freq</span><span id="6ede" class="ma mb it lw b gy nz md l me mf">#remove sparsity<br/>freq_sparsed &lt;- removeSparseTerms(freq, sparse = 0.995)</span><span id="bd34" class="ma mb it lw b gy nz md l me mf">freq_sparsed</span><span id="de89" class="ma mb it lw b gy nz md l me mf">#Convert cleaned document to a df<br/>df &lt;- as.data.frame(as.matrix(freq_sparsed))</span><span id="32b4" class="ma mb it lw b gy nz md l me mf">#Give unique names to colnames<br/>colnames(df) &lt;- make.names(colnames(df))</span><span id="3311" class="ma mb it lw b gy nz md l me mf">#Add the fraudelent colum<br/>df$fradulent &lt;- posting$fraudulent</span><span id="dfd1" class="ma mb it lw b gy nz md l me mf">#Remove duplicate column names<br/>colnames(df) &lt;-  make.unique(colnames(df), sep = "_")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/1a439c04569da3ea24a80796aae3ccd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_f9I02_UI3E1VyPnJa-lrQ.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Term Document Matrix</figcaption></figure><p id="de62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图是当您执行术语-文档频率操作时，您的新数据帧应该是什么样子。</p><h2 id="a55a" class="ma mb it bd nd ne nf dn ng nh ni dp nj li nk nl nm lm nn no np lq nq nr ns nt bi translated">训练集和测试集的拆分</h2><p id="4262" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">我们将使用caTools库上的split组件和ML模型的caret</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="8d08" class="ma mb it lw b gy mc md l me mf">#Create train and test dataset<br/>library(caTools)<br/>library(caret)</span><span id="d4cf" class="ma mb it lw b gy nz md l me mf">#Convert target variable to factor type<br/>df$fradulent &lt;- as.factor(df$fradulent)</span><span id="a738" class="ma mb it lw b gy nz md l me mf">#Split<br/>set.seed(2020, sample.kind = "Rounding")<br/>test_index &lt;- createDataPartition(y = df$fradulent, times = 1, p = 0.1, list= FALSE)<br/>train_set &lt;- df[-test_index, ]<br/>validation &lt;- df[test_index, ]</span><span id="1220" class="ma mb it lw b gy nz md l me mf">#Check the split ratio of the target variable<br/>table(train_set$fradulent)<br/>table(validation$fradulent)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/e7b26a08d1ac773f4508b7411c680eac.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*wXPHb0XeBC6bwW5tOFHq4g.jpeg"/></div></figure><p id="50ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于计算时间和巨大的类别不平衡的存在，我们将只使用1000个随机数据样本，但是如果适合你，你可以决定在整个数据集上训练。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="d68a" class="ma mb it lw b gy mc md l me mf">library(caret)<br/>#Get a sample number<br/>n &lt;- 1000</span><span id="64d4" class="ma mb it lw b gy nz md l me mf">#Cross validation contro;<br/>control&lt;- trainControl(method = "cv", number = 5, verboseIter = TRUE)</span><span id="9b46" class="ma mb it lw b gy nz md l me mf">#Number of trees for each train<br/>grid &lt;-data.frame(mtry = c(1, 5, 10, 25, 50, 100))</span><span id="7869" class="ma mb it lw b gy nz md l me mf">#create a sample from n number from dataset<br/>index &lt;- sample(nrow(train_set), n)</span><span id="0655" class="ma mb it lw b gy nz md l me mf">#subset data<br/>rf_train_data &lt;- train_set[index, ]</span><span id="b359" class="ma mb it lw b gy nz md l me mf">#Train random forest model<br/>subset_train_rf &lt;- train(fradulent ~ ., method = "rf", data = rf_train_data, ntree = 150, trControl = control, tuneGrid = grid)</span><span id="915c" class="ma mb it lw b gy nz md l me mf">#Accuracy on the sample train data<br/>prediction &lt;- predict(subset_train_rf, rf_train_data)</span><span id="4f44" class="ma mb it lw b gy nz md l me mf">#Confusion matrix<br/>confusionMatrix(prediction, rf_train_data$fradulent)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/ead18bc976ea426382fed53a1fcf76ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*z6-m-Gbz_IRF6vwM5YipTA.jpeg"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Accuracy from Confusion Matrix on the train data</figcaption></figure><p id="b441" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练数据上的<strong class="lb iu"> <em class="mh"> 97.6% </em> </strong>看起来不错，但我们需要看看它在验证集的早期分割上的表现如何(尽管我们使用了1000行的小集合来训练数据)。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="b9d2" class="ma mb it lw b gy mc md l me mf">#predict on the train set<br/>prediction01 &lt;- predict(subset_train_rf, validation)</span><span id="34c6" class="ma mb it lw b gy nz md l me mf">#confusion matrix<br/>confusionMatrix(validation$fradulent, prediction01)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/447a61add815d5e44660fc51aa8a9423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*qfgMFKsZ9JdtHsUfxagH6A.jpeg"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Accuracy from Confusion Matrix on Validation data</figcaption></figure><p id="1f33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有趣的是，该模型在超过1800个样本的验证集上仍然表现良好。</p><p id="9289" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你也可以继续使用其他模型，但在我的模型中，我使用了K-fold交叉验证来处理很可能由于类别不平衡而导致的过度拟合。最后，使用网格搜索为模型选择最佳超参数。</p><h2 id="2cf4" class="ma mb it bd nd ne nf dn ng nh ni dp nj li nk nl nm lm nn no np lq nq nr ns nt bi translated">结论</h2><p id="c25f" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">请注意，只有欺诈列旁边的功能描述列是唯一使用的列。但是，您可以通过编码来决定使用所有其他列。例如，诸如has_company_logo和telecommuting之类的列可以在创建术语文档之后添加到数据框中，从而被包括在内。其他列，如industry，可以简单地进行编码和追加。</p><p id="8e75" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，您应该考虑到您正在创建更多的要素，因此增加了计算时间。</p><p id="ef26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">访问专家视图— </strong> <a class="ae ky" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>