<html>
<head>
<title>Making an Image Classifier Using CNNs and PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用CNN和PyTorch制作图像分类器</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/making-an-image-classifier-using-cnns-and-pytorch-17518905c85b?source=collection_archive---------0-----------------------#2020-02-15">https://medium.datadriveninvestor.com/making-an-image-classifier-using-cnns-and-pytorch-17518905c85b?source=collection_archive---------0-----------------------#2020-02-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="c004" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">对于如何区分成千上万种不同的物体，我们通常不会多想。无论是苹果还是人，我们对大多数物体的分类都不会超过几秒钟。</p></blockquote><div class="kp kq kr ks gt ab cb"><figure class="kt ku kv kw kx ky kz paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><img src="../Images/d5bb0d7f4a96e278d771fbbc40ffe855.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*CmF1j5meI6hOR-T5"/></div></figure><figure class="kt ku kv kw kx ky kz paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><img src="../Images/8c3103d82330695ce4764d73a23d8dbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/0*mwtH_5pRFEM1j0F4"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk lk di ll lm">While we can easily tell that these images are of an apple and a person, computers have a much harder time with classification tasks.</figcaption></figure></div><p id="6362" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated">现在，如果我们能让计算机获得<em class="js">类似的性能，那些甚至不能“看”的机器会怎么样？就图像分类而言，<strong class="jt ir">卷积神经网络(CNN) </strong>是一种获得高精度结果的好方法。它们也很容易实现，我可以用<strong class="jt ir"> PyTorch </strong>创建一个CNN来分类不同类型的服装。我使用了<a class="ae lq" href="https://www.kaggle.com/zalando-research/fashionmnist" rel="noopener ugc nofollow" target="_blank">时尚-MNIST数据集</a>，它包含了<strong class="jt ir"> 70，000张十种不同类型服装的图片</strong>，以衬衫、连衣裙和外套为例。每张图像都是<em class="js"> 28×28像素</em>T12】。</em></p><h2 id="abdd" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">什么是CNN，它是如何工作的？</h2><figure class="kp kq kr ks gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi mk"><img src="../Images/44271a7d7c8468af317d7af319a6052b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Yu8KTpvRSsAT_Bnz.png"/></div></div></figure><p id="c3a9" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated">关于结构，CNN由输入、卷积层、全连接层和输出组成。<strong class="jt ir">卷积</strong>是将<strong class="jt ir">输入函数和过滤函数相乘</strong>以形成输出函数的过程，这是CNN的一个关键方面。对于CNN如何工作的更详细的概述，请随意通读这篇文章<a class="ae lq" href="https://medium.com/@vedaant.varshney/cnns-the-key-to-computer-vision-29c6fe1c6fdc" rel="noopener"><strong class="jt ir"/></a><strong class="jt ir"/>以获得更完整的描述。</p><div class="ml mm gp gr mn mo"><a href="https://www.datadriveninvestor.com/2019/01/23/which-is-more-promising-data-science-or-software-engineering/" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd ir gy z fp mt fr fs mu fu fw ip bi translated">数据科学和软件工程哪个更有前途？数据驱动的投资者</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">大约一个月前，当我坐在咖啡馆里为一个客户开发网站时，我发现了这个女人…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc le mo"/></div></div></a></div><h2 id="eecd" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">导入模块</h2><p id="cba1" class="pw-post-body-paragraph jq jr iq jt b ju nd jw jx jy ne ka kb ln nf ke kf lo ng ki kj lp nh km kn ko ij bi translated">从项目开始的一个好地方是导入所有需要的模块。提醒一下，我用PyTorch创建了这个网络。</p><pre class="kp kq kr ks gt ni nj nk nl aw nm bi"><span id="92d9" class="lr ls iq nj b gy nn no l np nq">import <strong class="nj ir">torch</strong><br/>import <strong class="nj ir">numpy</strong> as <strong class="nj ir">np</strong><br/>import <strong class="nj ir">torchvision.transforms </strong>as <strong class="nj ir">transforms</strong><br/>from <strong class="nj ir">torchvision</strong> import <strong class="nj ir">datasets</strong><br/>from <strong class="nj ir">torch.utils.data.sampler </strong>import <strong class="nj ir">SubsetRandomSampler<br/></strong>import <strong class="nj ir">matplotlib.pyplot </strong>as <strong class="nj ir">plt</strong><br/>import <strong class="nj ir">torch.nn</strong> as <strong class="nj ir">nn</strong><br/>import <strong class="nj ir">torch.nn.functional </strong>as <strong class="nj ir">F</strong><br/>import <strong class="nj ir">torch.optim</strong> as <strong class="nj ir">optim</strong><br/>%matplotlib inline</span></pre><p id="c137" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated">torchvision的数据集库允许我们直接下载和导入时尚MNIST，使过程变得更简单。</p><h2 id="b253" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">载入数据</h2><p id="c54c" class="pw-post-body-paragraph jq jr iq jt b ju nd jw jx jy ne ka kb ln nf ke kf lo ng ki kj lp nh km kn ko ij bi translated">制作图像分类器的第一步总是加载数据并设置训练、验证和测试集。我决定使用<strong class="jt ir"> 20%的训练数据进行验证</strong>，并应用一些标准数据扩充，这可以减少训练时的过度拟合。</p><pre class="kp kq kr ks gt ni nj nk nl aw nm bi"><span id="4229" class="lr ls iq nj b gy nn no l np nq">num_workers = 0<br/>batch_size = 36<br/>valid_size = 0.2</span><span id="3d8e" class="lr ls iq nj b gy nr no l np nq"><strong class="nj ir"># Data augmentation for train data + conversion to tensor</strong><br/>train_transforms = transforms.Compose([<br/>    transforms.RandomHorizontalFlip(),<br/>    transforms.RandomRotation(12),<br/>    transforms.ToTensor(),<br/>    transforms.Normalize((0.5,), (0.5,))<br/>   <br/>])</span><span id="5416" class="lr ls iq nj b gy nr no l np nq"><strong class="nj ir"># Data augmentation for test data + conversion to tensor</strong><br/>test_transforms= transforms.Compose([<br/>    transforms.ToTensor(),<br/>    transforms.Normalize((0.5,),(0.5,))<br/>])</span><span id="5fa8" class="lr ls iq nj b gy nr no l np nq"><strong class="nj ir"># Picking Fashion-MNIST dataset</strong><br/>train_data = datasets.FashionMNIST('Dataset', train=True, download=True, transform=train_transforms)<br/>test_data = datasets.FashionMNIST('Dataset', train=False, download=True, transform=test_transforms)</span></pre><p id="8add" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated">同样重要的是，要随机分割验证和训练数据，并创建数据加载器，我们可以通过它进行迭代训练。</p><pre class="kp kq kr ks gt ni nj nk nl aw nm bi"><span id="0573" class="lr ls iq nj b gy nn no l np nq"><strong class="nj ir"># Finding indices for validation set</strong><br/>num_train = len(train_data)<br/>indices = list(range(num_train))<br/><strong class="nj ir">#Randomize indices</strong><br/>np.random.shuffle(indices)</span><span id="3c47" class="lr ls iq nj b gy nr no l np nq">split = int(np.floor(num_train*valid_size))<br/>train_index, test_index = indices[split:], indices[:split]</span><span id="c664" class="lr ls iq nj b gy nr no l np nq"><strong class="nj ir"># Making samplers for training and validation batches</strong><br/>train_sampler = SubsetRandomSampler(train_index)<br/>valid_sampler = SubsetRandomSampler(test_index)</span><span id="10c0" class="lr ls iq nj b gy nr no l np nq"><strong class="nj ir"># Creating data loaders</strong><br/>train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)<br/>valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)<br/>test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)</span></pre><h2 id="d206" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">可视化数据</h2><p id="4b02" class="pw-post-body-paragraph jq jr iq jt b ju nd jw jx jy ne ka kb ln nf ke kf lo ng ki kj lp nh km kn ko ij bi translated">既然数据加载器已经设置好了，我们应该能够查看我们的图像，看看到目前为止是否一切正常。(代码在GitHub repo中)</p><div class="kp kq kr ks gt ab cb"><figure class="kt ku ns kw kx ky kz paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><img src="../Images/563ba252e521003b0e627386728e8ee3.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*d-YlRNBGEk72jltnzdrG0Q.png"/></div></figure><figure class="kt ku nt kw kx ky kz paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><img src="../Images/c1c05aa6afcf64319c9fa20f23fc0aa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*4GVlnDYqkQGyg8E1rK6ZiA.png"/></div></figure><figure class="kt ku nu kw kx ky kz paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><img src="../Images/bffff873206e66af3600088f343be3b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*hG1JGxXdrh7dw71yAwJRDA.png"/></div></figure></div><p id="e2a7" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated">即使图像只有<em class="js"> 28×28像素</em>和灰度<em class="js">、</em>，我们仍然能够区分它们。卷积神经网络可以<strong class="jt ir">处理更大的RGB图像</strong>；尽管训练时间同样会增加。</p><h2 id="1d8f" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">定义CNN的架构</h2><p id="4a59" class="pw-post-body-paragraph jq jr iq jt b ju nd jw jx jy ne ka kb ln nf ke kf lo ng ki kj lp nh km kn ko ij bi translated">对于我的网络，我采用了一个输入图像，并经历了以下步骤:</p><ol class=""><li id="2418" class="nv nw iq jt b ju jv jy jz ln nx lo ny lp nz ko oa ob oc od bi translated">我通过一个<em class="js">深度为8 </em>的<strong class="jt ir">卷积层</strong>和一个<strong class="jt ir"> maxpooling层</strong>将数组的长度和宽度缩小了2倍。</li><li id="5f4d" class="nv nw iq jt b ju oe jy of ln og lo oh lp oi ko oa ob oc od bi translated">接下来，我把第一层的输出通过另一个conv。深度为16的层，以及maxpooling层。</li><li id="ad33" class="nv nw iq jt b ju oe jy of ln og lo oh lp oi ko oa ob oc od bi translated">我<strong class="jt ir">把数组</strong>“展平”成一维数组，放入四个全连通层，最后得到一个输出。</li></ol><figure class="kp kq kr ks gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi oj"><img src="../Images/c40dad00ff93258b9948b12052884e73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z-Giw7KIenZVmXAtymBN_Q.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Visual representation of my CNN</figcaption></figure><pre class="kp kq kr ks gt ni nj nk nl aw nm bi"><span id="9ffe" class="lr ls iq nj b gy nn no l np nq">class Net(nn.Module):<br/>    def __init__(self):<br/>        super(Net, self).__init__()<br/>        <strong class="nj ir"># convolutional layers</strong><br/>        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)<br/>        self.conv2 = nn.Conv2d(8, 16, 3, padding =1)<br/>        <strong class="nj ir"># linear layers</strong><br/>        self.fc1 = nn.Linear(784, 256)<br/>        self.fc2 = nn.Linear(256, 128)<br/>        self.fc3 = nn.Linear(128, 64)<br/>        self.fc4 = nn.Linear(64, 10) <br/>       <strong class="nj ir"> # dropout</strong><br/>        self.dropout = nn.Dropout(p=0.2)<br/>    <strong class="nj ir">    # max pooling</strong><br/>        self.pool = nn.MaxPool2d(2, 2)<br/>    <br/>    def forward(self, x):<br/>       <strong class="nj ir"> # convolutional layers with ReLU and pooling</strong><br/>        x = self.pool(F.relu(self.conv1(x)))<br/>        x = self.pool(F.relu(self.conv2(x)))<br/>       <strong class="nj ir"> # flattening the image</strong><br/>        x = x.view(-1, 7*7*16)<br/>      <strong class="nj ir">  # linear layers</strong><br/>        x = self.dropout(F.relu(self.fc1(x)))<br/>        x = self.dropout(F.relu(self.fc2(x)))<br/>        x = self.dropout(F.relu(self.fc3(x)))<br/>        x = self.fc4(x)<br/>        return x<br/>        <br/>model = Net()<br/>print(model)<br/>model.cuda()</span></pre><h2 id="b1a1" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">定义损失函数和优化器</h2><p id="0c1d" class="pw-post-body-paragraph jq jr iq jt b ju nd jw jx jy ne ka kb ln nf ke kf lo ng ki kj lp nh km kn ko ij bi translated">对于这个网络，我决定使用一个<strong class="jt ir">交叉熵损失函数</strong>和随机<strong class="jt ir">梯度下降</strong>作为优化器。利用这些，我们可以提高基于分类误差的模型的性能，达到更高的精度。</p><pre class="kp kq kr ks gt ni nj nk nl aw nm bi"><span id="a31a" class="lr ls iq nj b gy nn no l np nq"><strong class="nj ir"># loss function (cross entropy loss)</strong><br/>criterion = nn.CrossEntropyLoss()<br/><strong class="nj ir"># optimizer</strong><br/>optimizer = optim.SGD(model.parameters(), lr = 0.001)</span></pre><h2 id="3daa" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">训练模型</h2><p id="05a5" class="pw-post-body-paragraph jq jr iq jt b ju nd jw jx jy ne ka kb ln nf ke kf lo ng ki kj lp nh km kn ko ij bi translated">既然模型的架构已经设置好了，我们可以创建一个训练循环。虽然我只为<strong class="jt ir"> 25个时期</strong>训练了模型，但验证损失<em class="js">继续减少</em>，我可能可以训练更长时间。</p><p id="e033" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated">顺便提一下，模型是使用支持CUDA的GPU进行训练的，这导致<em class="js">训练时间大约为</em><strong class="jt ir"><em class="js">20–30分钟</em> </strong>。训练循环代码可以在<a class="ae lq" href="https://github.com/Deep-Thoughts42/ImageClassifierCNN/blob/master/Image%20Classifier.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。最终得到的验证损失约为0。<em class="js"> 57，比最初的2.3 </em>有所减少。</p><h2 id="ccd0" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">模型精度</h2><p id="a7c2" class="pw-post-body-paragraph jq jr iq jt b ju nd jw jx jy ne ka kb ln nf ke kf lo ng ki kj lp nh km kn ko ij bi translated">完成训练循环后，最后一步是<strong class="jt ir">使用测试数据集检查模型的准确性</strong>，并查看其实际表现如何！</p><figure class="kp kq kr ks gt ku gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/5eb760c7e7ed20d10adf1d97763125af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*wBI-BUe19TvDghKWdzi6rw.png"/></div></figure><p id="f50d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated">在测试模型时，我们可以注意到<strong class="jt ir">更独特的服装</strong> <strong class="jt ir">项目比具有更一般特征的项目具有更高的准确率</strong>。例如，裤子的准确率为94.64%<strong class="jt ir"><em class="js"/></strong>，而衬衫的正确识别率仅为23.72%<strong class="jt ir">。衬衫很可能被误认为是类似的物品，如外套和套头衫，因为在如此小的图像尺寸下特征会是相似的。</strong></p><h2 id="2703" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">潜在的模型改进</h2><p id="739c" class="pw-post-body-paragraph jq jr iq jt b ju nd jw jx jy ne ka kb ln nf ke kf lo ng ki kj lp nh km kn ko ij bi translated">我的解决方案并不完美，主要是我的实验，我的目标是看看什么可行，什么不可行。</p><figure class="kp kq kr ks gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ol"><img src="../Images/68199d2a90e465a27cb041eca108fa69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Dm47cxfS_KIQQcL7.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">In general, training a well-designed model should result in decreased loss and increased test accuracy with an increased number of epochs.</figcaption></figure><p id="d5ea" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated"><strong class="jt ir">以下是一些提高性能的潜在方法:</strong></p><ul class=""><li id="b8bf" class="nv nw iq jt b ju jv jy jz ln nx lo ny lp nz ko om ob oc od bi translated">训练模型的时间越长，测试的准确性就越高。</li><li id="1922" class="nv nw iq jt b ju oe jy of ln og lo oh lp oi ko om ob oc od bi translated">在数据扩充阶段，规范化可能会影响潜在的特征检测，因此修改这些值可能会导致性能变化。</li><li id="dbd1" class="nv nw iq jt b ju oe jy of ln og lo oh lp oi ko om ob oc od bi translated">我使用的架构可能将图像合并了两次，简化了图像，减少了特征的细节，使检测图像之间的模式变得更加困难。</li><li id="96de" class="nv nw iq jt b ju oe jy of ln og lo oh lp oi ko om ob oc od bi translated">为了提高效率，我可能不需要四个完全连接的层，两个或三个层可能会产生类似的值</li></ul></div><div class="ab cl on oo hu op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="ij ik il im in"><p id="ffef" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated">尽管时尚-MNIST数据集包含只有一个颜色通道的小图像，但不要认为这是对CNN的轻视。<strong class="jt ir">它们可以用来对高清和RGB图像进行分类，并达到90多的精度水平。</strong></p><p id="1564" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated">图像分类的未来似乎倾向于卷积神经网络，它们是一种很好的工具，可能会在不久的将来得到很大的发展！</p></div><div class="ab cl on oo hu op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="ij ik il im in"><h2 id="e635" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">我在构建项目时获得/使用的酷资源</h2><ul class=""><li id="1447" class="nv nw iq jt b ju nd jy ne ln ou lo ov lp ow ko om ob oc od bi translated">这个项目是在<a class="ae lq" href="https://classroom.udacity.com/courses/ud188" rel="noopener ugc nofollow" target="_blank"> Udacity深度学习课程</a>的指导下完成的，这是一个学习如何编程和训练神经网络的优秀资源</li><li id="b6b9" class="nv nw iq jt b ju oe jy of ln og lo oh lp oi ko om ob oc od bi translated"><a class="ae lq" href="https://www.topbots.com/14-design-patterns-improve-convolutional-neural-network-cnn-architecture/" rel="noopener ugc nofollow" target="_blank">改进CNN模型的技巧</a></li><li id="77b0" class="nv nw iq jt b ju oe jy of ln og lo oh lp oi ko om ob oc od bi translated"><a class="ae lq" href="http://alexlenail.me/NN-SVG/index.html" rel="noopener ugc nofollow" target="_blank">用于可视化神经网络的工具</a></li></ul></div><div class="ab cl on oo hu op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="ij ik il im in"><p id="31d6" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated">谢谢你看我的文章！如果您有任何反馈、建议、评论或更正，我很乐意收到您的来信。我还提供了项目代码，以防您想更好地了解事情是如何工作的。</p><p id="ca15" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ln kd ke kf lo kh ki kj lp kl km kn ko ij bi translated"><strong class="jt ir">项目GitHub: </strong> <a class="ae lq" href="https://github.com/Deep-Thoughts42/ImageClassifierCNN/blob/master/Image%20Classifier.ipynb" rel="noopener ugc nofollow" target="_blank"> CNN图片分类器</a> <strong class="jt ir"> <br/>邮箱:</strong>vedaant.varshney@gmail.com<strong class="jt ir"><br/>LinkedIn:</strong><a class="ae lq" href="http://www.linkedin.com/in/vedaant-varshney" rel="noopener ugc nofollow" target="_blank">韦达安·瓦什尼</a> <br/> <strong class="jt ir">个人网站:</strong><a class="ae lq" href="https://vedaantv.com/" rel="noopener ugc nofollow" target="_blank">vedaantv.com</a></p><figure class="kp kq kr ks gt ku"><div class="bz fp l di"><div class="ox oy l"/></div></figure></div></div>    
</body>
</html>