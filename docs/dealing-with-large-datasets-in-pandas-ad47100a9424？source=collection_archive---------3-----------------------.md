# 在熊猫中处理大数据集

> 原文：<https://medium.datadriveninvestor.com/dealing-with-large-datasets-in-pandas-ad47100a9424?source=collection_archive---------3----------------------->

![](img/227a349dd718120910f92faf5a100896.png)

andas 可能是执行探索性数据分析和各种其他任务(如数据清理和转换)的首选库。通常，我们可能希望在大型数据集上利用熊猫的力量，而用传统的方法这样做通常很麻烦。在这篇博文中，我将展示我对此类问题的处理方法，以及它如何使分析过程变得更加可行。

# 分块加载数据集

当我得到一个 8GB 内存不足以加载 CSV 文件的错误时，我真的很惊讶。我的 spyder IDE 决定粉碎我的梦想，刚刚崩溃。

幸运的是，pandas 有办法将数据加载到你的内存可以处理的数据块中。没有你应该使用的固定块大小。这一切都是通过反复试验才知道什么最适合你的机器。一旦以块的形式加载了数据，就可以循环遍历这些块并单独处理它们。最后，将处理过的块连接成一个数据帧。

# 删除不必要的列

尽可能缩小你的数据帧总是更可取的，如果可能的话，最好在把它加载到 pandas 之前，因为这将极大地改善处理时间。

您可以删除不必要的列，或者只选择您需要的列。老实说，我更喜欢使用 drop 函数来删除它们，因为它清楚地显示了被忽略的内容。

# 更改数据类型

当使用高效的数据类型时，您可以存储和处理更大的数据集。一些值可以存储在内存要求较低的数据类型中。例如，具有相对较少唯一值的文本数据列可以存储为**分类**数据，因为它将每个唯一值存储一次，并使用有效的整数来表示什么属于什么。您可以使用 astype()函数来更改列的数据类型，如下所示。

此外，您可以使用 pandas to_numeric()函数将整数值向下转换为尽可能小的数据类型。

# 矢量化而不是循环

使用 iterrows()或 itertuples()在数据帧中循环只能在 pandas 矢量化无法应用时作为最后的选择。例如，如果您需要创建一个新列，该列是两个现有列相乘的结果，而不是遍历整个数据帧并一次更新一个单元格，您可以通过矢量化在一行代码中执行此操作。

此外，如果需要从 dataframe 中筛选出在特定列中具有特定值的行，可以使用 isin()函数，而不是像下面这样遍历 dataframe。

# 分块保存数据集

就像我们以块的形式加载 CSV 文件一样，我们也可以使用 to_csv()函数中的 chunksize 参数以块的形式保存数据。