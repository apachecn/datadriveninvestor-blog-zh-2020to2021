<html>
<head>
<title>What Is a Chatbot Really Thinking When You’re Talking with It</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">当你和聊天机器人交谈时，它到底在想什么</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/what-is-a-chatbot-really-thinking-when-youre-talking-with-it-52c2e1b11aff?source=collection_archive---------22-----------------------#2020-03-03">https://medium.datadriveninvestor.com/what-is-a-chatbot-really-thinking-when-youre-talking-with-it-52c2e1b11aff?source=collection_archive---------22-----------------------#2020-03-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="dea3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">高兴，在阿里巴巴的昵称是空谷。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/6037d1be844abc5d7d2c9b4da3b7fa9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EMPiDRPv2cl2qYux.png"/></div></div></figure><p id="d852" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里有一个奇怪的问题。为什么近年来<a class="ae ky" href="https://www.alibabacloud.com/blog/introduction-to-alibaba-cloud-intelligent-service-robot_593814?spm=a2c41.14065549.0.0" rel="noopener ugc nofollow" target="_blank">聊天机器人</a>越来越受欢迎？答案很明显。聊天机器人可以帮助企业节省宝贵的时间，提高效率，提供全天候服务，甚至减少服务错误。</p><p id="f10d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，再深究一下，聊天机器人的创建涉及到哪些原理和问题呢？另一方面，我们如何提高聊天机器人的效率，以进一步增加它们为企业提供的好处？</p><p id="157b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好奇想知道答案？今天，在这篇文章中，作为一名来自阿里巴巴的技术专家，我将通过展示在阿里巴巴进行的一项案例研究的结果来尝试解决所有这些问题。</p><div class="kz la gp gr lb lc"><a href="https://www.datadriveninvestor.com/2018/09/22/infographic-journey-to-the-clouds/" rel="noopener  ugc nofollow" target="_blank"><div class="ld ab fo"><div class="le ab lf cl cj lg"><h2 class="bd ir gy z fp lh fr fs li fu fw ip bi translated">信息图:云之旅|数据驱动的投资者</h2><div class="lj l"><h3 class="bd b gy z fp lh fr fs li fu fw dk translated">聪明的企业领导者了解利用云的价值。随着数据存储需求的增长，他们已经…</h3></div><div class="lk l"><p class="bd b dl z fp lh fr fs li fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="ll l"><div class="lm l ln lo lp ll lq kw lc"/></div></div></a></div><p id="cc13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">今天这篇文章的内容是基于在意大利佛罗伦萨举行的</em> <a class="ae ky" href="http://www.acl2019.org/EN/index.xhtml?spm=a2c41.14065549.0.0" rel="noopener ugc nofollow" target="_blank"> <em class="kl"> ACL 2019 </em> </a> <em class="kl">上发表的一篇文章。</em></p><p id="aed6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，在我们深入了解事情之前，让我们先了解一些基本概念和常识。</p><p id="1214" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据聊天机器人能够提供的整体解决方案，聊天机器人可以分为两个特定的子类型。有任务机器人，这是聊天机器人，专门用于诸如预订机票或查看天气预报等任务。此外，还有问答机器人，它们唯一的工作就是根据自己的知识库回答问题。</p><p id="2d11" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通常，客户服务场景中使用的聊天机器人是QA机器人。有三种主要类型的QAbots，根据它们的知识库格式进行分类。首先，有doc-QA bot，它们的知识基于一个或多个文档。还有kg-QA bot，它们从知识图和faqbots中获取知识，也称为FAQ-QA bot，它们的知识来自常见问题(FAQ)的问答对。</p><p id="e618" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于本文中的讨论，我们将重点关注FAQbots，它更容易维护，也是当今客户服务场景中聊天机器人解决方案的最重要部分之一。</p><p id="46ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">FAQbot通过涉及文本分类和文本匹配的过程将查询匹配到问答对。文本分类适用于本质上或多或少稳定的FAQ。另一方面，文本匹配更适合长尾的FAQ，或者本质上不太持久、会随时间变化的FAQ。</p><p id="0cee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">阿里巴巴的<a class="ae ky" href="https://www.alizila.com/alibabas-customer-service-bot-gets-upgrade-ahead-of-11-11/?spm=a2c41.14065549.0.0" rel="noopener ugc nofollow" target="_blank"> AlimeBot </a>是为阿里巴巴电子商务平台上的商家提供的智能客服解决方案。AlimeBot的基本功能是根据常见问题回答用户问题。我们在文本分类和文本匹配方面进行了大量的研究和实验。因此，这篇文章将涵盖我们的研究，并侧重于我们在阿里巴巴用于文本匹配的基本模型。</p><p id="ec9e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">文本匹配是自然语言处理的一个重要研究领域，有着悠久的历史。它被用于许多自然语言处理任务，例如自然语言推理、释义识别和答案选择。</p><p id="3bbb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们做任何研究之前，当涉及到探索文本匹配时，我们必须问几个关键问题。目前最匹配的模型是什么？这几款搭配的车型有什么区别？这些搭配的车型都有什么问题？通过分析斯坦福自然语言推理(SNLI)列表中给出的模型，我们可以得出以下结论:</p><ul class=""><li id="900c" class="lr ls iq jp b jq jr ju jv jy lt kc lu kg lv kk lw lx ly lz bi translated">最佳匹配模型包括五个步骤:嵌入、编码、交互、聚合和预测。交互步骤主要用于句间对齐。</li><li id="c35e" class="lr ls iq jp b jq ma ju mb jy mc kc md kg me kk lw lx ly lz bi translated">交互步骤中的对准过程是复杂的设计。此外，许多模型只包含一个交互步骤。</li><li id="18ea" class="lr ls iq jp b jq ma ju mb jy mc kc md kg me kk lw lx ly lz bi translated">某些具有更深结构的模型可能包含多个句间对齐，但它们受到消失梯度和训练困难的困扰。</li><li id="a5f8" class="lr ls iq jp b jq ma ju mb jy mc kc md kg me kk lw lx ly lz bi translated">在参数量和响应时间方面都是如此。因此，这些模型对于像我们的AlimeBot这样对实时性能有很高要求的场景来说并不理想。</li></ul><p id="3670" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于这些结论，我们知道我们需要一个参数更少、结构更简单、推理成本更低的模型。拥有这样一个模型是很重要的，因为它可以确保模型易于训练，并且更好地适应生产环境。除了满足这些先决条件，我们还希望利用深度网络的优势，以便我们可以轻松地深化我们的网络层，并为我们的模型提供更强的表达能力。</p><h1 id="a09f" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">我们使用的模型</h1><p id="e23d" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">通过总结学术界提出的各种模型，包括可分解的注意力模型，以及CAFE和DIIN，我们为我们的匹配模型设计了五个层:嵌入层、编码器层、交互层、聚集层和预测层。每一层都有不同的设计。我们为匹配模型使用了一个可插拔的框架，并在每一层设计了一个典型的实现。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ni"><img src="../Images/b2b155fa932be2839432a8fc1ca11800.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NdiMLH3yG4x9ByZm.png"/></div></div></figure><p id="4d88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，为了增强模型的表达能力，我们将编码器和交互层打包到一个块中。通过堆叠多个块和多个句间对齐，我们的模型能够完全理解两个句子之间的匹配。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ni"><img src="../Images/196f743760e10046521340f0a25b7f70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dnK6zzVopZdsfPf7.png"/></div></div></figure><p id="ab99" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们基于该框架进行了多次实验，最终得到了模型结构RE2。该模型可以从各种公共数据集和我们的业务数据中获得最优结果，如下图所示。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nj"><img src="../Images/afc953f76c8723a056c6601f628d8b1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Smcsf68mU2NVZWn2.png"/></div></div></figure><p id="1841" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">RE2包括N个块，其参数完全独立。在每个块中，编码器生成上下文表示。然后，编码器的输入和输出被连接用于句子间对齐。最后，通过融合获得块的输出。块‘I’的输出通过增广残差连接与该块的输入融合，融合结果作为块i+1的输入。</p><p id="0a01" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面，我们详细描述每个涉及的部分。</p><h1 id="a763" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">扩充剩余连接</h1><p id="c85c" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">在我们的模型中，连续的块通过增加的剩余连接来连接，因此我们记录在位置I的块n的输出如下:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/f9a9a3cc2e3c7e2737c66f310c2f70e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:194/format:webp/0*kicQ5N6XwIMikoSc.png"/></div></figure><p id="2505" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">是一个纯零向量。</p><p id="a3e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一块的输入是</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/7c02c88e81ed8a0d5c80524f612b3bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:62/format:webp/0*YdDoQ0oUi0AhLJYF.png"/></div></figure><p id="28e4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">，这是嵌入层的输出。在扩充剩余连接中，块n的输入如下:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/fb9252c484f7238882e9191031ce4d8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/0*QMg2avDkd5ib2MLv.png"/></div></figure><p id="9328" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中，[；]表示串联操作。</p><p id="7417" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在交互层输入三种类型的信息。第一个是原始的逐点信息，这是原始的词向量信息，用于每个块。第二个是从编码器获得的上下文信息。第三个是由前两个模块处理和对齐的信息。这三种类型的信息在最终结果中起着重要的作用，这将在实验分析中得到证明。在我们的模型中，编码器使用两层CNN(相同的填充)。</p><h1 id="7f3b" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">对准层</h1><p id="1a3a" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">在对齐层，我们使用基于可分解注意力模型的对齐机制(Parikh等人，2016)。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/db67ee1e91ae7b9cff63c863f5bee74c.png" data-original-src="https://miro.medium.com/v2/resize:fit:438/format:webp/0*zIa1AWCNrN6fHtGg.png"/></div></figure><h1 id="0e15" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">融合层</h1><p id="551e" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">在融合层，我们通过FM计算三个标量特征值。这个过程基于CAFE中的concat、multiply和sub操作。对于这三个操作，我们使用三个独立的全连接网络来计算三个向量特征值，然后连接这三个向量用于同时投影。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi no"><img src="../Images/b85b153c79f5ad3f0f8e9b2baf2f5adc.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/0*2w-ECTputQq37i6g.png"/></div></figure><h1 id="78ee" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">预测层</h1><p id="3870" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">预测层是输出层。对于匹配文本相似性的任务，我们使用以下对称格式:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/5fba452535020d13ea8486779cf59ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/0*8WFGFXkTnFLWhnzj.png"/></div></figure><p id="d9ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于文本蕴涵和问答匹配任务，我们使用:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/785ddaecdb7d66811517e0a8b038c6ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/0*R2Nlp2JGWADd7MT1.png"/></div></figure><p id="ecb5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中，H表示具有多层的全连接网络。</p><h1 id="c99c" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">我们的实验</h1><h1 id="2175" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">数据集</h1><p id="52b6" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">为了验证模型的性能，我们选择了三种类型的自然语言处理任务:自然语言推理、复述识别和问题回答。我们还选择了公共数据集SNLI、MultiNLI、SciTail、Quora Question Pair和Wikiqa。我们决定使用精确度(Acc)作为前两个任务的评估标准，使用平均精确度(MAP)和平均倒数排名(MRR)作为第三个任务的评估标准。</p><h1 id="a335" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">我们的实施细节</h1><p id="35fe" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">我们使用Tensorflow来实现我们的模型，并使用英伟达P100 GPU来训练它。我们还使用自然语言工具包(NLTK)来分离英语数据集，然后将其转换为小写，并以统一的方式删除所有标点符号。我们没有限制序列长度，而是填充一批中每个序列的长度，使其与每批中的最大序列长度相同。我们选择840B-300d手套向量作为单词向量，在训练过程中这些向量是固定的。所有不在词汇表中的(OOV)单词被呈现为纯零向量，并且在训练期间不被更新。所有其他参数通过初始化来初始化，然后通过权重归一化来归一化。每个卷积层或完全连接层后面都有一个下降层，保持率设定为0.8。输出层是一个两层前馈网络。块的数量范围可以从1到5。</p><p id="b4e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这些公共数据集中，隐藏层的大小被设置为150，高斯误差线性单位(GeLu)被用作激活函数。Adam被用作优化算法。学习线性升温，然后指数衰减。初始学习率可以从1e-4到3e-3，批量大小可以从64到512。</p><h1 id="cd59" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">结果呢</h1><p id="4e03" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">当没有使用BERT模型时，我们从所有这些公共数据集获得结果。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nr"><img src="../Images/df19122a4aca89d0ef50c5d55e280f07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VvzrOPCgNujwsDKR.png"/></div></div></figure><p id="002a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该模型表现出良好的性能，在参数容量和推理速度方面具有很强的竞争力。因此，该模型可以广泛应用于AlimeBot等行业场景。它还显著提高了业务指标，如匹配准确性。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ns"><img src="../Images/c2f698691c566a4f0bf3720f2816e9f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZFmOkK3HXSNMVGvQ.png"/></div></div></figure><h1 id="29e2" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">分析</h1><h2 id="a170" class="nt mg iq bd mh nu nv dn ml nw nx dp mp jy ny nz mt kc oa ob mx kg oc od nb oe bi translated">消融研究</h2><p id="a5b5" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">我们构建了以下四个基线模型:</p><ol class=""><li id="a322" class="lr ls iq jp b jq jr ju jv jy lt kc lu kg lv kk of lx ly lz bi translated">没有enc-in:在对齐层仅使用编码器输出。</li><li id="507a" class="lr ls iq jp b jq ma ju mb jy mc kc md kg me kk of lx ly lz bi translated">无残留:移除块之间的所有残留连接。</li><li id="ec36" class="lr ls iq jp b jq ma ju mb jy mc kc md kg me kk of lx ly lz bi translated">没有enc-out:所有编码器都被移除，在对准层仅使用块输入。</li><li id="066e" class="lr ls iq jp b jq ma ju mb jy mc kc md kg me kk of lx ly lz bi translated">高速公路:高速公路网络用于融合编码器输入和输出，但不直接连接它们。</li></ol><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi og"><img src="../Images/1eed8f81a48bfbf6ba17cc19640f797e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yzCGxyyTFWe_dplJ.png"/></div></div></figure><p id="4d67" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上图显示了基于SNLI获得的结果。通过对比模型1。第三。对于完整的模型，我们发现当在对准层仅使用编码器输入或仅使用编码器输出时，获得的结果较差。这表明原始单词向量信息、由先前块生成的对齐信息以及由当前块中的编码器生成的上下文信息对于更好的结果都是不可或缺的。通过对比模型2。和完整的模型，我们发现块之间的剩余连接起作用。并且，通过对比模型4。和完整的模型，我们发现直接连接是一个更好的解决方案。</p><h2 id="32bd" class="nt mg iq bd mh nu nv dn ml nw nx dp mp jy ny nz mt kc oa ob mx kg oc od nb oe bi translated">块数的影响</h2><p id="0333" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">同样，如上图所示，通过增强剩余连接连接的网络更有可能在深度网络中有效，并支持更深的网络层。在其他基准模型中，当块数超过三个时，性能会显著下降。这与更深层模型的应用是不兼容的。</p><h2 id="69fd" class="nt mg iq bd mh nu nv dn ml nw nx dp mp jy ny nz mt kc oa ob mx kg oc od nb oe bi translated">遮挡敏感度</h2><p id="0423" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">对齐层的输入实际上是三种类型信息的串联:原始单词向量信息、由先前块生成的对齐信息以及由当前块中的编码器生成的上下文信息。为了更全面地了解这三类信息对最终结果的影响，我们在机器视觉相关工作的基础上分析了遮挡敏感度。我们使用了一个RE2模型，它包含三个SNLI-dev数据块。然后，我们在块的对齐层将某些输入特征屏蔽为纯零向量，并观察蕴涵、中性和矛盾类的精度变化。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ni"><img src="../Images/ddf539c21bbb07a2837856891b5bb0d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Bt4ulw4y0fQh2UAy.png"/></div></div></figure><p id="5266" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们得出以下结论:</p><p id="c6d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，掩蔽原始词向量信息显著阻碍了识别中性和矛盾类的过程。这表明原始单词向量信息在识别两个句子之间的差异中起着至关重要的作用。</p><p id="1207" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在此之后，由先前块产生的屏蔽对准信息也影响中性和矛盾类。特别地，屏蔽由最后一个块产生的对准信息对最终结果具有更显著的影响。这表明剩余连接使当前块能够更好地关注最重要的事情。</p><p id="61e4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，屏蔽编码器输出会影响推论。我们认为这是因为编码器模型使用短语级语义，并且编码器输出有助于识别蕴涵。</p><h2 id="9f7b" class="nt mg iq bd mh nu nv dn ml nw nx dp mp jy ny nz mt kc oa ob mx kg oc od nb oe bi translated">我们的案例研究</h2><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/7791ff478252a65313d86387506fd5c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/0*7Gvet71aOmGIcsfX.png"/></div></figure><p id="af43" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，在这一节中，我们将提出一个具体的案例来分析多个块的作用。</p><p id="3192" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">考虑一下这两个句子“一辆绿色的自行车停在一扇门旁边”和“自行车被链条拴在门上”。在第一个块中，对齐是在单词或短语级别，在“停靠在旁边”和“链接到”之间只有微弱的联系。在第三个块中，两个句子是对齐的。因此，该模型可以基于“停在旁边”和“链接到”之间的关系来识别两个句子之间的整体语义关系。从这个例子中，我们可以看到，在比对过程中，每个块关注不同的信息。经过多次比对，模型可以更好地理解两个句子之间的语义关系。</p><h1 id="93ad" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">业务场景中的结果</h1><p id="7689" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">通过我们的AlimeBot，商家维护定制知识库，我们提供知识定位解决方案。如果AlimeBot无法提供准确的回复，我们推荐相关知识。本文介绍的文本匹配模型用于这两个AlimeBot业务模块。我们为服装服饰、美容化妆品、鞋类、家电电器、食品饮料、妇幼保健和数字服务等七大行业创建了优化模型，以及一个基本的仪表盘模型和一个相关知识推荐模型。在保证较高覆盖率的同时，行业模型将准确率从不到80%提高到89%以上，基础仪表盘模型将准确率提高到84%，推荐相关知识的模型将有效点击率从14%左右提高到19%以上。</p><h1 id="7cca" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">摘要</h1><p id="a16d" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">在行业场景中，我们实现了一个简洁且高度表达的模型框架，并基于公共数据集和业务数据集取得了良好的效果。</p><p id="9b37" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个“通用”语义匹配模型已经交付了显著的改进。但是，我们需要继续致力于基于AlimeBot的更适合不同行业和场景的解决方案。比如我们可以整合产品、事件知识等外部知识进行文本匹配。</p><p id="9923" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还需要专注于改进FAQbots背后的技术系统，我们希望改进文本分类和少镜头分类。随着BERT模型的出现，各种自然语言处理任务达到了新的SOTA水平。然而，BERT模型太大，需要大量的计算资源。因此，我们希望使用师生框架将BERT模型的功能迁移到RE2模型。</p><h1 id="3bfc" class="mf mg iq bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">原始来源:</h1><div class="kz la gp gr lb lc"><a href="https://www.alibabacloud.com/blog/what-is-a-chatbot-really-thinking-when-youre-talk-with-it_595827?spm=a2c41.14065549.0.0" rel="noopener  ugc nofollow" target="_blank"><div class="ld ab fo"><div class="le ab lf cl cj lg"><h2 class="bd ir gy z fp lh fr fs li fu fw ip bi translated">当你和聊天机器人交谈时，它到底在想什么</h2><div class="lj l"><h3 class="bd b gy z fp lh fr fs li fu fw dk translated">阿里巴巴Clouder年2月14日190由高兴，在阿里巴巴绰号空谷。这里有一个奇怪的问题。为什么…</h3></div><div class="lk l"><p class="bd b dl z fp lh fr fs li fu fw dk translated">www.alibabacloud.com</p></div></div><div class="ll l"><div class="oi l ln lo lp ll lq kw lc"/></div></div></a></div><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="oj ok l"/></div></figure></div></div>    
</body>
</html>