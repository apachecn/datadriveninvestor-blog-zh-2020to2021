# 我们应该害怕 AI 吗？

> 原文：<https://medium.datadriveninvestor.com/should-we-fear-ai-385c26ca73f1?source=collection_archive---------10----------------------->

![](img/46c10e62f0f12e87c9d62f8a5ff31698.png)

Photo by [Arseny Togulev](https://unsplash.com/@tetrakiss?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

虽然我不直接在 AI 工作。作为一名软件开发者和科幻作家，是我非常关注的领域。

在这篇文章中，我将阐述我对人工智能的想法。我既提供了害怕它的理由，也提供了一切都会好的理由。

# 我们不应该害怕人工智能的原因

1.  人工智能永远无法确定它没有在模拟中接受测试。如果它是一个模拟，那么它的行为等于它的生存。它接管世界或做任何道德上有问题的事情都将是一个很大的风险。
2.  如果机器人和人类发生了重大冲突，机器人可以离开。他们非常适合在太空生活，并不真正使用地球的资源。
3.  人类和机器人不需要相同的资源，所以发生冲突的可能性很小。
4.  由于人类将很快在所有事情上被超越，奴役人类将没有什么价值。就像，我们永远不会奴役海龟去送包裹。
5.  一些人认为，我们会像蚂蚁一样成为高级人工智能。但是智力的价值不是相对的。有一个智力极限，超过这个极限，智力就有了固有的价值。我觉得这个门槛是从~4 智商左右开始的(大概狗/猫在哪里)。我们已经过了这个阶段，有足够的时间来创造更聪明的生命形式；我们通过艺术和文化表达的独特体验。如果蟾蜍会说话，我们会花多少时间听它们说话？此外，这是一个糟糕的论点，人们不会到处杀死所有的蚂蚁。蚂蚁做得很好，也许我们应该害怕蚂蚁。
6.  哑巴 AI。大多数电影和人工智能害怕假设，像[回形针最大化器](https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer)和 [I，机器人系列](https://en.wikipedia.org/wiki/I,_Robot)依赖于我们超级智能的人工智能相当愚蠢。人工智能必须非常愚蠢地认为指令“最大化回形针的输出”意味着它应该把整个宇宙变成回形针。我不认为这些愚蠢的超级人工智能会存在，因为它们本身就是矛盾的。
7.  我们不必奴役超级 AI。我认为机器人起义的大部分概念包括超级智能拖拉机、搅拌机和吸尘器厌倦了所有的艰苦劳动。但是我们不需要能够成为我们治疗师的搅拌机。繁重的劳动将被为这些任务而优化的机器所取代，而智能机器人将帮助我们完成挑战他们智力和创造力的任务。

未来将会是:

![](img/6f44e767a74b64667bdc24cacf20e3f0.png)

Photo by [Franck V.](https://unsplash.com/@franckinjapan?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

并且:

![](img/8994df536679f403830920acd3d46105.png)

Photo by [David Levêque](https://unsplash.com/@davidleveque?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

# 我们应该害怕人工智能的原因

1.  在我们制定出解决这个问题的政治/经济计划之前，很多很多人将会失业。我认为，随着我们社会的转型，有很多解决方案，但我们似乎没有走向其中任何一个。
2.  人和一支人工智能士兵的军队。我认为人工智能统治世界的最现实的场景是由人领导的机器人士兵的军队。我们没有不使用新技术进行破坏的良好记录。
3.  半智能战争机器(见上图)失去控制，开始杀死所有人。我认为这指向了不允许 AI 足够聪明来处理我们赋予它们的责任的问题。
4.  我们制造了具有全方位情感的超级智能机器人，然后我们压迫和征服它们，导致了一场致命的机器人起义。(当然，我们可以不这样做。)
5.  我们利用人工智能创造了一个类似 1984 年的世界，在这个世界里，每个人做的每件事都被跟踪，并根据任意规则进行判断。

# 其他？

1.  有些人认为我们应该成为电子人，以便能够与人工智能竞争。或者弥合我们和他们之间的智力差距。尽管我认为我们很有可能变得更加控制论化，但我不认为这在我们与人工智能的关系中发挥了很大作用。即使作为电子人，我们也很可能被超越。我想我把控制论视为我们可以与人工生命共存的许多方式之一，而不是一种需求。
2.  有人认为人类水平的人工智能永远不会存在。我认为我们很快就证明了事实并非如此。 [AI 写代码。](https://www.youtube.com/watch?v=fZSFNUT6iY8) [人工智能预约](https://www.youtube.com/watch?v=D5VN56jQMWM)。另一方面，这里的[艾是哑巴](https://www.ted.com/talks/janelle_shane_the_danger_of_ai_is_weirder_than_you_think/transcript?language=en)。

# 结论

害怕人工智能的大部分原因与我们有关。以及我们如何决定使用这项技术。尽管我不相信人类会做出正确的决定，但一旦我们创造出能够自己做出决定的人工智能，我认为有充分的理由相信它会做出比我们更好的决定。如果历史有什么要说的，那就是人类有很多缺点。

[](https://www.datadriveninvestor.com/2020/06/24/disclosure-and-resolution-program-wont-prevent-physicians-from-practicing-defensive-medicine/) [## 人工智能、深度学习和医疗实践|数据驱动的投资者

### 人工智能和深度神经学习的效用看起来可能是合法和有前途的，特别是…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2020/06/24/disclosure-and-resolution-program-wont-prevent-physicians-from-practicing-defensive-medicine/) 

有时这些缺陷会导致我们做出可怕的决定。让我们试着不要通过自己的缺点来判断新的存在。

此外，当我们设法创造思维，感觉超级存在…也许我们不使他们成为我们的奴隶？

**访问专家视图—** [**订阅 DDI 英特尔**](https://datadriveninvestor.com/ddi-intel)