<html>
<head>
<title>The Infinite Art Machine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无限艺术机器</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/the-infinite-art-machine-3a2decab85d9?source=collection_archive---------3-----------------------#2020-02-15">https://medium.datadriveninvestor.com/the-infinite-art-machine-3a2decab85d9?source=collection_archive---------3-----------------------#2020-02-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jq jr js jt gh gi paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="gh gi gj"><img src="../Images/66c7cd8364f3ddbba95fb5552d100e54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pdSCMD6SOkoW2YzSsa5wOA.jpeg"/></div></div><figcaption class="ka kb gj gh gi kc kd bd b be z dk"><a class="ae ke" href="https://c4.wallpaperflare.com/wallpaper/579/612/913/space-simple-wallpaper-preview.jpg" rel="noopener ugc nofollow" target="_blank">https://c4.wallpaperflare.com/wallpaper/579/612/913/space-simple-wallpaper-preview.jpg</a></figcaption></figure><p id="ad80" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi ld translated">自古以来，人类就试图创造。我们从洞穴绘画开始，现在我们看着来自全球的照片，这些照片都是在一个闪亮的受热的沙子表面上拍摄的。数以千计的博物馆存在，每年花费数十亿美元来迎合我们对我们称之为艺术的新颖图案的渴望。</p><div class="lm ln gp gr lo lp"><a href="https://www.datadriveninvestor.com/2019/01/23/deep-learning-explained-in-7-steps/" rel="noopener  ugc nofollow" target="_blank"><div class="lq ab fo"><div class="lr ab ls cl cj lt"><h2 class="bd iu gy z fp lu fr fs lv fu fw is bi translated">深度学习用7个步骤解释-更新|数据驱动的投资者</h2><div class="lw l"><h3 class="bd b gy z fp lu fr fs lv fu fw dk translated">在深度学习的帮助下，自动驾驶汽车、Alexa、医学成像-小工具正在我们周围变得超级智能…</h3></div><div class="lx l"><p class="bd b dl z fp lu fr fs lv fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="ly l"><div class="lz l ma mb mc ly md jy lp"/></div></div></a></div><blockquote class="me mf mg"><p id="c5f3" class="kf kg mh kh b ki kj kk kl km kn ko kp mi kr ks kt mj kv kw kx mk kz la lb lc im bi translated">但是，如果我们能从伟大的大师和不那么伟大的大师身上学习呢？如果你，在把你的想法变成现实方面有点平庸的天赋，有能力创造一个无限的艺术机器会怎么样？</p></blockquote><p id="e1e8" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">正如任何试图赋予计算机思考能力的应用一样，我们来看看深度学习的概念。在这篇文章中，我们将尝试使用一种特殊类型的深度神经网络架构来完成上述任务，这种架构称为DCGAN或深度卷积GAN。参考文献部分提到了开始这一工作的论文。[ <a class="ae ke" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank"> 1 </a></p><p id="32bf" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">由于本教程旨在跟随，所以尝试在进行过程中编写代码。注意，你需要一个GPU来运行这个程序，所以如果你没有，你可以使用Google Colab[Google it；)].</p><h1 id="eef5" class="ml mm it bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated"><strong class="ak">第一阶段:库、环境和数据集</strong></h1><p id="4b75" class="pw-post-body-paragraph kf kg it kh b ki nj kk kl km nk ko kp kq nl ks kt ku nm kw kx ky nn la lb lc im bi translated">我们首先导入所有需要的库。这段代码是使用脸书的Pytorch库编写的，因为它更好地利用了GPU。</p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="f924" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">很明显，我们需要安装库，为此，可以在您的终端版本上运行以下命令。</p><blockquote class="me mf mg"><p id="5aa6" class="kf kg mh kh b ki kj kk kl km kn ko kp mi kr ks kt mj kv kw kx mk kz la lb lc im bi translated">pip3安装matplotlib火炬火炬视觉数字枕</p></blockquote><p id="89ac" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于那些使用环境的人，请确保你是对的。</p><p id="2176" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">至于数据集，我用过我朋友的美术作品。这个数据集的所有功劳都归他。请一定去看看他的作品，我真的很喜欢它们。</p><figure class="no np nq nr gt jt gh gi paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="gh gi nu"><img src="../Images/371063b3c269239ec979413a31cb530b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6_-RDyz1WVwT1Z75_kMWXg.png"/></div></div><figcaption class="ka kb gj gh gi kc kd bd b be z dk"><a class="ae ke" href="https://instagram.com/cinemcraft?igshid=705j03y371sq" rel="noopener ugc nofollow" target="_blank"><em class="nv">https://instagram.com/cinemcraft</em></a></figcaption></figure><p id="b59a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在，我们设置本教程剩余部分所需的参数。</p><ul class=""><li id="6c28" class="nw nx it kh b ki kj km kn kq ny ku nz ky oa lc ob oc od oe bi translated">种子:允许再现性</li><li id="dac8" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">dataroot:根目录(根据需要进行更改)</li><li id="0d5d" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">工作线程:数据加载器的线程数</li><li id="3dac" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">nc:输入中的通道数</li><li id="c1e7" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">nz:发电机输入的大小</li><li id="f7a0" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">ngf:生成器中特征映射的大小</li><li id="0c47" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">ndf:鉴别器中特征图的大小</li><li id="71a3" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">max_epochs=5</li><li id="402d" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">学习率</li><li id="2ad6" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">beta1:我们优化器的参数</li><li id="e741" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">ngpu:我们正在使用的gpu数量</li></ul><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="7db0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们现在必须加载数据并对其进行预处理以适应我们的模型。</p><p id="ecf0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们首先从文件夹中加载数据，将其调整到我们之前决定的图像大小，裁剪它并将其转换为张量。</p><blockquote class="me mf mg"><p id="314c" class="kf kg mh kh b ki kj kk kl km kn ko kp mi kr ks kt mj kv kw kx mk kz la lb lc im bi translated">张量是在神经网络中使用的数据表示。</p></blockquote><p id="a8b1" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后我们将图像标准化。这是一个图像处理步骤，用来实现图像像素范围的一致性。它将所有像素亮度映射到给定范围内的值。这使得神经网络能够更快更好地从这些图像中学习。</p><p id="5d86" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，我们批量加载整个数据集，也就是说，我们将整个数据分割成块，并逐个处理这些块，否则它们将无法放入内存。</p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="5b8e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们现在决定在哪里运行我们的模型。如果您使用的是cpu，请将设备更改为“CPU”。由于我有一个GPU，我正在为这个项目使用，我使用的参数' cuda '。</p><p id="56c7" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">之后，我们将数据集作为小批量加载，并绘制它们以查看它们是否正确加载。并不是说我们将批处理发送到GPU，而是必须将它们发送回CPU进行显示。</p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="6f9c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们得到了下面的图像:</p><figure class="no np nq nr gt jt gh gi paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="gh gi ok"><img src="../Images/101845627aa89820a1ac06fa35734619.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*1A4Lp4Y81keotTxTparG0A.png"/></div></div></figure><p id="6b6e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们现在转到特定的层，并尝试初始化其中的权重。这是通过下面这段代码完成的。</p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><h1 id="1538" class="ml mm it bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated"><strong class="ak">第二阶段:架构</strong></h1><p id="83de" class="pw-post-body-paragraph kf kg it kh b ki nj kk kl km nk ko kp kq nl ks kt ku nm kw kx ky nn la lb lc im bi translated">现在，对于架构，使用生成对抗神经网络(GAN)架构。简单来说，它分为两部分——生成器和鉴别器。</p><blockquote class="me mf mg"><p id="f74a" class="kf kg mh kh b ki kj kk kl km kn ko kp mi kr ks kt mj kv kw kx mk kz la lb lc im bi translated">生成器做的工作是试图创造艺术，而鉴别者试图证明生成器是错的。</p></blockquote><p id="bbf4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这一过程一直重复，直到作品与原作几乎无法区分，鉴别者也无法证明它是错误的。本文首次发表于[ <a class="ae ke" href="https://arxiv.org/pdf/1406.2661.pdf" rel="noopener ugc nofollow" target="_blank"> 2 </a> ]。</p><p id="ac81" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们首先创建发电机模型。请注意，本文中定义了发生器和鉴别器的架构。</p><figure class="no np nq nr gt jt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/b7d7833a591c8e970bc6d808ff5ea49f.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*j5V4TEP2BrrX0j5pzpvTew.png"/></div><figcaption class="ka kb gj gh gi kc kd bd b be z dk">The GAN Generator Architecture</figcaption></figure><p id="b70d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们在Pytorch中使用顺序表示，这允许我们一个接一个地传递层。</p><ul class=""><li id="072c" class="nw nx it kh b ki kj km kn kq ny ku nz ky oa lc ob oc od oe bi translated">ConvTranspose2d是一种二维转置操作，我们将输入传递给卷积运算。转置是一个学习参数。</li><li id="6d7e" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">BatchNorm2d是一种提高网络学习速率的技术。由于各层之间的参数不同，出现了一种称为协变量偏移的现象，这种现象阻碍了学习。BatchNorm2d减少了这种影响。</li><li id="1bb0" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">ReLU或整流线性单元是深度学习历史上的里程碑之一。这是一个简单的数学函数(Picewise线性),如果输入为正，则输出输入，否则输出零。这使得网络更容易训练，并在神经网络的结构中引入了非线性。这被称为激活函数。</li><li id="f264" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">现在轮到坦了。Tanh也是和ReLU一样的另一个激活功能。DCGan论文推荐使用这一层作为发生器的最后一层，而不是常规的ReLU。负权重被强映射，零输入被映射到零附近。这又使得网络更容易训练。</li></ul><p id="951e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">请注意，偏差函数用于向输出添加可学习的偏差，以获得更好的表示。</p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="5bd2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在我们已经定义了架构，我们把它传递给GPU。还使用了一个小助手函数来处理多个GPU。<br/>然后，我们应用权重函数，将所有权重转换为平均值0和标准偏差0.2。<br/>转发功能允许我们进入网络的下一层。</p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><figure class="no np nq nr gt jt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/33425234c646216fb19e3dcbbd743393.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*jGEeHqntH62zwx2cKw5LNA.png"/></div><figcaption class="ka kb gj gh gi kc kd bd b be z dk">The GAN Discriminator Architecture</figcaption></figure><p id="427c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，我们尝试定义鉴别器架构。这里的新术语如下。</p><ul class=""><li id="33e2" class="nw nx it kh b ki kj km kn kq ny ku nz ky oa lc ob oc od oe bi translated">LeakyReLU:这是对ReLU函数的一个修改，与ReLU相比，它赋予一个小的正值(例如:0.01)，而不是将值设置为0。</li><li id="c637" class="nw nx it kh b ki of km og kq oh ku oi ky oj lc ob oc od oe bi translated">Sigmoid:深度学习的另一个里程碑。这是另一个数学函数，叫做逻辑sigmoid。它有助于引入非线性，并将输出映射到0和1之间的真实值。</li></ul><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="6fa2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们现在遵循与生成器相同的步骤。</p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="c26a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们必须选择一个损失函数。这将允许我们的模型比较输出，并确定它们之间的差异。我们使用一种称为二元交叉熵损失的损失类型。因为我们只对真实图像和虚假图像进行分类，所以我们可以使用这种类型的损失。BCELoss接收我们之前定义的Sigmoid函数的输出作为输入。<br/>然后，我们创建一个随机噪声作为生成器必须转换的输入。<br/>我们使用Adam优化器。(这是另一个讨论的话题，更多信息可以在<a class="ae ke" href="https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c" rel="noopener" target="_blank">这里</a>找到)。</p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="84a7" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们现在为小批量处理的全部数据创建训练循环，并运行特定数量的时期。</p><h1 id="0518" class="ml mm it bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated">第三阶段:总结</h1><p id="2aa1" class="pw-post-body-paragraph kf kg it kh b ki nj kk kl km nk ko kp kq nl ks kt ku nm kw kx ky nn la lb lc im bi translated">这可能需要一些阅读来理解，因此涉及的步骤概述如下。</p><h2 id="2156" class="on mm it bd mn oo op dn mr oq or dp mv kq os ot mz ku ou ov nd ky ow ox nh oy bi translated">第1部分—鉴别器</h2><p id="322b" class="pw-post-body-paragraph kf kg it kh b ki nj kk kl km nk ko kp kq nl ks kt ku nm kw kx ky nn la lb lc im bi translated">1.我们必须更新鉴别器网络并最大化函数log(D(x)) + log(1 — D(G(z))。这意味着我们需要最大化鉴频器的输出。<br/> 2。我们将所有现有的梯度初始化为零<br/> 3。我们将当前批次连同标签一起发送到GPU<br/>4。我们将真正的批次通过鉴别器，并计算梯度<br/> 5。我们反向通过鉴别器并计算梯度<br/> 6。我们现在采取的是随机噪声<br/> 7的假批次。我们尝试用鉴别器<br/> 8对假货批次进行分类。我们将真假批次的梯度相加<br/> 9。我们在优化函数中采取了一个步骤</p><h2 id="9bb6" class="on mm it bd mn oo op dn mr oq or dp mv kq os ot mz ku ou ov nd ky ow ox nh oy bi translated">第2部分—发电机</h2><p id="bc39" class="pw-post-body-paragraph kf kg it kh b ki nj kk kl km nk ko kp kq nl ks kt ku nm kw kx ky nn la lb lc im bi translated">1.我们必须最大化函数log(D(G(z))。这将使我们的生成器变得更好，创建更真实的图像。<br/> 2。我们再次将所有现有梯度初始化为零<br/> 3。我们使用假标签作为发电机<br/> 4的真标签。我们获取输出并计算发电机损耗<br/> 5。然后，我们执行一个向后传递<br/> 6。我们在优化函数中采取了一个步骤</p><h2 id="f261" class="on mm it bd mn oo op dn mr oq or dp mv kq os ot mz ku ou ov nd ky ow ox nh oy bi translated">第3部分—输出</h2><p id="239b" class="pw-post-body-paragraph kf kg it kh b ki nj kk kl km nk ko kp kq nl ks kt ku nm kw kx ky nn la lb lc im bi translated">这是可选的，但将允许我们绘制我们的损失，并看到我们的训练进度。我们使用一个助手函数来创建一个图像网格，当它们在网络中传播时，将它们保存到一个列表中，这样我们就可以在稍后阶段绘制动画。</p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="8ea3" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">如果需要，我们现在可以画出发生器和鉴频器的损耗。运行该位留给读者。</p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="2670" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">由于看到我们的网络学习看起来真的很酷，我们使用一个小的助手函数将我们存储的权重绘制成一个很酷的动画并保存它。试试看。</p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="ns nt l"/></div></figure><figure class="no np nq nr gt jt gh gi paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="gh gi oz"><img src="../Images/20c5135d75bcf745c0e721640e87df34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b6o0M9h3uULnvXbcLNm5wg.png"/></div></div></figure><p id="1bf9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu"> Aaaaanddd…我们完成了:)</strong> <br/>祝贺那些坚持到最后的勇敢的灵魂们。<br/>既然你远道而来，这里有<a class="ae ke" href="https://www.thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">招待</a>。该页面使用GAN(与我们自己的不同)在您每次打开它时生成一个新的面孔。顾名思义，这张脸真的不存在，是由一个GAN生成的。</p><h2 id="bde1" class="on mm it bd mn oo op dn mr oq or dp mv kq os ot mz ku ou ov nd ky ow ox nh oy bi translated">谢谢大家！</h2><h2 id="6bc7" class="on mm it bd mn oo op dn mr oq or dp mv kq os ot mz ku ou ov nd ky ow ox nh oy bi translated"><strong class="ak">参考文献</strong></h2><p id="b1d0" class="pw-post-body-paragraph kf kg it kh b ki nj kk kl km nk ko kp kq nl ks kt ku nm kw kx ky nn la lb lc im bi translated">1)拉德福德大学、梅斯大学和钦塔拉大学(2015年)。深度卷积生成对抗网络的无监督表示学习。arXiv预印本arXiv:1511.06434。</p><p id="e9fa" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">2) Goodfellow，I .、Pouget-Abadie，j .、Mirza，m .、Xu，b .、Warde-Farley，d .、Ozair，s .、… &amp; Bengio，Y. (2014年)。生成对抗网络。神经信息处理系统进展(第2672-2680页)。</p><p id="2eed" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">3 ) <a class="ae ke" href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" rel="noopener ugc nofollow" target="_blank"> PyTorch DCGAN教程</a></p><figure class="no np nq nr gt jt"><div class="bz fp l di"><div class="pa nt l"/></div></figure></div></div>    
</body>
</html>