<html>
<head>
<title>A Gentle Introduction To Activation Functions in Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习中激活函数的温和介绍</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/a-gentle-introduction-to-activation-functions-in-deep-learning-5d5402fcb033?source=collection_archive---------3-----------------------#2020-02-03">https://medium.datadriveninvestor.com/a-gentle-introduction-to-activation-functions-in-deep-learning-5d5402fcb033?source=collection_archive---------3-----------------------#2020-02-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/16c21ab227ac83df56db42b883edcf40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3tLHUJWOjUrL5aZlWo56yQ.jpeg"/></div></div></figure><h2 id="8081" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><strong class="ak">简介</strong></h2><p id="dba5" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le kh lf lg lh kl li lj lk kp ll lm ln lo ij bi translated">当你开始深度学习时，你肯定会遇到术语<strong class="kw ir"> <em class="lp">激活函数</em> </strong>，也称为神经传递函数。<br/>在这篇博客中，我将解释什么是激活函数，以及为什么在深度学习模型中使用它们。</p><p id="8e04" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated"><strong class="kw ir">注:</strong> <em class="lp">我假设你对神经网络有基本的了解。</em></p><p id="0312" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">机器学习/深度学习算法的目标是识别数据中的模式。从数学的角度来看，这种模式可以被认为是一种函数。机器学习算法在给定数据中逼近这一基础函数的能力使得这种算法非常强大。<br/>对该函数或模式的识别使得模型预测新数据的输出成为可能。</p><p id="b885" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">作为数据基础的模式/功能可以是简单的，例如线性关系，有时也可以是复杂的，例如非线性关系。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/01c2911b27f3d1fae58563ac857e4e74.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*GeyQBtPVgcurFjY1LQdlxw.jpeg"/></div></figure><h2 id="f856" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><strong class="ak">一个简单的人工神经元</strong></h2><p id="c7ea" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le kh lf lg lh kl li lj lk kp ll lm ln lo ij bi translated">深度学习模型通常由许多分层堆叠的神经元组成。为了简单起见，让我们考虑单个神经元。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/8e82ebc4384a53a227a036fe94f4d118.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*Jsm0NBsPuVUKQvEjdpUOpg.png"/></div></figure><p id="a95b" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">神经元执行的操作基本上包括线性的乘法和加法操作，并产生输出。<br/>在这之后，一个激活函数被应用来产生最终的出神经元。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/58934f2e1ca87e5a5cdfd08e9ad8b284.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/0*Z5mWm24o4cDVZ5UI.png"/></div></figure><p id="676c" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">如果不应用激活函数，上面的函数就像一个线性函数，将输入映射到输出。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/cae439f15784a15ada2a9849c15d6488.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/0*Y3b42mQ4XMOglknn.png"/></div></figure><p id="ddd2" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">这使得神经元只能近似线性函数。因此，模型无法识别数据中的复杂模式。</p><div class="md me gp gr mf mg"><a href="https://www.datadriveninvestor.com/2019/01/23/deep-learning-explained-in-7-steps/" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd ir gy z fp ml fr fs mm fu fw ip bi translated">深度学习用7个步骤解释-更新|数据驱动的投资者</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">在深度学习的帮助下，自动驾驶汽车、Alexa、医学成像-小工具正在我们周围变得超级智能…</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu jw mg"/></div></div></a></div><h1 id="4ac8" class="mv jz iq bd ka mw mx my kd mz na nb kg nc nd ne kk nf ng nh ko ni nj nk ks nl bi translated">为什么需要激活功能？</h1><p id="da30" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le kh lf lg lh kl li lj lk kp ll lm ln lo ij bi translated">为了使神经网络逼近非线性或复杂函数，必须有一种方法将非线性属性添加到结果的计算中。<br/>使用激活函数的目的是将非线性引入模型。这使得深度学习模型可以在数据中找到复杂的模式。</p><h2 id="9871" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">任何非线性函数都可以用作激活函数吗？</h2><p id="488d" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le kh lf lg lh kl li lj lk kp ll lm ln lo ij bi translated">不，在函数可以被认为是深度学习模型的良好候选之前，它应该具有以下属性:</p><ol class=""><li id="fa03" class="nm nn iq kw b kx lq lb lr kh no kl np kp nq lo nr ns nt nu bi translated"><strong class="kw ir">非线性</strong> <br/>这需要在模型中引入非线性。</li><li id="6012" class="nm nn iq kw b kx nv lb nw kh nx kl ny kp nz lo nr ns nt nu bi translated"><strong class="kw ir">单调<br/> </strong>要么完全不增，要么完全不减的函数。</li><li id="99cf" class="nm nn iq kw b kx nv lb nw kh nx kl ny kp nz lo nr ns nt nu bi translated"><strong class="kw ir">可微分<br/> </strong>深度学习算法通过一种叫做<a class="ae oa" href="https://en.wikipedia.org/wiki/Backpropagation" rel="noopener ugc nofollow" target="_blank">反向传播</a>的算法来更新它们的权重。当使用的激活函数是可微的时，该算法可以工作。即它的导数可以计算。</li></ol><h1 id="b419" class="mv jz iq bd ka mw mx my kd mz na nb kg nc nd ne kk nf ng nh ko ni nj nk ks nl bi translated">激活功能的类型。</h1><p id="efbb" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le kh lf lg lh kl li lj lk kp ll lm ln lo ij bi translated">最有用的激活函数是非线性函数。下面列出了常见的激活功能。</p><h2 id="11c4" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><strong class="ak"> 1。Tahn或双曲正切函数</strong></h2><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/7a621e583e8ac8dad5a551186ed8e0e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/0*2Ltoo51YGOjC4Dlo"/></div></figure><p id="63fa" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">该函数的上限为1，下限为-1，因此它将产生范围在1到-1之间的输出。</p><h2 id="8df8" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">2.乙状结肠或逻辑函数</h2><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/8770db22f352e85cec37bd1e7f2558bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/0*8qWWTH6z50LP28jd.png"/></div></figure><p id="dfa8" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">该函数输出(0，1)之间的值，并且以0为中心。</p><h2 id="6f82" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">3.Relu ( <strong class="ak">整流线性单元)</strong></h2><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi od"><img src="../Images/cce68757056ce1935d0ed7aa023395dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/0*FVQSRNxLvditSAqD.png"/></div></figure><p id="81be" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">该函数产生0到无穷大之间的值。即它只输出正值。</p><h2 id="1d4c" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">4.泄漏Relu</h2><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/537b955f97025e46df0f587ab44af78a.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/0*jdLsPwZWmhZNPtd1.png"/></div></figure><p id="6b1c" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">这是<strong class="kw ir"> <em class="lp"> Relu的变种。</em> </strong>与Relu不同，<strong class="kw ir"> <em class="lp">漏Relu </em> </strong>允许更多的输出值。<br/>输出0.01到无穷大之间的值</p><h2 id="34ec" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">5.Softmax</h2><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi of"><img src="../Images/e5ba9c698af51d8b8bf692b915b2cca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/0*i20dHyZAjUFzsL_s"/></div></figure><p id="2063" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">该函数主要用于多类预测问题，它输出给定输入的类概率。</p><h1 id="02d7" class="mv jz iq bd ka mw mx my kd mz na nb kg nc nd ne kk nf ng nh ko ni nj nk ks nl bi translated"><strong class="ak">我应该使用哪个激活功能？</strong></h1><p id="d1ba" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le kh lf lg lh kl li lj lk kp ll lm ln lo ij bi translated">激活函数有优点也有缺点，这取决于它们允许模型学习用于泛化的特征的程度。</p><p id="dd06" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">激活函数的选择也取决于你要解决的问题。</p><ul class=""><li id="c677" class="nm nn iq kw b kx lq lb lr kh no kl np kp nq lo og ns nt nu bi translated"><strong class="kw ir"> Relu </strong>通常用于隐藏层，而<strong class="kw ir"> sigmoid / softmax </strong>通常用于输出层。<br/> <strong class="kw ir"> <em class="lp"> sigmoid </em> </strong>用于二分类问题<strong class="kw ir"> <em class="lp"> softmax </em> </strong>用于多类分类问题。</li><li id="7876" class="nm nn iq kw b kx nv lb nw kh nx kl ny kp nz lo og ns nt nu bi translated"><strong class="kw ir">由于<strong class="kw ir">死神经元</strong>问题，Tanh </strong>大部分时间被避免。</li><li id="9bdf" class="nm nn iq kw b kx nv lb nw kh nx kl ny kp nz lo og ns nt nu bi translated"><strong class="kw ir"> Sigmoid </strong>和<strong class="kw ir"> Tanh </strong>函数有时会由于消失梯度和死神经元问题而被避免。</li><li id="6f40" class="nm nn iq kw b kx nv lb nw kh nx kl ny kp nz lo og ns nt nu bi translated">如果我们在网络中遇到死亡神经元的<strong class="kw ir">情况，那么<strong class="kw ir"> leaky ReLU </strong>函数是最佳选择。</strong></li></ul><p id="0f44" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated"><strong class="kw ir">资源</strong></p><ul class=""><li id="bb42" class="nm nn iq kw b kx lq lb lr kh no kl np kp nq lo og ns nt nu bi translated"><a class="ae oa" href="https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/</a></li><li id="d78a" class="nm nn iq kw b kx nv lb nw kh nx kl ny kp nz lo og ns nt nu bi translated"><a class="ae oa" href="http://www.datastuff.tech/machine-learning/why-do-neural-networks-need-an-activation-function/" rel="noopener ugc nofollow" target="_blank">http://www . data stuff . tech/machine-learning/why-do-neural-networks-neural-needle-an-activation-function/</a></li><li id="b7b8" class="nm nn iq kw b kx nv lb nw kh nx kl ny kp nz lo og ns nt nu bi translated">https://en.wikipedia.org/wiki/Activation_function<a class="ae oa" href="https://en.wikipedia.org/wiki/Activation_function" rel="noopener ugc nofollow" target="_blank"/></li><li id="3c24" class="nm nn iq kw b kx nv lb nw kh nx kl ny kp nz lo og ns nt nu bi translated"><a class="ae oa" href="https://medium.com/@abhigoku10/activation-functions-and-its-types-in-artifical-neural-network-14511f3080a8" rel="noopener">https://medium . com/@ abhi Goku 10/activation-functions-and-its-types-in-artificial-neural-network-14511 f 3080 A8</a></li></ul><p id="5720" class="pw-post-body-paragraph ku kv iq kw b kx lq kz la lb lr ld le kh ls lg lh kl lt lj lk kp lu lm ln lo ij bi translated">在本文中，您了解了什么是激活函数，以及为什么在深度学习模型中需要激活函数，并且还了解了常用的激活函数。我希望这篇文章达到了向您介绍激活函数的目的。</p><figure class="lw lx ly lz gt jr"><div class="bz fp l di"><div class="oh oi l"/></div></figure></div></div>    
</body>
</html>