<html>
<head>
<title>Neural Style Transfer (AI in art) with Keras and TF2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经风格转移(人工智能在艺术中)与克拉斯和TF2</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/neural-style-transfer-ai-in-art-with-keras-and-tf2-34392aeaeb39?source=collection_archive---------9-----------------------#2020-04-01">https://medium.datadriveninvestor.com/neural-style-transfer-ai-in-art-with-keras-and-tf2-34392aeaeb39?source=collection_archive---------9-----------------------#2020-04-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="ff22" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">考虑到艺术在过去几年里在不同领域取得的进步，人工智能在艺术中是不可避免的。我们在人工智能方面取得的一切总是让我惊叹不已，但深入了解这些组件如何产生像艺术中的人工智能这样的想法，比想法本身更令人惊叹。</p><p id="5b71" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇文章中，我想以最简单的方式强调如何实现风格转换，这是一个在艺术中使用人工智能来实现一些惊人的美丽效果的概念。</p><h2 id="1dbf" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">内容</h2><ol class=""><li id="1235" class="le lf iq jp b jq lg ju lh jy li kc lj kg lk kk ll lm ln lo bi translated">什么是风格转移？</li><li id="e2e7" class="le lf iq jp b jq lp ju lq jy lr kc ls kg lt kk ll lm ln lo bi translated">我们将使用什么？</li><li id="bac2" class="le lf iq jp b jq lp ju lq jy lr kc ls kg lt kk ll lm ln lo bi translated">我们从哪里开始？</li><li id="4b34" class="le lf iq jp b jq lp ju lq jy lr kc ls kg lt kk ll lm ln lo bi translated">深度学习模型</li><li id="f3a7" class="le lf iq jp b jq lp ju lq jy lr kc ls kg lt kk ll lm ln lo bi translated">损失函数</li><li id="13f3" class="le lf iq jp b jq lp ju lq jy lr kc ls kg lt kk ll lm ln lo bi translated">计算渐变</li><li id="b3b8" class="le lf iq jp b jq lp ju lq jy lr kc ls kg lt kk ll lm ln lo bi translated">最佳化</li><li id="27c5" class="le lf iq jp b jq lp ju lq jy lr kc ls kg lt kk ll lm ln lo bi translated">对结果图像进行反向预处理</li><li id="608c" class="le lf iq jp b jq lp ju lq jy lr kc ls kg lt kk ll lm ln lo bi translated">来源和信用</li></ol><h2 id="4884" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated"><span class="l lu lv lw bm lx ly lz ma mb di"> W </span>什么是风格转移？</h2><p id="b3eb" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">风格转移是一个基本上在另一个图像上采用一个图像的视觉风格的概念。让我们举一个经典的例子，一张<a class="ae mf" href="https://en.wikipedia.org/wiki/Katsushika_Hokusai" rel="noopener ugc nofollow" target="_blank">葛饰北斋</a>的大波浪图像作为参考风格图像，一张狗图像作为内容图像组合在一起应该导致狗图像以大波浪图像的风格显示。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mg"><img src="../Images/dedd5d25a58fbe624528aa570d067041.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vyVUw3k2ciGTX5trZcc47g.jpeg"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Content Image</figcaption></figure><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mw"><img src="../Images/62e50dddd4379904c8be7ed6b8056a61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AEfXJgEnLgxnB8yVOQA0_w.jpeg"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Style Image</figcaption></figure><p id="5382" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在不再多说，我将向你展示如何创建这个程序，我相信你会发现，考虑到许多人对人工智能或深度学习表现出的神秘感，这并不困难。</p><div class="mx my gp gr mz na"><a href="https://www.datadriveninvestor.com/2020/03/04/on-artificial-intelligence-and-surveillance-capitalism/" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd ir gy z fp nf fr fs ng fu fw ip bi translated">人工智能和监督资本主义|数据驱动的投资者</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">大科技，总是现在:人工智能推动的大科技，已经使购物，搜索，在你的…</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no mq na"/></div></div></a></div><h2 id="d87d" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">我们将使用什么？</h2><p id="7f96" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">对于这个应用程序，我们将使用Keras进行后端和深度学习模型，使用PIL进行图像处理，使用scipy进行优化算法，使用time查看我们的训练过程每次迭代需要多长时间。</p><p id="a2f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">但是我不知道Keras。我该怎么办？</strong></p><p id="cb39" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">即使你不熟悉Keras，你也应该能够理解这一点，因为它的语法很简单，我会尽最大努力用尽可能简单的语言解释代码。</p><h2 id="c526" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">我们从哪里开始？</h2><p id="8573" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">我们将使用Jupyter笔记本，因此让我们导入一些基本的必需品，以及我们想要在环境中使用的图像。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Importing headers and the images</figcaption></figure><p id="af21" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将这些图像转换成numpy数组。我们将为这些numpy数组添加一个额外的维度，以便我们创建一个包含内容、风格和组合数据的张量，用于深度学习模型。</p><p id="2cb5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为我们将使用预训练的VGG16模型，所以我们需要对输入图像进行一些预处理。我们将使用图像网络数据集预先计算的平均值减去每个RGB通道。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="58a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在反转RGB到BGR，以匹配架构VGG16，这是写在咖啡馆。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="3947" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在把每个变量转换成张量。我们还创建了组合变量来保存创建时的组合图像。如前所述，我们将所有这些张量连接起来，为深度学习模型创建一个输入张量。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="e7f0" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">深度学习模型</h2><p id="c092" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">好了，在我们所有的输入准备之后，我们终于到了导入我们的深度学习模型VGG16并玩一些层的部分。</p><p id="1e4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">VGG16模型是为分类问题而创建的，但我们没有这样做，所以我们不需要一些负责分类的称为全连接层的层。我们可以通过使用include_top参数来排除它们。创建一个字典，如代码片段的最后一行所示，通过层名访问每个层。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="d42e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">VGG16模型的计划是让模型“理解”图像的特征。我们利用这一点来找出内容图像和组合图像之间以及样式图像和组合图像之间的损失，并计算梯度以最小化损失。</p><p id="728c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们继续编写损失函数。</p><h2 id="0657" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">损失函数</h2><p id="7666" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">考虑到我们之前看到的VGG16模型能够对图像的感知特征进行编码。我们将使用它的一些层来实现这一点。你可以在Gatys等人的<a class="ae mf" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">原始论文中读到模型层，但是我们将实现</a><a class="ae mf" href="https://arxiv.org/abs/1603.08155" rel="noopener ugc nofollow" target="_blank"> Johnson等人【2016】</a>的层</p><p id="500d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">内容丢失</strong></p><p id="fbb4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">内容图像和组合图像之间的损失就是这两个变量之间的MSE。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Calculate content loss with the combination image.</figcaption></figure><p id="9fae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">风格丧失</strong></p><p id="09d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">风格损失并不完全是我们计算内容损失的方式。我们想捕捉这两幅图像的风格。我们这样做的方法是通过计算gram矩阵，它是样式图像变量与其转置的点积。</p><p id="7c1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种转变带来了对风格的关注，而不是对图像内容的关注。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="757f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">总变化损失</strong></p><p id="92d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们计算<a class="ae mf" href="https://arxiv.org/abs/1412.0035" rel="noopener ugc nofollow" target="_blank">总变化损失</a>，以增加或减少损失项中的噪声，我们将看到它是如何做到的。</p><p id="6171" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但在此之前，我们需要给这三个损失一些权重，这样我们就可以改变每个损失对总损失项的影响。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="1988" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们创建一个损失变量，把所有这些损失加起来。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="abce" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">计算渐变</h2><p id="5365" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">我们需要的东西都准备好了。我们现在需要做的就是调用一个优化器来迭代和优化组合图像。让我们为组合变量的损失建立梯度。在这个特定的代码中，我使用TF1，因为我喜欢梯度函数，但在TF2 <a class="ae mf" href="https://github.com/tensorflow/tensorflow/issues/34235" rel="noopener ugc nofollow" target="_blank">梯度急切执行不被支持</a>(不确定这是一个错误还是一个功能)，所以我鼓励你尝试一下<a class="ae mf" href="https://www.tensorflow.org/api_docs/python/tf/GradientTape" rel="noopener ugc nofollow" target="_blank">梯度带</a>函数。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="66aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了更好地理解backend.function，看看这篇<a class="ae mf" href="https://stackoverflow.com/questions/48142181/whats-the-purpose-of-keras-backend-function" rel="noopener ugc nofollow" target="_blank">堆栈溢出帖子</a>。</p><p id="55df" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将评估函数中的损失和梯度，以确保我们有正确的值。</p><p id="4328" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了让我们的生活更轻松，我们将创建一个类，并返回损失值和梯度值，优化器将尝试修改这些值以产生最佳结果。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="cdba" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">最佳化</h2><p id="b7d9" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">所以让我们编写优化部分的代码。我们将使用来自scipy的<a class="ae mf" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html" rel="noopener ugc nofollow" target="_blank"> fmin_l_bfgs_b </a>算法。我们用随机数据创建一个变量，并将创建的图像存储在这个变量中。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">optimization</figcaption></figure><h2 id="2435" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">对结果图像进行反向预处理</h2><p id="6945" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">我们现在颠倒了我们以前的做法。将BGR转换为RGB值，我们将平均值添加到图像中。我们将我们的值裁剪为0到255个像素值。</p><p id="0063" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们看到了最终的图像。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/1fe149b9ace34dc95277121e0ac091d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*gOA0h-XeYCdGD9oUGoIOeQ.png"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Resultant image</figcaption></figure><h2 id="bd5c" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">来源和信用</h2><ol class=""><li id="da89" class="le lf iq jp b jq lg ju lh jy li kc lj kg lk kk ll lm ln lo bi translated"><a class="ae mf" href="https://harishnarayanan.org/writing/artistic-style-transfer/" rel="noopener ugc nofollow" target="_blank">https://harishnarayanan . org/writing/artistic-style-transfer/</a>风格转移方面最好的博客之一。感谢Harish Narayan如此精彩的解释。它帮助我练习风格转换。</li><li id="9e92" class="le lf iq jp b jq lp ju lq jy lr kc ls kg lt kk ll lm ln lo bi translated"><a class="ae mf" href="https://keras.io/examples/neural_style_transfer/" rel="noopener ugc nofollow" target="_blank">https://keras.io/examples/neural_style_transfer/</a>NST的Keras文档和Keras代码令人惊叹。</li></ol><p id="8963" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mf" href="https://github.com/anand0427/style-transfer-with-keras" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> Github回购本笔记本</strong> </a> <strong class="jp ir">或者从</strong> <a class="ae mf" href="https://anand0427.github.io/style-transfer-with-keras/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">本页面</strong> </a> <strong class="jp ir">看一看笔记本。</strong></p><p id="0672" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我想知道你对我博客的想法和看法。建设性的批评很受欢迎。如果你喜欢这个博客，你可以点击下面的按钮给我买杯咖啡。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><a href="https://www.buymeacoffee.com/anand0427"><div class="gh gi ns"><img src="../Images/6d60b235fcc46a4bd696b90e886419ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*Dpw8-hNGI2fDmosV4E8DVQ.png"/></div></a></figure><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="nt nq l"/></div></figure></div></div>    
</body>
</html>