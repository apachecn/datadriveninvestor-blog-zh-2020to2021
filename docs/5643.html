<html>
<head>
<title>De-bloat your Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">去膨胀你的神经网络</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/reducing-model-footprint-in-deep-learning-c500b3ff50b?source=collection_archive---------22-----------------------#2020-09-26">https://medium.datadriveninvestor.com/reducing-model-footprint-in-deep-learning-c500b3ff50b?source=collection_archive---------22-----------------------#2020-09-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/c146134339bcb680a7a06cae77f7ff56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eaCoZj6SF70BbTT8jWRZVg.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk"><a class="ae kf" href="https://thumbs.dreamstime.com/b/cutting-grass-pair-scissors-16225110.jpg" rel="noopener ugc nofollow" target="_blank">https://thumbs.dreamstime.com/b/cutting-grass-pair-scissors-16225110.jpg</a></figcaption></figure><p id="b5f4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">修剪是我很久以来一直感兴趣的事情，但不知何故，我从来没有实现它。我对它感兴趣有很多原因。主要是能够减少我的模型的大小、成本和计算需求，同时保持准确性(至少是某种程度上)。</p><p id="cda2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">TL；通常，这是通过以某种形式或方式删除参数来实现的。</p><p id="90dc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果需要，我们可以通过将网络的某些部分设置为0或删除它们来删除它们，而不是使用掩码。(又名权重和偏差)</p><p id="4b7b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在大多数情况下，网络首先被训练一段时间。然后修剪。这降低了它的准确性，因此被再次训练(微调)。这个循环一直重复，直到我们得到我们需要的结果。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h1 id="4b45" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">修剪方法的主要类型</h1><p id="a695" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">这种方法有很多种，但它们是根据它们对最初想法的改变来分类的。请注意，最终，主要思想是相同的，只是如何做是不同的。</p><h2 id="64e3" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">结构</h2><ul class=""><li id="dcec" class="na nb it ki b kj mj kn mk kr nc kv nd kz ne ld nf ng nh ni bi translated">关于结构选择，一些作者选择删减单个参数，产生稀疏网络(大量0)。这对于高效存储来说可能不是很理想。</li><li id="9bbe" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">其他一些人考虑将某些参数分组并作为组删除它们的方法。这样更优化。</li></ul><h2 id="c945" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">得分</h2><ul class=""><li id="7541" class="na nb it ki b kj mj kn mk kr nc kv nd kz ne ld nf ng nh ni bi translated">像所有网络一样，当我们试图选择去掉哪个参数时，评分变得至关重要。</li><li id="d600" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">一些作者建议基于绝对值移除，其他人决定基于该参数对整个网络的贡献进行修剪。</li><li id="8ce8" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">其他人根据给定的分数删除。</li><li id="be09" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">有些在本地执行修剪，而有些则在整个网络中全局执行。</li></ul><h2 id="87a9" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">行程安排</h2><ul class=""><li id="766b" class="na nb it ki b kj mj kn mk kr nc kv nd kz ne ld nf ng nh ni bi translated">一些一次修剪所有的重量</li><li id="14d5" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">其他的使用循环或其他条件反复修剪</li></ul><h2 id="f5bf" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">微调</h2><ul class=""><li id="c9d3" class="na nb it ki b kj mj kn mk kr nc kv nd kz ne ld nf ng nh ni bi translated">一些在修剪之前存储权重，并使用它来继续训练。</li><li id="2ee9" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">其他人试图回到以前的状态，重新初始化整个网络</li></ul><div class="no np gp gr nq nr"><a href="https://www.datadriveninvestor.com/2020/01/13/the-future-of-humanity-is-genetic-engineering-and-neural-implants/" rel="noopener  ugc nofollow" target="_blank"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd iu gy z fp nw fr fs nx fu fw is bi translated">人类的未来是基因工程和神经移植|数据驱动投资者</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">领先的技术、音乐和电影节将于2020年3月13日至22日举行。它将以前沿的谈话为特色…</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="oa l"><div class="ob l oc od oe oa of jz nr"/></div></div></a></div></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h1 id="115f" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">修剪试探法+代码</h1><p id="2aa1" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">从上一个主题扩展这个并尝试编码一点。(这些都在朱莉娅·朗)</p><p id="c20b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">注意</strong>这些代码是理解主要思想的玩具示例。正确的代码请参考我的知识库。<a class="ae kf" href="https://github.com/SubhadityaMukherjee/pytorchTutorialRepo/tree/master/Pruning" rel="noopener ugc nofollow" target="_blank">链接</a></p><p id="b843" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们在嵌套数组中获取一些随机值。在所有情况下，假设这些是网络的权重。比方说，每个子阵列代表网络的一层。</p><pre class="og oh oi oj gt ok ol om on aw oo bi"><span id="d60e" class="mo lm it ol b gy op oq l or os">weights = [rand(10) for _ in 1:10]</span></pre><p id="b6a9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还考虑要丢弃的值的百分比/数量作为输入。</p><h2 id="7703" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">全球震级</h2><ul class=""><li id="8ef7" class="na nb it ki b kj mj kn mk kr nc kv nd kz ne ld nf ng nh ni bi translated">取整个网络中的最低值。扔掉它们。</li></ul><p id="3dd7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好的，我们首先展平嵌套数组。然后我们可以很容易地找到n个最小值，因为现在它是一个长数组。我们可以写一个小函数来识别值是否大于值，否则返回0或原始值。</p><pre class="og oh oi oj gt ok ol om on aw oo bi"><span id="615a" class="mo lm it ol b gy op oq l or os">function setval(val, cmpval, setter)<br/>    if val&lt;cmpval<br/>        return setter<br/>    else<br/>        return val<br/>    end<br/>end</span></pre><p id="d816" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我们可以对这个扁平列表进行排序。之后，我们运行一个基于元素的map函数(在每一层上)并将每个元素传递给我们之前的函数。如果当前值小于我们选择的值，这将允许我们将所有必需的元素设置为0(或我们自己的值)。这将有效地降低价值。</p><pre class="og oh oi oj gt ok ol om on aw oo bi"><span id="f247" class="mo lm it ol b gy op oq l or os">"""<br/>weights = array<br/>n = lowest nth smallest value to prune below ( aka take the nth smallest value and prune below it ) (eg: 3)<br/>"""<br/>function global_mag_prune(weights, n = 3, setter = 0)<br/>    temp = collect(Iterators.flatten(weights))<br/>    sort!(temp)<br/>    map.( x-&gt; setval(x,temp[n], setter) ,  weights  )<br/>    <br/>end</span></pre><p id="f457" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还编写了一个函数来确定网络变得有多稀疏。(又名多少个零)。</p><pre class="og oh oi oj gt ok ol om on aw oo bi"><span id="c78f" class="mo lm it ol b gy op oq l or os">return temp2, sum(x-&gt;x==0, collect(Iterators.flatten(temp2)) , dims=1)/(size(temp)[1]*size(temp)[1])*100</span></pre><h2 id="0186" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">分层星等</h2><ul class=""><li id="b2d4" class="na nb it ki b kj mj kn mk kr nc kv nd kz ne ld nf ng nh ni bi translated">取网络中每层的最低值并进行修剪。</li></ul><p id="812a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">修改全局层的方式，并将其应用于每个层。为此，我们首先复制重量。然后，对于数组中的每一层，我们找到最少的n个值，取第n个值，并将所有其他值设置为0。作为边缘情况，如果输入的元素数量大于层的总长度，则整个层被设置为0。</p><pre class="og oh oi oj gt ok ol om on aw oo bi"><span id="e793" class="mo lm it ol b gy op oq l or os">"""<br/>weights = array<br/>n = lowest nth smallest value to prune below ( aka take the nth smallest value and prune below it ) (eg: 3)<br/>"""<br/>function layer_mag_prune(weights, n = 3, setter = 0)<br/>    backup = deepcopy(weights)<br/>    for layer in 1:length(weights)<br/>        sort!(backup[layer])<br/>        if n&gt;length(weights[layer])<br/>            n = length(weights[layer])<br/>        end<br/>        backup[layer] = map.( x-&gt; setval(x,weights[layer][n], setter) ,  weights[layer]  )<br/>    end<br/>    return backup, sum(x-&gt;x==0, collect(Iterators.flatten(backup)) , dims=1)/(size(weights)[1]*size(weights)[1])*100        <br/>end</span></pre><h2 id="254b" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">全球梯度幅度</h2><ul class=""><li id="e2ef" class="na nb it ki b kj mj kn mk kr nc kv nd kz ne ld nf ng nh ni bi translated">识别整个网络中的最低绝对值(权重*梯度)并移除它们</li></ul><p id="2b99" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为此，我们需要计算到目前为止权重的梯度。好吧，我可以用一个随机数组来证明这个概念。所以我们基本上采用之前的代码，将初始部分改为权重和梯度的乘积。</p><pre class="og oh oi oj gt ok ol om on aw oo bi"><span id="452c" class="mo lm it ol b gy op oq l or os">function global_grad_prune(weights, n = 3, setter = 0)<br/>    temp = weights*rand(size(weights))<br/>    temp = collect(Iterators.flatten(weights))<br/>    sort!(temp)<br/>    temp2 = map.( x-&gt; setval(x,temp[n], setter) ,  weights  )<br/>    return temp2, sum(x-&gt;x==0, collect(Iterators.flatten(temp2)) , dims=1)/(size(temp)[1]*size(temp)[1])*100<br/>end</span></pre><h2 id="2ef6" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">层状梯度大小</h2><ul class=""><li id="8a4f" class="na nb it ki b kj mj kn mk kr nc kv nd kz ne ld nf ng nh ni bi translated">最低的绝对值每层，并删除他们类似的，我们再次修改这一点，以适应我们的需要</li></ul><pre class="og oh oi oj gt ok ol om on aw oo bi"><span id="e759" class="mo lm it ol b gy op oq l or os">"""<br/>weights = array<br/>n = lowest nth smallest value to prune below ( aka take the nth smallest value and prune below it ) (eg: 3)<br/>"""<br/>function layer_grad_prune(weightsnew, n = 3, setter = 0)<br/>    weights = deepcopy(weightsnew)*rand(size(weightsnew))<br/>    backup = deepcopy(weights)<br/>    for layer in 1:length(weights)<br/>        sort!(backup[layer])<br/>        if n&gt;length(weights[layer])<br/>            n = length(weights[layer])<br/>        end<br/>        backup[layer] = map.( x-&gt; setval(x,weights[layer][n], setter) ,  weights[layer]  )<br/>    end<br/>        <br/>    return backup, sum(x-&gt;x==0, collect(Iterators.flatten(backup)) , dims=1)/(size(weights)[1]*size(weights)[1])*100<br/><br/>end</span></pre><h2 id="9f85" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">随意</h2><ul class=""><li id="0d46" class="na nb it ki b kj mj kn mk kr nc kv nd kz ne ld nf ng nh ni bi translated">每个权重被独立考虑，并以所需网络的一部分被丢弃</li></ul><p id="e2b5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为此，我们首先通过确定权重的总大小来确定要删除的值的数量，然后将其乘以要删除的值的分数。然后，我们展平数组，将不需要的值设置为0，然后重新成形为原始形状。</p><pre class="og oh oi oj gt ok ol om on aw oo bi"><span id="a3b8" class="mo lm it ol b gy op oq l or os">"""<br/>frac = percentage of values to remove<br/>"""<br/>function random_prune(weights, frac = .3, setter = 0)<br/>    num_prune = Int(round(frac*(size(weights)[1]*size(weights)[1])))<br/>    @info num_prune<br/>    backup = collect(Iterators.flatten(deepcopy(weights)))<br/>    backup[rand(1:length(backup), num_prune)] .= 0<br/>    @info size(weights)<br/>    return reshape(backup, size(weights))<br/>end</span></pre></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h1 id="a4cb" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">我们能从论文中学到什么(感谢Blalock等人)</h1><ul class=""><li id="8de9" class="na nb it ki b kj mj kn mk kr nc kv nd kz ne ld nf ng nh ni bi translated">修剪方法不能由单个数据集决定，而必须使用标准化测试对各种数据集进行测试来决定</li><li id="e1f6" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">如果需要少量压缩，在某些情况下，修剪实际上可能会提高我们的准确性</li><li id="f43e" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">随机修剪可能并不总是最好的选择</li><li id="192a" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">全局修剪更好</li><li id="20e5" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">根据图层类型分配不同的修剪百分比会有所帮助</li><li id="3163" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">稀疏模型通常优于密集模型</li><li id="285b" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">修剪后的模型有时可以获得比初始架构更高的精度</li><li id="f5c7" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">对于一开始就很差的架构更有效</li><li id="a3a1" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">也许能够改善时间/空间与精确度的权衡</li></ul></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h1 id="2891" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">太棒了，但是…</h1><ul class=""><li id="2251" class="na nb it ki b kj mj kn mk kr nc kv nd kz ne ld nf ng nh ni bi translated">有时你会选择一个更好、更高效的架构</li><li id="6e4e" class="na nb it ki b kj nj kn nk kr nl kv nm kz nn ld nf ng nh ni bi translated">这完全取决于你的目标是什么</li></ul><h1 id="10a5" class="ll lm it bd ln lo ot lq lr ls ou lu lv lw ov ly lz ma ow mc md me ox mg mh mi bi translated">~完成</h1><p id="8589" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">我们的修剪之旅到此结束。</p><p id="3d65" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你喜欢你所读的，请随时订阅/问我以下任何问题。</p><blockquote class="oy oz pa"><p id="0636" class="kg kh pb ki b kj kk kl km kn ko kp kq pc ks kt ku pd kw kx ky pe la lb lc ld im bi translated">注意，本文大部分内容基于Davis Blalock等人的一篇优秀论文<a class="ae kf" href="https://arxiv.org/pdf/2003.03033.pdf" rel="noopener ugc nofollow" target="_blank">神经网络修剪的状态是什么？</a></p></blockquote><p id="1bf9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">【引用】:Blalock，d .，Ortiz，J. J. G .，Frankle，j .，&amp; Guttag，J. (2020)。神经网络剪枝是什么状态？。arXiv预印本:2003.03033。</p><h2 id="9c5a" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">获得专家视图— <a class="ae kf" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>