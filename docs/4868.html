<html>
<head>
<title>Why RandAugment is the best Data Augmentation approach for Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么RandAugment是图像的最佳数据扩充方法</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/why-randaugment-is-the-best-data-augmentation-approach-4a48f22b2152?source=collection_archive---------0-----------------------#2020-08-27">https://medium.datadriveninvestor.com/why-randaugment-is-the-best-data-augmentation-approach-4a48f22b2152?source=collection_archive---------0-----------------------#2020-08-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c39e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">提摩西的两个词:性能和成本效益</h2></div><p id="a2a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了帮助我了解您<a class="ae lb" href="https://forms.gle/7MfQmKhEhyBTMDUD7" rel="noopener ugc nofollow" target="_blank">请填写此调查(匿名)</a></p><p id="9e53" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，如果你读过我的上一篇文章(点击这里查看<a class="ae lb" href="https://medium.com/@devanshverma425/how-did-google-researchers-beat-imagenet-while-using-fewer-resources-267243071ee4?source=friends_link&amp;sk=812b1b772b2254a41a8930fada21b504" rel="noopener"/>，我分析了谷歌<strong class="kh ir">的研究人员如何在使用<strong class="kh ir">成倍减少的资源</strong>(剧透:魔术)的情况下大幅超越</strong>当前的图像分类系统。研究人员提到使用RandAugment来产生输入噪声。自然，我对此很好奇。我学到的东西令人惊讶。所以请继续阅读为什么RandAugment是游戏中最好的。通过这篇文章，我们将了解山羊是如何工作的。由Cubuk等人提出的<strong class="kh ir"> </strong> <a class="ae lb" href="https://arxiv.org/abs/1909.13719" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> RandAugment:具有缩小的搜索空间的实用自动数据扩充</strong> </a> <strong class="kh ir"> </strong>。</p><h1 id="dd91" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">背景资料</h1><p id="c6e3" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">因为我的内容已经超过1000次浏览，我想我应该给我的文章增加一些变化。这里有一个视频描述了数据增强的重要性，以及RandAugment的工作原理。请投个赞并留下你的反馈。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="me mf l"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">Let's get this trending bois.</figcaption></figure><p id="ad5b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">RandAugment就是这么简单。取一幅图像，输入2个整数N和M，N是随机变换的次数，M是变换的幅度。仅通过这些参数，RandAugment就能够生成完全不同的图像，并提高学习者的水平。例如，在视频(N=2)中，在给定的M值下，我们可能有13 = 169个图像。这种随机性给了它基于ML的数据扩充的优势，因为我们正在处理更多的随机数据。这使得学习噪音的趋势变得不可能。这种简单性意味着"<em class="mk"> RandAugment可以跨不同的任务和数据集统一使用<br/>，并且开箱即用，<br/> </em> <strong class="kh ir"> <em class="mk">匹配或超过CIFAR-10/100、SVHN和ImageNet上所有以前的自动扩充</em> </strong> <em class="mk">方法。</em>”</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/2bdb6d9536d860a39c40b26bd2d6383b.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*KL0XXIViKfQKDtfeKPuNXg.png"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">Automated Augmentation models often struggle on larger datasets where they can’t adjust regularization strength. RandAugement is able to avoid that.</figcaption></figure><h1 id="e14a" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">为什么质量噪声很重要</h1><h2 id="39f0" class="mo ld iq bd le mp mq dn li mr ms dp lm ko mt mu lo ks mv mw lq kw mx my ls mz bi translated">(为什么习得性增强会失败)</h2><blockquote class="na nb nc"><p id="c65e" class="kf kg mk kh b ki kj jr kk kl km ju kn nd kp kq kr ne kt ku kv nf kx ky kz la ij bi translated">我们<!-- -->证明了数据扩充的最佳强度<strong class="kh ir">取决于模型大小和训练集大小</strong>。这一观察表明，对较小代理任务的增强策略的单独优化对于学习和转移增强策略来说可能是次优的。</p></blockquote><p id="d22c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是报纸上的一段引文。起初这个看似简单的陈述过于琐碎，以至于没有注意到。然而，这是不容忽视的。一般来说，数据样本越小，行为越极端。然而，本文提出了一个新的角度。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ng"><img src="../Images/b5e4b1453b40784aa0f5e29a318d63b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7lYrSfk9bXsa6zKameFCYw.png"/></div></div></figure><p id="5883" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">团队改变两个因素:模型大小和网络大小。图3a示出了对于不同的宽范围模型，随着失真幅度的增加而训练的模型的精度的相对增益。图3a展示了失真幅度的系统趋势。特别是，绘制所有宽ResNet架构与最佳失真幅度的关系图，突出了网络规模不断增加的明显单调趋势(图3b)。<em class="mk">更大的网络需要更大的数据失真来进行正则化</em>。基于的<strong class="kh ir">学习策略为所有架构提供了固定的失真幅度</strong>(图3b，虚线)，因此显然是次优的<em class="mk">。</em></p><p id="fb36" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图3b和d(右栏)也显示了类似的情况。很明显，在较小训练集上训练的模型可以从数据扩充中获得更多改进(例如，图3c中的3.0%对1.5%)。这是有意义的，因为对于较小的数据集，添加另一个图像时数据大小的相对增加更高。有趣的是，“<em class="mk">图3d展示了最佳失真幅度随着训练集大小单调增加。”</em>结合这两个因素，<em class="mk">“这种趋势突出了在更大的数据集上增加数据增强的强度的需要，以及在由训练数据的子集组成的代理任务上优化学习增强策略的缺点。</em> <strong class="kh ir"> <em class="mk">即，所学习的增强可以学习更适合于代理任务的增强强度，而不是更大的感兴趣的任务</em> </strong> <em class="mk">。”</em></p><blockquote class="nl"><p id="48cb" class="nm nn iq bd no np nq nr ns nt nu la dk translated"><em class="nv">即，所学习的增强可以学习更适合于代理任务的增强强度，而不是感兴趣的更大任务</em></p></blockquote><p id="0832" class="pw-post-body-paragraph kf kg iq kh b ki nw jr kk kl nx ju kn ko ny kq kr ks nz ku kv kw oa ky kz la ij bi translated">简而言之，RandAugment之所以胜出，是因为它能够以经济高效的方式根据数据和网络的规模进行扩展。这使得它非常适合大型网络和大型数据集。</p><div class="ob oc gp gr od oe"><a href="https://www.datadriveninvestor.com/2020/06/30/volcker-act-gets-sacked-corporate-giants-stand-to-benefit/" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd ir gy z fp oj fr fs ok fu fw ip bi translated">沃尔克法案被解雇，企业巨头受益|数据驱动的投资者</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">金融市场极其复杂。虽然在某种程度上可以由中央政府管理，但布局最好的…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="on l"><div class="oo l op oq or on os mm oe"/></div></div></a></div><h1 id="571b" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">衡量绩效</h1><p id="df3b" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi ot translated">既然我们已经了解了RandAugment的作用，以及它为什么如此有效，那么让我们来了解一下评估的细节。通过评估所使用的不同指标，我们可以了解论文的潜在扩展。它让我们通过查看基准测试的性能来评估这种技术的优势。</p><h1 id="7469" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">平均的</h1><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/2bdb6d9536d860a39c40b26bd2d6383b.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*KL0XXIViKfQKDtfeKPuNXg.png"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">This image makes a comeback</figcaption></figure><p id="913c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">平均性能是惊人的。RandAugment经历了一个非常小的。AA，下一个最小的有一个<strong class="kh ir">非百万倍大的</strong>搜索空间。那是<strong class="kh ir">的10亿倍</strong>的差异。呀。而RA还是比它做的好。PBA的搜索空间最大。可能的解的数量比我们太阳中的原子数量还要多(10，000倍)。RA也打败了它。</p><h2 id="ee06" class="mo ld iq bd le mp mq dn li mr ms dp lm ko mt mu lo ks mv mw lq kw mx my ls mz bi translated">超过不同的模型尺寸</h2><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/afb936c9dfa7805b12c6aba495264952.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*MWT7GOXNwdpIYibZfUkbyA.png"/></div></figure><p id="3259" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该表完美地代表了噪声部分提出的观点。我们看到，随着模型规模的增加，RA领先于其他增强技术。这在不同的架构中是一致的。</p><h2 id="918e" class="mo ld iq bd le mp mq dn li mr ms dp lm ko mt mu lo ks mv mw lq kw mx my ls mz bi translated">图像分类(ImageNet)</h2><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pd"><img src="../Images/880cba355de19bdae68bd2779d04bedb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*11iXUd9ZYXg6mQLpHSZgyw.png"/></div></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">Performance on ImageNet</figcaption></figure><p id="3932" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">ImageNet是图像分类的行业标准。在ImageNet的所有架构中，RA将自己与其他增强技术区分开来。</p><h2 id="1ef7" class="mo ld iq bd le mp mq dn li mr ms dp lm ko mt mu lo ks mv mw lq kw mx my ls mz bi translated">目标检测</h2><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/a885fa921d572e7b7f4b36f2fa6f444b.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*SLZFdq9Izd63wUWC4AXlaA.png"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">The one area where it doesn’t win</figcaption></figure><p id="f0a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">目标检测是一个蓬勃发展的领域。这对自动驾驶汽车和其他类似领域至关重要。在这个任务中，我们看到RA的性能低于AA。然而，有趣的是，RA仍然提高了基线，并且与AA具有竞争力。这令人印象深刻，因为AA使用15K GPU小时，而RA在6个参数上进行了调整。</p><h2 id="82c4" class="mo ld iq bd le mp mq dn li mr ms dp lm ko mt mu lo ks mv mw lq kw mx my ls mz bi translated">高亮纸</h2><p id="3b40" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">找到下面的注释文件。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="pf mf l"/></div></figure><p id="4ee8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请务必下载并阅读它，以获得对论文更完整的理解。我为初学者增加了重要的定义。</p><h1 id="87e8" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">向我伸出手</h1><p id="76f5" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">请在下面留下您对这篇文章的反馈。如果这对你有用，请分享并跟我来这里。</p><p id="9002" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看我在Medium上的其他文章。:【https://rb.gy/zn1aiu T4】</p><p id="9602" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我的YouTube。这是一个正在进行中的工作哈哈:<a class="ae lb" href="https://rb.gy/88iwdd" rel="noopener ugc nofollow" target="_blank">https://rb.gy/88iwdd</a></p><p id="c316" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在LinkedIn上联系我。我们来连线:<a class="ae lb" href="https://rb.gy/f7ltuj" rel="noopener ugc nofollow" target="_blank">https://rb.gy/f7ltuj</a></p><p id="e016" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我的推特:<a class="ae lb" href="https://twitter.com/Machine01776819" rel="noopener ugc nofollow" target="_blank">https://twitter.com/Machine01776819</a></p><p id="b327" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我的子任务:<a class="ae lb" href="https://devanshacc.substack.com/" rel="noopener ugc nofollow" target="_blank">https://devanshacc.substack.com/</a></p><p id="6dd2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想和我一起工作，请发邮件给我:devanshverma425@gmail.com</p><p id="8b48" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">twitch现场对话:<a class="ae lb" href="https://rb.gy/zlhk9y" rel="noopener ugc nofollow" target="_blank">https://rb.gy/zlhk9y</a></p><p id="ca59" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">获取我的内容更新-insta gram:<a class="ae lb" href="https://rb.gy/gmvuy9" rel="noopener ugc nofollow" target="_blank">https://rb.gy/gmvuy9</a></p><p id="8ba7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">获得罗宾汉的免费股票:<a class="ae lb" href="https://www.youtube.com/redirect?redir_token=QUFFLUhqa0xDdC1jTW9nSU91WXlCSFhEVkJ0emJvN1FaUXxBQ3Jtc0ttWkRObUdfem1DZzIyZElfcXVZNGlVNE1xSUc4aVhSVkxBVGtHMWpmei1lWWVKNzlDUXVJR24ydHBtWG1PSXNaMlBMWDQycnlIVXNMYjJZWjdXcHNZQWNnaFBnQUhCV2dNVERQajFLTTVNMV9NVnA3UQ%3D%3D&amp;q=https%3A%2F%2Fjoin.robinhood.com%2Ffnud75&amp;v=WAYRtSj0ces&amp;event=video_description" rel="noopener ugc nofollow" target="_blank">https://join.robinhood.com/fnud75</a></p><p id="fa57" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">访问专家视图— </strong> <a class="ae lb" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>