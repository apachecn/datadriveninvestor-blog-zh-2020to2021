<html>
<head>
<title>Kannada Mnist Classification: A Kaggle Case Study</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卡纳达语Mnist分类:Kaggle案例研究</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/kannada-mnist-classification-a-kaggle-case-study-fa1b3f72b54?source=collection_archive---------2-----------------------#2020-03-13">https://medium.datadriveninvestor.com/kannada-mnist-classification-a-kaggle-case-study-fa1b3f72b54?source=collection_archive---------2-----------------------#2020-03-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/de3eec9a92cff8a079e04e598b2ce0bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E2Qbqld_MwcZHGba443z4g.jpeg"/></div></div></figure></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><p id="0956" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">卡纳达语Mnist分类是最近结束的kaggle竞赛，是经典MNIST竞赛的延伸。卡纳达语是印度南部的一种语言，大约有450万人以此为母语。该数据集是在Vinay Uday Prabhu的得力指导下收集的。这是一场核心竞争。要了解更多关于比赛的信息和访问数据，请访问页面<a class="ae ld" href="https://www.kaggle.com/c/Kannada-MNIST/overview" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/Kannada-MNIST/overview</a>。</p><h2 id="c619" class="le lf iq bd lg lh li dn lj lk ll dp lm kq ln lo lp ku lq lr ls ky lt lu lv lw bi translated">数据集概述:</h2><p id="2265" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">为了读取数据集，我们可以使用熊猫图书馆。我们提供了4个csv文件。以下代码片段有助于我们阅读所有4个csv文件。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="697c" class="le lf iq mh b gy ml mm l mn mo">train=pd.read_csv('/home/aditya123/Downloads/Kannada-MNIST/train.csv')<br/>test=pd.read_csv('/home/aditya123/Downloads/Kannada-MNIST/test.csv')<br/>sample_sub=pd.read_csv('/home/aditya123/Downloads/Kannada-MNIST/sample_submission.csv')</span></pre><p id="2c2c" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">数据集有60000行和785列。为了了解这一点，我们可以使用下面的代码。要了解数据集的更多信息，我们可以使用head and describe函数。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="5d48" class="le lf iq mh b gy ml mm l mn mo">train.shape<br/>train.head()<br/>train.describe()</span></pre><p id="f52f" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">从head函数可以明显看出，数据集有一个作为目标标签的标签字段。我们应该指定为y，其余的为x</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="7028" class="le lf iq mh b gy ml mm l mn mo">x=train.iloc[:,1:].values<br/>y=train.iloc[:,0].values</span></pre><h2 id="881b" class="le lf iq bd lg lh li dn lj lk ll dp lm kq ln lo lp ku lq lr ls ky lt lu lv lw bi translated">重塑:</h2><p id="523e" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">x值的形状为(60000，784)。在后面的阶段，我们应该把它作为卷积神经网络的输入。例如，keras conv2D仅适用于3维。于是我们将其重塑为一种形态(<em class="mp"> n_images </em>、<em class="mp"> x_shape </em>、<em class="mp"> y_shape </em>、<em class="mp"> channels </em>)。为此，我们可以编写以下代码</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="d4a6" class="le lf iq mh b gy ml mm l mn mo">x=x.reshape(x.shape[0],28,28,1)</span></pre><h2 id="f930" class="le lf iq bd lg lh li dn lj lk ll dp lm kq ln lo lp ku lq lr ls ky lt lu lv lw bi translated">Y值的一次热编码:</h2><p id="f7dc" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">使用我们的模型不可能处理分类数据。所以我们必须把它转换成一个热编码值。例如，这将把数字4表示为[0，0，0，0，1，0，0，0，0，0]。为此，我们可以编写以下代码片段。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="3a29" class="le lf iq mh b gy ml mm l mn mo">y=keras.utils.to_categorical(y,10)</span></pre><h2 id="9110" class="le lf iq bd lg lh li dn lj lk ll dp lm kq ln lo lp ku lq lr ls ky lt lu lv lw bi translated">列车测试分离:</h2><p id="d5d1" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">我们需要在数据的某一部分上训练我们的数据，并且类似地在数据的完全未触及的部分上测试模型如何执行。为此，我们将求助于sklearn库。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="6887" class="le lf iq mh b gy ml mm l mn mo">x_train,x_valid,y_train,y_valid=train_test_split(x,y,test_size=0.10,random_state=42)</span></pre><h2 id="104b" class="le lf iq bd lg lh li dn lj lk ll dp lm kq ln lo lp ku lq lr ls ky lt lu lv lw bi translated">标准化:</h2><p id="753b" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">神经网络通常具有小的权重值，正如我们所看到的，输入是大的。因此，这可能会在训练模型时导致许多问题，例如降低模型的速度。因此，我们应该对像素值进行归一化，使得每个像素值的值在0和1之间。为此，我们可以简单地将所有像素除以255。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="9725" class="le lf iq mh b gy ml mm l mn mo">x_train=x_train/255</span></pre><h2 id="167e" class="le lf iq bd lg lh li dn lj lk ll dp lm kq ln lo lp ku lq lr ls ky lt lu lv lw bi translated">数据扩充:</h2><p id="4354" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">它使用各种技术来创建越来越多的例子，以便模型能够学习如何进行归纳。神经网络需要大量的数据来做正确的预测。数据扩充有助于我们完成这项任务。有各种技术来执行图像增强，例如<strong class="kh ir"><em class="mp"/></strong><strong class="kh ir"><em class="mp">旋转</em></strong><strong class="kh ir"><em class="mp">缩放变化</em></strong><strong class="kh ir"><em class="mp">剪切</em></strong><strong class="kh ir"><em class="mp">水平翻转。</em> </strong>对输入图像的这些变换可以改变图像的外观，但不会改变类别标签。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/781ea43c4d5a84e7682c5bacc56c5c64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*e6w_GNiXB7JEst1v.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">(Pic Source:Pyimage Search)</figcaption></figure><p id="112f" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">上图显示了一些就地执行图像增强的方法。为了执行同样的操作，我们将使用一个名为<strong class="kh ir"> <em class="mp">的ImageDataGenerator类。需要考虑的一件重要事情是，这个类只返回随机转换的数据。因此，数据增强的全部目的是确保网络看到从未见过的<strong class="kh ir"> <em class="mp">新</em> </strong>图像。此外，这种增强是在训练时完成的，而不是在预处理模块的一部分。在训练期间，它生成那些随机变换的图像。这段代码创建了一个图像增强对象。</em></strong></p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="066a" class="le lf iq mh b gy ml mm l mn mo">train_gen=ImageDataGenerator(rescale=1./255.,rotation_range=10,width_shift_range=0.25,height_shift_range=0.30,shear_range=0.15,zoom_range=0.30,horizontal_flip=False)</span></pre><h2 id="3db3" class="le lf iq bd lg lh li dn lj lk ll dp lm kq ln lo lp ku lq lr ls ky lt lu lv lw bi translated">建模:</h2><p id="811c" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">所以现在轮到我们做任何机器学习项目中最有趣的部分了。我们将使用keras顺序api建立一个模型。下面是完成建模任务的代码片段。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="4c4c" class="le lf iq mh b gy ml mm l mn mo">model = Sequential()</span><span id="7621" class="le lf iq mh b gy mv mm l mn mo">model.add(Conv2D(64, kernel_size=3, activation=’relu’, input_shape=(28, 28, 1)))<br/>model.add(BatchNormalization())<br/>model.add(Conv2D(64, kernel_size=3))<br/>model.add(LeakyRelu(alpha=0.1))</span><span id="851f" class="le lf iq mh b gy mv mm l mn mo">model.add(BatchNormalization())<br/>model.add(Conv2D(64, kernel_size=5, padding=’same’))<br/>model.add(LeakyRelu(alpha=0.1))</span><span id="6499" class="le lf iq mh b gy mv mm l mn mo">model.add(BatchNormalization())<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.2))</span><span id="c2fa" class="le lf iq mh b gy mv mm l mn mo">model.add(Conv2D(128, kernel_size=3))<br/>model.add(LeakyRelu(alpha=0.1))</span><span id="4fb0" class="le lf iq mh b gy mv mm l mn mo">model.add(BatchNormalization())<br/>model.add(Conv2D(128, kernel_size=3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Conv2D(128, kernel_size=5, padding=’same’))<br/>model.add(LeakyRelu(alpha=0.1))</span><span id="f195" class="le lf iq mh b gy mv mm l mn mo">model.add(BatchNormalization())<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.2))</span><span id="9121" class="le lf iq mh b gy mv mm l mn mo">model.add(Conv2D(256, kernel_size=3))<br/>model.add(LeakyRelu(alpha=0.1))</span><span id="b458" class="le lf iq mh b gy mv mm l mn mo">model.add(BatchNormalization())<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.2))</span><span id="82c1" class="le lf iq mh b gy mv mm l mn mo">model.add(Flatten())<br/>model.add(Dense(256))<br/>model.add(BatchNormalization())<br/>model.add(Dense(128))<br/>model.add(BatchNormalization())<br/>model.add(Dense(10, activation=’softmax’))<br/>model.compile(loss=’categorical_crossentropy’,optimizer=’adam’,metrics=[‘accuracy’])</span></pre><p id="8ff4" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">现在的问题是为什么这个建筑？为什么不是一些具有不同数量的内核和大小或激活功能的其他架构。原来(<strong class="kh ir"> <em class="mp">如andrew ng所说)</em> </strong>我们可以拥有任何一种架构，只要它与我们的输入兼容。此外，我们尝试不同的架构作为试验和错误，然后看看他们中的哪一个是最适合我们的任务。我们可以在任何标准的mooc中读到所有这些的功能。正如竞赛的一位奖牌获得者所提到的，<strong class="kh ir"> <em class="mp">泄漏relu </em> </strong>激活功能帮助他提高了他的模型的性能。compile方法通过一些初始化来创建架构，但不需要任何训练。当我们训练模型时，所有的参数都被优化到一个最佳值。</p><div class="mw mx gp gr my mz"><a href="https://www.datadriveninvestor.com/2019/03/22/fixing-photography/" rel="noopener  ugc nofollow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd ir gy z fp ne fr fs nf fu fw ip bi translated">修复摄影|数据驱动的投资者</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">汤姆·津伯洛夫在转向摄影之前曾在南加州大学学习音乐。作为一个…</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn jw mz"/></div></div></a></div><h1 id="44b6" class="no lf iq bd lg np nq nr lj ns nt nu lm nv nw nx lp ny nz oa ls ob oc od lv oe bi translated">回访:</h1><p id="dd6f" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">回调是在训练 过程中应用<strong class="kh ir"> <em class="mp">的不同功能集。例如，我们可能希望在达到某个准确度/损失后停止训练。这些是我们在训练模型时看到的回调类型。</em></strong></p><h2 id="4e5b" class="le lf iq bd lg lh li dn lj lk ll dp lm kq ln lo lp ku lq lr ls ky lt lu lv lw bi translated">提前停止:</h2><p id="e79a" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">该功能允许根据特定条件提前终止进程。例如，参数<strong class="kh ir"> <em class="mp">监控</em> </strong>表示被监控的值。参数<strong class="kh ir"> <em class="mp"> min_delta </em> </strong>指监控值的最小变化。类似地，参数<strong class="kh ir"> <em class="mp">耐心</em> </strong>是指我们必须等待的没有改善的时期的数量。</p><h2 id="f350" class="le lf iq bd lg lh li dn lj lk ll dp lm kq ln lo lp ku lq lr ls ky lt lu lv lw bi translated">模型检查点:</h2><p id="0087" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">模型检查点在每个时期后保存模型。这些是某些参数，如</p><ul class=""><li id="2891" class="of og iq kh b ki kj km kn kq oh ku oi ky oj lc ok ol om on bi translated"><strong class="kh ir"> filepath: </strong>是指我们要保存的路径。</li><li id="45b1" class="of og iq kh b ki oo km op kq oq ku or ky os lc ok ol om on bi translated"><strong class="kh ir">监控:</strong>该参数表示被监控的参数。</li><li id="a9fd" class="of og iq kh b ki oo km op kq oq ku or ky os lc ok ol om on bi translated"><strong class="kh ir"> save_best_only: </strong>如果我们不想覆盖当前的最佳模型，我们将此设置为true。</li><li id="c4fe" class="of og iq kh b ki oo km op kq oq ku or ky os lc ok ol om on bi translated"><strong class="kh ir">模式:</strong>可以采用自动、最小或最大值。例如，如果模式设置为<em class="mp">精度</em>，我们希望将其最小化。</li></ul><h2 id="6465" class="le lf iq bd lg lh li dn lj lk ll dp lm kq ln lo lp ku lq lr ls ky lt lu lv lw bi translated">学习率计划程序:</h2><p id="4329" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">它随时间将学习率调整到一个期望值，该值以历元为自变量，并返回学习率以用于随机梯度下降。在我们的代码中，我们在平台上使用<strong class="kh ir"> <em class="mp"> reduce。</em> </strong>当性能指标达到稳定水平时，它会以一定的因子降低优化器的学习率，也就是说验证损失没有改善，我们会降低学习率。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="6204" class="le lf iq mh b gy ml mm l mn mo">learning_rate_reduction= ReduceLROnPlateau(monitor=’val_loss’,patience=200,verbose=1,factor=0.2)<br/>es=EarlyStopping(monitor=’val_loss’,mode=’min’,verbose=1,patience=200)</span></pre><p id="715e" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">上面的代码片段达到了同样的效果。参数<strong class="kh ir"> <em class="mp">因子</em> </strong>是指学习率降低的量。</p><h2 id="6de6" class="le lf iq bd lg lh li dn lj lk ll dp lm kq ln lo lp ku lq lr ls ky lt lu lv lw bi translated">测试数据的训练和预测:</h2><p id="3615" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">在前面的步骤中，我们已经执行了图像增强。所以我们的数据集不是静态的。因此我们不能使用拟合函数。对于这种情况，我们应该使用<strong class="kh ir"> <em class="mp">拟合_生成器</em> </strong>功能。这里要记住一点，图像发生器使用时数据不要<strong class="kh ir"><em class="mp"/></strong>或<strong class="kh ir"> <em class="mp">太大。</em> </strong>需要注意的一点是<strong class="kh ir"><em class="mp">steps _ per _ epoch</em></strong>参数。由于我们的图像生成器函数无限循环，keras无法知道一个时期何时开始，何时结束。我们发现<strong class="kh ir"><em class="mp">steps _ per _ epoch</em></strong>参数为数据点总数除以批量大小。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="b3c9" class="le lf iq mh b gy ml mm l mn mo">history=model.fit_generator(train_gen.flow(x_train,y_train,batch_size=batch_size),steps_per_epoch=100,epochs=epochs,validation_data=valid_datagen.flow(x_valid,y_valid),validation_steps=50,callbacks=[learning_rate_reduction,es])</span></pre><p id="4567" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">上面的代码片段达到了同样的效果。</p><p id="eb9e" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">为了对测试数据集进行预测，我们可以编写以下代码。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="f28a" class="le lf iq mh b gy ml mm l mn mo">prediction=model.predict_classes(x_test/255.)</span><span id="9757" class="le lf iq mh b gy mv mm l mn mo">prediction=np.argmax(prediction,axis=1)</span></pre><h1 id="4748" class="no lf iq bd lg np nq nr lj ns nt nu lm nv nw nx lp ny nz oa ls ob oc od lv oe bi translated">提交:</h1><p id="1c96" class="pw-post-body-paragraph kf kg iq kh b ki lx kk kl km ly ko kp kq lz ks kt ku ma kw kx ky mb la lb lc ij bi translated">要使用csv文件提交，我们可以编写以下代码片段。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="f97e" class="le lf iq mh b gy ml mm l mn mo">sample_sub[‘label’]=prediction</span><span id="df7e" class="le lf iq mh b gy mv mm l mn mo">sample_sub.to_csv(‘sample_submission.csv’,index=False)</span></pre><p id="c244" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">要访问全部代码，请参见<a class="ae ld" href="https://github.com/mohantyaditya/Kannada-Mnist" rel="noopener ugc nofollow" target="_blank">https://github.com/mohantyaditya/Kannada-Mnist</a>。</p><figure class="mc md me mf gt jr"><div class="bz fp l di"><div class="ot ou l"/></div></figure></div></div>    
</body>
</html>