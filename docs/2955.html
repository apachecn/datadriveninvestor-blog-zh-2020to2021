<html>
<head>
<title>Review On RCNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">RCNN综述</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/review-on-rcnn-c079fc269a7d?source=collection_archive---------4-----------------------#2020-05-24">https://medium.datadriveninvestor.com/review-on-rcnn-c079fc269a7d?source=collection_archive---------4-----------------------#2020-05-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/36bfbd862f8d1b025ec149ade20177aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-UawiSzqTQc36RpDABeBtg.png"/></div></div></figure><p id="f755" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">深度卷积网络显著提高了图像分类和目标检测的准确性。当进行目标检测时，与图像分类相比，它是具有挑战性的，因为我们需要定位目标。为了进行对象检测，我们需要知道对象的类别以及边界框的大小和位置<strong class="ka ir">。</strong></p><p id="3245" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">区域CNN (R-CNN)是最先进的基于CNN的深度学习对象检测方法之一。基于此，有<strong class="ka ir">快速R-CNN </strong>和<strong class="ka ir">更快R-CNN </strong>用于更快速度的对象检测，以及<strong class="ka ir">掩模R-CNN </strong>用于对象实例分割。我觉得对于从物体检测开始的人来说，理解快速RCNN是不可避免的。</p><p id="8639" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该论文首次表明，与基于更简单的HOG-like特征的系统相比，CNN可以在PASCAL VOC上导致显著更高的对象检测性能。</p><div class="kw kx gp gr ky kz"><a href="https://www.datadriveninvestor.com/2020/02/12/has-general-ai-exceeded-the-intellectual-capacity-of-humans/" rel="noopener  ugc nofollow" target="_blank"><div class="la ab fo"><div class="lb ab lc cl cj ld"><h2 class="bd ir gy z fp le fr fs lf fu fw ip bi translated">AI将军是否已经超过了人类的智力容量？数据驱动的投资者</h2><div class="lg l"><h3 class="bd b gy z fp le fr fs lf fu fw dk translated">不仅在游戏中，而且在劳动力市场上，机器都比人类聪明。在今天的许多领域，使用…</h3></div><div class="lh l"><p class="bd b dl z fp le fr fs lf fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="li l"><div class="lj l lk ll lm li ln jw kz"/></div></div></a></div><p id="b7a9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本地化对象的基本思想是使用滑动窗口方法。这是一个简单的解决方案。然而，不同的对象或相同的对象可以有不同的长宽比和大小，这取决于图像和离相机的距离。所以我们可以建议使用图像金字塔。但即使这样，计算也将非常缓慢。RCNN通过使用选择性搜索算法从图像中产生区域建议来解决这个问题。我们将文章分为4个部分:</p><ol class=""><li id="4217" class="lo lp iq ka b kb kc kf kg kj lq kn lr kr ls kv lt lu lv lw bi translated"><strong class="ka ir">建筑</strong></li><li id="a288" class="lo lp iq ka b kb lx kf ly kj lz kn ma kr mb kv lt lu lv lw bi translated"><strong class="ka ir">选择性搜索</strong></li><li id="b7d5" class="lo lp iq ka b kb lx kf ly kj lz kn ma kr mb kv lt lu lv lw bi translated"><strong class="ka ir">特征提取和输出</strong></li><li id="7078" class="lo lp iq ka b kb lx kf ly kj lz kn ma kr mb kv lt lu lv lw bi translated"><strong class="ka ir">结果</strong></li></ol></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="35fe" class="mj mk iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">1.体系结构</h1><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/0a86e7467c3e9fce2f3d73e446f2feda.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*UfN2lA5F_Vd3wGElVPS3Jg.png"/></div></figure><p id="e9ff" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由三个模块组成。</p><ol class=""><li id="6574" class="lo lp iq ka b kb kc kf kg kj lq kn lr kr ls kv lt lu lv lw bi translated"><strong class="ka ir">首先生成与类别无关的区域建议。</strong></li><li id="3601" class="lo lp iq ka b kb lx kf ly kj lz kn ma kr mb kv lt lu lv lw bi translated"><strong class="ka ir">第二个模块是大型卷积神经网络，从每个区域提取固定长度的特征向量。</strong></li><li id="e974" class="lo lp iq ka b kb lx kf ly kj lz kn ma kr mb kv lt lu lv lw bi translated">第三个模块是一组特定于类的线性支持向量机。</li></ol><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/034903c45eea6f156e504b288a65aff5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*m8B8hG3D1aDJ3WBJig8u_A.png"/></div></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="6091" class="mj mk iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">2.选择性搜索</h1><p id="79d5" class="pw-post-body-paragraph jy jz iq ka b kb nn kd ke kf no kh ki kj np kl km kn nq kp kq kr nr kt ku kv ij bi translated">算法:</p><ol class=""><li id="2b73" class="lo lp iq ka b kb kc kf kg kj lq kn lr kr ls kv lt lu lv lw bi translated"><strong class="ka ir">使用有效的基于图的分割对输入图像进行初始子分割。将对应于分割部分的所有边界框添加到区域提议列表中。</strong></li><li id="d3a7" class="lo lp iq ka b kb lx kf ly kj lz kn ma kr mb kv lt lu lv lw bi translated"><strong class="ka ir">现在基于相似性递归地将较小的区域合并成较大的区域。</strong></li><li id="d830" class="lo lp iq ka b kb lx kf ly kj lz kn ma kr mb kv lt lu lv lw bi translated"><strong class="ka ir">在多次迭代中重复步骤2，并且在每次迭代中，对应于通过组合较小区域形成的较大段的bbox坐标被添加到区域提议列表中。最后我们将得到大约2000个地区提案。</strong></li></ol><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/47a39df7cf8ac6effcb6679d84cc0543.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*Qr2Qtz2dNprPsdmragilzA.png"/></div></figure><p id="19d4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">注意:选择性搜索使用4种相似性度量:颜色相似性、纹理相似性、尺寸相似性和形状紧密性。总相似性被认为是这些的线性组合</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="d64a" class="mj mk iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">3.特征提取和输出</h1><p id="f9d9" class="pw-post-body-paragraph jy jz iq ka b kb nn kd ke kf no kh ki kj np kl km kn nq kp kq kr nr kt ku kv ij bi translated">AlexNet用于从区域提议中提取特征。对于每个区域提议，我们获得4096维向量。通过将均值相减的227×227RGB图像向前传播通过五个卷积层和两个全连接层来计算特征。</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi gj"><img src="../Images/c065f399024958efb8baa19e769da64c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uAFqfgHw8h8ZZukYKiDndQ.png"/></div></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk">AlexNet</figcaption></figure><p id="67e4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该架构要求输入像素大小为227x227。因此，无论候选区域的大小或纵横比如何，我们都将它周围的紧密边界框中的所有像素扭曲到所需的大小。在扭曲之前，他们扩大了紧密边界框，使得在扭曲尺寸下，在原始框周围正好有p个像素的扭曲图像上下文(他们使用p= 16)。</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/2e93dc82d457a40f82718562e385cc45.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*gABrm6hz1XVqPzMnw6Tz7w.png"/></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk">wrapped training samples</figcaption></figure><p id="87cb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">特征向量由为每一类训练的SVM评分。对于每个类，高IoU(交集/并集)重叠边界框被拒绝，因为它们包围相同的对象。预测的边界框可以由另一个边界框回归器进一步微调。即，除了预测区域提议内对象的存在，该算法还预测四个偏移值，以增加边界框的精度。例如，给定一个区域提议，该算法将预测到一个人的存在，但是该区域提议中的那个人的脸可能已经被切成两半。因此，偏移值有助于调整区域提议的边界框。</p><h1 id="56a1" class="mj mk iq bd ml mm ny mo mp mq nz ms mt mu oa mw mx my ob na nb nc oc ne nf ng bi translated">4.结果</h1><h2 id="0908" class="od mk iq bd ml oe of dn mp og oh dp mt kj oi oj mx kn ok ol nb kr om on nf oo bi translated">4.1 2010年挥发性有机化合物</h2><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi op"><img src="../Images/38b0adcdb151d616d9029e1f01e3e8e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-rCM3W4au9qcmfZ5hFL9_Q.png"/></div></div></figure><p id="4251" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">RCNN和RCNN边界框都产生最高的mAP(平均平均预测)</p><h2 id="02e2" class="od mk iq bd ml oe of dn mp og oh dp mt kj oi oj mx kn ok ol nb kr om on nf oo bi translated">4.2 ILSVR 2013</h2><p id="897d" class="pw-post-body-paragraph jy jz iq ka b kb nn kd ke kf no kh ki kj np kl km kn nq kp kq kr nr kt ku kv ij bi translated">RCNN的表现优于2013年ILSVR竞赛的获胜者overfeat。</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/cfde37814f1e7e12379c10e8a9d678e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*NZtYAmPpjqOFlPYbIvdQGw.png"/></div></figure><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi or"><img src="../Images/230c972cafe6df33787904d49d09cd77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*LqoTP_BmfeDIUTxinqNtaQ.png"/></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk">ILSVR 2013 detections</figcaption></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="ac36" class="mj mk iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">参考</h1><ul class=""><li id="4503" class="lo lp iq ka b kb nn kf no kj os kn ot kr ou kv ov lu lv lw bi translated"><a class="ae ow" href="https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/" rel="noopener ugc nofollow" target="_blank">https://www . learnopencv . com/selective-search-for-object-detection-CPP-python/</a></li><li id="8346" class="lo lp iq ka b kb lx kf ly kj lz kn ma kr mb kv ov lu lv lw bi translated">https://arxiv.org/pdf/1311.2524.pdf<a class="ae ow" href="https://arxiv.org/pdf/1311.2524.pdf" rel="noopener ugc nofollow" target="_blank"/></li><li id="5b5f" class="lo lp iq ka b kb lx kf ly kj lz kn ma kr mb kv ov lu lv lw bi translated"><a class="ae ow" href="https://medium.com/coinmonks/review-r-cnn-object-detection-b476aba290d1" rel="noopener">https://medium . com/coin monks/review-r-CNN-object-detection-b 476 ABA 290d 1</a></li><li id="4234" class="lo lp iq ka b kb lx kf ly kj lz kn ma kr mb kv ov lu lv lw bi translated"><a class="ae ow" href="https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9" rel="noopener">https://medium . com/@ Jonathan _ hui/what-do-we-learn-from-region-based-object-detectors-faster-r-CNN-r-fcn-fpn-7e 354377 a7c 9</a></li></ul><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="ox oy l"/></div></figure></div></div>    
</body>
</html>