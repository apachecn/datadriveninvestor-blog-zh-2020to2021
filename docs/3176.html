<html>
<head>
<title>Assumptions Of Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归的假设</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/assumptions-of-linear-regression-90fe0fa17121?source=collection_archive---------10-----------------------#2020-06-04">https://medium.datadriveninvestor.com/assumptions-of-linear-regression-90fe0fa17121?source=collection_archive---------10-----------------------#2020-06-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="c273" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi kl translated"><span class="l km kn ko bm kp kq kr ks kt di"> H </span> ello世界！我的数据科学社区博客。在这里，我们将讨论线性回归的基本假设。有兴趣开始学习线性回归的人，那么这个博客是为你准备的。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi ku"><img src="../Images/435bf8e4099b9aa1a57fe70e86bc1b83.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/0*es973jA2hjc2slai.png"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">Scatter Plot [‘Image By Author’]</figcaption></figure><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi lg"><img src="../Images/ee85d3cd2c06f58a604d689b462a03cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/0*hX3pG82v7-Dva4hm.png"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">QQ Plot [‘Image By Author’]</figcaption></figure><p id="1cbe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">线性回归</strong>是一种评估一个或多个预测变量是否解释因变量(标准变量)的分析，是一种基于监督学习的机器学习算法。它执行回归任务来计算回归系数。回归模型是基于独立变量的目标预测。</p><div class="lh li gp gr lj lk"><a href="https://www.datadriveninvestor.com/2020/02/19/five-data-science-and-machine-learning-trends-that-will-define-job-prospects-in-2020/" rel="noopener  ugc nofollow" target="_blank"><div class="ll ab fo"><div class="lm ab ln cl cj lo"><h2 class="bd ir gy z fp lp fr fs lq fu fw ip bi translated">将定义2020年就业前景的五大数据科学和机器学习趋势|数据驱动…</h2><div class="lr l"><h3 class="bd b gy z fp lp fr fs lq fu fw dk translated">数据科学和ML是2019年最受关注的趋势之一，毫无疑问，它们将继续发展…</h3></div><div class="ls l"><p class="bd b dl z fp lp fr fs lq fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="lt l"><div class="lu l lv lw lx lt ly la lk"/></div></div></a></div><p id="1b01" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有不同种类的回归模型。这些模型的不同之处在于自变量和因变量之间的关系，以及正在使用的自变量的数量。</p><h1 id="20d9" class="lz ma iq bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">什么时候应该使用线性回归？</h1><p id="81aa" class="pw-post-body-paragraph jn jo iq jp b jq mx js jt ju my jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated">线性回归是一种参数模型。在参数模型的帮助下，我们只能处理回归问题。参数模型是出于分析目的对数据做出一些假设的模型。我们需要记住线性回归的假设，否则模型无法提供数据的良好结果。</p><p id="f70b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了执行成功的回归分析，我们有五个关键假设。</p><ol class=""><li id="0ae2" class="nc nd iq jp b jq jr ju jv jy ne kc nf kg ng kk nh ni nj nk bi translated">线性关系</li><li id="1d2e" class="nc nd iq jp b jq nl ju nm jy nn kc no kg np kk nh ni nj nk bi translated">自相关</li><li id="b5d6" class="nc nd iq jp b jq nl ju nm jy nn kc no kg np kk nh ni nj nk bi translated">多重共线性</li><li id="846e" class="nc nd iq jp b jq nl ju nm jy nn kc no kg np kk nh ni nj nk bi translated">异方差</li><li id="e9f6" class="nc nd iq jp b jq nl ju nm jy nn kc no kg np kk nh ni nj nk bi translated">误差项的正态分布</li></ol><p id="7087" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们走吧！</p><ol class=""><li id="f25c" class="nc nd iq jp b jq jr ju jv jy ne kc nf kg ng kk nh ni nj nk bi translated"><strong class="jp ir">线性关系:</strong></li></ol><p id="c5a0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您将线性模型与非线性、非加性数据集相匹配，回归算法将无法从数学上捕捉趋势，从而导致模型效率低下。此外，这将导致对未知数据集的错误预测。</p><p id="a689" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">寻找残差与拟合值图(解释如下)。此外，您可以在模型中包含多项式项(X，X，X)来捕捉非线性效应。</p><p id="e273" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">导入所需的包</p><pre class="kv kw kx ky gt nq nr ns nt aw nu bi"><span id="41e6" class="nv ma iq nr b gy nw nx l ny nz">%matplotlib inline<br/>import matplotlib.pyplot as plt<br/>plt.style.use('seaborn-whitegrid')<br/>from sklearn.datasets.samples_generator import make_regressionfrom sklearn.datasets.samples_generator import make_regression<br/>x1, y1 = make_regression(n_samples=100, n_features=1, noise=10)<br/>plt.plot(x1, y1, 'o', color='black');<br/>plt.title("Linear Relationship Exists")</span></pre><p id="3049" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.<strong class="jp ir">自相关:</strong></p><p id="73fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">误差项中相关性的存在大大降低了模型的准确性。这通常发生在下一个时刻依赖于前一个时刻的时间序列模型中。如果误差项相关，估计的标准误差往往会低估真实的标准误差。</p><p id="acf8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果发生这种情况，会导致置信区间和预测区间变窄。较窄的置信区间意味着95%的置信区间包含系数实际值的概率小于0.95。让我们通过一个例子来理解窄预测区间:</p><p id="0eb7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，X的最小二乘系数为15.02，其标准差为2.08(无自相关)。但是在存在自相关的情况下，标准误差降低到1.20。因此，预测区间从(12.94，17.10)缩小到(13.82，16.22)。</p><p id="9988" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，较低的标准误差会导致相关的p值低于实际值。这将使我们错误地得出一个参数具有统计显著性的结论。</p><p id="6c01" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">寻找德宾-沃森(DW)统计。它必须介于0和4之间。如果DW = 2，意味着没有自相关，0 &lt; DW &lt; 2 implies positive autocorrelation while 2 &lt; DW &lt; 4 indicates negative autocorrelation. Also, you can see the residual vs time plot and look for the seasonal or correlated pattern in residual values.</p><pre class="kv kw kx ky gt nq nr ns nt aw nu bi"><span id="b273" class="nv ma iq nr b gy nw nx l ny nz">from numpy import *<br/>import numpy as N<br/>import pylab as Pfn = 'data.txt'<br/>x = loadtxt(fn,unpack=True,usecols=[1])<br/>time = loadtxt(fn,unpack=True,usecols=[0])def estimated_autocorrelation(x):<br/>    n = len(x)<br/>    variance = x.var()<br/>    x = x-x.mean()<br/>    r = N.correlate(x, x, mode = 'full')[-n:]<br/>    #assert N.allclose(r, N.array([(x[:n-k]*x[-(n-k):]).sum() for k in range(n)]))<br/>    result = r/(variance*(N.arange(n, 0, -1)))<br/>    return resultP.plot(time,estimated_autocorrelation(x))<br/>P.xlabel('time (s)')<br/>P.ylabel('autocorrelation')<br/>P.show()</span></pre><p id="bf33" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3. <strong class="jp ir">多重共线性:</strong></p><p id="e802" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当发现自变量中度相关或高度相关时，就存在这种现象。在具有相关变量的模型中，找出预测变量与响应变量的真实关系是一项艰巨的任务。换句话说，很难找出哪个变量实际上有助于预测响应变量。</p><p id="8768" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另一点，随着相关预测因子的出现，标准误差有增加的趋势。而且，标准误差越大，置信区间越宽，导致斜率参数的估计精度越低。</p><p id="064b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，当预测值相关时，相关变量的估计回归系数取决于模型中可用的其他预测值。如果发生这种情况，你将会得出一个错误的结论，即一个变量强烈/微弱地影响着目标变量。因为，即使你从模型中去掉一个相关变量，它的估计回归系数也会改变。那可不好！</p><p id="91d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以使用散点图来显示变量之间的相关性。同样，你也可以使用VIF因子。VIF值&lt;= 4 suggests no multicollinearity whereas a value of &gt; = 10意味着严重的多重共线性。最重要的是，相关表也应该解决这个问题。</p><pre class="kv kw kx ky gt nq nr ns nt aw nu bi"><span id="f24c" class="nv ma iq nr b gy nw nx l ny nz">from statsmodels.stats.outliers_influence import variance_inflation_factordef calc_vif(X):# Calculating VIF<br/>    vif = pd.DataFrame()<br/>    vif["variables"] = X.columns<br/>    vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]return(vif)</span></pre><p id="a274" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4.<strong class="jp ir">异方差:</strong></p><p id="28a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">误差项中非恒定方差的存在导致异方差。一般来说，非常数方差出现在异常值或极端杠杆值的情况下。看起来，这些值得到了太多的权重，从而不成比例地影响了模型的性能。当这种现象发生时，样本外预测的置信区间往往过宽或过窄。</p><p id="4f03" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以查看残差与拟合值图。如果存在异方差，该图将呈现漏斗形模式(见下一节)。此外，您可以使用breu sch-Pagan/Cook-Weisberg测试或White general测试来检测这种现象。</p><pre class="kv kw kx ky gt nq nr ns nt aw nu bi"><span id="4f30" class="nv ma iq nr b gy nw nx l ny nz">from statsmodels.stats.diagnostic import het_breuschpagan<br/>from statsmodels.stats.diagnostic import het_white<br/>from statsmodels.formula.api import ols<br/>bp_stats = het_breuschpagan(model.resid,model.model.exog)<br/>from statsmodels.compat import lzip<br/>name=['F statistic','p-value']<br/>test = sms.het_goldfeldquandt(model.resid,model.model.exog)<br/>lzip(name,test)</span></pre><p id="952c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">5.<strong class="jp ir">误差项的正态分布</strong></p><p id="dc33" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果误差项是非正态分布的，置信区间可能变得过宽或过窄。一旦置信区间变得不稳定，就会导致基于最小二乘估计系数的困难。非正态分布的存在表明，有几个不寻常的数据点必须仔细研究，以便建立一个更好的模型。</p><p id="769a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可以看看QQ图(如下图)。你也可以进行正态性的统计检验，如科尔莫戈罗夫-斯米尔诺夫检验，夏皮罗-维尔克检验。</p><pre class="kv kw kx ky gt nq nr ns nt aw nu bi"><span id="643c" class="nv ma iq nr b gy nw nx l ny nz">import numpy as np <br/>import pylab <br/>import scipy.stats as stats</span><span id="4b45" class="nv ma iq nr b gy oa nx l ny nz">measurements = np.random.normal(loc = 20, scale = 5, size=100)   <br/>stats.probplot(measurements, dist="norm", plot=pylab)<br/>pylab.show()</span></pre><h1 id="c9e6" class="lz ma iq bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">结论</h1><p id="1a42" class="pw-post-body-paragraph jn jo iq jp b jq mx js jt ju my jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated">在这篇博客中，我们看到了线性回归的不同假设。这篇文章背后的动机是获得回归假设的直觉和洞察力。此外，我们没有涵盖文章中提到的所有测试。但是，我想，这有助于探索其他测试和方法。</p><p id="0aa7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你喜欢这篇文章，请给我鼓掌，并帮助其他人找到它。</p><p id="ed1b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，如果我错过了假设/主题，请告诉我。乐于学习和融入。</p><p id="c8db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与我联系:- <a class="ae oc" href="https://www.linkedin.com/in/dheerajkumar1997/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a></p><p id="8709" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与我联系:- <a class="ae oc" href="https://github.com/DheerajKumar97?tab=repositories" rel="noopener ugc nofollow" target="_blank"> Github </a></p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="od oe l"/></div></figure></div></div>    
</body>
</html>