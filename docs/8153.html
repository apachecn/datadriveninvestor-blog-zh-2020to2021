<html>
<head>
<title>Imbalance data handling strategies</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡数据处理策略</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/imbalance-data-handling-strategies-d4711b18246f?source=collection_archive---------13-----------------------#2021-01-03">https://medium.datadriveninvestor.com/imbalance-data-handling-strategies-d4711b18246f?source=collection_archive---------13-----------------------#2021-01-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/a3a7eb70aa2404fdd5fa5f218f293fa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*yLpYc6qV9LYneI3KO9AsCA.png"/></div></figure><h1 id="4a02" class="jx jy it bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">介绍</h1><p id="f031" class="pw-post-body-paragraph kv kw it kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">如果你从事机器学习或数据科学，你应该听说过不平衡数据处理这个术语。当大部分数据样本属于一个类别而只有少数样本属于另一个类别时，就会出现这种情况。这个问题经常出现在一些场景中，如检测异常情况，如识别罕见疾病、银行欺诈交易等。</p><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/b6665265688b699b96cd04dde32b400f.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*9xSKjc4RmUdiZD-qiNGa_Q.png"/></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk">Distribution of majority and minority class</figcaption></figure><p id="e026" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">我们将看一个不平衡数据的例子。考虑这样一个场景，在医院里对100名病人进行体检。</p><p id="0010" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">总观察值= 100，检测为阳性的患者数= 20，检测为阴性的患者数= 80，不平衡比率= 1:4。</p><p id="2007" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">我们不能保证我们可以通过采取或改变上述实验的样本数量来获得一个平衡的比率。</p><h1 id="cd77" class="jx jy it bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">数据不平衡的问题</h1><p id="3696" class="pw-post-body-paragraph kv kw it kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">传统的评价指标不能用来衡量分类不平衡数据的性能。传统的分类算法(如逻辑回归和决策树算法)偏向于数据集的偏斜度。因此，很有可能所有样本都被预测到具有多数样本的一个类别中。因为有时少数类样本可能被当作噪声忽略。混淆矩阵将清楚地显示实际标签和预测标签的样本分布情况。</p><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mh"><img src="../Images/16c9480368db47d948dea67121c80b3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iywOTNJFMmRl2ecLhHI8zQ.jpeg"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk">Confusion Matrix</figcaption></figure><h1 id="9be3" class="jx jy it bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">处理数据不平衡的策略</h1><h2 id="6475" class="mm jy it bd jz mn mo dn kd mp mq dp kh lg mr ms kl lk mt mu kp lo mv mw kt mx bi translated">数据级策略(重采样)</h2><p id="4e95" class="pw-post-body-paragraph kv kw it kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">重采样方法通过为少数类生成新的样本，在不平衡的数据集中创建一个平衡。这个过程必须在向模型提供数据之前的预处理阶段完成。这里我们可以通过减少多数类中的样本数或者增加少数类中的样本数来达到平衡。我们可以讨论许多可用于处理不平衡数据的重采样方法。</p><p id="44a8" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">我们可以使用以下命令安装不平衡学习:</p><pre class="lu lv lw lx gt my mz na nb aw nc bi"><span id="2c45" class="mm jy it mz b gy nd ne l nf ng">sudo pip install imbalanced-learn</span></pre><p id="ccdc" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">此外，我们可以通过运行以下命令来检查安装的库的版本:</p><pre class="lu lv lw lx gt my mz na nb aw nc bi"><span id="a877" class="mm jy it mz b gy nd ne l nf ng">import imblearn<br/>print(imblearn.__version__)</span></pre><p id="866b" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">可以使用以下代码生成不平衡的虚拟数据集:</p><pre class="lu lv lw lx gt my mz na nb aw nc bi"><span id="a4bd" class="mm jy it mz b gy nd ne l nf ng">from sklearn.datasets import make_classification</span><span id="7470" class="mm jy it mz b gy nh ne l nf ng"># defining the dataset<br/>train_X, train_y = make_classification(n_samples=5000, weights=[0.98])</span></pre><p id="8c2f" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated"><strong class="kx iu">随机欠采样</strong></p><p id="d99c" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">在这种情况下，该算法从多数类中随机选择并消除样本，直到两个类达到平衡。因此，训练数据将减少到非常小的数量，这可能导致训练时间减少。丢失重要数据样本的可能性很高。因此，这将导致不适当的数据分布。</p><p id="1473" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">随机过采样的样本代码如下所示:</p><pre class="lu lv lw lx gt my mz na nb aw nc bi"><span id="2f1f" class="mm jy it mz b gy nd ne l nf ng">from imblearn.under_sampling import RandomUnderSampler</span><span id="73ee" class="mm jy it mz b gy nh ne l nf ng"># defining oversampling<br/>oversample = RandomUnderSampler(sampling_strategy='minority')</span><span id="916e" class="mm jy it mz b gy nh ne l nf ng"># fitting the dataset to the model<br/>new_X, new_y = oversample.fit_resample(train_X, train_y)</span><span id="ed17" class="mm jy it mz b gy nh ne l nf ng"># summarizing<br/>print(len(train_y), len(new_y))</span></pre><p id="3a55" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated"><strong class="kx iu">随机过采样</strong></p><p id="72af" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">随机过采样算法通过复制随机选择的少数样本来增加少数类中的样本数量。这种方法优于欠采样技术，因为没有丢失信息的可能性。但是过度拟合的可能性很高，因为我们要多次复制现有的少数样本。</p><pre class="lu lv lw lx gt my mz na nb aw nc bi"><span id="101e" class="mm jy it mz b gy nd ne l nf ng">from imblearn.over_sampling import RandomOverSampler</span><span id="1b8f" class="mm jy it mz b gy nh ne l nf ng"># defining undersampling<br/>undersample = RandomOverSampler(sampling_strategy='majority')</span><span id="34fe" class="mm jy it mz b gy nh ne l nf ng"># fit to the model<br/>new_X, new_y = undersample.fit_resample(train_X, train_y)</span><span id="0c53" class="mm jy it mz b gy nh ne l nf ng"># summarizing<br/>print(len(train_y), len(new_y))</span></pre><p id="7730" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated"><strong class="kx iu">不平衡数据的综合少数过采样技术(SMOTE) </strong></p><p id="d2de" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">该算法有助于减少过拟合的影响，因为它忽略了重复复制现有样本。它从现有的少数样本中合成新的样本。这些新创建的样本将被添加回原始数据集中。最后，新数据集将用于训练模型。</p><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi ni"><img src="../Images/62e7678b7a0110c27267c88c8eb2a9b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gcVUObXIwjnXUlk_CU31qw.png"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk">SMOTE Algorithm</figcaption></figure><p id="a892" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">SMOTE算法随机选择两个少数点，并在连接两个所选样本的线上合成一个新点。因此，该算法克服了随机过采样的过拟合问题和随机欠采样的信息丢失问题。但是，SMOTE不考虑相邻的类，而是创建可能与多个类重叠的样本。而且，如果我们处理高维数据，这种算法不会更有效和高效。</p><p id="a157" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">SMOTE的示例代码如下所示:</p><pre class="lu lv lw lx gt my mz na nb aw nc bi"><span id="a1b4" class="mm jy it mz b gy nd ne l nf ng">from imblearn.over_sampling import SMOTE</span><span id="d7f1" class="mm jy it mz b gy nh ne l nf ng"># defining SMOTE<br/>smote = SMOTE()</span><span id="337c" class="mm jy it mz b gy nh ne l nf ng"># fit the dataset to the model<br/>new_X, new_y = smote.fit_resample(train_X, train_y)</span><span id="4c75" class="mm jy it mz b gy nh ne l nf ng"># summarizing<br/>print(len(train_y), len(new_y))</span></pre><p id="6b96" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated"><strong class="kx iu">几何击杀</strong></p><p id="de91" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">几何SMOTE是SMOTE算法的推广。G-SMOTE初始化随机选择的少数点周围的几何区域，并在初始化的空间中合成新的样本。并且G-SMOTE的表现优于SMOTE。除了SMOTE之外，G-SMOTE算法主要实现三个目标。</p><ul class=""><li id="82ef" class="nj nk it kx b ky mc lc md lg nl lk nm lo nn ls no np nq nr bi translated">该算法试图定义一个安全区域并在定义的区域内合成点。这将有助于减少噪音点的产生。</li><li id="ab3f" class="nj nk it kx b ky ns lc nt lg nu lk nv lo nw ls no np nq nr bi translated">增加各种类型或种类的点。因此，少数民族阶层地区可以进一步扩大。</li><li id="2075" class="nj nk it kx b ky ns lc nt lg nu lk nv lo nw ls no np nq nr bi translated">使用几何方程并基于参数化来定义该空间。</li></ul><h2 id="1e7b" class="mm jy it bd jz mn mo dn kd mp mq dp kh lg mr ms kl lk mt mu kp lo mv mw kt mx bi translated">算法集成技术</h2><p id="f914" class="pw-post-body-paragraph kv kw it kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">可以修改现有算法来处理dat不平衡，而不是改变数据。集成方法可以用来提高分类器的性能。这里，在两个阶段中找到分类器，并且将给出聚合预测。</p><p id="61d7" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated"><strong class="kx iu">装袋</strong></p><p id="e008" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">该算法通过替换从不平衡数据中产生n个组。学习算法单独学习它们，我们可以结合预测得到一个最终的输出。这种方法有助于减少差异和过度拟合。</p><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nx"><img src="../Images/62a012ce44317a7a222339cd6d4a94fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sa0f2WU4rzFmJNRZ9JyUkQ.png"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk">Bagging Approach</figcaption></figure><p id="3324" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">随机森林算法以类似的逻辑工作。尽管如此，这种算法在不平衡的数据集上并没有表现得更好。当我们选择替换样本时，该数据集的子集可能不包含数据样本，也不包含同一样本的一个或多个副本。</p><p id="fd5c" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">下面给出了使用bagging classifier scikit-sk learn类的示例代码:</p><pre class="lu lv lw lx gt my mz na nb aw nc bi"><span id="ef7b" class="mm jy it mz b gy nd ne l nf ng">from sklearn.ensemble import BaggingClassifier</span><span id="6572" class="mm jy it mz b gy nh ne l nf ng"># defining classifier<br/>classifier = BaggingClassifier()</span><span id="26bf" class="mm jy it mz b gy nh ne l nf ng"># fit the dataset to the model<br/>classifier.fit_resample(train_X, train_y)</span></pre><p id="a202" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated"><strong class="kx iu">增压</strong></p><p id="8e59" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">Boosting算法结合了弱学习模型，以产生强学习算法。用基础学习者初始化Boosting算法。基础学习者被认为是弱学习者。如果我们稍微改变数据集，得到的模型有很大偏差，那么就会被认为是弱学习者。在完成基础学习阶段后，下一个级别的学习者将主要关注预测错误的场景。</p><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi ny"><img src="../Images/4203b1c5803fb8788d2e365a03066b16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Hx3wtEINefrefIOLh8BOw.png"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk">Boosting algorithm</figcaption></figure><p id="ee59" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">最后，我们可以说，没有一种方法可以作为处理数据不平衡的一站式解决方案。为了取得更好的成绩，我们必须尝试各种方法。</p><p id="7c2d" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated"><strong class="kx iu">参考文献</strong></p><p id="b51a" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">[1] N. V. Chawla、K. W .鲍耶、L. O. Hall和W. P. Kegelmeyer，“SMOTE:合成少数过采样技术”，<em class="nz"> jair </em>，第16卷，第321-357页，2002年6月。</p><p id="faa3" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated">[2]G. Douzas和F. Bacao，“几何SMOTE对SMOTE的几何增强插入式替代”，<em class="nz">信息科学</em>，第501卷，第118–135页，2019年10月。</p><p id="aef9" class="pw-post-body-paragraph kv kw it kx b ky mc la lb lc md le lf lg me li lj lk mf lm ln lo mg lq lr ls im bi translated"><strong class="kx iu">访问专家视图— </strong> <a class="ae oa" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="kx iu">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>