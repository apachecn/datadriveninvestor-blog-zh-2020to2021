<html>
<head>
<title>How do you use Yolo to detect objects?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你是怎么用Yolo检测物体的？</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/how-do-you-use-yolo-to-detect-objects-8bb634ec7d2c?source=collection_archive---------6-----------------------#2020-09-01">https://medium.datadriveninvestor.com/how-do-you-use-yolo-to-detect-objects-8bb634ec7d2c?source=collection_archive---------6-----------------------#2020-09-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="35ac" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">有史以来最简单的对象检测教程—使用YoloV5和Python</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/577809302c984566f357942c9d834e74.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*MkC411R1rYxzzJZ14ul7mw.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk"><a class="ae ku" href="https://commons.wikimedia.org/wiki/File:Alain_St._Ange,_October_2014.jpg" rel="noopener ugc nofollow" target="_blank">Source</a>. <a class="ae ku" href="https://en.wikipedia.org/wiki/en:Creative_Commons" rel="noopener ugc nofollow" target="_blank">Creative Commons</a> <a class="ae ku" href="https://creativecommons.org/licenses/by/4.0/deed.en" rel="noopener ugc nofollow" target="_blank">Attribution 4.0 International</a>. Adaptations by author.</figcaption></figure><p id="6aa6" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在本文中，我将给出开始使用YoloV5进行对象检测的步骤。对象检测的目标是在图像上的对象上绘制包围盒。YoloV5是完成这项工作的最佳工具之一，只需少量的工作。</p><p id="b4a4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">YoloV5模型已经过预训练。我们可以选择进一步训练它，但在本文中，我将展示如何开箱即用YoloV5。</p><p id="8588" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">你可以在这里找到完整的笔记本<a class="ae ku" href="https://jooskorstanje.com/super_simple_yolo_notebook.html" rel="noopener ugc nofollow" target="_blank"><strong class="kx iu"/></a><strong class="kx iu">】以防你想跟随。</strong></p><h1 id="f251" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">1.安装YoloV5</h1><p id="084b" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated">下面的代码块将把预先训练好的YoloV5模型下载到您的计算机上。</p><p id="879d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">它还将安装所需的库和需求。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h1 id="458b" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">2.把你的图片放在一个目录里</h1><p id="03db" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated">在本教程中，我使用了6张来自维基共享的图片，这是我手动下载的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/cf00f027f5ef030e6370c2a8d4740efa.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/0*ldKPdSzfMEydtBsZ.jpg"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/862df0393ea221909fa32eb76077792c.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/0*XBxNZYIHjH_UfxaZ.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk"><a class="ae ku" href="https://commons.wikimedia.org/wiki/File:Alex_Smith_TEDx_Speech.png" rel="noopener ugc nofollow" target="_blank">Source</a>. <a class="ae ku" href="https://en.wikipedia.org/wiki/en:Creative_Commons" rel="noopener ugc nofollow" target="_blank">Creative Commons</a> <a class="ae ku" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en" rel="noopener ugc nofollow" target="_blank">Attribution-Share Alike 4.0 International</a>.</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/6f8d3608d03878a87bf8122550252554.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/0*xKB60Z2kQaJ9h-kN.jpg"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk"><a class="ae ku" href="https://commons.wikimedia.org/wiki/File:Andrei_codrescu.jpg" rel="noopener ugc nofollow" target="_blank">Source</a>. <a class="ae ku" href="https://en.wikipedia.org/wiki/en:Creative_Commons" rel="noopener ugc nofollow" target="_blank">Creative Commons</a> <a class="ae ku" href="https://creativecommons.org/licenses/by/2.0/deed.en" rel="noopener ugc nofollow" target="_blank">Attribution 2.0 Generic</a>.</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/9d0d47256fe034ec55ea8124651c68b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*W5q-BrXjKkZ64qha.jpg"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk"><a class="ae ku" href="https://commons.wikimedia.org/wiki/File:Anna_Kaplan_2018.jpg" rel="noopener ugc nofollow" target="_blank">Source</a>. <a class="ae ku" href="https://en.wikipedia.org/wiki/en:Creative_Commons" rel="noopener ugc nofollow" target="_blank">Creative Commons</a> <a class="ae ku" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en" rel="noopener ugc nofollow" target="_blank">Attribution-Share Alike 4.0 International</a>.</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/52d44cc038bda164732fff7c455e44c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/0*dXWn2uUQ_glwq3Ar.jpg"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk"><a class="ae ku" href="https://commons.wikimedia.org/wiki/File:Astronaut_candidate_Jeremy_Hansen_speaks_to_a_crowd_at_Johnson_Space_Center.jpg" rel="noopener ugc nofollow" target="_blank">Source</a>. <a class="ae ku" href="https://en.wikipedia.org/wiki/en:Creative_Commons" rel="noopener ugc nofollow" target="_blank">Creative Commons</a> <a class="ae ku" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en" rel="noopener ugc nofollow" target="_blank">Attribution-Share Alike 4.0 International</a>.</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/a0989edda3de4c282504a1af283c2000.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/0*qbZYGxkk0KOLgwi9.jpg"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk"><a class="ae ku" href="https://commons.wikimedia.org/wiki/File:6_GFCA_2018_Myim_Bialik.jpg" rel="noopener ugc nofollow" target="_blank">Source</a>. Public Domain Image.</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/06e235a0c70d178b6774d504f044e4ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/0*BZxesOIsImygHMhN.jpg"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk"><a class="ae ku" href="https://commons.wikimedia.org/wiki/File:6_GFCA_2018_Myim_Bialik.jpg" rel="noopener ugc nofollow" target="_blank">Source</a>. <a class="ae ku" href="https://en.wikipedia.org/wiki/en:Creative_Commons" rel="noopener ugc nofollow" target="_blank">Creative Commons</a> <a class="ae ku" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en" rel="noopener ugc nofollow" target="_blank">Attribution-Share Alike 4.0 International</a>.</figcaption></figure><h1 id="2874" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">3.使用预先训练的Yolov5进行预测</h1><p id="ce66" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated">由于我们使用预训练的YoloV5模型，因此可以直接进入预测阶段。我们可以使用下面一行预测目录中的所有图像:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="0d23" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这将在位于<em class="mx"> yolov5/inference/output </em>的目录中生成包含原始图像和边界框的新图像。</p><div class="my mz gp gr na nb"><a href="https://www.datadriveninvestor.com/2020/07/23/learn-data-science-in-a-flash/" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab fo"><div class="nd ab ne cl cj nf"><h2 class="bd iu gy z fp ng fr fs nh fu fw is bi translated">一瞬间学会数据科学！？数据驱动的投资者</h2><div class="ni l"><h3 class="bd b gy z fp ng fr fs nh fu fw dk translated">在我之前的职业生涯中，我是一名训练有素的古典钢琴家。还记得那些声称你可以…</h3></div><div class="nj l"><p class="bd b dl z fp ng fr fs nh fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nk l"><div class="nl l nm nn no nk np ko nb"/></div></div></a></div><h1 id="45e9" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">4.检查结果</h1><p id="910e" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated">为了检查结果，我们只需打开新生成的带注释的图像，如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/cd3b63e6351501456d07d639d6095ca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KP9S43NGRxq9s565BiCiMA.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nv"><img src="../Images/44e376d58f44b0c64963bbc98dcdd07f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bq7bZksYkTnxG_jOWF3zBg.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nw"><img src="../Images/851323eb9f47b11b9ca670a23c0321c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l1tDTvy9T5-ej8mNEgJbVg.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nx"><img src="../Images/2504647a26e5eb972ef2ee7c7429fe70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wuyMp_bnYouos_rJI7RJsQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nx"><img src="../Images/153df9d85795f7e7b1852b41721387bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qhmt-QTXmezTV_bZRslYxQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nv"><img src="../Images/01ed5c586b54ff09de584e934ba17428.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5QHkWahET_84071bMczz7g.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi ny"><img src="../Images/d94ac4707b986a662b7e6e5bda43ed27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5ujD2E6aQg3M9izzQ0fhvA.png"/></div></div></figure><h1 id="97b1" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">结论</h1><p id="1844" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated">YoloV5让物体检测的入门变得超级简单。为了适应您自己的图像并获得更好的准确性，您还可以通过重新训练来调整模型，但这将在以后的文章中讨论。<em class="mx">目前，感谢阅读！</em></p><h2 id="d472" class="nz ls it bd lt oa ob dn lx oc od dp mb le oe of md li og oh mf lm oi oj mh ok bi translated">访问专家视图— <a class="ae ku" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>