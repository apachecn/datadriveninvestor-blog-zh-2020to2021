<html>
<head>
<title>How do Regression Trees Work?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归树是如何工作的？</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/how-do-regression-trees-work-94999c5105d?source=collection_archive---------4-----------------------#2020-04-15">https://medium.datadriveninvestor.com/how-do-regression-trees-work-94999c5105d?source=collection_archive---------4-----------------------#2020-04-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7fa9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">之前我们谈到了决策树以及如何在分类问题中使用它们。现在我们把注意力转移到回归树上。回归树的不同之处在于，它们旨在预测一个可以被认为是实数的结果(例如，房子的价格或个人的身高)。“回归”这个词对你来说可能听起来很熟悉，也应该如此。我们看到这个术语出现在一个非常流行的叫做线性回归的统计技术中。尽管线性回归和回归并不相似，但是“回归”部分背后的基本思想是相同的。回归试图确定一个因变量和一系列自变量之间的关系。</p><p id="57ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们希望说明线性回归和回归树在有用性上的区别，构建我们自己的回归树，并用Python实例化一个回归树。</p><h1 id="b9fb" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">问题</strong></h1><p id="0c7a" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">假设我们是科学家，已经开发出一种全新的药物来治疗普通流感。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/927d42e9f102527bafd4972dc8d6719a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bjyQC6A8dhYuKcFC_iunYw.png"/></div></div></figure><p id="a2a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，我们不知道患者的最佳剂量。为了研究这个问题，我们进行了一个不同剂量的临床试验，并测量每个剂量的有效性。最终，我们希望准确预测药物在某一剂量水平下的疗效。</p><h2 id="f893" class="mb kn iq bd ko mc md dn ks me mf dp kw jy mg mh la kc mi mj le kg mk ml li mm bi translated">线性回归</h2><p id="6d1a" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">如果我们在一些假设的场景中绘制临床试验的结果，数据点可能看起来类似于下图。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mn"><img src="../Images/6a283cf821f55509a6a08e4470bc8b45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lr4rzUCDO7cb3wWKvrSnUg.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Plot A</figcaption></figure><p id="3f47" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上图(图A)中的数据点表明药物剂量和药物效率之间存在某种正相关。这意味着一般来说，剂量越高，效率越高。我们可以很容易地用线性回归拟合出该数据的直线，并使用最佳拟合线来绘制预测。例如，23毫克的药物剂量具有63%效率的预测值。不幸的是，数据似乎并不总是表现得那么好。更现实的情况是，我们最终得到的数据点可能会更加嘈杂。这在下面的情节中可以看到。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ms"><img src="../Images/ed00b5a6206182eb936f1731800b00c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HqqTwl1dB2XrFLyHU_91IQ.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Plot B</figcaption></figure><p id="7f92" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将线性回归应用于上述数据点(图B ),我们注意到，对于23 mg的药物剂量，预测值和实际值之间存在很大差异。显然，线性回归可能不是对数据建模的最佳方法。好吧，我们还能用什么方法呢？是的，你猜对了，就在标题里:<strong class="jp ir">回归树。</strong></p><div class="mt mu gp gr mv mw"><a href="https://www.datadriveninvestor.com/2020/03/24/encoder-decoder-sequences-how-long-is-too-long/" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd ir gy z fp nb fr fs nc fu fw ip bi translated">编码器解码器序列:多长是太长？数据驱动的投资者</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">在机器学习中，很多时候我们处理的输入是序列，输出也是序列。我们称这样的一个…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk lz mw"/></div></div></a></div><h2 id="20e5" class="mb kn iq bd ko mc md dn ks me mf dp kw jy mg mh la kc mi mj le kg mk ml li mm bi translated">回归树</h2><p id="cedb" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">回归树类似于决策树，但是有代表真实值的叶节点。为了说明回归树，我们将从一个简单的例子开始。不要担心，我们将很快进入细节。对于我们树的<em class="nl">根节点</em>，我们问:“剂量小于14 mg吗？”。然后使用图B中的数据点，我们应该得到一个类似下图的树。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/71f0a1b08e68c460f4dfab76315b52c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*lP8cFrVYC6u_9RDtu7DScQ.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Example of a regression tree</figcaption></figure><p id="4638" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果根节点中问题的答案是“真”，那么我们被定向到左边的节点，否则，我们被定向到右边的节点，这样继续下去。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nn"><img src="../Images/46f7b7b4fde1af5780f83da2e71ae233.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oNc8APhYCBZYuVNDKQD1Hw.png"/></div></div></figure><p id="50c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们关注左边的第一个叶节点:我们是如何得到4.5%这个值的？因为我们在根节点中有一个阈值14，我们查看比14少<strong class="jp ir"/>的观察值，并计算它们的<strong class="jp ir">平均值</strong>。在我们的例子中，前6次观察的平均值是4.5%(效率)。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi no"><img src="../Images/f1d3fb1a43b2ce0fad4bbdcff6625067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xMWxnU8S-ZesWCatCgQ95Q.png"/></div></div></figure><p id="5e3a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦第一个叶节点完成，我们可以对右侧的节点应用相同的过程。下图中的每个红色块代表一个叶节点。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi np"><img src="../Images/f8a5b30290c50e85a2b3982b14c9d788.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dsvYEUthFWoeDEMqmpvEyA.png"/></div></div></figure><blockquote class="nq nr ns"><p id="8851" class="jn jo nl jp b jq jr js jt ju jv jw jx nt jz ka kb nu kd ke kf nv kh ki kj kk ij bi translated"><em class="iq">让我们看看如何得到</em><strong class="jp ir"><em class="iq"/></strong><em class="iq"/><strong class="jp ir"><em class="iq"/></strong><em class="iq">(效率为100%的叶节点)</em></p></blockquote><p id="4d65" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过遵循节点设定的条件直到最后，我们得到右边的最后一个叶节点。如果剂量大于14但小于29和24，我们将剩下一个间隔，在下图中突出显示。红框中4次观察的平均药物有效性为100%。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nw"><img src="../Images/37d5fec071c82aa51a32e7b30f53095f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hY2V0E9NHBOxow-tJoTq0Q.png"/></div></div></figure><p id="222b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，该树使用平均值(100%)作为14.5到23.5之间剂量的预测值。</p><h1 id="ab70" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">构建我们自己的回归树</h1><p id="f026" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">既然我们已经完成了回归树的示例，让我们使用图b中相同的非结构化数据从头开始开发一个。构建回归树的第一部分是<strong class="jp ir">决定根节点</strong>中的阈值。你还记得博客中关于决策树的类似问题吗？</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nx"><img src="../Images/f3c638f69ce8c7976fad1dc3e2a0be38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0gJLnRuyKtryaB01CaQqHA.png"/></div></div></figure><p id="5490" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了帮助我们做出决定，我们将首先关注两个最小剂量<strong class="jp ir">的观察结果</strong>。这两名患者之间的平均剂量为<strong class="jp ir"> 3毫克</strong>。我们在点3处画了一条垂直线来表示我们数据中的分裂。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ny"><img src="../Images/122230f45bf61a605f481f3e4534d09f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NPCcV6xp6gN-l-EY6Re35g.png"/></div></div></figure><p id="febf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">突出显示为红色的两个点代表两个最小的剂量。红色虚线将数据分为两部分。下一步是计算红色虚线左侧和右侧观察值的平均效率。在左侧(小于3 mg)，只有一个观察值，其平均值为0%。右手边(大于3mg)观察多，平均值38.8。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/8b089ac0163ed142e67f4babd3f62396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wj36hIG-wFWuHyK17pHC7Q.png"/></div></div></figure><p id="1869" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们用“剂量&lt; 3” as the root node and two subsequent leaf nodes. The average on the left-hand side of the dotted line goes into the left leaf node and the average on the right-hand side goes to the right leaf node. The values in the leaf nodes are the predictions that this simple tree will make for drug effectiveness.</p><blockquote class="nq nr ns"><p id="b64c" class="jn jo nl jp b jq jr js jt ju jv jw jx nt jz ka kb nu kd ke kf nv kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">创建一个简单的树如何确定我们的简单树拆分数据</em> </strong> <em class="iq">有多好？</em></p></blockquote><p id="f5ae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">左叶节点完美地预测了结果。剂量小于3毫克的实际效率是0%，我们的树也是这样预测的。但是，当有这么多的观测值需要考虑时，我们如何检查右侧的准确性呢？</p><p id="720c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以使用线性回归中常用的一种方法:</p><blockquote class="nz"><p id="99ad" class="oa ob iq bd oc od oe of og oh oi kk dk translated">残差平方和</p></blockquote><p id="ee8a" class="pw-post-body-paragraph jn jo iq jp b jq oj js jt ju ok jw jx jy ol ka kb kc om ke kf kg on ki kj kk ij bi translated">残差是从数据点到回归线的距离的度量。SSR测量我们的数据和回归树预测的值之间的总体差异。一般来说，较低的SSR表明回归模型可以更好地解释数据，而较高的SSR表明模型不能很好地解释数据。SSR的公式:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/f5f53ce25c5741957f5b5a0aa3fd14df.png" data-original-src="https://miro.medium.com/v2/resize:fit:296/format:webp/1*TEcgOkHbFbiSoHgQ_MTjkQ.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Formula for SSR</figcaption></figure><p id="2263" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以通过构造从观察值到预测值的直线来显示简单树的残差。请再次注意，在左侧，预测值等于观察值。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi op"><img src="../Images/f31bbca1fc4932ae3d6afb04f0cadacb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4yP6HKADZhWV4yYh1eVX5Q.png"/></div></div></figure><p id="a045" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以使用残差来量化简单树所做预测的质量。接下来，我们通过添加左右叶节点的SSR来计算树的SSR。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/c23a9b9a9b0394adf871bebb485e1d44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*_Ko1JgHk1Q_DUPOsPjeZDw.png"/></div></figure><p id="8586" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们得到该树的总SSR值为27.5。然后将整个过程应用于第二个和第三个最低的观察值、第三和第四个最低的观察值，依此类推...</p><p id="ff0b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦我们计算了由成对的观察得到的树的所有SSR值，我们可以将SSR值绘制成剂量阈值的函数。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi or"><img src="../Images/5f3da6c0eab2be5e52fd9b221a997935.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*cYMZIUI5JpsfhCSsYCFIUQ.png"/></div></figure><p id="39d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">最低的SSR值代表剂量阈值，它将位于树的根节点。</strong>在这种情况下，最低的SSR值是14。</p><p id="388c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦决定了根节点，数据将被分成左右两个节点。这些节点还需要一个最佳阈值来进一步分割数据。我们如何着手选择这些阈值？用于获得根节点的相同过程现在被应用于树的剩余节点。每个节点应该有一个代表可用的最低SSR值的阈值。一旦数据不能被进一步分割(在训练数据中只有一个观测值)或者分割是多余的(如果所有观测值具有相同的值)，节点本身就成为叶节点。</p><h1 id="de47" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">用Python构建回归树</strong></h1><p id="489a" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在这里，我们将快速浏览一下用Sklearn包在Python中构建回归树</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi os"><img src="../Images/0d80dd237d059863b2b147db8321da73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jVKsZjucxOyWWbEWh1I2hw.jpeg"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Photo by <a class="ae kl" href="https://unsplash.com/@codestorm?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Safar Safarov</a> on <a class="ae kl" href="https://unsplash.com/s/photos/code?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="1e29" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">关于数据集</strong></p><p id="483a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将生成一个随机数据集来代表前面讨论的临床试验示例。</p><p id="df96" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="nl">注意</em>:在笔记本中，我们不清理数据。这样做的原因是博客的目的是说明如何运行回归树分类器，而不是展示数据清理技术。正确清理数据的责任在读者身上。数据清理和准备是数据科学领域中极其重要的阶段，不容忽视。</p><p id="8cb3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">导入必要的库</strong></p><pre class="lq lr ls lt gt ot ou ov ow aw ox bi"><span id="4c47" class="mb kn iq ou b gy oy oz l pa pb">import pandas as pd<br/>import numpy as np<br/>from sklearn.tree import DecisionTreeRegressor<br/>from sklearn.model_selection import train_test_split<br/>import matplotlib.pyplot as plt</span></pre><p id="404c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">创建随机数据集</strong></p><pre class="lq lr ls lt gt ot ou ov ow aw ox bi"><span id="06aa" class="mb kn iq ou b gy oy oz l pa pb">rng = np.random.RandomState(1)<br/>X = np.sort(5 * rng.rand(80, 1), axis=0)<br/>y = np.sin(X).ravel()<br/>y[::5] += 3 * (0.5 - rng.rand(16))</span></pre><p id="88bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用上面的代码生成x和Y数组。用户可以选择自己的重现性参数。</p><p id="5f3c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">查看数据集</strong></p><pre class="lq lr ls lt gt ot ou ov ow aw ox bi"><span id="a2e2" class="mb kn iq ou b gy oy oz l pa pb">plt.figure()<br/>plt.xlabel("Dosage (mg)")<br/>plt.ylabel("Efficiency")<br/>plt.scatter(X, y)<br/>plt.show()</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/dc03ee728e20d2a6928a33b77cf481ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*xsF4y_4rs5po3QikbsppAw.png"/></div></figure><p id="4fa8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与例子中的因变量不同，我们将考虑一些任意的药物剂量效率的度量。注意图中的趋势。最佳剂量似乎是1.8毫克左右。我们的目标是在给定剂量的情况下预测药物的疗效，所有这些都要借助回归树。</p><p id="686e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">创建培训和测试数据集</strong></p><p id="3db6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一步是将我们的数据分成<strong class="jp ir">训练</strong>和<strong class="jp ir">测试</strong>数据集。训练数据集用于训练/创建回归树。然后在我们的测试数据集上测试回归树，看看它在看不见的数据上表现如何。我们使用Sklearn.model_selection中的train_test_split函数来实现这一点。</p><pre class="lq lr ls lt gt ot ou ov ow aw ox bi"><span id="bfd1" class="mb kn iq ou b gy oy oz l pa pb"># Create the training and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)</span></pre><p id="34c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">实例化回归树分类器</strong></p><p id="4258" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们实例化回归树分类器并设置参数。所有参数在<a class="ae kl" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html" rel="noopener ugc nofollow" target="_blank">这里</a>都有详细说明。我们将只讨论其中的几个:</p><p id="6101" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1)<strong class="jp ir">criteria<em class="nl">{ " MSE "，" friedman_mse "，" mae"}，default="mse" </em> : </strong>衡量一个拆分质量的函数。支持的标准是均方误差的“mse ”,其等同于作为特征选择标准的方差减少，并使用每个终端节点的平均值最小化L2损失，“friedman_mse ”,其使用具有friedman改进分数的均方误差用于潜在分裂，以及平均绝对误差的“mae ”,其使用每个终端节点的中值最小化L1损失。</p><p id="2fd7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2) <strong class="jp ir"> max_depth: <em class="nl"> int，default=None: </em> </strong>树的最大深度。如果没有，则扩展节点，直到所有叶子都是纯的，或者直到所有叶子包含少于min_samples_split样本。</p><p id="198d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3)<strong class="jp ir">min _ samples _ split:<em class="nl">int或float，default=2 </em> : </strong>拆分内部节点所需的最小样本数</p><p id="7304" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可以调整参数，以便根据一些选择的标准找到最佳回归树。网格搜索是一种用于返回最佳参数的常用方法。</p><pre class="lq lr ls lt gt ot ou ov ow aw ox bi"><span id="adb5" class="mb kn iq ou b gy oy oz l pa pb">clf = DecisionTreeRegressor(max_depth=2)</span></pre><p id="e35f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">使分类器适合训练集</strong></p><pre class="lq lr ls lt gt ot ou ov ow aw ox bi"><span id="999a" class="mb kn iq ou b gy oy oz l pa pb">clf.fit(X_train, y_train)</span></pre><p id="cc21" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">预测测试集的目标变量:y_pred </strong></p><p id="c59d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们的情况下，这是药物效率。</p><pre class="lq lr ls lt gt ot ou ov ow aw ox bi"><span id="60c1" class="mb kn iq ou b gy oy oz l pa pb">y_pred = clf.predict(X_test)</span></pre><p id="be58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">查看测试数据集中的预测值和观察值。</strong></p><pre class="lq lr ls lt gt ot ou ov ow aw ox bi"><span id="ad2e" class="mb kn iq ou b gy oy oz l pa pb">plt.figure()<br/>plt.scatter(X_test, y_pred, s=20, edgecolor="black",<br/>            c="darkorange", label="Observed values")<br/>plt.scatter(X_test, y_test, s=20, edgecolor="black",<br/>            c="blue", label="Predicted values")</span><span id="15e1" class="mb kn iq ou b gy pd oz l pa pb">plt.xlabel("Dosage (mg)")<br/>plt.ylabel("Efficiency")<br/>plt.title("Decision Tree Regression")<br/>plt.legend()<br/>plt.show()</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/5d3baebbc5bf1242122306bbac323f0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*8nsRA0ZYqm-DukVpXjTgBw.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Regression tree on test data</figcaption></figure><p id="1ad9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">警告</strong></p><p id="3847" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">深度值较大的回归树很有可能过度拟合训练数据集。当这种情况发生时，当暴露于新的和看不见的数据时，模型不太可能表现良好。为了克服这个障碍，可以减小树的最大深度，或者增加分裂内部节点所需的最小样本数。另一种流行的技术是修剪回归树。修剪是一种通过删除树中对实例分类没有什么帮助的部分来减小回归规模的技术。</p><p id="2f76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="nl">参考文献</em></p><div class="mt mu gp gr mv mw"><a href="https://corporatefinanceinstitute.com/resources/knowledge/other/sum-of-squares/" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd ir gy z fp nb fr fs nc fu fw ip bi translated">平方和-定义、公式、回归分析</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">平方和(SS)是一种统计工具，用于确定数据的离差以及数据的好坏</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">corporatefinanceinstitute.com</p></div></div><div class="nf l"><div class="pf l nh ni nj nf nk lz mw"/></div></div></a></div><p id="e0c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://www.youtube.com/watch?v=g9c66TUylZ4&amp;t=493s" rel="noopener ugc nofollow" target="_blank">Josh Starmer的stat quest</a></p><div class="mt mu gp gr mv mw"><a href="https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd ir gy z fp nb fr fs nc fu fw ip bi translated">决策树回归-sci kit-了解0.22.2文档</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">基于决策树的1D回归。决策树用于拟合带有附加噪声观测值的正弦曲线。作为…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">scikit-learn.org</p></div></div><div class="nf l"><div class="pg l nh ni nj nf nk lz mw"/></div></div></a></div><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="ph pi l"/></div></figure></div></div>    
</body>
</html>