<html>
<head>
<title>Review On MobileNet v1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MobileNet v1综述</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/review-on-mobilenet-v1-abec7888f438?source=collection_archive---------1-----------------------#2020-06-10">https://medium.datadriveninvestor.com/review-on-mobilenet-v1-abec7888f438?source=collection_archive---------1-----------------------#2020-06-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="6287" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇文章中，我将解释关于<a class="ae kl" href="https://arxiv.org/pdf/1704.04861.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> MobileNets:用于移动视觉应用的高效卷积神经网络</strong> </a>论文来自<strong class="jp ir">谷歌</strong>。他们开发了一类称为MobileNets的高效模型，主要关注移动和嵌入式视觉应用。一句话，他们模型的主要焦点是通过在不牺牲性能的情况下减少参数数量来提高网络的效率。</p><h1 id="a031" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">主题</strong></h1><ol class=""><li id="f257" class="lk ll iq jp b jq lm ju ln jy lo kc lp kg lq kk lr ls lt lu bi translated"><strong class="jp ir">深度方向可分离卷积</strong></li><li id="669a" class="lk ll iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated"><strong class="jp ir">网络架构</strong></li><li id="5628" class="lk ll iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated"><strong class="jp ir">宽度乘数</strong></li><li id="8e6b" class="lk ll iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated"><strong class="jp ir">分辨率乘数</strong></li><li id="2039" class="lk ll iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated"><strong class="jp ir">性能对比</strong></li></ol></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="a091" class="km kn iq bd ko kp mh kr ks kt mi kv kw kx mj kz la lb mk ld le lf ml lh li lj bi translated">1.深度方向可分卷积</h1><p id="b7c2" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">这是MobileNet纸的核心基础。这是一个<strong class="jp ir">深度方向卷积</strong>，后面是一个<strong class="jp ir">点方向卷积</strong>。在开始深度方向卷积和点方向卷积之前，让我们了解一下普通卷积是如何工作的。</p><h2 id="cce0" class="mp kn iq bd ko mq mr dn ks ms mt dp kw jy mu mv la kc mw mx le kg my mz li na bi translated"><strong class="ak">正常卷积是怎么做的？</strong></h2><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/4b78d44a66051ddba71af894cb1884cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*uARpIQg5ggw9RVriPLU4_g.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">Normal convolution</figcaption></figure><p id="edbc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们有一个输入图像大小为12x12x3。如果我们使用步幅=1的5x5x3内核进行卷积，我们将得到8x8x1的输出大小。通常，在卷积运算中，我们指定输出中需要N个通道。在这段时间里，相同的操作用不同的内核重复了N次。假设N = 10。那么总的计算成本就变成了<strong class="jp ir">8</strong>T26】8×5×5×3×10 = 48000</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/b2926c51094e81a5e91ff69b2ccb183c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*uRZThybnquduWf6jLrrVNA.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">Normal convolution</figcaption></figure><p id="46b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以说，标准卷积图层输入将输入作为一个<strong class="jp ir"> Df x Df x M </strong>特征地图，并生成<strong class="jp ir"> Df x Df x N </strong>输出特征地图，其中Df是方形输入特征地图的空间宽度和高度。m是输入通道的数量，N是输出通道的数量。标准卷积层由大小为Dk×Dk×M×N的卷积核K参数化，因此总计算成本变为<strong class="jp ir">Dk×Dk×M×N×Df×Df。</strong></p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi no"><img src="../Images/e50af2272f84fa9674f72bfe6c56ac97.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/format:webp/1*vWvIApW31JfDK8i8fTFpMQ.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">computational cost standard convolution</figcaption></figure><h2 id="8d82" class="mp kn iq bd ko mq mr dn ks ms mt dp kw jy mu mv la kc mw mx le kg my mz li na bi translated">深度方向可分卷积</h2><p id="45d9" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">如果我们能够根据深度来划分这个卷积过程。深度方向可分离卷积由两部分组成:</p><ul class=""><li id="bec4" class="lk ll iq jp b jq jr ju jv jy np kc nq kg nr kk ns ls lt lu bi translated"><strong class="jp ir">深度方向卷积</strong></li><li id="2e96" class="lk ll iq jp b jq lv ju lw jy lx kc ly kg lz kk ns ls lt lu bi translated"><strong class="jp ir">逐点卷积</strong></li></ul><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/19f21048de709caf3dab0a081eeaf160.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*Iepc5N3HT6LqG-eHIGlodA.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">Depthwise convolution</figcaption></figure><p id="2453" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们有3个输入通道。假设我们有3 5 x 5 x 1个内核。这里发生的是5x5x1内核迭代输入图像的第一个通道以产生8x8x1输出。每个5×5×1内核对输入图像中相应的通道进行操作。现在，我们将所有三个这样的输出堆叠起来，得到8×8×3的输出。这就是深度卷积的工作原理。</p><p id="5877" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一个是<strong class="jp ir">逐点卷积</strong>。我们将使用1 x 1 x 3内核对获得的8 x 8 x 3图像进行卷积。这将产生一个特征图。我们将使用10个不同的1 x 1 x 3内核重复这一过程，以产生10个特征图，并将它们堆叠在一起。</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/d927ca136ad86869f6ea213218095c7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*cr1SOrfs12nKS--wuh1dcg.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">pointwise convolution</figcaption></figure><p id="ae54" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里计算的总数是8<strong class="jp ir">x 8x 5 x 5 x 3+8 x 8 x 10 x 3 = 4800+1920 = 6720</strong></p><p id="82e0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">总计算成本为</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/3f7634a98c5af54e9a9a854e1fadc534.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*6Oufi21VVA0Hw3i1H4lhMQ.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">computational cost depth separable convolution</figcaption></figure><p id="e4f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，计算量减少为</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/9987a567831f2d0836b6e5c523328fe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*qzZg9HpN2QYAzZnwGj8XrQ.png"/></div></figure><p id="435c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">注意:通过使用3x3内核，可以减少大约7到8倍的计算量(4 <em class="nx"> 8000/6720 =~ 7.14 </em>)。</strong></p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="6a41" class="km kn iq bd ko kp mh kr ks kt mi kv kw kx mj kz la lb mk ld le lf ml lh li lj bi translated"><strong class="ak"> 2。网络架构</strong></h1><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/dee1fe7b3b594b46e5c278b2d0c22f93.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*VFKaq4--oskDyYIOnZmK_A.png"/></div></figure><ul class=""><li id="5ac0" class="lk ll iq jp b jq jr ju jv jy np kc nq kg nr kk ns ls lt lu bi translated">该网络由28个卷积层和1个全连接层组成，后面是softmax层。</li><li id="d0bb" class="lk ll iq jp b jq lv ju lw jy lx kc ly kg lz kk ns ls lt lu bi translated">注意，在卷积之后应用批量归一化和ReLU</li></ul><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/90c7f8fcdba833680b30da560bab4d1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*X7ytIiV0EWm7OJgXgnvOBQ.png"/></div></figure></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="741e" class="km kn iq bd ko kp mh kr ks kt mi kv kw kx mj kz la lb mk ld le lf ml lh li lj bi translated"><strong class="ak"> 3。宽度乘数</strong></h1><p id="7ff1" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">引入宽度乘数αα以进一步降低计算成本。所以M变成αM。所以深度方向可分离的计算成本变成</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/370c020e1acd81f69c115486b8653aa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*hC0xcUg4iwOW2-G0FBk9qg.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">computational cost with width multiplier.</figcaption></figure><p id="d549" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中α在0到1之间。α的典型值为1、0.75、0.5和0.25。当α = 1时，我们有基线MobileNet。</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/72d1e18448d38ff16fe419fd32d48ac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*bzOtsuixqjGt8S9ekO_2KA.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">performance with different α values</figcaption></figure></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="f95d" class="km kn iq bd ko kp mh kr ks kt mi kv kw kx mj kz la lb mk ld le lf ml lh li lj bi translated">4.分辨率乘数</h1><p id="4a45" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">引入分辨率乘数ρ来控制网络的图像分辨率。用ρ计算成本变成</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/4a7c976e2af7315a7e857e0c5c99ee89.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*hWi8MYQRdSBPvt4wK1AFxQ.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">computational cost with resolution multiplier</figcaption></figure><p id="7dcb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中ρ在0到1之间。相应的分辨率为224、192、160和128。当ρ=1时，为基线MobileNet。</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi od"><img src="../Images/048b2ac1c05fdea556c028ba1d0ffd20.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*lISAALBBTjpYQtyeSVW_tA.png"/></div></figure></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="737f" class="km kn iq bd ko kp mh kr ks kt mi kv kw kx mj kz la lb mk ld le lf ml lh li lj bi translated">5.性能比较</h1><ul class=""><li id="ddcf" class="lk ll iq jp b jq lm ju ln jy lo kc lp kg lq kk ns ls lt lu bi translated">MobileNet-224的性能优于GoogLeNet(2014年ILSVRC冠军)和VGGNet(2014年ILSVRC亚军),而且参数也更低。</li></ul><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/faf74d93f45a398f6bc0a15ede4a57ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*GxXjiHa3Y0v-utzcCd5ySA.png"/></div></figure><ul class=""><li id="6d55" class="lk ll iq jp b jq jr ju jv jy np kc nq kg nr kk ns ls lt lu bi translated">当使用更小的MobileNet(<strong class="jp ir">0.50 MobileNet-160</strong>)时，它以更少的add和参数胜过AlexNet和Squuezenet。</li></ul><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi of"><img src="../Images/5187a6720297c997b003ae4b242d9930.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*QSS0QAp-k3a-V0Tyluokfw.png"/></div></figure><ul class=""><li id="fbfe" class="lk ll iq jp b jq jr ju jv jy np kc nq kg nr kk ns ls lt lu bi translated">对于使用移动网络作为主干的对象检测任务，性能如下</li></ul><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi og"><img src="../Images/99a1d2b12f835264ab40f4d110f5bdd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*dgt_IZRwe6msNAWsHnku4w.png"/></div></figure><p id="ce45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="nx">你可以查看我的</em> </strong> <a class="ae kl" href="https://github.com/arunm8489/Paper-Model-Implementation-From-Scratch" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> <em class="nx">笔记本</em> </strong> </a> <strong class="jp ir"> <em class="nx">对于PyTorch实现的MobileNet v1。</em> </strong></p><div class="oh oi gp gr oj ok"><a href="https://www.datadriveninvestor.com/2019/03/22/fixing-photography/" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd ir gy z fp op fr fs oq fu fw ip bi translated">修复摄影|数据驱动的投资者</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">汤姆·津伯洛夫在转向摄影之前曾在南加州大学学习音乐。作为一个…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy nh ok"/></div></div></a></div></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="e966" class="km kn iq bd ko kp mh kr ks kt mi kv kw kx mj kz la lb mk ld le lf ml lh li lj bi translated"><strong class="ak">参考</strong></h1><ul class=""><li id="1e2a" class="lk ll iq jp b jq lm ju ln jy lo kc lp kg lq kk ns ls lt lu bi translated"><a class="ae kl" href="https://arxiv.org/pdf/1704.04861.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1704.04861.pdf</a></li><li id="68e4" class="lk ll iq jp b jq lv ju lw jy lx kc ly kg lz kk ns ls lt lu bi translated"><a class="ae kl" href="https://towardsdatascience.com/review-mobilenetv1-depthwise-separable-convolution-light-weight-model-a382df364b69" rel="noopener" target="_blank">https://towards data science . com/review-mobilenetv1-depth wise-separable-convolution-light-weight-model-a 382 df 364 b 69</a></li><li id="6bd5" class="lk ll iq jp b jq lv ju lw jy lx kc ly kg lz kk ns ls lt lu bi translated"><a class="ae kl" href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728" rel="noopener" target="_blank">https://towards data science . com/a-basic-introduction-to-separable-convolutions-b99ec 3102728</a></li></ul><h2 id="2e4a" class="mp kn iq bd ko mq mr dn ks ms mt dp kw jy mu mv la kc mw mx le kg my mz li na bi translated">获得专家视图— <a class="ae kl" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>