<html>
<head>
<title>Extreme Learning Machines III</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">极限学习机III</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/extreme-learning-machines-ef3b229d63c5?source=collection_archive---------1-----------------------#2020-07-05">https://medium.datadriveninvestor.com/extreme-learning-machines-ef3b229d63c5?source=collection_archive---------1-----------------------#2020-07-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f70b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">第三部分:好点了吗？</h2></div><p id="a039" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">嗯，看情况。</p><p id="7766" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就像说的那样，它的主要优点是<strong class="kh ir">最小的训练时间和误差</strong>以及<strong class="kh ir">更好的泛化性能。</strong> ELM具有最简单的算法，因为我们不必决定隐藏层数、学习速率和其他超参数。即使更简单，ELM在准确度、精确度和召回率方面也优于任何其他算法。</p><p id="8555" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是ELM架构大多以第一层的隐藏节点数量较多而告终，这<strong class="kh ir">会影响测试时间</strong>。如果模型的应用不需要更少的训练时间，但需要更快的结果作为其优先考虑，那么ELM不应该是您的首选。例如，ELM在实时图像分类方面表现不佳。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/a82c0bf57915741b2f0f60d8c850bb1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ENwvhCYH5DKV019iyG2-Rw.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Comparison from source [3]</figcaption></figure><h2 id="236c" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">与LSTM和HTM的比较</h2><p id="a2da" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">这里使用的OR-ELM是一种用于在线递归时间序列数据的ELM算法。这个实验是为了预测云环境中的故障而做的。</p><p id="1dce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里使用的参数是NRMSE，它是归一化均方根误差。在图1(a)中，我们可以看到，ELM算法具有更低的NRMSE，整体性能更好。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mp"><img src="../Images/7899bcd02f23863dad7b7839bac9a4fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J7CYqAQsX_kK3t8cul8C5w.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Fig.1 (a) Prediction error for the 40 days from source[1]</figcaption></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mq"><img src="../Images/571fb75f7752b81edfe3ed1f7c13d9e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qFuoV0w2U4qbXqlBBMYedA.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Fig.1 (b) Prediction error when rapid changes of inputs occurred from source[1]</figcaption></figure><p id="02eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">时间比较:</strong>ELM算法所用的时间大约不到其比较时间的10%,并且总体误差较小。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mr"><img src="../Images/28f613b0618f9ed5b8d8e6d0ece6e6ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZYSMTT1xObomZ2MvEz8JRA.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Fig.2 Comparison with <strong class="bd lt">(I)NRMSE</strong>, <strong class="bd lt">(II)MAPE</strong>, <strong class="bd lt">(III)Computational Time</strong> (in sec) from source[1]</figcaption></figure><h2 id="cf1b" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">与支持向量机和随机森林的比较</h2><p id="c3a8" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">数据集被随机化并分成三部分:全样本、半样本和1/4样本。完整数据集包括65，535个样本，半数据集包括32，767个样本，1/4数据集包括18，383个样本。准确度、精确度和召回率被用作评估指标。</p><p id="7bdb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，数据集被分成80%的训练和20%的测试。</p><p id="977d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与SVM(线性)、SVM (RBF)和RF相比，ELM在全数据样本上的性能更好，而SVM (RBF)在半数据样本上的精度优于RF和ELM。SVM(线性)在1/4数据样本上优于其他技术。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ms"><img src="../Images/d2f9968bd64f45373dc4ba7ec67262ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ojfxUnZ8Yaa0BHbK.gif"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Fig. 3 (a) Accuracy of SVM, RF and ELM</figcaption></figure><p id="8d68" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在全数据样本上，ELM的精度优于所有方法。在半数据样本上，SVM(线性)的精度高于SVM (RBF)、ELM和RF。而SVM在1/4数据集上表现出比ELM和RF更好的性能。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ms"><img src="../Images/48cde61b909146f928b4559b3cb5015d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pIGzGOt6zU9-qcF2.gif"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Fig. 3 (b)</figcaption></figure><p id="753d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于全样本，ELM的召回率优于所有其他算法，并且随着样本大小的减小而降低。这表明SVM在小数据集上表现更好，而EML在大数据集上优于其他方法。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ms"><img src="../Images/2a5832f079e15e8f6481da9b3a9ec2de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Psktb3QgczWGucs8.gif"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Fig. 3 (c )</figcaption></figure><h1 id="525c" class="mt ls iq bd lt mu mv mw lw mx my mz lz jw na jx mc jz nb ka mf kc nc kd mi nd bi translated">结论</h1><p id="7312" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">我们可以得出结论，在MNIST OCR数据集、交通标志识别和3D图形应用等方面，ELM在给定大量数据的情况下具有比其他任何算法更好的性能，并且将训练时间从几天(通过深度学习)缩短到几分钟(通过ELM)。</p><p id="b18b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除此之外，如图1所示，当输入数据快速变化时，ELM甚至表现得更好</p><p id="e4eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用ELM算法的唯一缺点是在某些情况下测试时间会稍微长一点，而且数据集应该足够大。</p></div><div class="ab cl ne nf hu ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="ij ik il im in"><p id="63c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本系列上一篇:<strong class="kh ir">第二部分:算法</strong><a class="ae nl" href="https://medium.com/@prasad.kumkar/extreme-learning-machines-9c8be01f6f77" rel="noopener">https://medium . com/@ Prasad . kumkar/extreme-learning-machines-9 c8 be 01 F6 f 77</a></p><h1 id="45c2" class="mt ls iq bd lt mu mv mw lw mx my mz lz jw na jx mc jz nb ka mf kc nc kd mi nd bi translated">参考</h1><ol class=""><li id="3dfc" class="nm nn iq kh b ki mk kl ml ko no ks np kw nq la nr ns nt nu bi translated">J.Park和J. Kim，“在线递归极限学习机及其在时间序列预测中的应用”，2017年国际神经网络联合会议(IJCNN)，安克雷奇，AK，2017年，第1983–1990页，doi:10.1109/ij CNN . 2017 . 19966650965</li><li id="bf1e" class="nm nn iq kh b ki nv kl nw ko nx ks ny kw nz la nr ns nt nu bi translated">I. Ahmad，M. Basheri，M. J. Iqbal和A. Rahim，“支持向量机、随机森林和极限学习机在入侵检测中的性能比较”，载于<em class="oa"> IEEE Access </em>，第6卷，第33789–33795页，2018年，doi:10.1109/Access . 2019106</li><li id="23cc" class="nm nn iq kh b ki nv kl nw ko nx ks ny kw nz la nr ns nt nu bi translated"><a class="ae nl" href="https://www.ntu.edu.sg/home/egbhuang/" rel="noopener ugc nofollow" target="_blank">https://www.ntu.edu.sg/home/egbhuang/</a></li></ol></div></div>    
</body>
</html>