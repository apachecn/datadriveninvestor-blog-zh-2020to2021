<html>
<head>
<title>Forecasting a Recession in the USA</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测美国的经济衰退</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/forecasting-a-recession-in-the-usa-b7cf8de5bcda?source=collection_archive---------14-----------------------#2020-07-07">https://medium.datadriveninvestor.com/forecasting-a-recession-in-the-usa-b7cf8de5bcda?source=collection_archive---------14-----------------------#2020-07-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div class="gh gi io"><img src="../Images/b0f9f799997ae18a83e4975ea6509e6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*-oUhIW8_6hAyMATOwUlhBg.png"/></div></figure><div class=""/><h1 id="f62f" class="ju jv ix bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">第四章:</h1><h1 id="1f52" class="ju jv ix bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">数据扩展策略。</h1><h2 id="84fd" class="ks jv ix bd jw kt ku dn ka kv kw dp ke kx ky kz ki la lb lc km ld le lf kq lg bi translated">故事到此为止</h2><p id="174c" class="pw-post-body-paragraph lh li ix lj b lk ll lm ln lo lp lq lr kx ls lt lu la lv lw lx ld ly lz ma mb ij bi translated">在这项研究的第一部分，我分析了为什么衰退是重要的，以及它们如何影响股票市场的回报(S&amp;P500)。第二章的重点是数据集及其EDA的创建。在第三部分中，我处理了降维的问题，列出了两个策略来实现这个目标(SelectFromModel with logistic regression和PCA ),稍后将在ML-pipeline的构建中使用。在这一章中，我将探索数据缩放策略。</p><h2 id="4f12" class="ks jv ix bd jw kt ku dn ka kv kw dp ke kx ky kz ki la lb lc km ld le lf kq lg bi translated">索引:</h2><p id="5a74" class="pw-post-body-paragraph lh li ix lj b lk ll lm ln lo lp lq lr kx ls lt lu la lv lw lx ld ly lz ma mb ij bi translated">4.1数据缩放——概述和目标；<br/> 4.2数据缩放——两个特征的例子；<br/> 4.3数据缩放——测试备选方案；<br/> 4.4结论。</p><h1 id="5a72" class="ju jv ix bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">4.1数据扩展—概述和目标</h1><p id="3078" class="pw-post-body-paragraph lh li ix lj b lk ll lm ln lo lp lq lr kx ls lt lu la lv lw lx ld ly lz ma mb ij bi translated">最大似然算法的性能会受到它们所输入的数据量的影响。如果一个特征的级别远远高于其他特征的级别，那么这个特定的特征可以支配所有其他特征。大多数情况下，数据集将包含在量级、单位和范围上变化很大的要素。但是由于大多数机器学习算法在计算中使用两个数据点之间的欧几里德距离，这是一个问题。如果不加处理，这些算法自然会“加重”较大幅度的特征，忽略较小的特征。例如，在数据集中，ISM-PMI的平均值高于50，大部分时间得分值在40到60之间，而所有以百分比计算的特征平均值接近于零，很少超过+/-5%。在距离计算中，幅值较高的要素比幅值较低的要素权重更大。为了抑制这种效应，我需要将所有的特征放在相同的量级上。这可以通过缩放来实现。为了克服这些缺点，测试了SciKit-Learn中提供的不同数据缩放方法:</p><ul class=""><li id="f464" class="mc md ix lj b lk me lo mf kx mg la mh ld mi mb mj mk ml mm bi translated">标准定标器；</li><li id="9d54" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">量化转换器-统一；</li><li id="e2b6" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">量化转换器-正常；</li><li id="4c5d" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">PowerTransformer</li><li id="e78b" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">MinMaxScaler和</li><li id="e122" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">鲁棒定标器。</li></ul><p id="1c42" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">作为一般的提醒，一个不详尽的(！)其性能受数据缩放影响的一些ML模型的列表如下:</p><ul class=""><li id="9d06" class="mc md ix lj b lk me lo mf kx mg la mh ld mi mb mj mk ml mm bi translated">线性和逻辑回归；</li><li id="bdcc" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">最近的邻居；</li><li id="c471" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">神经网络；</li><li id="2a8d" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">具有径向偏置核函数的支持向量机:和</li><li id="d494" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">主成分分析。</li></ul><p id="7308" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">特别是，由于PCA是我在这个项目中选择应用的降维工具之一，因此对数据进行适当的缩放是一个必要的步骤。</p><p id="11d3" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated"><strong class="lj iy">目标</strong>:本章的主要目的是了解在美国经济衰退/扩张期分类中，不同的标度过程对模型泛化性能的影响。这个想法是列出一组策略，在分析的后期嵌入到管道中。</p><h1 id="cdbd" class="ju jv ix bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">4.2数据缩放—两个特征的例子</h1><p id="a4be" class="pw-post-body-paragraph lh li ix lj b lk ll lm ln lo lp lq lr kx ls lt lu la lv lw lx ld ly lz ma mb ij bi translated">为了理解缩放如何提高模型的性能，我首先通过使用PCA从原始数据集中仅提取两个特征来实现一个示例。</p><p id="dedc" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">我实施以下步骤:</p><ul class=""><li id="2428" class="mc md ix lj b lk me lo mf kx mg la mh ld mi mb mj mk ml mm bi translated">在导入了本章将要用到的所有库和训练数据集之后，我在训练和验证子集之间拆分了数据(提醒一下，我已经在训练和测试集之间拆分了数据，后者将只在最后用于评估所选模型的泛化属性)。验证集等于整个训练数据集的30%。</li></ul><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/260c1cb5db4baf106f28368319176bcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*wIk8yOZEEiez2ZUzd6KiKg.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Out.1: Code Output</figcaption></figure><ul class=""><li id="5af4" class="mc md ix lj b lk me lo mf kx mg la mh ld mi mb mj mk ml mm bi translated">我通过在训练子集上拟合和变换最小最大缩放器来创建新特征的数据框架。然后，使用PCA从未缩放的数据集中提取两个新特征，并从未缩放的数据集中提取两个新特征。</li></ul><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/5c5997e910dd1b5d6f51233afea753b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*rIbvgciK7t6E5xgAc3CG_A.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Out.2 Code Output</figcaption></figure><ul class=""><li id="065e" class="mc md ix lj b lk me lo mf kx mg la mh ld mi mb mj mk ml mm bi translated">关于缩放如何影响分析的第一印象来自于从缩放和未缩放数据中提取的两组特征的散点图的纯粹可视化。就衰退和扩张观察的规模和相对位置而言，这两组特征大相径庭。现在，我通过在两组数据上训练KNN分类器，将分析向前推进了一步。</li></ul><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nj"><img src="../Images/f2b8f1886f3a50ce61d5024d5882fdc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AU4Alpc7_rXmLPJfq8Krrw.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Pic.1 — PCA with 2 features on Unscaled and Scaled Data</figcaption></figure><ul class=""><li id="dcd4" class="mc md ix lj b lk me lo mf kx mg la mh ld mi mb mj mk ml mm bi translated">首先，我训练一个KNN分类器，该分类器具有来自未缩放数据集的两个特征的6个邻居。然后，将相同的模型拟合到从缩放数据中提取的PCA特征上。结果记录在下面的两个图表中。如分数所示，对缩放数据的处理将模型的验证分数提高了2.5%，从87.6%提高到90.1%。尽管相关性较低，但在训练数据集上的性能也略有提高，提高了1.7%。</li></ul><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nk"><img src="../Images/68d6d7c639aa6abeb6e9d5ebeb0531f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fk74j02Hne3RlTTKp0ZpkQ.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Pic.2 — KNN Performance and Graphic Representation when fitted on Un-Scaled date.</figcaption></figure><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nk"><img src="../Images/0ecf1890833a63a2b2850d6523b0ce32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DLGtYdYHhONFkX54uXn1XQ.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Pic.3 — KNN Performance and Graphic Representation when fitted on scaled data.</figcaption></figure><h1 id="8100" class="ju jv ix bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">4.3数据缩放—测试备选方案</h1><p id="09db" class="pw-post-body-paragraph lh li ix lj b lk ll lm ln lo lp lq lr kx ls lt lu la lv lw lx ld ly lz ma mb ij bi translated">下一步是通过在16个PCA特征上应用更广泛的定标器来概括这种分析。我将在几个ML算法上测试缩放器，以尽可能地概括结果，而不是过度依赖特定的模型。</p><p id="9ce8" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">如前所述，将要测试的定标器集合如下:</p><ol class=""><li id="4155" class="mc md ix lj b lk me lo mf kx mg la mh ld mi mb nl mk ml mm bi translated">标准定标器；</li><li id="a877" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb nl mk ml mm bi translated">分位数-变压器-统一；</li><li id="daf1" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb nl mk ml mm bi translated">分位数-转换器-正常；</li><li id="491a" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb nl mk ml mm bi translated">PowerTransformer</li><li id="ca87" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb nl mk ml mm bi translated">MinMaxScaler和</li><li id="6897" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb nl mk ml mm bi translated">鲁棒定标器。</li></ol><p id="4ae2" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">当这些ML算法被用作测试器时:</p><ul class=""><li id="f523" class="mc md ix lj b lk me lo mf kx mg la mh ld mi mb mj mk ml mm bi translated">GaussianNaiveBayes</li><li id="110d" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">物流回收；</li><li id="1e2b" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">KNeighborsClassifier</li><li id="3e72" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">树外分级机；</li><li id="8580" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">SVC，kernel = ' rbf</li><li id="add7" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">LinearSVC</li><li id="0886" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">用GaussianNB装袋；和</li><li id="c076" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated">MLP分类器。</li></ul><p id="6034" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">首先对这些模型中的每一个进行训练，并在整个未缩放的数据集上测试其性能(表中的<strong class="lj iy">“无缩放-所有特征”</strong>行)。然后，我尝试使用PCA从未缩放的数据集中提取16个特征，并在其上训练和测试模型(<strong class="lj iy">“无缩放-PCA”</strong>)。这一行应提供对未缩放数据使用PCA的负面影响的洞察，以及列表中模型的进一步比较。然后，根据上面列举的六个度量来缩放训练和验证数据集。对它们中的每一个进行PCA分析，并提取16个特征。然后，在验证集(表中的所有其他行)上对每个模型进行定型和测试。结果在两个表中报告:一个报告训练数据集的分数，另一个最重要的是验证数据的分数。最好的分数用浅蓝色标出。</p><p id="b5e5" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">生成结果的代码如下:</p><p id="9687" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">下面是结果表:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/c4877bc6fa888d67c7333fb99c8cb6ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*lG50CJaOVvIGa314vNdjIQ.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Table.1 — Analysis Results</figcaption></figure><h1 id="0e03" class="ju jv ix bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">4.4结论</h1><p id="c17e" class="pw-post-body-paragraph lh li ix lj b lk ll lm ln lo lp lq lr kx ls lt lu la lv lw lx ld ly lz ma mb ij bi translated">在某些情况下，使用适当的缩放策略可以显著提高验证数据的模型性能。对于具有RBF核模型的SVC，提升超过10%,对于KNN分类器，提升大约7%。从技术角度来看，与在整个数据集上实现的性能相比，使用从未缩放数据中提取的特征的模型性能更差，但有两种情况。对输出使用均匀边际分布的分位数-转换定标器似乎表现得特别好，而最小最大定标器表现第二好。在所有情况下，最好的分数是在缩放的数据中实现的。分位数转换器性能良好的一个特殊原因可能与我在EDA中强调的数据集的一个特征有关:离群值的广泛存在。分位数转换器对于异常值是稳健的，因此它们是缩放数据集的可靠选择。作为一种替代的度量标准，可以考虑使用MinMaxScaler。</p><p id="7340" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">最后，根据分析，为了扩展数据集，我将考虑以下两个步骤:</p><ul class=""><li id="f9ca" class="mc md ix lj b lk me lo mf kx mg la mh ld mi mb mj mk ml mm bi translated"><strong class="lj iy">分位数转换器，对转换后的数据进行均匀的边际分布</strong>；和</li><li id="7949" class="mc md ix lj b lk mn lo mo kx mp la mq ld mr mb mj mk ml mm bi translated"><strong class="lj iy">最小最大缩放器</strong>。</li></ul><p id="1112" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">本章的代码和结果可以在我的Github库<a class="ae nn" href="https://github.com/fabriziobasso/Data-Scaling-Strategies/blob/master/DataScaling.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="85db" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated"><em class="no">感谢阅读！</em></p><p id="347b" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi">— — — — — — — — — — — —</p><p id="427e" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">前面的文章:</p><p id="9d25" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated"><a class="ae nn" href="https://medium.com/@fabrbasso/forecasting-a-recession-the-usa-d6306adc9540" rel="noopener">第一章:引言</a></p><p id="7f52" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated"><a class="ae nn" href="https://medium.com/@fabrbasso/forecasting-a-recession-in-the-usa-82988caa556e" rel="noopener">第二章:数据集、特征工程和解释性数据分析</a></p><p id="2bc3" class="pw-post-body-paragraph lh li ix lj b lk me lm ln lo mf lq lr kx ms lt lu la mt lw lx ld mu lz ma mb ij bi translated">第三章:降维:特征选择和特征提取。</p></div></div>    
</body>
</html>