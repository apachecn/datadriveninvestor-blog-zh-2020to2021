<html>
<head>
<title>Recommendation Engines: A to Z (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">推荐引擎:A到Z(第2部分)</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/recommendation-engines-a-to-z-part-2-a099ca021121?source=collection_archive---------9-----------------------#2020-05-18">https://medium.datadriveninvestor.com/recommendation-engines-a-to-z-part-2-a099ca021121?source=collection_archive---------9-----------------------#2020-05-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="ec98" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">内部人工智能</h2><div class=""/><p id="4532" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这是推荐引擎博客系列的第2部分。这个博客系列将从头开始介绍推荐引擎。</p><p id="206f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">你没看过第一部分吗？不后悔，从<a class="ae ku" href="https://medium.com/datadriveninvestor/recommendation-engines-a-to-z-part-1-3ab585c11324" rel="noopener">这里得到。</a></p><p id="8196" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">至此，我们已经介绍了推荐系统的类型，之后是基于知识的推荐系统和基于排名的推荐系统。</p><p id="6316" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在这篇博客中，我们将讨论协同过滤技术，我将解释它是如何向用户推荐商品的。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi kv"><img src="../Images/77942b90ad006035141586b4e11c464d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HRHc5xlTU8daDVfuj4ZkPw.png"/></div></div></figure><h1 id="8e42" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">协作过滤:</h1><p id="27a6" class="pw-post-body-paragraph jw jx iq jy b jz mf kb kc kd mg kf kg kh mh kj kk kl mi kn ko kp mj kr ks kt ij bi translated"><strong class="jy ja">协同过滤</strong>是一种仅基于用户和项目之间的交互进行推荐的方法。这张图片会帮助你…</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="ab gu cl mk"><img src="../Images/5138009ef59bf2c1b0f5446bcfc35832.png" data-original-src="https://miro.medium.com/v2/format:webp/1*FefgqLfxJ6RNJf0YPz4Vgg.jpeg"/></div></figure><p id="7ef3" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">明白了吗？</strong>如果买披萨、甜甜圈、薯条；而另一个买披萨和甜甜圈的人，那么他也会被推荐买薯条。因为系统会发现你们俩口味相似。</p><p id="ad49" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">通常协同过滤有两种:<br/> <strong class="jy ja">基于Item-Item </strong>的协同过滤:<strong class="jy ja"> <em class="ml">喜欢过X item的用户也喜欢y .</em></strong><em class="ml"><br/></em><strong class="jy ja">基于User-Item </strong>的协同过滤:<em class="ml"> </em> <strong class="jy ja"> <em class="ml">和你相似的用户也喜欢XYZ。</em> </strong></p><h2 id="8f99" class="mm li iq bd lj mn mo dn ln mp mq dp lr kh mr ms lv kl mt mu lz kp mv mw md iw bi translated">q)上图是哪一个？如果你的答案是逐项的，那么你是对的！</h2><blockquote class="mx"><p id="2d86" class="my mz iq bd na nb nc nd ne nf ng kt dk translated">思考如何实现？</p></blockquote><p id="c2d2" class="pw-post-body-paragraph jw jx iq jy b jz nh kb kc kd ni kf kg kh nj kj kk kl nk kn ko kp nl kr ks kt ij bi translated">抓紧了！现在就开始讨论…</p><p id="017e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">实现协同过滤有两种方法:1)基于邻居的方法2)基于模型的方法(在下一篇博客中)</p><h1 id="0e91" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">1.基于邻域的协同过滤</h1><p id="69d7" class="pw-post-body-paragraph jw jx iq jy b jz mf kb kc kd mg kf kg kh mh kj kk kl mi kn ko kp mj kr ks kt ij bi translated">在这种方法中，用户-用户和项目-项目之间的距离可以以多种方式找到，并且它将给予我们它们之间的相似性的值。</p><p id="b004" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">计算相似度有五种方法:<br/> 1)皮尔逊相关系数<br/> 2)斯皮尔曼相关系数<br/> 3)肯德尔τ<br/>4)欧氏距离<br/> 5)曼哈顿距离<br/> 6)余弦距离</p><p id="b3b3" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">哦！这么无聊？别担心，我们不会深入讨论的。(只是见解😉)</p><p id="0999" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">1.皮尔逊相关系数:与线性的强弱和方向有关。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/68ffb3ee3c82ded92860a40ba52b650a.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*HqYykm_qRR0rKURIHIP_CQ.png"/></div></figure><p id="81c9" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在哪里，</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/f2eb75a6c6aec9fa5e0f81be54eb1825.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/format:webp/1*-0-GrSJHJmqY33GHlGOdTQ.png"/></div></figure><p id="2647" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">2.斯皮尔曼相关系数:它是一个<a class="ae ku" href="https://en.wikipedia.org/wiki/Nonparametric_statistics" rel="noopener ugc nofollow" target="_blank">非参数</a>统计量。这里r0表示排名值。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi no"><img src="../Images/2fb287a38618f278efbda55427d3a0c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*D2X51KHHPkAvxWtV9cB3QQ.png"/></div></figure><p id="0832" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在哪里，</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi np"><img src="../Images/e32af612aece183c3791a5f6c2cc71a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/1*i2rdoeYsUgcgFKra8vJ24w.png"/></div></figure><p id="ec8c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">3.肯德尔τ:类似于斯皮尔曼的相关系数，因为它是关系中的非参数测量。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/148975050f964af7818c76490ce3b7b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*t1Hr2Z1nF6cjUrNcTOQmFQ.png"/></div></figure><p id="d7ad" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">其中sgn采用与排序值的差异相关联的符号。</p><p id="8429" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">4.欧几里得距离:两个向量之间的直线距离。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/99acc89993a09fd61f826011a07929f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*GjqNDBZ83ORBSz6JUFHaBg.png"/></div></figure><p id="4b8d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">5.曼哈顿距离:沿垂直轴测量的两点之间的距离。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/c8d6c48fe84f04d8dec5f53fdad500f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*c77bXDlDvhdc6nXMXemcFw.png"/></div></figure><p id="13c9" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">6.余弦距离:使用欧几里得点积公式。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nt"><img src="../Images/dabb0ca6a1bbcf81c7cc35aee293535c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JJXxsZ1SdnaLZPXvVyxDbQ.png"/></div></div></figure><p id="c4ff" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">所以，这些是发现用户-用户和物品-物品之间相似性的方法。</p><p id="e32e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">现在我们已经找到了相似之处，让我们开始实现；</p><blockquote class="mx"><p id="6484" class="my mz iq bd na nb nc nd ne nf ng kt dk translated">我在这里不包括太多的编码部分，因为许多人看到它会感到厌烦！😃你可以在这里访问本博客附带的笔记本<a class="ae ku" href="https://github.com/prashantjadiya/Recommendation-engines/tree/master/Collaborative%20filtering" rel="noopener ugc nofollow" target="_blank">。</a></p></blockquote><p id="90ba" class="pw-post-body-paragraph jw jx iq jy b jz nh kb kc kd ni kf kg kh nj kj kk kl nk kn ko kp nl kr ks kt ij bi translated">在通过相关得到相似性之后，我们不能得到满意的结果，因为我们有稀疏的数据(许多值是NaN)。所以我试着用欧几里德距离来得到相似性。你可以参考这里的<a class="ae ku" href="https://github.com/prashantjadiya/Recommendation-engines/tree/master/Collaborative%20filtering" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="7436" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">首先，我们不想推荐用户自己已经购买的商品。</p><p id="aeb1" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">之后，我们找到最近的邻居，并检索他们喜欢的项目列表。该列表将用于推荐相似的用户。</p><p id="0476" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">你可以在我的<a class="ae ku" href="https://github.com/prashantjadiya/Recommendation-engines/tree/master/Collaborative%20filtering" rel="noopener ugc nofollow" target="_blank"> Github库</a>中的基于电影的推荐示例中看到整个方法。</p><blockquote class="nu nv nw"><p id="ab0e" class="jw jx ml jy b jz ka kb kc kd ke kf kg nx ki kj kk ny km kn ko nz kq kr ks kt ij bi translated">因为我的许多同行建议不要在博客中包含更多的技术细节，比如代码，所以我没有这样做。如果您对此有任何建议，请在下面回复。</p></blockquote><p id="ca89" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">谢谢你阅读这篇博客。如果你喜欢我的博客，请在你的左边鼓掌，这将意味着很多。在<a class="ae ku" href="http://www.linkedin.com/in/prashant-jadiya" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上连线吧。</p><p id="aba5" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在下一篇博文中，我们将讨论基于模型的协同过滤方法。敬请期待！</p></div></div>    
</body>
</html>