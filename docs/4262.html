<html>
<head>
<title>Multivariable Linear Regression: A practical approach with python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多变量线性回归:python的实用方法</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/multivariable-linear-regression-a-practical-approach-with-python-f01f4e302221?source=collection_archive---------6-----------------------#2020-07-30">https://medium.datadriveninvestor.com/multivariable-linear-regression-a-practical-approach-with-python-f01f4e302221?source=collection_archive---------6-----------------------#2020-07-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1a06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我之前的博客里，你可以了解到什么是线性回归，线性回归有多少种类型。点击<a class="ae kl" href="https://medium.com/@mistrynirav123/linear-regression-a-practical-approach-with-python-e3f676361e07" rel="noopener">这里</a>阅读博客。我们将看到如何实现<strong class="jp ir">多变量线性回归</strong>。现在我们用一个简单的数据集来寻找多元变量之间的线性回归。你可以在给定的<a class="ae kl" href="https://www.kaggle.com/harlfoxem/housesalesprediction" rel="noopener ugc nofollow" target="_blank">链接</a>上找到数据集。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/abea5a1d8d9abbfeadf660665fc9c16a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fWbOXUmsqODGOLc1h-hLEQ.png"/></div></div></figure><p id="8e51" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个数据集，其中不同的变量代表可能影响房价预测的不同参数。</p><p id="a300" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将首先使用panda加载python中的数据集，然后将数据绘制成散点图。然后我们将变量应用到X轴和Y轴。然后我们将从scikit learn导入线性回归模型。之后，我们会找到预测值和一个误差值。最后一步是找到线的截距和系数。</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="0602" class="ld le iq kz b gy lf lg l lh li">import pandas as pd  <br/>import numpy as np  <br/>import matplotlib.pyplot as plt  <br/>import seaborn as seabornInstance <br/>from sklearn.model_selection import train_test_split <br/>from sklearn.linear_model import LinearRegression<br/>from sklearn import metrics<br/>%matplotlib inline</span></pre><p id="bb67" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用熊猫读取数据集。</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="96c7" class="ld le iq kz b gy lf lg l lh li">dataset = pd.read_csv('../input/housesalesprediction/kc_house_data.csv')<br/>dataset</span></pre><p id="7922" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们将在每一列中找到空值。</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="d563" class="ld le iq kz b gy lf lg l lh li">dataset.isnull().any()</span></pre><p id="7bca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果有任何空列，我们将使用<strong class="jp ir"> ffill </strong>方法填充该列或单元格。</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="2a72" class="ld le iq kz b gy lf lg l lh li">dataset = dataset.fillna(method='ffill')</span></pre><p id="de4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们将变量给X和Y轴。</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="63ec" class="ld le iq kz b gy lf lg l lh li">X = dataset[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above','sqft_basement','yr_built','yr_renovated','sqft_living15','sqft_lot15']].values<br/>y = dataset['price'].values</span></pre><p id="b927" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，如果我们对多个数据使用散点图，我们将有多个图形。</p><p id="124d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，这里我们将使用distplot可视化数据集的分布。</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="f3cc" class="ld le iq kz b gy lf lg l lh li">plt.figure(figsize=(15,10))<br/>plt.tight_layout()<br/>seabornInstance.distplot(dataset['price'])</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lj"><img src="../Images/d51fad49835c82f1b40d22d8dad9a730.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ElRDAeTYX0gaB-tSUadYyA.png"/></div></div></figure><p id="c6ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们将训练数据集。</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="6fd2" class="ld le iq kz b gy lf lg l lh li">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)</span></pre><p id="6248" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对定型数据集应用线性回归。</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="8d34" class="ld le iq kz b gy lf lg l lh li">regressor = LinearRegression()  <br/>regressor.fit(X_train, y_train)</span></pre><p id="7cc0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">输出:</strong>线性回归()</p><p id="3c13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这个定型数据集中，我们将找到Y轴的价格预测值。</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="613a" class="ld le iq kz b gy lf lg l lh li">y_pred = regressor.predict(X_test)<br/>df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})<br/>df1 = df.head(25)<br/>print(df1)</span></pre><p id="ebc9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">输出:</strong></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/57e284634ae1b943095cc5d26e86efd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*vhpZ_KxLlL_Nq-3Ixq34Cw.png"/></div></figure><p id="1ef0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们将绘制实际值与预测值的条形图。</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="0d93" class="ld le iq kz b gy lf lg l lh li">df1.plot(kind='bar',figsize=(10,8))<br/>plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')<br/>plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')<br/>plt.show()</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/afbbee97897ea244be6f8c017913f5b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*KYMKsSsmmH2LQzIjj5AScA.png"/></div></figure><p id="57b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，我们将找到误差，以找出模型预测值与实际值之间的差异。</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="b55b" class="ld le iq kz b gy lf lg l lh li">print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  <br/>print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  <br/>print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))</span></pre><p id="24ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">输出:</strong></p><p id="7722" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">平均绝对误差:13149575807<br/>均方误差:4214957504.036904<br/>均方根误差:20005</p></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><p id="1637" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="lt">原载于2020年7月30日</em><a class="ae kl" href="https://www.numpyninja.com/post/multivariable-linear-regression-a-practical-approach-with-python" rel="noopener ugc nofollow" target="_blank"><em class="lt">https://www.numpyninja.com</em></a>T22。</p></div></div>    
</body>
</html>