<html>
<head>
<title>Hierarchical clustering with a work-out example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">层次聚类与算例</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/hierarchical-clustering-with-a-work-out-example-b5b0c86f9c53?source=collection_archive---------15-----------------------#2020-09-24">https://medium.datadriveninvestor.com/hierarchical-clustering-with-a-work-out-example-b5b0c86f9c53?source=collection_archive---------15-----------------------#2020-09-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/558441703b93b1bf0a375f4f9f7d0116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FoZc60lQMsBybnI4"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@amandamocci?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Amanda Mocci</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="95fe" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设您有一堆点(或对象，假设每个点或对象之间有合理的相似性)，现在您想将它们排列成漂亮的小桶，但问题是您不知道要将它们划分成多少个不同的集合。所以你不能使用k均值或任何相关的均值(很明显，因为k的值是未知的或不可能被猜到的)。你现在能做什么？那我们就分等级吧！</p><figure class="le lf lg lh gt ju"><div class="bz fp l di"><div class="li lj l"/></div></figure><p id="0e92" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好吧，玩笑归玩笑😉。分层聚类的思想是构建从上到下具有主导顺序的聚类(<a class="ae kf" href="https://www.kdnuggets.com/2019/09/hierarchical-clustering.html" rel="noopener ugc nofollow" target="_blank">到这个站点</a>，非常棒的解释)。在这一集里，我们来看看层次聚类建立的基础，它的分类，算法，以及一如既往的建立牢固概念的例子。</p><p id="e016" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">请注意</strong>这不是介绍性的文章(如果这是你要找的，那么<a class="ae kf" href="https://towardsdatascience.com/hierarchical-clustering-explained-e58d2f936323" rel="noopener" target="_blank">这里有一篇大师级文章</a>)，所以我假设你已经对层次聚类有了大致的了解。这篇博文的目的是展示算法的内部机制，我的目标是通过解决一个例子来实现。</p><div class="lk ll gp gr lm ln"><a href="https://www.datadriveninvestor.com/2020/08/27/what-is-a-data-catalog-and-how-does-it-enable-machine-learning-success/" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab fo"><div class="lp ab lq cl cj lr"><h2 class="bd iu gy z fp ls fr fs lt fu fw is bi translated">什么是数据目录，它如何使机器学习取得成功？数据驱动的投资者</h2><div class="lu l"><h3 class="bd b gy z fp ls fr fs lt fu fw dk translated">数据目录是机器学习和数据分析的燃料。没有它，你将不得不花费很多…</h3></div><div class="lv l"><p class="bd b dl z fp ls fr fs lt fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb jz ln"/></div></div></a></div><h1 id="77cd" class="mc md it bd me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz bi translated">为什么要分层聚类</h1><p id="54af" class="pw-post-body-paragraph kg kh it ki b kj na kl km kn nb kp kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">不知道k值的事实不够直观。所以我想出了这个例子。比方说，你正在研究地理对文化的影响，假设你从亚洲开始。在亚洲，有受印度文化影响的国家，它们可能形成一个集群(比如集群的名字是印度)，然后有受中国文化影响的国家形成另一个集群(集群中国)，这些是第一级集群。这两个集群将合并成一个更大的集群(比如印度支那)，因为印度和中国文化可能有相似之处，这是第二级集群。假设这个第2级集群与另一个第2级集群(比如波斯集群)合并，形成第3级集群，这就是亚洲本身(为了说明的目的而过于简化)。一开始，每个国家都是一个0级的集群。我想解释的是，当除了聚类之外，还需要知道聚类及其组件和聚合之间的关系时，就使用这种聚类技术。希望这个疯狂的例子对读者有所启发。</p><h1 id="4322" class="mc md it bd me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz bi translated">分类。</h1><p id="a736" class="pw-post-body-paragraph kg kh it ki b kj na kl km kn nb kp kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">大致有两种类型。</p><p id="263d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">agglomerate</strong>:在这个类中，每个迭代步骤中的单个簇合并成一个更大的簇，直到出现一个大簇。一个集群包含所有这些！</p><figure class="le lf lg lh gt ju"><div class="bz fp l di"><div class="nf lj l"/></div></figure><p id="c747" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">分裂</strong>:顾名思义，它的工作方式正好与凝聚相反，分解较大的集群，直到每个集群都由一个项目组成。我们将主要关注凝聚集群，因为我们相信建设而不是破坏，只是开玩笑😜。</p><h1 id="567b" class="mc md it bd me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz bi translated">该算法</h1><p id="a1e2" class="pw-post-body-paragraph kg kh it ki b kj na kl km kn nb kp kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">用文字描述，我们得到一个距离矩阵，首先(我们马上会看到它是什么样子)包含点之间的成对距离。我们要做的是把独立的点打包成簇。我们从具有最小距离的两个点开始，并将它们包括在一个聚类中。然后测量重新考虑矩阵，并用当前最小距离打包点，注意，在确定距离时，每个新形成的簇被视为普通点。现在出现的一个大问题是如何计算一个星团和一个点之间的距离？为了客观地看待这个问题，假设我们有一个集群[A，B]和一个独立的点C，如何计算距离呢？事实证明，有很多方法可以做到这一点。</p><ol class=""><li id="d605" class="ng nh it ki b kj kk kn ko kr ni kv nj kz nk ld nl nm nn no bi translated">最小方法:这里的距离是成对距离的最小值，就像上面的例子一样，</li></ol><blockquote class="np nq nr"><p id="4bec" class="kg kh ns ki b kj kk kl km kn ko kp kq nt ks kt ku nu kw kx ky nv la lb lc ld im bi translated">d([A，B]，C) = min(d(A，C)，d(B，C))。</p></blockquote><p id="91ba" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这也称为单联动。</p><ol class=""><li id="b538" class="ng nh it ki b kj kk kn ko kr ni kv nj kz nk ld nl nm nn no bi translated">最大接近度:两两距离的最大值。</li><li id="bce0" class="ng nh it ki b kj nw kn nx kr ny kv nz kz oa ld nl nm nn no bi translated">平均值:两两距离的平均值。喜欢</li></ol><blockquote class="np nq nr"><p id="b213" class="kg kh ns ki b kj kk kl km kn ko kp kq nt ks kt ku nu kw kx ky nv la lb lc ld im bi translated">d([A，B]，C) = (d(A，C) + d(B，C)) / 2</p></blockquote><p id="6593" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，这些绝不是唯一使用的指标，有相当多的指标，如加权/未加权平均值、沃德距离等。好吧，我听到你在问用哪一个。这取决于您正在处理的数据集、数据的分散程度、您想要从中获得什么以及其他一些因素。根据数据科学家的说法，尝试所有方法，然后决定最好的结果来自哪里，这可能是一个明智的选择。到目前为止，我将在本文的其余部分使用单一链接度量。半正式伪代码可能看起来像这样，</p><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ob"><img src="../Images/a5e257aa2d16c7b80157e4e8fce620b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SQVw8B-3gPc09IBoFQwPSQ.png"/></div></div></figure><h1 id="8d1a" class="mc md it bd me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz bi translated">小锻炼</h1><p id="5631" class="pw-post-body-paragraph kg kh it ki b kj na kl km kn nb kp kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">在这个例子中，我将使用下面的距离矩阵，</p><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oc"><img src="../Images/e266c1eee2ad4b3bd8d8a94f01500c45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tEhYgbmKjaa77BE4TL8uZQ.jpeg"/></div></div></figure><p id="fd5d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，对角线被置零，矩阵是下三角形，因为从一个点到它自己的距离被认为是0，距离需要打印一次。</p><p id="fcb9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，搜索距离最小的一对。也就是2，点3和点5之间的距离。所以把它们聚集起来，像这样展示，</p><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi od"><img src="../Images/d7b62dca6336af1cdc1094775e354d73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VUn7u6Uua5fWImeK6XbzkQ.jpeg"/></div></div></figure><p id="1d41" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有相当多的观察要做。首先，矩阵的维数下降了1，从5 x 5降到4 x 4。然后重新排列距离(用灰色标记的是感兴趣的距离，其余的只是从以前的状态复制下来的)。</p><p id="30b0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对距离调整的了解不多:</p><blockquote class="np nq nr"><p id="5f16" class="kg kh ns ki b kj kk kl km kn ko kp kq nt ks kt ku nu kw kx ky nv la lb lc ld im bi translated">d([P3，P5]，P1) = min (d(P3，P1)，d(P5，P1)) = min(3，11) = 3</p><p id="e7f4" class="kg kh ns ki b kj kk kl km kn ko kp kq nt ks kt ku nu kw kx ky nv la lb lc ld im bi translated">d([P3，P5]，P2) = min (7，10) = 7</p><p id="c050" class="kg kh ns ki b kj kk kl km kn ko kp kq nt ks kt ku nu kw kx ky nv la lb lc ld im bi translated">d([P3，P5]，[P3，P5]) = 0</p><p id="04ed" class="kg kh ns ki b kj kk kl km kn ko kp kq nt ks kt ku nu kw kx ky nv la lb lc ld im bi translated">d([P3，P5]，P4) = min (8，9) = 8</p></blockquote><p id="8feb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是第一次迭代。然后重复相同的计算，直到剩下最后一个集群。这是第二次迭代后矩阵的样子，</p><figure class="le lf lg lh gt ju gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/725f4b978af586fac0fef0528611734b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*o7mAJi8k9vBctUKISfafQw.jpeg"/></div></figure><p id="186e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我想你已经明白了这个概念，并且可以很好地从这里继续下去。只需选择最短的距离，并将端点打包到一个新的集群中。仅此而已。</p><p id="812b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">希望这能帮助你处理所有的分支。一如既往，保持冷静！</p><h2 id="8ab8" class="of md it bd me og oh dn mi oi oj dp mm kr ok ol mq kv om on mu kz oo op my oq bi translated">访问专家视图— <a class="ae kf" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>