<html>
<head>
<title>Toxic Comment Classification: A Kaggle Case Study</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">有毒评论分类:Kaggle案例研究</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/toxic-comment-classification-a-kaggle-case-study-a929b37150b?source=collection_archive---------0-----------------------#2020-03-06">https://medium.datadriveninvestor.com/toxic-comment-classification-a-kaggle-case-study-a929b37150b?source=collection_archive---------0-----------------------#2020-03-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/23a430609fff34690b1384c611114fdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KMvO-mNN9BxIJSCi"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">(Photo By Dimitri Karastev On Unsplash)</figcaption></figure><p id="6297" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">毒性评论分类</strong>是nlp领域流行的kaggle比赛。这场比赛大约两年前就结束了。挑战的主要目的是在网上评论中发现不同类型的毒性，如<strong class="ke ir"> <em class="la">【威胁】</em></strong><strong class="ke ir"><em class="la">淫秽</em></strong><strong class="ke ir"><em class="la">侮辱</em></strong><strong class="ke ir"><em class="la">基于身份的仇恨</em> </strong>。该数据集是从维基百科的对话页面链接中收集的。要了解更多关于比赛的信息，请访问比赛主页<a class="ae lb" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/jigsaw-toxic-comment-class ification-challenge</a>。</p><h2 id="30e8" class="lc ld iq bd le lf lg dn lh li lj dp lk kn ll lm ln kr lo lp lq kv lr ls lt lu bi translated">数据集:</h2><p id="2593" class="pw-post-body-paragraph kc kd iq ke b kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv lz kx ky kz ij bi translated">收集的数据集已经被人类评级员标记为有毒行为。毒性类型分别标注为<strong class="ke ir"> <em class="la">毒性</em></strong><strong class="ke ir"><em class="la">重度_毒性</em></strong><strong class="ke ir"><em class="la">淫秽</em></strong><strong class="ke ir"><em class="la">威胁</em></strong><strong class="ke ir"><em class="la">侮辱</em> </strong> <em class="la"> </em>和<em class="la"> </em> <strong class="ke ir"> <em class="la">身份仇恨</em> </strong> <em class="la">。</em>我们的目标是建立一个能获取仇恨程度的模型。</p><p id="a786" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了加载数据集，我们可以使用pandas库。包含培训、测试和提交文件的数据集已在竞赛主页中提供。</p><p id="0536" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了读取数据帧，我们将使用下面的代码。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="305a" class="lc ld iq mf b gy mj mk l ml mm">train=pd.read_csv(‘/home/aditya123/Downloads/jigsaw-toxic-comment-classification-challenge/train.csv’)<br/>test=pd.read_csv(‘/home/aditya123/Downloads/jigsaw-toxic-comment-classification-challenge/test.csv’)</span></pre><p id="8c1b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">上面的代码片段加载数据集。现在我们可以使用下面的代码片段来了解更多。知道</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="bf58" class="lc ld iq mf b gy mj mk l ml mm">train.head()</span><span id="5806" class="lc ld iq mf b gy mn mk l ml mm">train.describe()</span></pre><h2 id="5c6f" class="lc ld iq bd le lf lg dn lh li lj dp lk kn ll lm ln kr lo lp lq kv lr ls lt lu bi translated">预处理:</h2><p id="094e" class="pw-post-body-paragraph kc kd iq ke b kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv lz kx ky kz ij bi translated">按照预处理步骤，我们将检查列中是否存在任何空值。如果它存在，那么我们将通过<em class="la"> fillna </em>方法填充它。此外，我们会把所有的字符变成小写形式。在目标值中我们将列值作为等级，分别为<strong class="ke ir"><em class="la"/></strong><strong class="ke ir"><em class="la">【严重_中毒】</em></strong><strong class="ke ir"><em class="la">淫秽</em></strong><strong class="ke ir"><em class="la">威胁</em></strong><strong class="ke ir"><em class="la">侮辱</em></strong><strong class="ke ir"><em class="la">身份_仇恨</em>为此，我们可以编写以下代码片段。</strong></p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="9047" class="lc ld iq mf b gy mj mk l ml mm">train[‘comment_text’].fillna(‘fillna’)<br/>test[‘comment_text’].fillna(‘fillna’)<br/>x_train=train[‘comment_text’].str.lower()<br/>y_train=train[[“toxic”, “severe_toxic”, “obscene”, “threat”, “insult”, “identity_hate”]].values<br/>x_test=test[‘comment_text’].str.lower()</span></pre><h2 id="6998" class="lc ld iq bd le lf lg dn lh li lj dp lk kn ll lm ln kr lo lp lq kv lr ls lt lu bi translated">特色化:</h2><p id="c599" class="pw-post-body-paragraph kc kd iq ke b kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv lz kx ky kz ij bi translated">深度学习或机器学习模型无法理解人类语言。因此，我们需要将它们转换成数学形式，这将是一个特定维度的向量，将其作为模型的输入。有许多方法可以做到这一点，例如我们可以使用tfidf等统计方法，或者我们可以借助word2vec或glove等预训练模型将它们转换为向量。我们还可以使用gensim包从头开始构建一个单词嵌入模型。然而，在这种情况下，我们将采取keras嵌入层的帮助。因此嵌入层获取索引并将它们映射到密集向量中。它将<strong class="ke ir">将整数作为输入</strong>，并在字典中寻找其<strong class="ke ir">对应的密集向量</strong>，并将其返回，作为深度学习模型的输入。</p><div class="mo mp gp gr mq mr"><a href="https://www.datadriveninvestor.com/2019/01/23/deep-learning-explained-in-7-steps/" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd ir gy z fp mw fr fs mx fu fw ip bi translated">深度学习用7个步骤解释-更新|数据驱动的投资者</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">在深度学习的帮助下，自动驾驶汽车、Alexa、医学成像-小工具正在我们周围变得超级智能…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf jw mr"/></div></div></a></div><h1 id="eb7d" class="ng ld iq bd le nh ni nj lh nk nl nm lk nn no np ln nq nr ns lq nt nu nv lt nw bi translated">嵌入层:</h1><p id="6ce1" class="pw-post-body-paragraph kc kd iq ke b kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv lz kx ky kz ij bi translated">嵌入层采用整数的2D张量作为输入，其将样本数和序列长度作为输入。要成批嵌入可变长度的序列，我们必须使它们具有相同的长度。采取这一步是因为我们应该把它们带到张量。因此，这确保了大于某个阈值的序列将被截断，另一方面，小于某个阈值的序列必须用零填充。</p><h2 id="81cc" class="lc ld iq bd le lf lg dn lh li lj dp lk kn ll lm ln kr lo lp lq kv lr ls lt lu bi translated">如何在嵌入层中调整权重:</h2><p id="0612" class="pw-post-body-paragraph kc kd iq ke b kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv lz kx ky kz ij bi translated">最初，嵌入层的权重以随机权重的任意方式开始。在训练过程中，模型通过反向传播学习找到合适的权重。完成训练后，它将能够找到一个合适的结构。</p><h2 id="4130" class="lc ld iq bd le lf lg dn lh li lj dp lk kn ll lm ln kr lo lp lq kv lr ls lt lu bi translated">双向LSTM:</h2><p id="0fdf" class="pw-post-body-paragraph kc kd iq ke b kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv lz kx ky kz ij bi translated">调整嵌入向量后，我们将建立模型。这里，我们将使用一种称为双向lstm的深度学习模型，而不是传统的机器学习。虽然<em class="la"/><strong class="ke ir"/><em class="la"/>是对RNNs的<em class="la"> </em>改进，在一定程度上解决了消失梯度问题，但是双向也允许LSTM从相反方向获得上下文。</p><h2 id="caf9" class="lc ld iq bd le lf lg dn lh li lj dp lk kn ll lm ln kr lo lp lq kv lr ls lt lu bi translated">GlobalMaxPool1D:</h2><p id="044f" class="pw-post-body-paragraph kc kd iq ke b kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv lz kx ky kz ij bi translated">Globalmaxpool类似于任何其他池，池长度等于整个输入长度。例如，如果我们有一个池长度为3的输入[2，3，4，5，6，6，7]，则输出将分别为4，5，6，6，7，而globalmaxpool1d将获取输出7。</p><h2 id="99fe" class="lc ld iq bd le lf lg dn lh li lj dp lk kn ll lm ln kr lo lp lq kv lr ls lt lu bi translated">辍学:</h2><p id="6392" class="pw-post-body-paragraph kc kd iq ke b kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv lz kx ky kz ij bi translated">Dropout随机忽略某些神经元，从而避免过度拟合的问题。这意味着所选择的神经元在训练时的向前或向后传递期间将不被考虑。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nx"><img src="../Images/c9839959a28b0a070c62e100c202a778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hg-XrpxzhA8r-AYa.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">(Pic Credit: Srivastava, Nitish, et al. ”Dropout: a simple way to prevent neural networks from<br/>overfitting”, JMLR 2014)</figcaption></figure><h2 id="01ea" class="lc ld iq bd le lf lg dn lh li lj dp lk kn ll lm ln kr lo lp lq kv lr ls lt lu bi translated">回访:</h2><p id="87b9" class="pw-post-body-paragraph kc kd iq ke b kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv lz kx ky kz ij bi translated">我们几乎不可能决定模型需要多少个历元才能获得最佳参数集。因此，我们应该对模型进行监控，并在验证损失不再改善时停止训练，而不是对任意数量的时期任意训练模型。因此<em class="la">回调</em>是在拟合模型时传递的对象，并在训练的各个部分被调用。</p><h2 id="4453" class="lc ld iq bd le lf lg dn lh li lj dp lk kn ll lm ln kr lo lp lq kv lr ls lt lu bi translated">代码:</h2><p id="27d2" class="pw-post-body-paragraph kc kd iq ke b kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv lz kx ky kz ij bi translated">理论到此为止！！！！现在让我们直接构建模型。我们将使用keras功能api对其进行编码。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="9586" class="lc ld iq mf b gy mj mk l ml mm">embed_size=100<br/>max_features=20000<br/>max_len=100</span></pre><p id="8213" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这里我们指定了3个参数。嵌入大小将把每个单词转换成100维向量。<em class="la"> max_features </em>参数告诉要考虑的前20000个常用词。类似地，<em class="la"> max_len </em>参数表示要考虑的每个输入的大小，这里取为100。如果我们的句子长度超过100，它将被截断，否则它将用零填充。下面的代码片段完成了上述的大部分任务，这是不言自明的。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="833a" class="lc ld iq mf b gy mj mk l ml mm">tokenizer= Tokenizer(num_words=max_features,lower= True)<br/>tokenizer.fit_on_texts(list(x_train))<br/>tokenized_train=tokenizer.texts_to_sequences(x_train)<br/>tokenized_test=tokenizer.texts_to_sequences(x_test)<br/>train_x=pad_sequences(tokenized_train,maxlen=max_len)<br/>test_x=pad_sequences(tokenized_test,maxlen=max_len)</span></pre><p id="bc40" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">因为我们有6个不同的类，我们将有一个有6个神经元的密集层。我们会把它附加在模型的末尾。参见下面的代码片段，了解如何使用keras functional api构建模型。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="81a2" class="lc ld iq mf b gy mj mk l ml mm">inp = Input(shape=(max_len,))<br/>x = Embedding(max_features,embed_size)(inp)<br/>x = Bidirectional(LSTM(64, return_sequences=True))(x)<br/>x = GlobalMaxPool1D()(x)<br/>x= Dropout(0.1)(x)<br/>x= Dense(6,activation=”sigmoid”) (x)<br/>model = Model(inputs=inp, outputs=x)<br/>model.compile(loss=’binary_crossentropy’,optimizer= Adam(lr=1e-3),metrics=[‘accuracy’])<br/>print(model.summary())</span></pre><p id="b220" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">当我们使用函数式api来构建模型时，它以张量的形式接受输入。我们之前已经讨论过模型架构。这里需要注意的重要一点是<strong class="ke ir"> <em class="la">编译</em> </strong>方法。它构建了模型架构，其中<strong class="ke ir">还没有执行</strong>训练。</p><p id="4e09" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如前所述，我们可以利用回调对模型进行适当的训练。我们还将使用模型检查点来存储模型在不同训练点的权重。下面的代码片段实现了同样的目的</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="6213" class="lc ld iq mf b gy mj mk l ml mm">callbacks_list = [keras.callbacks.EarlyStopping(monitor=’acc’,patience=2,), keras.callbacks.ModelCheckpoint(filepath=’my_model.h5',monitor=’val_loss’,save_best_only=True,)]</span></pre><p id="74e0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这里，耐心参数表示我们希望看到没有改善的时期的数量。</p><p id="a779" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在编译方法中，我们只定义了架构并初始化了它。现在我们必须调整参数，以获得最佳模型。为此，我们通过模型传递训练数据。<em class="la">拟合</em>方法通过模型传递数据并计算损失。同样基于损耗，它进行反向传播并调整参数。下面的代码片段做了同样的事情</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="871a" class="lc ld iq mf b gy mj mk l ml mm">model.fit(train_x,y_train,epochs=epochs,batch_size=batch_size,validation_split=0.1,callbacks=callbacks_list,verbose=1)</span></pre><p id="9908" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们可以根据产生的结果改变参数。运行5个时期后，达到的验证精度为0.98。我们可以尝试更多数量的lstms和更多的epochs来改善这一点。</p><p id="cb5d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在，为了进行预测，我们将使用<strong class="ke ir"> <em class="la">预测</em> </strong>方法。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="2939" class="lc ld iq mf b gy mj mk l ml mm">y_pred=model.predict(test_x,batch_size=batch_size,verbose=1)</span></pre><h2 id="95c0" class="lc ld iq bd le lf lg dn lh li lj dp lk kn ll lm ln kr lo lp lq kv lr ls lt lu bi translated">提交:</h2><p id="8276" class="pw-post-body-paragraph kc kd iq ke b kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv lz kx ky kz ij bi translated">在培训并获得输出后，我们将提交输出。同样，我们将使用csv文件来写入结果。下面的代码片段实现了同样的目的</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="b822" class="lc ld iq mf b gy mj mk l ml mm">submission=pd.read_csv(‘/home/aditya123/Downloads/jigsaw-toxic-comment-classification-challenge/sample_submission.csv’)<br/>submission[[“toxic”,”severe_toxic”,”obscene”,”threat”,”insult”,”identity_hate”]]=y_pred<br/>submission.to_csv(‘submission.csv’,index=False)</span></pre><p id="1e91" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">提交后，我们获得了0.96670的分数。我们可以通过更好的超参数调整和运行更多的历元来改善它。</p><p id="58f7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">完整代码可在<a class="ae lb" href="https://github.com/mohantyaditya/Toxic-Comment-identification" rel="noopener ugc nofollow" target="_blank">https://github . com/mohantyaditya/Toxic-Comment-identificati on</a>获得。</p><figure class="ma mb mc md gt jr"><div class="bz fp l di"><div class="ny nz l"/></div></figure></div></div>    
</body>
</html>