<html>
<head>
<title>K-Means Clustering Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-均值聚类算法</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/k-means-clustering-algorithm-6860c0171ac3?source=collection_archive---------7-----------------------#2020-02-19">https://medium.datadriveninvestor.com/k-means-clustering-algorithm-6860c0171ac3?source=collection_archive---------7-----------------------#2020-02-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1565" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">K-means是一种基于原型的分区聚类技术，它试图找到用户指定数量的聚类K，这些聚类由它们的质心表示。K-means也被认为是最简单的聚类算法之一。我将通过提及该算法的关键点来解释它，并尝试简化它。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/db89c21fe42f1b8566adc442830866c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/1*E9R_N48ftoul7kp1y9-OIg.gif"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><a class="ae kx" href="https://aws.amazon.com/blogs/machine-learning/k-means-clustering-with-amazon-sagemaker/" rel="noopener ugc nofollow" target="_blank">A description of k-means</a></figcaption></figure><p id="7bc2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该算法从选择K个代表点开始，假设K个点作为初始质心。一个<strong class="jp ir"> <em class="ky">形心</em> </strong>是一个星团中各点的重心。然后，基于所选的特定接近度，将每个点分配到最近的质心。<strong class="jp ir"> <em class="ky">接近度度量</em> </strong>表征对象之间存在的相似性或不相似性。我们需要一个接近度度量，它量化最近的符号，欧几里德距离通常用于欧几里德空间中的数据点，余弦相似度更适合文档。一旦聚类形成，每个聚类的质心被更新。然后，该算法迭代地重复这两个步骤，即:将点分配给最近的质心并更新质心，这种重复一直持续到质心不变为止。通常，用于K-means的相似性度量非常简单，因为该算法重复计算每个点到每个质心的相似性。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="kz la l"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><a class="ae kx" href="https://media.giphy.com/media/VryvUKuOxNLqM/giphy." rel="noopener ugc nofollow" target="_blank">A realistic illustration of the K-means algorithm</a></figcaption></figure><p id="303b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的gif展示了算法是如何工作的。我找不到更好的方式来说明算法是如何运行的。下面是对上面gif的一个简单解释:在第一次迭代中，随机的初始质心被分配，更精确地说是三个质心，这意味着K是三，然后将点分配给这些质心。在随后的迭代中，质心改变位置直到收敛，或者换句话说，质心不再改变。形心由“X”表示，并且属于同一聚类的所有点具有相同的颜色。</p><div class="lb lc gp gr ld le"><a href="https://www.datadriveninvestor.com/2019/03/22/the-seductive-business-logic-of-algorithms/" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">算法诱人的商业逻辑|数据驱动的投资者</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">某些机器行为总是让我感到惊讶。我对他们从自己的成就中学习的能力感到惊讶…</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls kr le"/></div></div></a></div><p id="84e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，为了得出结论，K-means算法按照以下步骤运行:</p><p id="7338" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 1。</strong>选择k个集群。<br/>2<strong class="jp ir">。</strong>计算k个星团的质心。<br/> <strong class="jp ir"> 3 </strong>。计算数据集中每个对象到每个质心的欧几里德距离。<br/> <strong class="jp ir"> 4。</strong>根据上一步计算的距离，将每个对象分配到离其最近的簇。<br/> <strong class="jp ir"> 5。</strong>再次计算每个簇的质心。<br/> <strong class="jp ir"> 6。</strong>根据最小距离将对象重新分配到集群，如果没有变化，则转到7，否则转到5。<br/> <strong class="jp ir"> 7。</strong>停止</p><p id="c947" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">已知k-means算法具有O(<em class="ky">n</em>*<em class="ky">k</em>*<em class="ky">l</em>)的时间<strong class="jp ir">复杂度</strong>，其中<em class="ky"> n </em>是模式的数量，<em class="ky"> k </em>是聚类的数量，<em class="ky"> l </em>是算法收敛所需的迭代次数。</p><p id="27c3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意:尽管在大多数情况下使用k-means时，<em class="ky"> k </em>是随机选择的，但我必须指出，结果并不十分准确。所以这真的很重要，你在选择时应该非常小心:聚类的数量和初始质心，因为这两个是影响K-means算法性能的主要因素。</p><h2 id="d7ea" class="lt lu iq bd lv lw lx dn ly lz ma dp mb jy mc md me kc mf mg mh kg mi mj mk ml bi translated">参考</h2><p id="1307" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">奥萨马·阿布·阿巴斯。数据聚类算法之间的比较，第322页</p><p id="29b8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">聚类分析:基本概念和算法，第497页</p><p id="4d68" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据聚类:算法和应用(查普曼&amp;霍尔/CRC数据挖掘和知识发现系列，第89页</p><p id="d218" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">耶稣基督，日惹。数据挖掘领域的聚类技术研究，第34页</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="mr la l"/></div></figure></div></div>    
</body>
</html>