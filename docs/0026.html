<html>
<head>
<title>A Regression Problem with Python — House Prices: Advanced Regression Techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的回归问题——房价:高级回归技术</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/a-regression-problem-with-python-house-prices-advanced-regression-techniques-98616d31f0ab?source=collection_archive---------0-----------------------#2020-01-03">https://medium.datadriveninvestor.com/a-regression-problem-with-python-house-prices-advanced-regression-techniques-98616d31f0ab?source=collection_archive---------0-----------------------#2020-01-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0d19" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用Scikit-Learn理解Python中的回归方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/4daba41839138835040f5f9724efcd63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*lXctuwyDMqn6h2huHFiQqg.jpeg"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk">House Prices</figcaption></figure><p id="4886" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是我之前做的关于Python中高级回归技术的Kaggle竞赛。</p><h2 id="5797" class="lq lr it bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated"><a class="ae mj" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" rel="noopener ugc nofollow" target="_blank">房价:高级回归技术</a></h2><p id="978c" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">我们可以请购房者描述他们梦想中的房子，他们可能不会从地下室天花板的高度或靠近东西向铁路开始。但是这个游乐场竞赛的数据集证明，影响价格谈判的远不止卧室的数量或白色尖桩栅栏。这个比赛的目的是预测每栋房子的最终价格。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="7003" class="mw lr it bd ls mx my mz lv na nb nc ly jz nd ka mb kc ne kd me kf nf kg mh ng bi translated">数据描述</h1><p id="9f0a" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">有79个解释变量描述了爱荷华州埃姆斯住宅的各个方面，这场比赛挑战我们预测每栋房子的最终价格。下面是数据文件的简要描述。</p><ul class=""><li id="06c7" class="nh ni it kw b kx ky la lb ld nj lh nk ll nl lp nm nn no np bi translated"><strong class="kw iu"><em class="nq"/></strong>——你试图预测的目标变量。</li><li id="3bae" class="nh ni it kw b kx nr la ns ld nt lh nu ll nv lp nm nn no np bi translated">地址(包括邻居和公用设施)</li><li id="7aab" class="nh ni it kw b kx nr la ns ld nt lh nu ll nv lp nm nn no np bi translated">销售情况(包括销售和建造年份)</li><li id="4745" class="nh ni it kw b kx nr la ns ld nt lh nu ll nv lp nm nn no np bi translated">房屋状况(包括房间类型、地下室尺寸、屋顶、供暖系统、空调、电气系统、地板尺寸、壁炉、车库尺寸、游泳池等)。)</li></ul></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="8e96" class="mw lr it bd ls mx my mz lv na nb nc ly jz nd ka mb kc ne kd me kf nf kg mh ng bi translated"><strong class="ak">数据预处理</strong></h1><p id="9d04" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated"><strong class="kw iu">数据预处理</strong>是数据挖掘过程中的一个重要步骤，数据被转换或编码，使其达到机器可以轻松解析的状态。</p><div class="nw nx gp gr ny nz"><a href="https://www.datadriveninvestor.com/2019/02/07/8-skills-you-need-to-become-a-data-scientist/" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">成为数据科学家所需的8项技能|数据驱动型投资者</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">数字吓不倒你？没有什么比一张漂亮的excel表更令人满意的了？你会说几种语言…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on ko nz"/></div></div></a></div><p id="04f9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，我们应该决定哪些训练和测试数据应该丢弃，并考虑训练和测试数据中缺失值的百分比大于0.7。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="9697" class="lq lr it op b gy ot ou l ov ow">train_missing = train_data.isna().sum() / train_data.shape[0]<br/>train_missing[train_missing &gt; <strong class="op iu">0.7</strong>]</span><span id="da1d" class="lq lr it op b gy ox ou l ov ow">Alley          0.937671<br/>PoolQC         0.995205<br/>Fence          0.807534<br/>MiscFeature    0.963014</span><span id="ca43" class="lq lr it op b gy ox ou l ov ow">test_missing = test_data.isna().sum() / test_data.shape[0]<br/>test_missing[test_missing &gt; <strong class="op iu">0.7</strong>]</span><span id="9e80" class="lq lr it op b gy ox ou l ov ow">Alley          0.926662<br/>PoolQC         0.997944<br/>Fence          0.801234<br/>MiscFeature    0.965045</span></pre><p id="2adc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，我们丢弃训练和测试数据，缺失值的百分比大于0.7。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="35f8" class="lq lr it op b gy ot ou l ov ow">train_data.drop(train_missing[train_missing &gt; 0.7].index, axis = 1, inplace = True)<br/>test_data.drop(test_missing[test_missing &gt; 0.7].index, axis = 1, inplace = True)</span></pre><p id="011e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">其次，对训练数据集中缺失值的百分比小于0.7的数据进行处理。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="f5e4" class="lq lr it op b gy ot ou l ov ow">train_data['LotFrontage'].interpolate(axis=0, inplace=True)<br/>train_data[['MasVnrType']].fillna('None', inplace=True)<br/>train_data.dropna(subset=['GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond'], inplace=True)<br/>train_data.dropna(subset=['BsmtQual', 'BsmtCond', 'BsmtFinType1'], inplace=True)<br/>train_data.dropna(subset=['MasVnrType', 'MasVnrArea'], inplace=True)<br/>train_data.drop('FireplaceQu', axis=1, inplace=True)<br/>train_data['BsmtExposure'].fillna('No', inplace=True)<br/>train_data['BsmtFinType2'].fillna('Unf', inplace=True)<br/>train_data['Electrical'].fillna('SBrkr', inplace=True)</span></pre><p id="a8e0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">此外，我们还管理测试数据集中的缺失值。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="fe09" class="lq lr it op b gy ot ou l ov ow">test_data.fillna(method='ffill', inplace=True)<br/>test_data.fillna(method='bfill', inplace=True)</span></pre><p id="eed0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下一步，我们应该处理分类变量的问题。对于分类变量，一个热编码是一个过程，通过该过程分类变量被转换成可以提供给ML算法以在预测中做得更好的形式。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="a389" class="lq lr it op b gy ot ou l ov ow"># Copy Train data excluding target<br/>trainData_Copy = train_data.drop(['SalePrice', 'Id'], axis=1).copy()<br/>testData_Copy = test_data.drop('Id', axis=1).copy()</span><span id="67c7" class="lq lr it op b gy ox ou l ov ow"># Combine Train and test for <strong class="op iu">One Hot Encoding</strong><br/>combined_Data = pd.concat([trainData_Copy,testData_Copy], keys = [0,1])</span><span id="cf3a" class="lq lr it op b gy ox ou l ov ow"># Do One Hot Encoding for categorical features<br/>combined_Data = pd.get_dummies(combined_Data)</span><span id="0054" class="lq lr it op b gy ox ou l ov ow"># Separate Train data and test data<br/>X_train = combined_Data.xs(0)<br/>X_test = combined_Data.xs(1)<br/>y_train = train_data["SalePrice"]</span></pre></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="4e7a" class="mw lr it bd ls mx my mz lv na nb nc ly jz nd ka mb kc ne kd me kf nf kg mh ng bi translated">模型</h1><p id="cfa2" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">不同模型的详细描述已经在<a class="ae mj" href="https://towardsdatascience.com/a-classification-problem-with-python-homesite-quote-conversion-15174bca09b8" rel="noopener" target="_blank">上显示了Python的分类问题——home site报价转换</a>。根据预测值的对数和观察到的销售价格的对数之间的<a class="ae mj" href="https://en.wikipedia.org/wiki/Root-mean-square_deviation" rel="noopener ugc nofollow" target="_blank">均方根误差(RMSE) </a>对模型进行评估。(取日志意味着预测贵房子和便宜房子的误差会同等影响结果。)</p><p id="b935" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里我解释一下我之前创建的模型。</p><h2 id="fc88" class="lq lr it bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">决策树回归器</h2><p id="84fb" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">决策树是一种决策支持工具，它使用树状图形或决策模型及其可能的结果，包括偶然事件结果、资源成本和效用。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="e59b" class="lq lr it op b gy ot ou l ov ow">from sklearn.tree import DecisionTreeRegressor</span><span id="fea8" class="lq lr it op b gy ox ou l ov ow">clf = DecisionTreeRegressor()<br/>clf.fit(X_train, y_train)<br/>clf_predict = clf.predict(X_test)</span></pre><p id="0b16" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">决策树回归器的误差(RMSE):0.20875</p><h2 id="3df5" class="lq lr it bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">随机森林回归量</h2><p id="2789" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">随机森林是一种集成学习方法，它在数据子集上拟合多个决策树，并对结果进行平均。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="aec1" class="lq lr it op b gy ot ou l ov ow">from sklearn.ensemble import RandomForestRegressor</span><span id="1722" class="lq lr it op b gy ox ou l ov ow">rfc = RandomForestRegressor()<br/>rfc.fit(X_train, y_train)<br/>rfc_predict = rfc.predict(X_test)</span></pre><p id="c369" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">随机森林回归量的误差(RMSE ): 0.17001</p><h2 id="614e" class="lq lr it bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">MLP回归器(神经网络)</h2><p id="e3de" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">神经网络是一种机器学习算法，涉及拟合许多用于表示与突触激活功能相连的神经元的隐藏层。这些基本上使用一个非常简化的大脑模型来建模和预测数据。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="3b07" class="lq lr it op b gy ot ou l ov ow">from sklearn.neural_network import MLPRegressor</span><span id="3912" class="lq lr it op b gy ox ou l ov ow">mlp = MLPRegressor()<br/>mlp.fit(X_train, y_train)<br/>mlp_predict = mlp.predict(X_test)</span></pre><p id="4171" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">MLP回归量的误差(RMSE):0.42138</p><h2 id="ba7b" class="lq lr it bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">支持向量回归机</h2><p id="f58a" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">支持向量机可以用作回归方法，保持表征算法的所有主要特征(最大间隔)。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="60c1" class="lq lr it op b gy ot ou l ov ow">from sklearn.svm import SVR</span><span id="18c3" class="lq lr it op b gy ox ou l ov ow">svr = SVR()<br/>svr.fit(X_train, y_train)<br/>svr_predict = svr.predict(X_test)</span></pre><p id="42dd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">支持向量回归机的误差(RMSE):0.24711</p><h2 id="60e2" class="lq lr it bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">梯度推进回归器</h2><p id="800a" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">梯度推进是一组机器学习算法，将许多弱学习模型结合在一起，创建一个强预测模型。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="fdc3" class="lq lr it op b gy ot ou l ov ow">from sklearn.ensemble import GradientBoostingRegressor</span><span id="071a" class="lq lr it op b gy ox ou l ov ow">search_random = {'n_estimators': range(1000, 5000, 100), 'learning_rate':[0.01, 0.1, 0.05]}<br/>abc = GradientBoostingRegressor()<br/>abc.fit(X_train, y_train)<br/>abc_predict = abc.predict(X_test)</span></pre><p id="063d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">梯度推进回归器的误差(RMSE):0.13910</p><h2 id="b837" class="lq lr it bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">堆叠模型</h2><p id="ffec" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">模型堆叠是一种有效的集成学习技术，其中通过使用各种机器学习算法生成的预测被用作第二层学习算法中的输入。该第二层算法被训练成最佳地组合模型预测以形成一组新的预测。在堆叠模型中，该数据点靠近神经网络和支持向量回归的位置。但是，堆叠模型的整体预测准确性更好。因此，我们使用决策树、随机森林和神经网络的堆叠模型来进行预测。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="0ea3" class="lq lr it op b gy ot ou l ov ow">models = [MLPRegressor(**grid_parm_mlp), RandomForestRegressor(**grid_parm_rfc), DecisionTreeRegressor(**grid_parm)]<br/>      <br/>S_Train, S_Test = stacking(models, X_train, y_train, X_test, regression=True, verbose=2)</span><span id="ee11" class="lq lr it op b gy ox ou l ov ow">model = RandomForestRegressor()  <br/>model = model.fit(S_Train, y_train)<br/>model_pred = model.predict(S_Test)</span></pre><p id="55fb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">叠加模型误差(RMSE):0.16718</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="eff7" class="mw lr it bd ls mx my mz lv na nb nc ly jz nd ka mb kc ne kd me kf nf kg mh ng bi translated">比较和结论</h1><p id="743f" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">基于我创建的模型，首先我们需要找出哪个算法得到最低的RMSE。因此，我们可以认识到梯度推进回归得到最低的误差(RMSE)。此外，梯度推进模型因其在分类复杂数据集方面的有效性而变得越来越受欢迎，最近已被用于赢得许多Kaggle数据科学竞赛。然后，对于堆叠模型，它也获得了比其他模型更低的误差(RMSE ),因为它最佳地组合了模型预测以形成一组新的预测，并且堆叠模型的整体预测准确性更好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="oz pa di pb bf pc"><div class="gh gi oy"><img src="../Images/5e10d455a2e2739d007548127cea5b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x9RdzBI83PtI1nlOxRuqBg.png"/></div></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk">Comparison</figcaption></figure><p id="a443" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">总之，我们使用Scikit-Learn的不同高级回归技术(决策树、随机森林、支持向量机、神经网络和梯度推进)来预测最终销售价格，并专注于预测准确性。目的是学习一个可以最小化均方根误差(RMSE)的模型，比较不同的算法，并选择性能最佳的算法。</p><p id="6584" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">创建这篇文章的源代码可以在<a class="ae mj" href="https://github.com/shirley0823/Machine-Learning-with-Python/blob/master/House_Prices_Advanced_Regression_Techniques.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="6a8a" class="mw lr it bd ls mx my mz lv na nb nc ly jz nd ka mb kc ne kd me kf nf kg mh ng bi translated">关于我</h1><p id="37d2" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">非常感谢您阅读我的文章！大家好，我是雪莉，目前在亚利桑那州立大学攻读商业分析硕士学位。如果您有任何问题，请随时联系我！</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="c429" class="lq lr it op b gy ot ou l ov ow">Email me at <strong class="op iu"><em class="nq">kchen122@asu.edu</em></strong><em class="nq"> </em>and feel free to connect me on <a class="ae mj" href="https://www.linkedin.com/in/kuanyinchen-shirley/" rel="noopener ugc nofollow" target="_blank"><strong class="op iu">LinkedIn</strong></a>!</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pd pe l"/></div></figure></div></div>    
</body>
</html>