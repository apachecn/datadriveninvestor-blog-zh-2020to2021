<html>
<head>
<title>Pytorch for NLP: Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向NLP的Pytorch:第1部分</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/pytorch-for-nlp-part-1-32000fedcae4?source=collection_archive---------9-----------------------#2020-03-20">https://medium.datadriveninvestor.com/pytorch-for-nlp-part-1-32000fedcae4?source=collection_archive---------9-----------------------#2020-03-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="550a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下系列文章将介绍Pytorch的基础知识、基本文本分析、用于自然语言处理的神经网络(NLP)等等！</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/577e9f8c9d5fc2838b075daa034d6d2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fGlCZXkTwb79g37P"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">“Torch” — Photo by <a class="ae lb" href="https://unsplash.com/@mateusmaia?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Mateus Maia</a> on <a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="75ab" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">路标</h1><ul class=""><li id="019a" class="ma mb iq jp b jq mc ju md jy me kc mf kg mg kk mh mi mj mk bi translated"><strong class="jp ir">py torch简介</strong></li><li id="3964" class="ma mb iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">张量介绍</strong></li><li id="2aeb" class="ma mb iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">py torch</strong>中的张量基础(实例化张量，随机张量，Python-NumPy桥)</li><li id="a998" class="ma mb iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">张量运算</strong>(加、减、除、乘、点积、转置)</li><li id="d678" class="ma mb iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">张量操作</strong>(切片、索引、连接)</li><li id="cd50" class="ma mb iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">杂项</strong>(类型、大小、形状、尺寸)</li></ul><h1 id="1c34" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">PyTorch</h1><blockquote class="mq mr ms"><p id="9c9c" class="jn jo mt jp b jq jr js jt ju jv jw jx mu jz ka kb mv kd ke kf mw kh ki kj kk ij bi translated"><em class="iq">py torch:Python中的张量和动态神经网络，具有强大的GPU加速</em></p></blockquote><p id="cce0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">PyTorch是深度学习和张量操纵库。它类似于Tensorflow，Keras是一个深度学习库，同时也提供像NumPy这样的库的功能。与NumPy的主要区别是它提供了强大的GPU加速，这对数据/计算密集型任务至关重要。</p><div class="mx my gp gr mz na"><a href="https://www.datadriveninvestor.com/2019/01/23/which-is-more-promising-data-science-or-software-engineering/" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd ir gy z fp nf fr fs ng fu fw ip bi translated">数据科学和软件工程哪个更有前途？数据驱动的投资者</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">大约一个月前，当我坐在咖啡馆里为一个客户开发网站时，我发现了这个女人…</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no kv na"/></div></div></a></div></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="d96d" class="lc ld iq bd le lf nw lh li lj nx ll lm ln ny lp lq lr nz lt lu lv oa lx ly lz bi translated">安装PyTorch</h1><p id="aa74" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy ob ka kb kc oc ke kf kg od ki kj kk ij bi translated">要安装PyTorch，请访问<a class="ae lb" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank">官方网站</a>并根据您的机器、环境和CUDA规范构建查询。例如，下面是我用来在Linux系统上安装PyTorch的查询，使用的是pip和CUDA 10.1。</p><pre class="km kn ko kp gt oe of og oh aw oi bi"><span id="12a7" class="oj ld iq of b gy ok ol l om on">pip install torch torchvision</span></pre><h1 id="00bb" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">张量介绍</h1><p id="bd7f" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy ob ka kb kc oc ke kf kg od ki kj kk ij bi translated">张量是保存一些维度数据的数学对象。零阶张量只是一个数字或一个标量。一阶张量(秩一张量)是一组数字或一个<em class="mt">向量</em>。类似地，秩为2的张量是一个矩阵。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi oo"><img src="../Images/0b969e371ea68b031a43907b926b6c4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x3xIaO_nGN-nEfgcEeTH_Q.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Different types of tensors. <a class="ae lb" href="https://www.amazon.in/Natural-Language-Processing-PyTorch-Applications-ebook/dp/B07N17TMFH" rel="noopener ugc nofollow" target="_blank">Source</a>.</figcaption></figure><h1 id="85f0" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">PyTorch中张量的基础知识</h1><p id="a74b" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy ob ka kb kc oc ke kf kg od ki kj kk ij bi translated">为了在Pytorch中创建张量，我们使用了<strong class="jp ir"> <em class="mt"> torch。张量</em>命令。</strong></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="e566" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就产生了一个<strong class="jp ir"> <em class="mt"> n * m </em> </strong>的量纲张量。这里，“n”是指行数，“m”是指列数。</p><p id="5c8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用<strong class="jp ir"> torch.rand() </strong>命令用均匀分布的随机值初始化一个张量，即在区间[0，1]上。<strong class="jp ir"> torch.randn </strong>命令用正态分布[-1，1]的随机值初始化张量。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="6bf6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了创建具有特定值的张量，我们使用了<strong class="jp ir"> fill_() </strong>方法。我们也可以用全0或全1初始化张量。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="c20e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Pytorch还使用函数<strong class="jp ir"> from_numpy </strong>处理NumPy数组。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="op oq l"/></div></figure><h1 id="006f" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">张量运算</h1><p id="435c" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy ob ka kb kc oc ke kf kg od ki kj kk ij bi translated">PyTorch具有用于所有基本操作和高级操作的内置函数。下面的要点告诉你如何加，减，乘，除，并采取张量转置。</p><h1 id="36ff" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">基础知识</strong></h1><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="op oq l"/></div></figure><h1 id="e3ed" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">先进的</h1><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="op oq l"/></div></figure><h1 id="294f" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">张量操作</h1><p id="8ab2" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy ob ka kb kc oc ke kf kg od ki kj kk ij bi translated">在使用张量时，对张量进行切片和索引是至关重要的。PyTorch张量切片/索引类似于Python中的列表。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="0415" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在PyTorch中连接两个张量可以通过多种方式完成:垂直、水平和堆叠两个张量。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="op oq l"/></div></figure><h1 id="5849" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">多方面的</h1><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="op oq l"/></div></figure></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="543b" class="lc ld iq bd le lf nw lh li lj nx ll lm ln ny lp lq lr nz lt lu lv oa lx ly lz bi translated">结论</h1><p id="71f1" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy ob ka kb kc oc ke kf kg od ki kj kk ij bi translated">在帖子里，我们看到了PyTorch和处理张量的基础知识。在下一篇文章中，我们将进一步探讨如何使用Pytorch进行NLP！</p><p id="87bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以关注我<a class="ae lb" href="https://twitter.com/Obhijith" rel="noopener ugc nofollow" target="_blank"> @Abhijith </a>或者在这里找到更多<a class="ae lb" href="http://cabhijith.github.io" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="or oq l"/></div></figure></div></div>    
</body>
</html>