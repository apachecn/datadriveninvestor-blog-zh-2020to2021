<html>
<head>
<title>How to Use Tree-Based Algorithms for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用基于树的算法进行机器学习</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/how-to-use-tree-based-algorithms-for-machine-learning-9da624c75755?source=collection_archive---------7-----------------------#2020-09-08">https://medium.datadriveninvestor.com/how-to-use-tree-based-algorithms-for-machine-learning-9da624c75755?source=collection_archive---------7-----------------------#2020-09-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e4b4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用和理解随机森林算法的指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/f0c28f09d8ecaac13c3eca4f21d01040.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v6xFfm_-RrdOhCNsk9ZRYw.jpeg"/></div></figure><p id="b10c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">基于树的算法是用于解决监督学习问题的流行的机器学习方法。这些算法非常灵活，可以解决手边的任何类型的问题(分类或回归)。</p><p id="52c9" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">基于树的算法在对其所属区域的训练样本进行预测时，倾向于使用连续特征的<strong class="kp ir">均值</strong>或分类特征的<strong class="kp ir">模式</strong>。他们还产生具有<strong class="kp ir">高精度</strong>、<strong class="kp ir">稳定性</strong>、<strong class="kp ir">易解释</strong>的预测。</p><h1 id="c799" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">基于树的算法的例子</h1><p id="4314" class="pw-post-body-paragraph kn ko iq kp b kq mb jr ks kt mc ju kv kw md ky kz la me lc ld le mf lg lh li ij bi translated">您可以使用不同的基于树的算法，例如</p><ul class=""><li id="8a1b" class="mg mh iq kp b kq kr kt ku kw mi la mj le mk li ml mm mn mo bi translated">决策树</li><li id="f825" class="mg mh iq kp b kq mp kt mq kw mr la ms le mt li ml mm mn mo bi translated">随机森林</li><li id="8074" class="mg mh iq kp b kq mp kt mq kw mr la ms le mt li ml mm mn mo bi translated">梯度推进</li><li id="8f6f" class="mg mh iq kp b kq mp kt mq kw mr la ms le mt li ml mm mn mo bi translated">引导聚集</li></ul><p id="39c4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">所以每个数据科学家都应该学习这些算法，并在他们的机器学习项目中使用它们。</p><p id="d9bd" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在本文中，您将了解更多关于随机森林算法的内容。完成本文后，您应该能够熟练使用随机森林算法，通过scikit-learn解决和构建分类问题的预测模型。</p><h1 id="cd73" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">什么是随机森林？</h1><p id="1c4b" class="pw-post-body-paragraph kn ko iq kp b kq mb jr ks kt mc ju kv kw md ky kz la me lc ld le mf lg lh li ij bi translated">随机森林是最流行的基于树的监督学习算法之一。它也是最灵活、最容易使用的。</p><p id="de40" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">该算法可用于解决分类和回归问题。随机森林倾向于组合数百个<em class="mu"> </em> <strong class="kp ir">决策树</strong> <em class="mu"> </em>，然后在不同的观察样本上训练每个决策树。</p><p id="cdb7" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">随机森林的最终预测是通过对每棵树的预测进行平均而得到的。</p><p id="2288" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">随机森林的好处很多。单个决策树倾向于<strong class="kp ir">过度适应</strong>训练数据，但是随机森林可以通过<strong class="kp ir">平均</strong>来自不同树的预测结果来缓解这个问题。这使得随机森林比单个决策树具有更高的预测准确性。</p><p id="50f3" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">随机森林算法还可以帮助您在数据集中找到重要的要素。它是<a class="ae mv" href="https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a" rel="noopener" target="_blank"> Boruta算法</a>的基础，该算法选择数据集中的重要特征。</p><p id="662f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">随机森林已经在各种应用中使用，例如在电子商务中向客户提供不同产品的推荐。</p><p id="3edb" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在医学上，可以使用随机森林算法，通过分析患者的病历来识别患者的疾病。</p><p id="9dc6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">此外，在银行部门，它可用于轻松确定客户是欺诈性的还是合法的。</p><h1 id="f67c" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">随机森林算法是如何工作的？</h1><p id="7a79" class="pw-post-body-paragraph kn ko iq kp b kq mb jr ks kt mc ju kv kw md ky kz la me lc ld le mf lg lh li ij bi translated">随机森林算法通过完成以下步骤来工作:</p><p id="84d1" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">步骤1 </strong>:算法从提供的数据集中选择随机样本。</p><p id="ec9a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">第二步:</strong>算法会为每个选中的样本创建一个决策树。然后，它将从创建的每个决策树中获得一个预测结果。</p><p id="54ac" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">步骤3: V </strong>然后对每个预测结果进行投票。对于一个分类问题，它会使用<strong class="kp ir">模式</strong>，对于一个回归问题，它会使用<strong class="kp ir">均值</strong>。</p><p id="718c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">步骤4 </strong>:最后，算法将选择投票最多的预测结果作为最终预测。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mw"><img src="../Images/49ea4aac54a166ddd43ddb785bb1a78e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtKarMUmzpx-X2WzKej7bQ.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">How It works</figcaption></figure><h1 id="e02c" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">实践中的随机森林</h1><p id="370a" class="pw-post-body-paragraph kn ko iq kp b kq mb jr ks kt mc ju kv kw md ky kz la me lc ld le mf lg lh li ij bi translated">现在您已经知道了随机森林算法的来龙去脉，让我们构建一个随机森林分类器。</p><p id="c457" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们将使用Pima Indians糖尿病数据集构建一个随机森林分类器。皮马印第安人糖尿病数据集包括根据提供的医疗细节预测5年内糖尿病的发病。这是一个二元分类问题。</p><div class="nf ng gp gr nh ni"><a href="https://www.datadriveninvestor.com/2020/08/27/what-is-a-data-catalog-and-how-does-it-enable-machine-learning-success/" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd ir gy z fp nn fr fs no fu fw ip bi translated">什么是数据目录，它如何使机器学习取得成功？数据驱动的投资者</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">数据目录是机器学习和数据分析的燃料。没有它，你将不得不花费很多…</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw kl ni"/></div></div></a></div><p id="8f42" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们的任务是在Pima Indian糖尿病数据集上分析并创建一个模型，以预测特定患者在给定其他独立因素的情况下是否有患糖尿病的风险。</p><p id="ce3c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们将从导入重要的包开始，我们将使用这些包来加载数据集并创建随机森林分类器。我们将使用<a class="ae mv" href="http://scikit-learn.org/stable/tutorial/index.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>库来加载和使用随机森林算法。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="0617" class="oc lk iq ny b gy od oe l of og"># import important packages<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/><br/>%matplotlib inline<br/><br/>from sklearn.model_selection import train_test_split<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.preprocessing import StandardScaler, MinMaxScaler<br/>import pandas_profiling<br/><br/>from matplotlib import rcParams<br/>import warnings<br/><br/>warnings.filterwarnings("ignore")<br/><br/># figure size in inches<br/>rcParams["figure.figsize"] = 10, 6<br/>np.random.seed(42)</span></pre><h1 id="4583" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">资料组</h1><p id="1dfc" class="pw-post-body-paragraph kn ko iq kp b kq mb jr ks kt mc ju kv kw md ky kz la me lc ld le mf lg lh li ij bi translated">然后从数据目录加载数据集:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="d770" class="oc lk iq ny b gy od oe l of og"># Load dataset<br/>data = pd.read_csv("../data/pima_indians_diabetes.csv")<br/></span></pre><p id="1417" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在我们可以观察数据集的样本。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="958a" class="oc lk iq ny b gy od oe l of og"># show sample of the dataset<br/>data.sample(5)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi oh"><img src="../Images/914969d42fed7973b51344bbe4fb0b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d9GtL70YfzKKcR7DmGhU9g.png"/></div></div></figure><p id="1a72" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如您所见，在我们的数据集中，我们有不同的带有数值的要素。</p><p id="88ee" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们来了解一下该数据集中的要素列表。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="5a11" class="oc lk iq ny b gy od oe l of og"># show columns<br/>data.columns</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/650b46fadd1d3eb3f3e562685aacddb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*W-EZsFXv75IpKbm9MTpVcg.png"/></div></figure><p id="2a0b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在该数据集中，有8个输入要素和1个输出/目标要素。缺失值被认为是用零值编码的。变量名的含义如下(从第一个到最后一个特征):</p><ul class=""><li id="ec34" class="mg mh iq kp b kq kr kt ku kw mi la mj le mk li ml mm mn mo bi translated">怀孕次数。</li><li id="2d38" class="mg mh iq kp b kq mp kt mq kw mr la ms le mt li ml mm mn mo bi translated">口服葡萄糖耐量试验中2小时的血浆葡萄糖浓度。</li><li id="183b" class="mg mh iq kp b kq mp kt mq kw mr la ms le mt li ml mm mn mo bi translated">舒张压(毫米汞柱)。</li><li id="de35" class="mg mh iq kp b kq mp kt mq kw mr la ms le mt li ml mm mn mo bi translated">三头肌皮褶厚度(毫米)。</li><li id="3f10" class="mg mh iq kp b kq mp kt mq kw mr la ms le mt li ml mm mn mo bi translated">2小时血清胰岛素(μU/ml)。</li><li id="3706" class="mg mh iq kp b kq mp kt mq kw mr la ms le mt li ml mm mn mo bi translated">体重指数(体重单位为千克/(身高单位为米))。</li><li id="5d84" class="mg mh iq kp b kq mp kt mq kw mr la ms le mt li ml mm mn mo bi translated">糖尿病谱系功能。</li><li id="74b4" class="mg mh iq kp b kq mp kt mq kw mr la ms le mt li ml mm mn mo bi translated">年龄(岁)。</li><li id="4cd9" class="mg mh iq kp b kq mp kt mq kw mr la ms le mt li ml mm mn mo bi translated">类别变量(0或1)。</li></ul><p id="277b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">然后我们将数据集分成独立特征和目标特征。这个数据集的目标特性叫做<strong class="kp ir">类。</strong></p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="357a" class="oc lk iq ny b gy od oe l of og"># split data into input and taget variable(s)<br/><br/>X = data.drop("class", axis=1)<br/>y = data["class"]</span></pre><h1 id="4a9e" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">预处理数据集</h1><p id="c417" class="pw-post-body-paragraph kn ko iq kp b kq mb jr ks kt mc ju kv kw md ky kz la me lc ld le mf lg lh li ij bi translated">在我们创建模型之前，我们需要通过使用scikit-learn的<code class="fe oj ok ol ny b">standardScaler</code>方法来标准化我们的独立特征。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="b383" class="oc lk iq ny b gy od oe l of og"># standardize the dataset<br/>scaler = StandardScaler()<br/>X_scaled = scaler.fit_transform(X)</span></pre><p id="10c5" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">点击<a class="ae mv" href="https://towardsdatascience.com/how-and-why-to-standardize-your-data-996926c2c832" rel="noopener" target="_blank">这里</a>，你可以从这篇文章中了解更多关于如何以及为什么要标准化你的数据。</p><h1 id="4d3e" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">将数据集拆分为训练数据和测试数据</h1><p id="d94c" class="pw-post-body-paragraph kn ko iq kp b kq mb jr ks kt mc ju kv kw md ky kz la me lc ld le mf lg lh li ij bi translated">现在，我们将处理过的数据集分成训练数据和测试数据。测试数据将占整个已处理数据集的10%。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="4ae6" class="oc lk iq ny b gy od oe l of og"># split into train and test set<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    X_scaled, y, stratify=y, test_size=0.10, random_state=42<br/>)</span></pre><h1 id="eb0f" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">构建随机森林分类器</h1><p id="6d51" class="pw-post-body-paragraph kn ko iq kp b kq mb jr ks kt mc ju kv kw md ky kz la me lc ld le mf lg lh li ij bi translated">现在是时候创建我们的随机森林分类器，然后在训练集上训练它。我们还将通过名为<strong class="kp ir"> n_estimators的<strong class="kp ir"> </strong>参数传递我们想要使用的森林中的树木数量(100)。</strong></p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="925f" class="oc lk iq ny b gy od oe l of og"># create the classifier<br/>classifier = RandomForestClassifier(n_estimators=100)<br/><br/># Train the model using the training sets<br/>classifier.fit(X_train, y_train)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/6010caac10f02b0dbd09f557629edd27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*TzobvdF6VfRurbQHTqrp8A.png"/></div></figure><p id="1352" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上面的输出显示了在训练数据的训练过程中使用的随机森林分类器的不同参数值。</p><p id="d12b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">经过训练后，我们可以对测试数据进行预测。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="ee8a" class="oc lk iq ny b gy od oe l of og"># predictin on the test set<br/>y_pred = classifier.predict(X_test)</span></pre><p id="71ac" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">然后，我们使用测试数据中的实际值和预测值来检查准确性。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="8e87" class="oc lk iq ny b gy od oe l of og"># Calculate Model Accuracy<br/>print("Accuracy:", accuracy_score(y_test, y_pred))</span></pre><p id="7d2d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">精确度:0.801948051948052</p><p id="bcde" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们的准确率在80.5%左右，这是不错的。但我们总能让它变得更好。</p><h1 id="2474" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">识别重要特征</h1><p id="3a53" class="pw-post-body-paragraph kn ko iq kp b kq mb jr ks kt mc ju kv kw md ky kz la me lc ld le mf lg lh li ij bi translated">我之前说过，我们也可以通过使用scikit-learn中随机森林算法的<strong class="kp ir"> feature_importances_ </strong>变量来检查重要特性。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="4e4c" class="oc lk iq ny b gy od oe l of og"># check Important features<br/>feature_importances_df = pd.DataFrame(<br/>    {"feature": list(X.columns), "importance": classifier.feature_importances_}<br/>).sort_values("importance", ascending=False)<br/><br/># Display<br/>feature_importances_df</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/2758d79b5fe48cd6bf3f63d656e5641f.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*Z2L63kdk16uqXi0rU_yn_A.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">Important Features</figcaption></figure><p id="7fb3" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上图显示了特征的相对重要性及其对模型的贡献。我们还可以使用seaborn和matplotlib库来可视化这些特性及其得分。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="b087" class="oc lk iq ny b gy od oe l of og"># visualize important featuers<br/><br/># Creating a bar plot<br/>sns.barplot(x=feature_importances_df.feature, y=feature_importances_df.importance)<br/># Add labels to your<br/><br/>plt.xlabel("Feature Importance Score")<br/>plt.ylabel("Features")<br/>plt.title("Visualizing Important Features")<br/>plt.xticks(<br/>    rotation=45, horizontalalignment="right", fontweight="light", fontsize="x-large"<br/>)<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi oo"><img src="../Images/05b80c78fdbdd3a78360c8d4f484ff23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XnwLzKrO7LUQDQAOY4NP3A.png"/></div></div></figure><p id="cf52" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">从上图中，您可以看到<strong class="kp ir">三头肌_皮褶_厚度特征</strong>的重要性较低，对预测没有太大贡献。</p><p id="d11e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这意味着我们可以删除此功能，并再次训练我们的随机森林分类器，然后看看它是否可以提高测试数据的性能。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="aa56" class="oc lk iq ny b gy od oe l of og"># load data with selected features<br/>X = data.drop(["class", "triceps_skinfold_thickness"], axis=1)<br/>y = data["class"]<br/><br/># standardize the dataset<br/>scaler = StandardScaler()<br/>X_scaled = scaler.fit_transform(X)<br/><br/># split into train and test set<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    X_scaled, y, stratify=y, test_size=0.10, random_state=42</span></pre><p id="0ac9" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们将使用从数据集中选择的已处理要素来训练随机森林算法，执行预测，然后确定模型的准确性。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="bc7e" class="oc lk iq ny b gy od oe l of og"># Create a Random Classifier<br/>clf = RandomForestClassifier(n_estimators=100)<br/><br/># Train the model using the training sets<br/>clf.fit(X_train, y_train)<br/><br/># prediction on test set<br/>y_pred = clf.predict(X_test)<br/><br/># Calculate Model Accuracy,<br/>print("Accuracy:", accuracy_score(y_test, y_pred))</span></pre><p id="cf17" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">精确度:0.81818181818182</p><p id="93a4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在，在我们移除了最不重要的特征<em class="mu">triceps _ skin fold _ thickness</em>之后，模型精度从<strong class="kp ir"> 80.5% </strong>提高到了<strong class="kp ir"> 81.8% </strong>。</p><p id="00ef" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这表明检查重要的特征并查看是否可以移除最不重要的特征以提高模型的性能是非常重要的。</p><h1 id="cf97" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">包扎</h1><p id="e544" class="pw-post-body-paragraph kn ko iq kp b kq mb jr ks kt mc ju kv kw md ky kz la me lc ld le mf lg lh li ij bi translated">基于树的算法对于每个数据科学家来说都是非常重要的。在本文中，您了解了基于树的算法的基础，以及如何使用随机森林算法创建分类模型。</p><p id="9c5e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我还建议你尝试其他类型的基于树的算法，比如<a class="ae mv" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier" rel="noopener ugc nofollow" target="_blank">额外树算法</a>。</p><p id="96c4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">你可以在这里下载本文用到的数据集和笔记本:<a class="ae mv" href="https://github.com/Davisy/Random-Forest-classification-Tutorial" rel="noopener ugc nofollow" target="_blank">https://github . com/Davisy/Random-Forest-class ification-Tutorial</a></p><p id="e0f4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">恭喜你，你已经完成了这篇文章的结尾！</p><p id="bb93" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如果你学到了新的东西或者喜欢阅读这篇文章，请分享给其他人看。在那之前，下期帖子再见！也可以通过推特<a class="ae mv" href="https://twitter.com/Davis_McDavid" rel="noopener ugc nofollow" target="_blank"> @Davis_McDavid </a>联系到我</p><p id="0af5" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">本文首次发表于<a class="ae mv" href="https://www.freecodecamp.org/news/how-to-use-the-tree-based-algorithm-for-machine-learning/" rel="noopener ugc nofollow" target="_blank"> freecodecamp </a>。</p><p id="2a0e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> <em class="mu">最后一件事:</em> </strong> <em class="mu">在以下链接中阅读更多类似这样的文章。</em></p><div class="nf ng gp gr nh ni"><a href="https://towardsdatascience.com/14-lesser-known-impressive-features-of-scikit-learn-library-e7ea36f1149a" rel="noopener follow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd ir gy z fp nn fr fs no fu fw ip bi translated">Scikit学习库的14个鲜为人知的令人印象深刻的特性。</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">scikit学习库中经常未知和被低估的功能示例。</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">towardsdatascience.com</p></div></div><div class="nr l"><div class="op l nt nu nv nr nw kl ni"/></div></div></a></div><div class="nf ng gp gr nh ni"><a href="https://chatbotslife.com/how-to-use-texthero-to-prepare-a-text-based-dataset-for-your-nlp-project-734feea75a5a" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd ir gy z fp nn fr fs no fu fw ip bi translated">如何使用Texthero为您的NLP项目准备基于文本的数据集</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">一个简单的python工具包，可以快速、轻松地处理基于文本的数据集。</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">chatbotslife.com</p></div></div><div class="nr l"><div class="oq l nt nu nv nr nw kl ni"/></div></div></a></div><div class="nf ng gp gr nh ni"><a href="https://medium.com/analytics-vidhya/15-undiscovered-open-source-machine-learning-frameworks-you-need-to-know-in-2020-77ad6e6f109d" rel="noopener follow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd ir gy z fp nn fr fs no fu fw ip bi translated">2020年你需要知道的15个未被发现的开源机器学习框架。</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">在你的下一个机器学习项目中有用的ML框架。</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">medium.com</p></div></div><div class="nr l"><div class="or l nt nu nv nr nw kl ni"/></div></div></a></div><p id="9c3c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">访问专家视图— </strong> <a class="ae mv" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="kp ir">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>