<html>
<head>
<title>Virtual Make-up : Snapchat Style Hat Filter</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">虚拟化妆:Snapchat风格的帽子滤镜</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/virtual-make-up-snapchat-style-hat-filter-7f57fcabb9dc?source=collection_archive---------7-----------------------#2020-12-26">https://medium.datadriveninvestor.com/virtual-make-up-snapchat-style-hat-filter-7f57fcabb9dc?source=collection_archive---------7-----------------------#2020-12-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="2a51" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">给一张脸添加不同种类的帽子是一个非常酷的功能，我想自己尝试一下。因此，当我有机会将它作为正在进行的OpenCV课程的一部分来实现时，我欣然接受了这个机会。以下是我的做法。</p><p id="630d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">步骤1:面部标志检测</strong></p><p id="3d60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这一步中，我们加载图像并应用Dlib面部标志检测器来检测给定图像上的标志点。下面是原图。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/bf4226fbc4b328723d8c83ece439084f.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*m8fQ7E9F6QCBqBUs9rtAIQ.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Girl without make-up</figcaption></figure><pre class="km kn ko kp gt kx ky kz la aw lb bi"><span id="7ff4" class="lc ld iq ky b gy le lf l lg lh">points = fbc.getLandmarks(faceDetector, landmarkDetector, imDlib)</span></pre><p id="c630" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了检测到的标志点。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi li"><img src="../Images/c251ae7be74ad93a7198cf074687296b.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*4SEJX6bxoFlvosUmGyiKjA.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Girl’s face with detected landmark points</figcaption></figure><p id="b897" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第二步:加载帽子的图片并调整大小</strong></p><p id="db13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这一步中，我们加载帽子的图像，并调整其高度和宽度，以匹配面部的尺寸。我们还必须考虑到帽子通常比脸宽的事实。因此，调整后的图像必须至少是脸的两倍宽。这是通过下面几行代码实现的。</p><pre class="km kn ko kp gt kx ky kz la aw lb bi"><span id="0088" class="lc ld iq ky b gy le lf l lg lh">hatWidthResized = points[16][0] - points[0][0]<br/>hatWidthResized = int(math.ceil(hatWidthResized / 100.0)) * 100</span><span id="3d58" class="lc ld iq ky b gy lj lf l lg lh">width = int(hatWidthResized * 2.5)<br/>height = int(width / 2)</span><span id="cfbd" class="lc ld iq ky b gy lj lf l lg lh">hatResize = cv2.resize(imgHat,(width,height),<br/>interpolation = cv2.INTER_AREA)</span></pre><p id="2ffc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们的例子中，我们决定将帽子的宽度增加2.5倍，这样可以获得更好的效果，因此我们将帽子的大小调整为脸部宽度的2.5倍。下面我们展示了帽子的图像。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/16318a513075e03a5e8a5dfd6e492413.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*3ZAdGm4Zl0KJZUjapFbhng.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Image of resized hat according to 2.5 times face</figcaption></figure><p id="8e7f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第三步:分离帽子图像的颜色和alpha通道</strong></p><pre class="km kn ko kp gt kx ky kz la aw lb bi"><span id="31d4" class="lc ld iq ky b gy le lf l lg lh">hatOriginal = hatResize[:,:,0:3]<br/>hatOriginal = cv2.cvtColor(hatOriginal,cv2.COLOR_BGR2RGB)<br/>maskHat = hatResize[:,:,3]</span></pre><p id="4780" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这一步中，我们将帽子图像的RGB和alpha通道分成不同的变量。这些将在稍后用于计算帽子图像的遮罩。</p><p id="6b59" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第四步:确定帽子的位置</strong></p><p id="3fbc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这一步中，我们必须将帽子放置在头部的正中央。方法是根据鼻子上的点对齐帽子，因为这些点或多或少在脸的中心。所以我们把点27和点30作为我们感兴趣的区域点。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/2258e8e00384a12e022c02d4001ba09b.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*8jXK_-uTtCtJQWrjY5wHsA.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Landmark points. Notice points 27 to 30 Nose points</figcaption></figure><pre class="km kn ko kp gt kx ky kz la aw lb bi"><span id="bd83" class="lc ld iq ky b gy le lf l lg lh">midNosePointX, midNosePointY = points[27]<br/>topNosePointX, topNosePointY = points[30]<br/>noseLength = topNosePointY - midNosePointY</span></pre><p id="1fe5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">步骤5:基于面部确定感兴趣区域。</strong></p><pre class="km kn ko kp gt kx ky kz la aw lb bi"><span id="da1b" class="lc ld iq ky b gy le lf l lg lh">nose_length_constant = 6.8 <br/>y1 = int(midNosePointY-(nose_length_constant * noseLength)) <br/>y2 = y1 + height<br/>x1 = midNosePointX - int(width/2)<br/>x2 = midNosePointX + int(width/2)</span></pre><p id="6832" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们计算需要放置帽子的面的长度，以达到最佳效果。在这里，我们通过实验确定了一个常数，这个常数需要乘以机头长度，以获得帽子的最佳位置；<em class="lm">"鼻长常数= 6.8" </em></p><div class="ln lo gp gr lp lq"><a href="https://www.datadriveninvestor.com/2020/11/19/social-media-and-covert-censorship-by-sponsoring-popularity-over-credibility/" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd ir gy z fp lv fr fs lw fu fw ip bi translated">社交媒体和通过赞助受欢迎度超过可信度的秘密审查|数据驱动的投资者</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">“喜欢”按钮，如选项、鼓掌、关注或推荐按钮，是社交网络平台、互联网…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="lz l"><div class="ma l mb mc md lz me kr lq"/></div></div></a></div><p id="f098" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第六步:限制边界点</strong></p><p id="622a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这一步中，我们限制感兴趣区域的边界点值。如果我们不做这一步，那么一些帽子的图像可能会导致边界点超过人脸的界限，这是不希望的。</p><pre class="km kn ko kp gt kx ky kz la aw lb bi"><span id="1394" class="lc ld iq ky b gy le lf l lg lh">if x2 &gt; origImageWidth:<br/>    x2 = origImageWidth<br/>    hatOriginal = cv2.resize(hatOriginal,(x2-x1,y2-y1))<br/>    maskHat = cv2.resize(maskHat,(x2-x1,y2-y1))</span><span id="3fcb" class="lc ld iq ky b gy lj lf l lg lh"># taking y1 as the centre coordinate<br/>if y1 &lt; 0:<br/>    y1 = 0<br/>    hatOriginal = cv2.resize(hatOriginal,(x2-x1,y2-y1))<br/>    maskHat = cv2.resize(maskHat,(x2-x1,y2-y1))<br/>    <br/>if x1 &lt; 0:<br/>    x1 = 0<br/>    hatOriginal = cv2.resize(hatOriginal,(x2-x1,y2-y1))<br/>    maskHat = cv2.resize(maskHat,(x2-x1,y2-y1))</span></pre><p id="0e28" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我们还必须限制帽子图像的遮罩尺寸。</p><p id="3920" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">步骤7:创建帽子图像和感兴趣区域的组合掩模。</strong></p><pre class="km kn ko kp gt kx ky kz la aw lb bi"><span id="9186" class="lc ld iq ky b gy le lf l lg lh">maskedHatImage = cv2.merge((maskHat,maskHat,maskHat))<br/>aughatmasked = cv2.bitwise_and(hatOriginal,maskedHatImage)</span></pre><p id="20ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在此步骤中，我们通过对帽子的原始图像和帽子图像的遮罩执行按位and运算，来创建帽子图像的3通道遮罩和帽子的组合遮罩。</p><p id="ed53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">步骤8:创建帽子图像和感兴趣区域的组合掩模。</p><pre class="km kn ko kp gt kx ky kz la aw lb bi"><span id="c26f" class="lc ld iq ky b gy le lf l lg lh">hatGirlRegionOfInterest = hatGirl[y1:y2,x1:x2]</span><span id="cf4e" class="lc ld iq ky b gy lj lf l lg lh">hatGirlRegionOfInterestImage = cv2.bitwise_and(hatGirlRegionOfInterest, cv2.bitwise_not(maskedHatImage))</span><span id="481a" class="lc ld iq ky b gy lj lf l lg lh">hatGirlRegionOfInterestCombined = cv2.bitwise_or(hatGirlRegionOfInterestImage, aughatmasked)</span></pre><p id="28c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在该步骤中，我们基于x1、x2、y1、y2点提取感兴趣区域。然后，我们对带有感兴趣区域的帽子图像的反转遮罩执行按位and运算。然后，我们使用按位“或”运算将该遮罩与帽子图像的扩充遮罩相结合。</p><p id="51d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第九步:创建最终图像</strong></p><p id="99f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这一步中，我们用帽子和感兴趣区域图像的组合遮罩替换原始图像中的感兴趣区域，以获得以下结果。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/9bccef5a42ae4d9ab042c73d997f2bc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*ebly0F6uLZ8LqVP0fFoW1g.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Girl with Harry Potter Sorting Hat</figcaption></figure><p id="c3b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结论</strong></p><p id="a3ae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该算法的难点在于确定鼻长常量值。因为人脸尺寸不同，所以确定常数值很棘手，可能会影响不同图像的性能。</p><h2 id="0d43" class="lc ld iq bd mg mh mi dn mj mk ml dp mm jy mn mo mp kc mq mr ms kg mt mu mv mw bi translated">访问专家视图— <a class="ae mx" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>