# Google 的开源 BERT 模型是如何增强 NLP 的

> 原文：<https://medium.datadriveninvestor.com/how-googles-open-source-bert-model-is-enhancing-nlp-2691bb40bba5?source=collection_archive---------11----------------------->

![](img/393d0b7b58708cf54341dcbc22286798.png)

变压器的双向编码器表示，也称为 BERT 是一种训练模型，它极大地提高了 NLP 模型的效率和效果。既然 Google 已经将 BERT 模型开源，那么它就可以改进所有行业的 NLP 模型。在文章中，我们来看看 BERT 是如何将 NLP 变成当今世界最强大和最有用的人工智能解决方案之一的。

# 应用 BERT 模型进行搜索

谷歌的搜索引擎因其呈现相关内容的能力而闻名于世，他们已经将这个自然语言处理程序向世界开放源代码。

随着世界指数级地产生新数据，系统阅读和解释自然语言的能力变得越来越重要。谷歌的字义、短语和呈现相关内容的一般能力库是开源的。除了自然语言处理，他们的 BERT 模型还具有从大量非结构化数据中提取信息的能力，可以应用于为任何图书馆创建搜索界面。

在本文中，我们将比较 BERT 增强前后的搜索结果，并剖析能源领域的一个应用程序。

BERT(来自变压器的双向编码器表示)是由[谷歌人工智能语言](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)小组提出的一种预训练方法，旨在克服早期 NLP 模型的一个常见问题:缺乏足够的训练数据。

让我们在不涉及太多细节的情况下详细阐述一下:

# 培训模型

低级(例如命名实体识别、主题分割)和高级(例如情感分析、语音识别)NLP 任务需要特定于任务的标注数据集。虽然它们很难获得并且组装起来很昂贵，但标记数据集在浅层和深层神经网络模型的性能中起着至关重要的作用。只有当数百万甚至数十亿带注释的训练样本可用时，才能获得高质量的推理结果。这是一个让许多 NLP 任务无法实现的问题。直到伯特被开发出来。

BERT 是一个通用语言表示模型，在大型未标注文本语料库上训练。当模型接触到大量文本内容时，它*会学习*理解上下文和句子中单词之间的关系。不像以前的学习模型只在单词层面上表达意思(*银行*在“银行账户”和“草地银行”中的意思是一样的)，BERT 实际上关心上下文。也就是说，在一个句子中，这个词的前后是什么。上下文被证明是 NLP 模型的一个主要缺失功能，对模型性能有直接影响。许多人认为设计像 BERT 这样的上下文感知模型是 NLP 新时代的开始。

在大量文本内容上训练 BERT 是一种被称为*预训练*的技术。这意味着模型的权重可以针对一般的文本理解任务进行调整，并且可以在此基础上构建更细粒度的模型。当作者在 11 个 NLP 任务中使用基于 BERT 的模型时，他们已经证明了这种技术的优越性，并取得了最先进的结果。

# 预训练模型

最好的一点是:预先训练的 BERT 模型是开源的，可以公开获得。这意味着任何人都可以处理 NLP 任务，并在 BERT 的基础上构建他们的模型。没有什么能打败它，对吗？哦，等等:这也意味着 NLP 模型现在可以在更小的数据集上训练(微调)，而不需要从头开始训练。一个新时代的开始。

这些预先训练好的模型可以帮助公司降低部署 NLP 模型的成本和时间，以供内部或外部使用。teambuilding.com 一家虚拟团队文化建设公司的首席执行官 Michael Alexis 强调了训练有素的 NLP 模型的有效性。

*“NLP 最大的好处是对信息的可扩展和一致的推理和处理。”——teambuilding.com*[T5的首席执行官迈克尔·亚历克西斯](https://teambuilding.com/)

迈克尔陈述了 NLP 如何应用于文化培育项目，如破冰或调查。一家公司可以通过分析员工的反应来获得对公司文化的宝贵见解。这不仅通过分析文本，而且通过分析文本的注释来实现。从本质上来说，该模型还“从字里行间”推断情感、感觉和整体前景。BERT 可以在这种情况下提供帮助，它可以通过一个指标基础来预先训练模型，从而揭示语言的细微差别，并提供更准确的见解。

[](https://www.datadriveninvestor.com/2020/08/11/being-good-at-google-is-a-skill/) [## 擅长谷歌是一种技能|数据驱动的投资者

### 擅长‘谷歌’是一种技能。是的，你听到了。知道什么和如何谷歌或搜索的东西是一个…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2020/08/11/being-good-at-google-is-a-skill/) 

# 改进查询

对上下文建模的能力让 BERT 成为了 NLP 的英雄，并彻底改变了谷歌搜索本身。下面是谷歌搜索产品团队的一段话，以及他们在调试 BERT 以理解查询背后的意图时的测试经历。

> 以下是一些例子，展示了伯特理解你搜索背后意图的能力。以下是对“2019 年前往美国的巴西游客需要签证”的搜索。单词“to”及其与查询中其他单词的关系对于理解其含义尤其重要。这是关于一个巴西人去美国旅行，而不是相反。以前，我们的算法无法理解这种联系的重要性，我们返回了有关美国公民前往巴西的结果。有了 BERT，搜索就能够把握这种细微差别，并且知道非常常见的单词“to”在这里实际上非常重要，我们可以为这个查询提供更相关的结果。
> - [比以往任何时候都更好地理解搜索](https://www.blog.google/products/search/search-language-understanding-bert/)，作者 Pandu Nayak，谷歌研究员兼搜索副总裁。

![](img/a6223c3d9bbd880bc747bcebf00f1dd8.png)

在我们上一篇关于 [**NLP 和 OCR**](https://blueorange.digital/bold-nlp-and-ocr-use-cases/) 的文章中，我们展示了 NLP 在房地产领域的一些应用。我们也提到了“NLP 工具是理想的信息提取工具”。让我们看看能源行业，看看像 BERT 这样的颠覆性 NLP 技术如何实现新的应用用例。

# 自然语言处理在能源领域的应用

# NLP 模型可以从大量的非结构化数据中提取信息

使用 NLP 模型的一种方式是从非结构化文本数据中提取关键信息。电子邮件、日记、笔记、日志和报告都是文本数据源的例子，是企业日常运营的一部分。其中一些文件可能对提高运营效率和降低成本的组织工作至关重要。

当旨在实施**风力涡轮机预测性维护时，** **故障报告**可能包含关于不同组件行为的关键信息。但是由于不同的风力涡轮机制造商具有不同的数据收集规范(即，维护报告以不同的格式甚至语言出现)，手动识别相关数据项对于电厂所有者来说可能很快变得昂贵。 **NLP 工具可以从非结构化内容中提取相关的概念、属性和事件。**然后可以使用文本分析在不同的数据源中寻找相关性和模式。这使工厂所有者有机会根据故障报告中确定的定量措施实施预测性维护。

# NLP 模型可以提供自然语言搜索接口

类似地，为石油和天然气公司工作的地球科学家通常需要审阅许多与过去的钻井作业、测井记录和地震数据相关的文档。由于此类文档也有不同的格式，并且通常分布在多个位置(包括物理位置和数字位置)，因此他们会浪费大量时间在错误的位置查找信息。在这种情况下，一个可行的解决方案是一个基于自然语言处理的搜索界面，它允许用户用自然语言查找数据。然后，NLP 模型可以关联数百个文档中的数据，并返回一组查询答案。然后，工作人员可以根据他们自己的专业知识验证输出，反馈将进一步改进模型。

然而，部署这样的模型也有技术上的考虑。一个方面是，特定行业的行话可能会混淆没有适当语义理解的传统学习模型。其次，模型的性能可能会受到训练数据集大小的影响。这时，BERT 等预训练模型就能证明是有益的。上下文表示可以模拟适当的词义，并消除由特定行业术语引起的任何混淆。通过使用预先训练的模型，可以在较小的数据集上训练网络。这节省了从头开始培训所需的时间、精力和资源。

# 自己的事业呢？

你能想到任何 NLP 任务可以帮助你削减成本和提高运营效率吗？

[蓝橙数字](https://blueorange.digital/)数据科学团队也很乐意为您的利益调整 BERT！

有关人工智能和技术趋势的更多信息，请参见 Blue Orange Digital 为[供应链](https://blueorange.digital/casestudy/supply-chain-revenue-predictions-for-pharmaceuticals/)、[医疗保健文档自动化](https://blueorange.digital/casestudy/digital-transformation-of-government-documents/)和[提供数据驱动解决方案的首席执行官 Josh Miramant。](https://blueorange.digital/case-study/)

*关注我上*[*Twitter*](https://twitter.com/BlueOrangeData)*或*[*LinkedIn*](https://www.linkedin.com/in/joshmiramant/)*。查看我的* [*网站*](https://blueorange.digital/) *。*

![](img/d03313e0bdd35e90c0cff4e74339b1c2.png)

Josh Miramant 是 Blue Orange Digital 的首席执行官和创始人，Blue Orange Digital 是一家数据科学和机器学习机构，在纽约市和华盛顿州 DC 设有办公室。米拉曼特是一位受欢迎的演讲者、未来学家，也是企业和初创公司的战略商业和技术顾问。他是一个连续的企业家和软件工程师，已经建立和扩大了 3 家创业公司。他帮助组织优化和自动化其业务，实施数据驱动的分析技术，并了解人工智能、大数据和物联网等新技术的影响。

在 IBM ThinkLeaders、戴尔技术和纽约市 10 大人工智能开发和定制软件开发机构上进行了专题报道，在 Clutch 和 YahooFinance 上对他在 NLP、人工智能和机器学习方面的贡献进行了评论。专注于预测性维护、统一数据湖、供应链/网格/营销/销售优化、异常检测、推荐系统，以及为众多行业提供的其他 ML 解决方案。

访问 [BlueOrange.digital](https://blueorange.digital/) 了解更多信息和[案例研究](https://blueorange.digital/case-study/)。

最初发表:[联合起来。艾](https://www.unite.ai/how-language-processing-is-being-enhanced-through-googles-open-source-bert-model/)

## 访问专家视图— [订阅 DDI 英特尔](https://datadriveninvestor.com/ddi-intel)