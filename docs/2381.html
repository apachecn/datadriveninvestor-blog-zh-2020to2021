<html>
<head>
<title>Can AI be fooled?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AI会被忽悠吗？</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/can-ai-be-fooled-722f59bb2e9a?source=collection_archive---------14-----------------------#2020-04-27">https://medium.datadriveninvestor.com/can-ai-be-fooled-722f59bb2e9a?source=collection_archive---------14-----------------------#2020-04-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1af2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在过去的几十年里，计算机能够像人类一样观察世界的前景已经成为越来越感兴趣的话题。通过多年的研究，我们已经了解了人类视觉系统的复杂性，以及在机器中复制这些过程将会多么令人印象深刻。为了复制人类“看”世界的方式，计算机必须破译多维数据，并识别数据中的模式。当然，这并不容易。</p><p id="8737" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">深度神经网络(DNN)是一种前馈型网络，用于模拟各种复杂的非线性关系。在计算机视觉方面(更具体地说是图像识别)，经过训练识别交通标志的DNN将使用给定图像的数据来计算图像中的标志是某个交通标志的概率。最近，DNNs已经在许多任务中实现了接近人类的性能，例如视觉分类和模式识别。</p><div class="kl km gp gr kn ko"><a href="https://www.datadriveninvestor.com/2020/02/12/has-general-ai-exceeded-the-intellectual-capacity-of-humans/" rel="noopener  ugc nofollow" target="_blank"><div class="kp ab fo"><div class="kq ab kr cl cj ks"><h2 class="bd ir gy z fp kt fr fs ku fu fw ip bi translated">AI将军是否已经超过了人类的智力容量？数据驱动的投资者</h2><div class="kv l"><h3 class="bd b gy z fp kt fr fs ku fu fw dk translated">不仅在游戏中，而且在劳动力市场上，机器都比人类聪明。在今天的许多领域，使用…</h3></div><div class="kw l"><p class="bd b dl z fp kt fr fs ku fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="kx l"><div class="ky l kz la lb kx lc ld ko"/></div></div></a></div><p id="332b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，鉴于dnn能够如此好地分类图像，问题就出现了:人类和计算机视觉之间有什么区别吗？有没有可能存在人类看似无法识别，但计算机却相当明显的图像？反之亦然。你可能很高兴听到人类视觉在某些领域仍然超过计算机视觉。最近的研究表明，DNNs可以被愚弄，而且事实上相当容易。一项<a class="ae le" href="http://www.evolvingai.org/fooling" rel="noopener ugc nofollow" target="_blank">研究</a>显示，有可能创造/进化出人类无法识别的合成图像(例如电视静态图像)，但计算机有很高的把握将其归类为熟悉的物体。</p><p id="312f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有两种方法来发展这些“愚蠢”的形象。首先通过直接编码图像:这是通过独立地优化每个像素中的颜色值来完成的。直接编码的图像输出类似白噪声的视觉效果(或者对我们人类来说是电视静电噪声)。DNN已经将下面的图像归类为熟悉的物体。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/c1aeee1ba29e17234209be50d545bc31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*863zppZEAzrV5cKg21SnYg.png"/></div></div></figure><p id="9be1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第二，人们可以用间接编码来发展图像，间接编码使用更规则的模式来产生图像。这些类型的图像可以被人类和DNA识别。类似地，下面的图像对人类来说是不可识别的，但是DNNs还是以某种方式对它们进行了高度确定的分类。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lq"><img src="../Images/3286b35947c15a0dc91cb0748aaf72bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NI-yuaB-HhDlEsKr1czvKQ.png"/></div></div></figure><h2 id="392d" class="lr ls iq bd lt lu lv dn lw lx ly dp lz jy ma mb mc kc md me mf kg mg mh mi mj bi translated">为什么DNNs会犯这样的错误？</h2><p id="4b4d" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">这一切都与DNN关注的焦点有关。在直接编码图像的情况下，DNNs可能会看到模糊地类似于它所训练的图像的集中的彩色像素。在其他情况下，图像可能具有某一类别的正确颜色或图案，这表明一个无法识别的图像是一个熟悉的对象。</p><h2 id="edf2" class="lr ls iq bd lt lu lv dn lw lx ly dp lz jy ma mb mc kc md me mf kg mg mh mi mj bi translated">为什么愚弄DNNs很重要？</h2><p id="bbf2" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">想象一个场景，部署一个面部识别系统来检测哪些员工有权访问某些文件。犯罪分子可能会通过制作合成图像来欺骗或绕过系统。这是一个相当大的安全风险，并向我们表明，在能够取代人类之前，计算机视觉还有很长的路要走</p><p id="e7e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mp">参考文献</em></p><p id="f6f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae le" href="http://anhnguyen.me/" rel="noopener ugc nofollow" target="_blank">阮一甲</a>，<a class="ae le" href="http://yosinski.com/" rel="noopener ugc nofollow" target="_blank">林斯基J </a>，<a class="ae le" href="http://jeffclune.com/" rel="noopener ugc nofollow" target="_blank">克卢恩J </a>。深度神经网络很容易被忽悠:对无法识别的图像的高置信度预测。《计算机视觉和模式识别》(CVPR 2015年)，IEEE，2015年。(<a class="ae le" href="http://www.evolvingai.org/files/DNNsEasilyFooled_cvpr15.pdf" rel="noopener ugc nofollow" target="_blank"> pdf </a>)</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="mq mr l"/></div></figure></div></div>    
</body>
</html>