<html>
<head>
<title>How to Deploy your NLP Model to Production as an API with Algorithmia</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Algorithmia将您的NLP模型作为API部署到生产中</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/how-to-deploy-your-nlp-model-to-production-as-an-api-with-algorithmia-e4081854d524?source=collection_archive---------1-----------------------#2020-12-05">https://medium.datadriveninvestor.com/how-to-deploy-your-nlp-model-to-production-as-an-api-with-algorithmia-e4081854d524?source=collection_archive---------1-----------------------#2020-12-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e679" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种在无服务器产品上逐步部署NLP模型的简单方法。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4c992699bd1c24c2da9dbb6d1b6e9493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6vuGjbQ8K9Zj-SMTvv2XGg.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://www.pexels.com/@cottonbro?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">cottonbro</a> from <a class="ae kv" href="https://www.pexels.com/photo/person-in-blue-denim-jacket-holding-black-smartphone-5053740/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Pexels</a></figcaption></figure><p id="96f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你知道90%的机器学习模型从未真正投入生产吗？</p><p id="b222" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这意味着当人们学习机器学习时，很少讨论机器学习部署的话题。因此，许多AI从业者知道如何创建有用的ML模型，但他们发现很难将它们部署到生产中。</p><p id="b66c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不用说，如果你要使用ML模型，机器学习部署是你应该拥有的更重要的技能之一。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/d63634756e94ca363dd0be91a100a221.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/0*pjf8zzOM1Gj4JRBm.jpeg"/></div></figure><p id="4a74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型部署是将模型集成到现有生产环境中的过程。该模型将接收输入并预测输出，以便针对特定用例做出决策。</p><p id="c00d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，可以在电子商务网站中部署一个模型，它可以预测关于特定产品的评论是正面的还是负面的。</p><blockquote class="lt lu lv"><p id="ec26" class="kw kx lw ky b kz la jr lb lc ld ju le lx lg lh li ly lk ll lm lz lo lp lq lr ij bi translated"><em class="iq">只有当一个模型与业务系统完全整合时，我们才能从它的预测中提取真正的价值。—克里斯托弗·萨米乌拉</em></p></blockquote><p id="7e9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有不同的方法可以将机器学习模型部署到生产中。但是在今天的文章中，您将学习如何使用Algorithmia将您的NLP模型作为API部署到生产中。</p><p id="e43d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，您将了解到:</p><ul class=""><li id="6b82" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated">如何创建检测垃圾短信的NLP模型</li><li id="b9e9" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">如何使用MLOps平台Algorithmia？</li><li id="8023" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">如何将您的模型部署到Algorithmia平台</li><li id="1286" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">如何在任何Python应用程序中使用您部署的NLP模型。</li></ul><p id="96d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的第一步是创建一个可以检测垃圾短信的机器学习模型。所以我们开始吧！</p><h1 id="52c3" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">如何建立ML模型</h1><p id="c3f0" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">首先，我们需要建立我们的模型。下面是你应该遵循的步骤。</p><h1 id="e5cb" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">导入Python包</h1><p id="dc09" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">我们首先导入所有重要的python包，这些包将用于加载数据、预处理数据和创建文本分类模型。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="c1e2" class="nq mp iq nm b gy nr ns l nt nu"># import important modules<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from string import punctuation </span><span id="d198" class="nq mp iq nm b gy nv ns l nt nu"># sklearn modules<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.naive_bayes import MultinomialNB<br/>from sklearn.svm import SVC<br/>from sklearn.metrics import (<br/>    accuracy_score,<br/>    classification_report,<br/>    plot_confusion_matrix,<br/>    f1_score,<br/>    roc_auc_score,<br/>)<br/>from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.model_selection import cross_val_score, RandomizedSearchCV</span><span id="a0c5" class="nq mp iq nm b gy nv ns l nt nu"># text preprocessing modules<br/>from nltk.tokenize import word_tokenize<br/>from cleantext import clean</span><span id="2aab" class="nq mp iq nm b gy nv ns l nt nu">import nltk<br/>from nltk.corpus import stopwords<br/>from nltk.stem import WordNetLemmatizer <br/>import re #regular expression<br/></span><span id="ddf8" class="nq mp iq nm b gy nv ns l nt nu">from wordcloud import WordCloud, STOPWORDS</span><span id="1795" class="nq mp iq nm b gy nv ns l nt nu"># Download dependency<br/>for dependency in (<br/>    "brown",<br/>    "names",<br/>    "wordnet",<br/>    "averaged_perceptron_tagger",<br/>    "universal_tagset",<br/>    "stopwords"<br/>):<br/>    nltk.download(dependency)</span><span id="d1be" class="nq mp iq nm b gy nv ns l nt nu">#nltk.download('stopwords')</span><span id="7d20" class="nq mp iq nm b gy nv ns l nt nu">import warnings<br/>warnings.filterwarnings("ignore")<br/># seeding<br/>np.random.seed(123)</span></pre><h1 id="4047" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">加载垃圾邮件数据集</h1><p id="330f" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">然后，我们从数据目录加载垃圾邮件数据集，如下所示:</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="e964" class="nq mp iq nm b gy nr ns l nt nu"># load data<br/>data = pd.read_csv("../data/spam.tsv", sep="\t")</span></pre><p id="bbe4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看看数据集的前五行。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="1726" class="nq mp iq nm b gy nr ns l nt nu"># show top five rows<br/>data.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/c836a987cf1bcf7f070d8cf8cd2642bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mEtYoXxOphJqxemk.PNG"/></div></div></figure><p id="4a1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集有四列，但是我们将只关注消息和标签列。</p><p id="7638" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来看看数据集的形状:</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="2355" class="nq mp iq nm b gy nr ns l nt nu"># check the shape<br/>data.shape</span></pre><p id="0d2b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:(5572，4)</p><p id="0edc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们有5572行和4列。</p><h1 id="8274" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">如何处理缺失值</h1><p id="0dee" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">有时数据可能会有缺失值。我们可以使用pandas的<strong class="ky ir"> isnull() </strong>方法来检查我们的数据集是否有任何缺失值。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="0e45" class="nq mp iq nm b gy nr ns l nt nu"># check missing values<br/>data.isnull().sum()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/ca2e72c67c18c6b872cdbc5b82eb1fe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:430/0*F-N1xTM4ed8yf0CI.PNG"/></div></figure><p id="1e42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出显示我们的数据集没有任何缺失值。</p><h1 id="c078" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">如何评价班级分布</h1><p id="e791" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">我们可以使用pandas包中的<strong class="ky ir"> value_counts() </strong>方法来评估数据集的类分布。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="73d1" class="nq mp iq nm b gy nr ns l nt nu"># evalute class distribution<br/>data["label"].value_counts()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/3b40497477b82d87efb2fa7ba0c4abe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/0*g2UukdplNSriq6kJ.PNG"/></div></figure><p id="f4df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在该数据集中，合法邮件(ham)比垃圾邮件多。</p><h1 id="c798" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">探索性数据分析</h1><p id="cf44" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">这是创建你的机器学习项目非常重要的一步。它有助于您更好地了解数据集。</p><p id="bab9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这一步中，我们将找到合法邮件和垃圾邮件中经常使用的单词。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="5a2d" class="nq mp iq nm b gy nr ns l nt nu"># collect words from the dataset<br/>def collect_words(data, label):<br/>    collected_words = " "</span><span id="7004" class="nq mp iq nm b gy nv ns l nt nu">    # iterate through the csv file<br/>    for val in data.message[data["label"] == label]:</span><span id="b284" class="nq mp iq nm b gy nv ns l nt nu">        # typecaste each val to string<br/>        val = str(val)</span><span id="8d9e" class="nq mp iq nm b gy nv ns l nt nu">        # split the value<br/>        tokens = val.split()</span><span id="471f" class="nq mp iq nm b gy nv ns l nt nu">        # Converts each token into lowercase<br/>        for i in range(len(tokens)):<br/>            tokens[i] = tokens[i].lower()</span><span id="e3cd" class="nq mp iq nm b gy nv ns l nt nu">        for words in tokens:<br/>            collected_words = collected_words + words + " "</span><span id="f2af" class="nq mp iq nm b gy nv ns l nt nu">    return collected_words</span></pre><p id="2631" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面这个名为<strong class="ky ir"> collect_words() </strong>的函数会根据标签(ham或spam)从数据集中收集所有单词。</p><p id="6665" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后我们可以通过使用<strong class="ky ir"> wordcloud </strong> Python包来可视化常用词。我们将从标记为ham(合法)的消息开始。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="c402" class="nq mp iq nm b gy nr ns l nt nu"># visualize ham labeled sms<br/>cloud_stopwords = set(STOPWORDS)<br/>ham_words = collect_words(data, label="ham")</span><span id="7926" class="nq mp iq nm b gy nv ns l nt nu">print("Total words {}".format(len(ham_words)))</span><span id="9bfc" class="nq mp iq nm b gy nv ns l nt nu">wordcloud = WordCloud(<br/>    width=1000,<br/>    height=1000,<br/>    background_color="white",<br/>    stopwords=cloud_stopwords,<br/>    min_font_size=10,<br/>).generate(ham_words)</span><span id="d8b2" class="nq mp iq nm b gy nv ns l nt nu"># plot the WordCloud image<br/>plt.figure(figsize=(15, 8), facecolor=None)<br/>plt.imshow(wordcloud)<br/>plt.axis("off")<br/>plt.tight_layout(pad=0)</span><span id="07f0" class="nq mp iq nm b gy nv ns l nt nu">plt.show()</span></pre><p id="b22f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总字数:349132</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/5d569c010756090975d1f354edcf6e92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/0*-fNr_7AEP_Gt0rmw.png"/></div></figure><p id="ba18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在合法的留言里可以看到，出现频率最高的词是<em class="lw"> will，gt，now，ok，call，want，got，</em>等等。</p><p id="254e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们可以将标记为垃圾邮件的邮件中最常见的单词可视化。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="65b6" class="nq mp iq nm b gy nr ns l nt nu"># visualize spam labeled sms<br/>cloud_stopwords = set(STOPWORDS)<br/>spam_words = collect_words(data, label="spam")</span><span id="185e" class="nq mp iq nm b gy nv ns l nt nu">print("Total words {}".format(len(spam_words)))</span><span id="2603" class="nq mp iq nm b gy nv ns l nt nu">wordcloud = WordCloud(<br/>    width=1000,<br/>    height=1000,<br/>    background_color="white",<br/>    stopwords=cloud_stopwords,<br/>    min_font_size=10,<br/>).generate(spam_words)</span><span id="1283" class="nq mp iq nm b gy nv ns l nt nu"># plot the WordCloud image<br/>plt.figure(figsize=(10, 8), facecolor=None)<br/>plt.imshow(wordcloud)<br/>plt.axis("off")<br/>plt.tight_layout(pad=0)</span><span id="17c1" class="nq mp iq nm b gy nv ns l nt nu">plt.show()</span></pre><p id="dbac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总字数:104304</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/1aef5db2b1d2346e49866a2a54ded2b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/0*IMOxnAnI9HTVw-V9.png"/></div></figure><p id="4ba3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上图中显示，出现频率最高的词是那些像<em class="lw">来电、认领、免费、txt、移动、回复、优惠、</em>等等。</p><h1 id="1c6a" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">如何处理数据</h1><p id="2cca" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">在探索和分析数据集之后，下一步是在创建我们的机器学习模型之前，将数据集预处理成正确的格式。</p><p id="41ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们首先用数值替换ham和spam类。ham类将被标记为0，而spam类将被标记为1。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="ca79" class="nq mp iq nm b gy nr ns l nt nu"># replace ham to 0 and spam to 1<br/>new_data = data.replace({"ham": 0, "spam": 1})<br/>new_data.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/22fe44e8b7d93bb9206c0f6035c741e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FaB2kG0VntA9CrfG.PNG"/></div></div></figure><p id="4ace" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个数据集中的消息包含了很多我们在创建机器学习模型时不需要的不必要的单词和字符。</p><p id="33a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将通过删除停用字词、数字和标点来清理邮件。然后我们将单词转换成小写，最后通过使用NLTK包中的词汇化过程将每个单词转换成它的基本形式。</p><p id="64d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">函数将处理所有必要的步骤来清理我们的数据集。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="5bb2" class="nq mp iq nm b gy nr ns l nt nu">stop_words =  stopwords.words('english')<br/><br/>def text_cleaning(text, remove_stop_words=True, lemmatize_words=True):<br/>    # Clean the text, with the option to remove stop_words and to lemmatize word<br/><br/>    # Clean the text<br/>    text = re.sub(r"[^A-Za-z0-9]", " ", text)<br/>    text = re.sub(r"\'s", " ", text)<br/>    text = re.sub(r"n't", " not ", text)<br/>    text = re.sub(r"I'm", "I am", text)<br/>    text = re.sub(r"ur", " your ", text)<br/>    text = re.sub(r" nd "," and ",text)<br/>    text = re.sub(r"\'d", " would ", text)<br/>    text = re.sub(r"\'ll", " will ", text)<br/>    text = re.sub(r" tkts "," tickets ",text)<br/>    text = re.sub(r" c "," can ",text)<br/>    text = re.sub(r" e g ", " eg ", text)<br/>    text =  re.sub(r'http\S+',' link ', text)<br/>    text = re.sub(r'\b\d+(?:\.\d+)?\s+', '', text) # remove numbers<br/>    text = re.sub(r" u "," you ",text)<br/>    text = text.lower()  # set in lowercase <br/>        <br/>    # Remove punctuation from text<br/>    text = ''.join([c for c in text if c not in punctuation])<br/>    <br/>    # Optionally, remove stop words<br/>    if remove_stop_words:<br/>        text = text.split()<br/>        text = [w for w in text if not w in stop_words]<br/>        text = " ".join(text)<br/>    <br/>    # Optionally, shorten words to their stems<br/>    if lemmatize_words:<br/>        text = text.split()<br/>        lemmatizer = WordNetLemmatizer() <br/>        lemmatized_words = [lemmatizer.lemmatize(word) for word in text]<br/>        text = " ".join(lemmatized_words)<br/>    <br/>    # Return a list of words<br/>    return(text)</span></pre><p id="a23c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们可以通过使用<strong class="ky ir"> text_cleaning() </strong>函数来清理我们的数据集。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="7bfe" class="nq mp iq nm b gy nr ns l nt nu">#clean the dataset <br/>new_data["clean_message"] = new_data["message"].apply(text_cleaning)</span></pre><p id="a03a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们将数据集分成训练和测试数据。测试规模是整个数据集的15%。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="a1e8" class="nq mp iq nm b gy nr ns l nt nu"># split data into train and test<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    new_data["clean_message"],<br/>    new_data["label"],<br/>    test_size=0.15,<br/>    random_state=0,<br/>    shuffle=True,<br/>    stratify=data["label"],<br/>)</span></pre><p id="a1f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">scikit-learn的CountVectorizer方法将帮助我们将清理后的数据集转换为数值。方法将文本文档的集合转换为令牌计数的矩阵。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="0b80" class="nq mp iq nm b gy nr ns l nt nu"># Transform text data <br/>vectorizer = CountVectorizer(lowercase=False)<br/>vectorizer.fit(X_train)</span><span id="e569" class="nq mp iq nm b gy nv ns l nt nu">#transform train data <br/>X_train_trans = vectorizer.transform(X_train)</span><span id="17a7" class="nq mp iq nm b gy nv ns l nt nu">#transform test data<br/>X_text_trans = vectorizer.transform(X_test)</span></pre><h1 id="ae9c" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">如何实际创建我们的模型</h1><p id="b0be" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">我们将训练多项式朴素贝叶斯算法来分类消息是合法的还是垃圾邮件。这是文本分类最常用的算法之一。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="6358" class="nq mp iq nm b gy nr ns l nt nu"># Create a classifier</span><span id="def7" class="nq mp iq nm b gy nv ns l nt nu">spam_classifier = MultinomialNB()</span></pre><p id="a7fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们使用交叉验证来训练我们的分类器，以避免过拟合。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="46aa" class="nq mp iq nm b gy nr ns l nt nu"># Train the model with cross validation<br/>scores = cross_val_score(spam_classifier,X_train_trans,y_train,cv=10,verbose=3,n_jobs=-1)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/152a300989496c313a55b3f1a7baf720.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Yv0MXqgGW-mCrDiS.PNG"/></div></div></figure><p id="8db4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看看平均分数。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="8ae0" class="nq mp iq nm b gy nr ns l nt nu"># find the mean of the all scores<br/>scores.mean()</span></pre><p id="a4a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:0.976713936539371</p><p id="d06f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分数的平均值在97.68%左右。我们的模型表现良好，但我们可以通过使用scikit-learn的随机搜索方法优化其超参数值来提高其性能。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="eaf2" class="nq mp iq nm b gy nr ns l nt nu"># fine turning model parameters</span><span id="bca9" class="nq mp iq nm b gy nv ns l nt nu">distribution = {"alpha": [1, 0.1, 0.01, 0.001, 0.0001, 0, 0.2, 0.3]}</span><span id="0f4a" class="nq mp iq nm b gy nv ns l nt nu">grid = RandomizedSearchCV(<br/>    spam_classifier,<br/>    param_distributions=distribution,<br/>    n_jobs=-1,<br/>    cv=10,<br/>    n_iter=20,<br/>    random_state=42,<br/>    return_train_score=True,<br/>    verbose=2,<br/>)</span></pre><p id="0112" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将优化模型中的<strong class="ky ir"> alpha </strong>超参数，以获得提高模型性能的最佳值。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="de04" class="nq mp iq nm b gy nr ns l nt nu"># training with randomized search<br/>grid.fit(X_train_trans, y_train)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/5125ff3a7eb1b3664838f6923fd01634.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hkzK8L4niV6LWJqB.PNG"/></div></div></figure><p id="938d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要显示超参数优化结果:</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="19e9" class="nq mp iq nm b gy nr ns l nt nu"># summarize the results of the random parameter search<br/>print(grid.best_score_)<br/>print(grid.best_estimator_)<br/>print(grid.best_params_)</span></pre><p id="98f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">0.9767713936539371 <br/>多项式inb(alpha = 1)<br/>{ ' alpha ':1 }</p><p id="cc27" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最好成绩和上一个一样。现在让我们用测试数据来测试我们的模型。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="2869" class="nq mp iq nm b gy nr ns l nt nu"># predict on the test data<br/>y_pred = spam_classifier.predict(X_text_trans)</span></pre><p id="9bec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将使用<strong class="ky ir"> accuracy_score </strong>评估指标来评估模型的性能。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="b12a" class="nq mp iq nm b gy nr ns l nt nu"># check accuracy score<br/>accuracy_score(y_test, y_pred)</span></pre><p id="1655" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:0.976076550239234</p><p id="23e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型准确率在<strong class="ky ir"> 97.6% </strong>左右，表现不错。</p><p id="9a02" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当数据集中存在类别不平衡时，另一个有用的评估指标是<strong class="ky ir"> f1_score </strong>。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="006f" class="nq mp iq nm b gy nr ns l nt nu"># check f1_ score<br/>f1_score(y_test, y_pred)</span></pre><p id="253d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:0.908256880733945</p><p id="f3c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分数为<strong class="ky ir"> 0.91 </strong>更接近<strong class="ky ir"> 1 </strong>。这意味着我们的模型具有良好的性能，我们现在可以将它部署到生产中。</p><div class="od oe gp gr of og"><a href="https://www.datadriveninvestor.com/2020/11/19/how-machine-learning-and-artificial-intelligence-changing-the-face-of-ecommerce/" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd ir gy z fp ol fr fs om fu fw ip bi translated">机器学习和人工智能如何改变电子商务的面貌？|数据驱动…</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">电子商务开发公司，现在，整合先进的客户体验到一个新的水平…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="op l"><div class="oq l or os ot op ou kp og"/></div></div></a></div><p id="a05a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型将被保存在模型的目录中。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="7387" class="nq mp iq nm b gy nr ns l nt nu">#save model <br/>import joblib </span><span id="9966" class="nq mp iq nm b gy nv ns l nt nu">joblib.dump(spam_classifier, '../models/spam-detection-model.pkl')</span></pre><p id="3cfa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">['../models/spam-detection-model . pkl ']</p><p id="ce8e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的计数矢量器也将保存在预处理目录中。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="b84b" class="nq mp iq nm b gy nr ns l nt nu">#save Vectorizer<br/>joblib.dump(vectorizer,'../preprocessing/count_vectorizer.pkl')</span></pre><p id="6b6c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">['../preprocessing/count _ vector izer . pkl ']</p><p id="c575" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在创建了我们的垃圾邮件检测模型之后，是时候在Algorithmia平台上部署它了。</p><h1 id="fd95" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">什么是Algorithmia？</h1><p id="c0dd" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated"><a class="ae kv" href="https://algorithmia.com/" rel="noopener ugc nofollow" target="_blank"> Algorithmia </a>是一个MLOps工具，它提供了一种简单而快速的方法来将您的机器学习模型部署到生产中。</p><p id="bb4a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Algorithmia专门研究<strong class="ky ir">“算法即服务”</strong>。它允许用户创建运行ML模型的代码片段，并将它们托管在Algorithmia上。然后你可以调用你的代码作为一个API。</p><p id="36f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，您的模型可以用于您选择的不同应用程序，如web应用程序、移动应用程序或电子商务，只需从Algorithmia调用一个简单的API。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/58dd529a2450353526119255b282f9b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/0*n6xztSFstcQStulC.png"/></div></figure><p id="894b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Algorithmia支持R、Python、Java、Scala等不同编程语言开发的机器学习模型。它还支持流行的机器和深度学习框架，如Pytorch、Tensorflow、scikit-learn、XGBoost和Keras。</p><p id="1ab8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Algorithmia在其无服务器人工智能层上使用CPU和GPU来优化成本，并最大限度地提高其性能，以满足您的需求。<br/>目前，该平台拥有超过60，000名开发者，拥有4，500种算法。</p><p id="6056" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是在Algorithmia上部署机器学习模型需要遵循的六个步骤。</p><h1 id="8504" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">步骤1:在Algorithmia上创建一个帐户</h1><p id="6a0b" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">第一步是通过访问这个页面在Algorithmia中创建一个账户:<a class="ae kv" href="https://algorithmia.com/signup" rel="noopener ugc nofollow" target="_blank">https://algorithmia.com/signup</a>。</p><h1 id="1178" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">步骤2:创建一个新算法</h1><p id="0636" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">创建并确认您的帐户和电子邮件后，下一步是通过单击名为<strong class="ky ir">“新建”</strong>的下拉菜单按钮来创建新的算法。然后你只要选择页面右上角的<strong class="ky ir">算法</strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/f5bd06094eea3eb685cb1301e7fb6b7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zgmEDnB2sEaDW3f9.PNG"/></div></div></figure><p id="7f93" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后输入算法的名称，例如，垃圾短信检测。在<strong class="ky ir">源代码</strong>部分，您可以决定您的算法的源代码将位于何处。</p><p id="2ea5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">默认情况下，源代码将位于Algorithmia平台上。您可以选择将其保留在GitHub上，但是对于本文，我们将使用默认选项。</p><p id="7857" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一节指定了环境。Algorithmia为您提供了不同的选项来选择不同的环境，如Python、R、JavaScript、Java和Scala。默认选项是Python 3。这里我们将继续这个选项。最后，点击“<strong class="ky ir">创建新算法</strong>按钮。</p><h1 id="86d6" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">步骤3:将预先训练好的模型和计数矢量器上传到Algorithmia</h1><p id="6543" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">您可以通过点击Algorithmia平台左侧面板上的<strong class="ky ir">数据源</strong>将您选择的模型上传到数据部分。然后点击<strong class="ky ir">我的托管数据</strong>目录，在那里你可以创建一个新的文件夹来保存你为这个特定算法上传的所有pkl文件。</p><p id="a3f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在“我的托管数据”目录中，我创建了一个名为<strong class="ky ir"> sms_spam_detection </strong>的新文件夹。然后，我上传了我们预先训练的模型和训练的CountVectorizer，以将文本消息(sms)转换为术语/令牌计数的向量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/3ddda27339b4597a4b9c777252a8d737.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VYdPH-IDKERHjcwq.PNG"/></div></div></figure><h1 id="7252" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">步骤4:添加源代码</h1><p id="da5d" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">上传我们的预训练模型后，点击<strong class="ky ir">源代码</strong>选项卡。它将打开一个IDE，您可以在其中添加源代码来运行我们创建的机器学习模型。下面是添加源代码的方法:</p><p id="918d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> (a)导入包</strong> <br/>我们首先导入重要的Python包，包括Algorithmia，它将调用我们创建的算法。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="0604" class="nq mp iq nm b gy nr ns l nt nu">import sys<br/>import joblib<br/>import pickle<br/>import numpy as np<br/>import Algorithmia<br/>from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer<br/>from string import punctuation<br/>import re <br/>import nltk<br/>#download dependency<br/>nltk.download('stopwords')<br/>nltk.download('wordnet')<br/>from nltk.corpus import stopwords<br/>from nltk.stem import WordNetLemmatizer</span></pre><p id="c2e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意:Algorithmia的平台会自动导入文件中的Algorithmia Python包。</p><p id="8a50" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> (b)创建客户端</strong> <br/>然后我们从Algorithmia包中创建一个客户端，它提供了调用任何算法的标准化方法。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="bac1" class="nq mp iq nm b gy nr ns l nt nu"># we are creating the variable in global scope to use throughout our algorithm.<br/>client = Algorithmia.client()</span></pre><p id="aa71" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ( c)添加加载预训练模型和计数矢量器pkl文件的函数</strong><br/><strong class="ky ir">load _ model()</strong>函数将从数据源目录加载我们的预训练模型，<strong class="ky ir"> load_preprocessing() </strong>函数将加载计数矢量器文件。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="c6fa" class="nq mp iq nm b gy nr ns l nt nu">def load_preprocessing():<br/>    # Get file by name<br/>    # Open file and load model<br/>    file_path = 'data://Davis/sms_spam_detection/count-vectorizer.pkl'<br/>    object_path = client.file(file_path).getFile().name<br/>    # Open file and preprocessin object<br/>    with open(object_path, 'rb') as f:<br/>        object = joblib.load(f)<br/>        return object    </span><span id="7d87" class="nq mp iq nm b gy nv ns l nt nu">def load_model():<br/>    # Get file by name<br/>    # Open file and load model<br/>    file_path = 'data://Davis/sms_spam_detection/spam-detection-model.pkl'<br/>    model_path = client.file(file_path).getFile().name<br/>    # Open file and load model<br/>    with open(model_path, 'rb') as f:<br/>        model = joblib.load(f)<br/>        return model</span><span id="2b5c" class="nq mp iq nm b gy nv ns l nt nu"># Load model outside of the apply function so it only gets loaded once</span><span id="dbcb" class="nq mp iq nm b gy nv ns l nt nu">model = load_model()<br/>vectorizer = load_preprocessing()</span></pre><p id="3b37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> (d)添加清理文本输入的函数</strong> <br/>这里我们将使用同样的<strong class="ky ir"> text_clean() </strong>函数来清理短信。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="d7e6" class="nq mp iq nm b gy nr ns l nt nu">#set stopwords<br/>stop_words = stopwords.words('english')</span><span id="f35b" class="nq mp iq nm b gy nv ns l nt nu">def text_cleaning(text, remove_stop_words=True, lemmatize_words=True):<br/>    # Clean the text, with the option to remove stop_words and to lemmatize word</span><span id="01a5" class="nq mp iq nm b gy nv ns l nt nu">    # Clean the text<br/>    text = re.sub(r"[^A-Za-z0-9]", " ", text)<br/>    text = re.sub(r"\'s", " ", text)<br/>    text = re.sub(r"n't", " not ", text)<br/>    text = re.sub(r"I'm", "I am", text)<br/>    text = re.sub(r"ur", " your ", text)<br/>    text = re.sub(r" nd ", " and ", text)<br/>    text = re.sub(r"\'d", " would ", text)<br/>    text = re.sub(r"\'ll", " will ", text)<br/>    text = re.sub(r" tkts ", " tickets ", text)<br/>    text = re.sub(r" c ", " can ", text)<br/>    text = re.sub(r" e g ", " eg ", text)<br/>    text = re.sub(r'http\S+', ' link ', text)<br/>    text = re.sub(r'\b\d+(?:\.\d+)?\s+', '', text)  # remove numbers<br/>    text = re.sub(r" u ", " you ", text)<br/>    text = text.lower()  # set in lowercase</span><span id="547a" class="nq mp iq nm b gy nv ns l nt nu">    # Remove punctuation from text<br/>    text = ''.join([c for c in text if c not in punctuation])</span><span id="0e55" class="nq mp iq nm b gy nv ns l nt nu">    # Optionally, remove stop words<br/>    if remove_stop_words:<br/>        text = text.split()<br/>        text = [w for w in text if not w in stop_words]<br/>        text = " ".join(text)</span><span id="f03c" class="nq mp iq nm b gy nv ns l nt nu">    # Optionally, shorten words to their stems<br/>    if lemmatize_words:<br/>        text = text.split()<br/>        lemmatizer = WordNetLemmatizer()<br/>        lemmatized_words = [lemmatizer.lemmatize(word) for word in text]<br/>        text = " ".join(lemmatized_words)</span><span id="c6b3" class="nq mp iq nm b gy nv ns l nt nu">    # Return a list of words<br/>    return (text)</span></pre><p id="f360" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> (e)添加对输入进行预处理的函数</strong><br/><strong class="ky ir">process _ input()</strong>方法将在进行预测之前对输入的短信进行预处理。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="dbf8" class="nq mp iq nm b gy nr ns l nt nu">def process_input(input):<br/>    # Preprocess and Create numpy array from the input<br/>    <br/>    message = str(input)<br/>    clean_message = text_cleaning(message)<br/>    <br/>    #vectorize the message <br/>    vect_message = vectorizer.transform([clean_message])<br/>    <br/>    print(vect_message)<br/>    <br/>    return vect_message</span></pre><p id="3409" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> (f)添加应用模型进行预测的函数</strong> <br/>最后一个名为<strong class="ky ir"> apply() </strong>的函数将负责执行来自预处理文本sms的预测。如果消息是合法的，它将返回<em class="lw">“正常消息</em>”,如果消息是垃圾消息，它将返回<em class="lw">“垃圾消息”</em>。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="d4db" class="nq mp iq nm b gy nr ns l nt nu">def apply(input):<br/>    # pefrom prediction from the input. <br/>   <br/>    message = process_input(input)<br/>    prediction = model.predict(message)<br/>    if prediction[0] == 0:<br/>        return "normal message"<br/>    else:<br/>        return "spam message"</span></pre><p id="8ec9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们保存添加到文件中的源代码。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/7a8bac02e454cab680c6fdcec9e75c48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OI5UF_om-tfFwfeJ.PNG"/></div></div></figure><h1 id="49fb" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">步骤5:向Algorithmia添加依赖项</h1><p id="a1ca" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">从UI中点击<strong class="ky ir"> dependencies选项卡</strong>,并添加我们的模型所依赖的以下包:</p><ul class=""><li id="b8ca" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated">numpy</li><li id="40b2" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">joblib</li><li id="b662" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">scikit-learn == 0.22.2.post1</li><li id="2555" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">统一代码</li><li id="3103" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">nltk == 3.5</li></ul><p id="1653" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后点击右下角的<strong class="ky ir">保存依赖关系</strong>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/430cad949647cbb81d5a813d8df165cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2h9xIEL0dUomyP-f.PNG"/></div></div></figure><p id="4776" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意:Algorithmia中的依赖文件与requirements.txt文件相同，后者从PyPi中提取所列出的依赖文件。</p><p id="41b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在编辑器页面上，点击右上角的<strong class="ky ir">构建选项卡</strong>，安装依赖文件中列出的所有依赖项。如果成功安装了所有依赖项，您将会看到您的算法的特定版本现在处于联机状态，可以发布了。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/3e74eca078acd3468b082647e0673806.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*o5vJyvYaWsQ3LzOI.PNG"/></div></div></figure><h1 id="70ce" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">步骤6:发布算法</h1><p id="0af5" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">我们的最后一步是公布算法。发布算法有3个步骤:记录所有更改、添加示例输入和输出，以及配置算法设置。</p><p id="50d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> (a)文档更改</strong> <br/>您将看到您的提交历史，并且您将能够添加一个发布说明。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/19a2e50bceebf4a0651ccf5a106e2975.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*62DGC4o2XpbsbBRq.PNG"/></div></div></figure><p id="87c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> (b)添加一个示例</strong> <br/>在本节中，你创建你的示例输入和输出，以便用户可以尝试你的算法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pc"><img src="../Images/3be360e4cb6c8797d0873bfb75eb637b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qPdQ-1-R9ngDf-QP.PNG"/></div></div></figure><p id="cb4a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">配置算法设置</strong> <br/>最后，您选择您的算法是<strong class="ky ir">公共</strong>(这意味着任何人都可以调用它)还是<strong class="ky ir">私有</strong>(这意味着只有所有者可以调用它)。您还需要设置版税，然后单击页面底部的<strong class="ky ir">发布</strong>按钮。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pd"><img src="../Images/010d02c037e82e3f3d219876a5fda2aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ntPQBLezI-IGP2bk.PNG"/></div></div></figure><p id="738e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的NLP模型已经成功部署在Algorithmia平台上。让我们看看如何在Python应用程序(如Flask或Django)中使用我们部署的模型。</p><h1 id="6f17" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">如何安装Algorithmia Python客户端</h1><p id="6b65" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">我们首先使用PIP安装Algorithmia Python客户端。这将帮助我们调用运行NLP模型的代码。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="9c7a" class="nq mp iq nm b gy nr ns l nt nu">pip install algorithmia</span></pre><h1 id="b67c" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">收集API密钥</h1><p id="0e6d" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">单击算法面板上的“API密钥”选项卡来收集API密钥，这将帮助您调用运行NLP模型的代码。</p><h1 id="97b1" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">创建Algorithmia客户端</h1><p id="6aaf" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">我们首先导入Algorithmia Python包，然后创建算法客户端对象</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="c18f" class="nq mp iq nm b gy nr ns l nt nu">import Algorithmia<br/><br/># Authenticate with your API key<br/>apiKey = "YOUR_API_KEY"<br/><br/># Create the Algorithmia client object<br/>client = Algorithmia.client(apiKey)</span></pre><h1 id="df5f" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">调用算法</h1><p id="a18a" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">为了调用算法，我们需要将算法的名称及其版本添加到我们创建的客户端对象中。</p><p id="9624" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">名称是<strong class="ky ir">“Davis/spam _ detection/0 . 2 . 0”，</strong>包括您在Algorithmia上的帐户名称，后跟我们创建的算法名称。最后一位是算法的版本(0.2.0)。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="df79" class="nq mp iq nm b gy nr ns l nt nu"># Create the algorithm object using the Summarizer algorithm<br/>algo = client.algo('Davis/spam_detection/0.2.0')</span><span id="2393" class="nq mp iq nm b gy nv ns l nt nu"># Pass in input required by algorithm<br/>input_sms = "Win a Â£1000 cash prize or a prize worth Â£5000"</span><span id="687b" class="nq mp iq nm b gy nv ns l nt nu">try:<br/>    # Get the result<br/>    print(algo.pipe(input_sms).result)<br/>except Exception as error:<br/>    # Algorithm error if, for example, the input is not correctly formatted<br/>    print(error)</span></pre><p id="27a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个例子，模型预测sms是一个<strong class="ky ir">“垃圾消息”</strong>。酷，成功了！</p><h1 id="0aca" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">包扎</h1><p id="9e35" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">恭喜你，你已经完成了这篇文章的结尾！</p><p id="9bac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在这里下载本文使用的数据集和笔记本:<a class="ae kv" href="https://github.com/Davisy/SMS-Spam-Text-Classification" rel="noopener ugc nofollow" target="_blank">https://github.com/Davisy/SMS-Spam-Text-Classification</a></p><p id="f126" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你学到了新的东西或者喜欢阅读这篇文章，请分享给其他人看。在那之前，下期帖子再见！也可以通过Twitter <a class="ae kv" href="https://twitter.com/Davis_McDavid" rel="noopener ugc nofollow" target="_blank"> @Davis_McDavid </a>联系到我。</p><p id="d961" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文最初发表于<a class="ae kv" href="https://www.freecodecamp.org/news/deploy-ml-model-to-production-as-api/" rel="noopener ugc nofollow" target="_blank">免费代码营</a>。</p><p id="56ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="lw">最后一件事:</em> </strong> <em class="lw">在以下链接中阅读更多类似这样的文章。</em></p><div class="od oe gp gr of og"><a href="https://towardsdatascience.com/how-to-deploy-machine-learning-model-in-laravel-application-5e021494d316" rel="noopener follow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd ir gy z fp ol fr fs om fu fw ip bi translated">如何在Laravel应用中部署机器学习模型</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">从Algorithmia调用模型API并在Laravel中预测</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="pe l or os ot op ou kp og"/></div></div></a></div><div class="od oe gp gr of og"><a href="https://chatbotslife.com/how-to-use-texthero-to-prepare-a-text-based-dataset-for-your-nlp-project-734feea75a5a" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd ir gy z fp ol fr fs om fu fw ip bi translated">如何使用Texthero为您的NLP项目准备基于文本的数据集</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">一个简单的python工具包，可以快速、轻松地处理基于文本的数据集。</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">chatbotslife.com</p></div></div><div class="op l"><div class="pf l or os ot op ou kp og"/></div></div></a></div><div class="od oe gp gr of og"><a href="https://medium.com/analytics-vidhya/15-undiscovered-open-source-machine-learning-frameworks-you-need-to-know-in-2020-77ad6e6f109d" rel="noopener follow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd ir gy z fp ol fr fs om fu fw ip bi translated">2020年你需要知道的15个未被发现的开源机器学习框架。</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">在你的下一个机器学习项目中有用的ML框架。</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">medium.com</p></div></div><div class="op l"><div class="pg l or os ot op ou kp og"/></div></div></a></div><h2 id="5782" class="nq mp iq bd mq ph pi dn mu pj pk dp my lf pl pm na lj pn po nc ln pp pq ne pr bi translated">访问专家视图— <a class="ae kv" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>