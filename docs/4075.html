<html>
<head>
<title>Predicting Instagram Influencers Engagement with Machine Learning in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测Instagram影响者参与Python中的机器学习</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/predicting-instagram-influencers-engagement-with-machine-learning-in-python-726c68bda29b?source=collection_archive---------1-----------------------#2020-07-22">https://medium.datadriveninvestor.com/predicting-instagram-influencers-engagement-with-machine-learning-in-python-726c68bda29b?source=collection_archive---------1-----------------------#2020-07-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6ee9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从获取Instagram数据到使用机器学习进行预测，逐步预测Instagram影响者的参与度</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b6f9107f01063e4fbdc944a6ac84a79b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*knhm5B_L_trEaVZ3"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@maddibazzocco?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Maddi Bazzocco</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="228f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在过去的几周里，我试图做一个与<strong class="lb iu">机器学习</strong>相关的<strong class="lb iu">数据科学迷你项目</strong>。在思考了很久之后，我最终决定制作一个机器学习模型，可以预测一个<strong class="lb iu"> Instagram影响者参与度</strong>在接下来的一个月里是<strong class="lb iu">增长</strong>还是<strong class="lb iu">下降</strong>。这个迷你项目是一个<strong class="lb iu">端到端</strong>项目，本文将分为四个部分:</p><ol class=""><li id="4bdd" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">使用硒和美汤从Instagram影响者检索数据</strong>。</li><li id="21e0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">数据预处理从<strong class="lb iu">数据清理</strong>、<strong class="lb iu">特征工程</strong>、<strong class="lb iu">特征选择</strong>等开始，直到数据准备好被机器学习模型消费。</li><li id="cc4a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">建模使用了机器学习算法(<strong class="lb iu">线性回归</strong>、<strong class="lb iu">随机森林</strong>、<strong class="lb iu"> XGBoost </strong>)，还做了一些调优<strong class="lb iu">超参数</strong>。</li><li id="b859" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">解释来自机器学习的预测输出的结果</strong>。</li></ol><div class="mj mk gp gr ml mm"><a href="https://www.datadriveninvestor.com/2020/05/04/could-machine-learning-and-nlp-have-predicted-oils-crash-the-answer-is-yes/" rel="noopener  ugc nofollow" target="_blank"><div class="mn ab fo"><div class="mo ab mp cl cj mq"><h2 class="bd iu gy z fp mr fr fs ms fu fw is bi translated">机器学习和NLP能预测石油的崩溃吗？答案是肯定的。|数据驱动…</h2><div class="mt l"><h3 class="bd b gy z fp mr fr fs ms fu fw dk translated">2020年4月20日，WTI原油期货(美国原油基准)历史上首次达到负…</h3></div><div class="mu l"><p class="bd b dl z fp mr fr fs ms fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mv l"><div class="mw l mx my mz mv na ks mm"/></div></div></a></div><p id="a019" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以在读完这篇文章后，我希望读者能够获得一些与获取外部数据、预处理数据和机器学习模型相关的知识。准备好开始你自己的迷你机械学习项目了吗？。</p><blockquote class="nb nc nd"><p id="eff0" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated">要了解本教程，您至少应该了解:<br/> 1。<strong class="lb iu"> Python </strong>中的基础编程。<br/> 2。用于数据分析工具的<strong class="lb iu"> Pandas </strong>和<strong class="lb iu"> Numpy </strong>库。<br/> 3。用于数据可视化的<strong class="lb iu"> Matplotlib </strong>和<strong class="lb iu"> Seaborn </strong>库。<br/> 4。<strong class="lb iu"> Scikit-Learn </strong>用于机器学习的库。<br/> 5。<strong class="lb iu">硒</strong>和<strong class="lb iu">美汤</strong>库用于获取instagram数据<br/> 6。<strong class="lb iu"> Jupyter笔记本</strong>。</p></blockquote><p id="2ad2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ne">完整的数据集和代码可以在我的</em><a class="ae ky" href="https://github.com/adiptamartulandi/Project-Instagram-Influencers-Prediction" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="ne">Github</em></strong></a><em class="ne">下载，所有工作都在Jupyter笔记本上完成。</em></p></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><p id="de2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi np translated"><span class="l nq nr ns bm nt nu nv nw nx di"> 1 </span> <strong class="lb iu">使用硒和美汤从Instagram影响者那里获取数据。</strong></p><p id="e4d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一步是最耗时的一步，因为在Instagram上检索影响者数据需要很长时间。步骤1包括3个阶段:</p><blockquote class="nb nc nd"><p id="a02b" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated"><em class="it"> 1.1列出将被预测的影响者。我从印尼拿了前1000名影响者(来源</em><a class="ae ky" href="https://starngage.com/app/id/influencer/ranking?page=1" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">starngage</strong></a><em class="it">)。</em></p></blockquote><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="4a25" class="od oe it nz b gy of og l oh oi"><strong class="nz iu">#Create Empty List</strong><br/>ranking = []<br/>username = []<br/>category = []<br/>category_2 = []</span><span id="ed67" class="od oe it nz b gy oj og l oh oi"><strong class="nz iu">#Function to scrape username information<br/>def scrape_username(url):</strong><br/>    <br/>    <strong class="nz iu">#accessing and parsing the input url</strong><br/>    response = requests.get(url)<br/>    print(f'page {a} respose {response}')<br/>    soup = BeautifulSoup(response.content, 'html.parser')<br/>    list_username = soup.find_all('tr')<br/>    <br/>    <strong class="nz iu">#looping to the element that we want to scrape</strong><br/>    for p in list(list_username):<br/>        try:<br/>            <strong class="nz iu">#getting the information (rank, names, and category)</strong><br/>            rank = p.find('td', 'align-middle').get_text().strip()<br/>            ranking.append(rank)<br/>            name = p.find('a').get_text().strip()<br/>            username.append(name)<br/>            cat = p.find_all('span', 'badge badge-pill badge-light samll text-muted')<br/>            category_2 = []<br/>            for c in cat:<br/>                d = c.find('a', 'link').get_text()<br/>                category_2.append(d)<br/>            category.append(category_2)<br/>        except:<br/>            continue</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/6e6990563ab1d49cf505e86303655f8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*pGAM3fP9a5ZvoMXr64ODag.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Sneak Peak Output of Step 1.1</figcaption></figure><blockquote class="nb nc nd"><p id="a20c" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated"><em class="it"> 1.2使用Selenium获取Instagram上每个有影响力的人的帖子链接。</em></p></blockquote><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="c98d" class="od oe it nz b gy of og l oh oi"><strong class="nz iu">#Create Empty List</strong><br/>link = []<br/>names = []</span><span id="b206" class="od oe it nz b gy oj og l oh oi"><strong class="nz iu">#Function to get Post Link<br/>def get_influencer_link(username):</strong></span><span id="e618" class="od oe it nz b gy oj og l oh oi"><strong class="nz iu">    #to influencer url</strong><br/>    url = f'<a class="ae ky" href="https://www.instagram.com/{username}/'" rel="noopener ugc nofollow" target="_blank">https://www.instagram.com/{username}/'</a><br/>    driver = webdriver.Chrome()<br/>    driver.get(url)</span><span id="0663" class="od oe it nz b gy oj og l oh oi">    time.sleep(5)</span><span id="bfad" class="od oe it nz b gy oj og l oh oi">    i = 0<br/>    while i &lt; 8:   <br/>        try:<br/>            <strong class="nz iu">#get the links</strong><br/>            pages = driver.find_elements_by_tag_name('a')<br/>            for data in pages:<br/>                data_2 = data.get_attribute("href")<br/>                if '/p/' in data_2:<br/>                    link.append(data.get_attribute("href"))<br/>                    names.append(name)</span><span id="7dfe" class="od oe it nz b gy oj og l oh oi">            <strong class="nz iu"># Scroll down to bottom</strong><br/>            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")</span><span id="92cf" class="od oe it nz b gy oj og l oh oi">            <strong class="nz iu"># Wait to load page</strong><br/>            time.sleep(1)<br/>            i += 1<br/>        except:<br/>            i += 1<br/>            continue<br/>    driver.quit()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/8c4615ed4d47555ae414383f2c45eb04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*ZiQoqysu_7FyP5PNVe5_yA.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Sneak Peak Output of Step 1.2</figcaption></figure><blockquote class="nb nc nd"><p id="f89a" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated"><em class="it"> 1.3从每个帖子中检索信息，如点赞数、评论数、标题等。用漂亮的汤。</em></p></blockquote><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="899c" class="od oe it nz b gy of og l oh oi"><strong class="nz iu">#Create Empty List</strong><br/>likes = []<br/>comment_counts = []<br/>dates = []<br/>captions = []<br/>type_posts = []<br/>links = []</span><span id="e62d" class="od oe it nz b gy oj og l oh oi"><strong class="nz iu">#Function to get information</strong><br/><strong class="nz iu">def get_information(link):   </strong> <br/>    <strong class="nz iu">try:</strong><br/>        global i, n<br/>        <br/>        <strong class="nz iu">#accessing and parsing the website url</strong><br/>        url = link<br/>        response = requests.get(url)<br/>        soup = BeautifulSoup(response.content)<br/>        <br/>        <strong class="nz iu">#find element that contain information</strong><br/>        body = soup.find('body')<br/>        script = body.find('script')<br/>        raw = script.text.strip().replace('window._sharedData =', '').replace(';', '')<br/>        json_data=json.loads(raw)<br/>        posts =json_data['entry_data']['PostPage'][0]['graphql']<br/>        posts= json.dumps(posts)<br/>        posts = json.loads(posts)<br/>        <br/>        <strong class="nz iu">#acquiring information</strong><br/>        like = posts['shortcode_media']['edge_media_preview_like']['count']<br/>        comment_count = posts['shortcode_media']['edge_media_to_parent_comment']['count']<br/>        date = posts['shortcode_media']['taken_at_timestamp']<br/>        caption = posts['shortcode_media']['edge_media_to_caption']['edges'][0]['node']['text']<br/>        type_post = posts['shortcode_media']['__typename']<br/>        likes.append(like)<br/>        comment_counts.append(comment_count)<br/>        dates.append(date)<br/>        captions.append(caption)<br/>        type_posts.append(type_post)<br/>        links.append(link)<br/>        i += 1<br/>    <strong class="nz iu">except:</strong><br/>        i += 1<br/>        n += 1<br/>        print(f'number of link error {n} at iteration {i}')<br/>       <strong class="nz iu"> pass</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/5a2cc332606562d5bb458e8fb76defd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BhV_sH-TjLUHIAa7EH620Q.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Sneak Peak Output of Step 1.3</figcaption></figure><p id="deb3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi np translated"><span class="l nq nr ns bm nt nu nv nw nx di"> 2 </span>数据预处理从<strong class="lb iu">数据清洗</strong>、<strong class="lb iu">特征工程</strong>、<strong class="lb iu">特征选择</strong>开始，直到数据准备好被机器学习模型消费。</p><p id="bfed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">步骤2包括3个阶段，即数据清理、特征工程和特征选择。</p><blockquote class="nb nc nd"><p id="c664" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated"><em class="it"> 2.1数据清理包括2件事，即将仍处于纪元时间的日期特征格式转换为日期时间，并清理特征标题。</em></p></blockquote><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="8c06" class="od oe it nz b gy of og l oh oi"><strong class="nz iu">#convert epoch time --&gt; datetime<br/>#The format is year-month-day-hour<br/></strong>df['dates'] = df['dates'].apply(lambda x: dt.datetime.fromtimestamp(x).strftime('%Y-%m-%d-%H'))</span><span id="8676" class="od oe it nz b gy oj og l oh oi"><strong class="nz iu">#remove unused characters in feature captions</strong><br/>df['captions'] = df['captions'].replace(r'[\n]', '', regex=True)</span><span id="39d9" class="od oe it nz b gy oj og l oh oi"><strong class="nz iu">#fill missing value in features captions</strong><br/>df['captions'] = df['captions'].fillna('no captions')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/6e735d4f9e04f81e94e07c2c47867d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ge2nbYfASO50t3jndlxbTg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Sneak Peak Output of Step 2.1</figcaption></figure><blockquote class="nb nc nd"><p id="4cd4" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated"><em class="it"> 2.2这一步是特征工程，从10个特征中可以产生52个新特征。这个阶段还为建模过程制作了基础表。</em></p></blockquote><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="3f20" class="od oe it nz b gy of og l oh oi"><strong class="nz iu">#create features lag of n_post (last 3 month)<br/>#number of n_post 1 months ago</strong><br/>base_table['n_post_01'] = base_table.groupby(['username'])['n_post'].shift(1).fillna(0)</span><span id="ab4e" class="od oe it nz b gy oj og l oh oi"><strong class="nz iu">#number of n_post 2 months ago</strong><br/>base_table['n_post_02'] = base_table.groupby(['username'])['n_post'].shift(2).fillna(0)</span><span id="2001" class="od oe it nz b gy oj og l oh oi"><strong class="nz iu">#number of n_post 3 months ago</strong><br/>base_table['n_post_03'] = base_table.groupby(['username'])['n_post'].shift(3).fillna(0)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/19b4062a02b64f5a0ae61697be013541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*37dno9mdVkUo1uJjVxBzaw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Sneak Peak Output of Step 2.2</figcaption></figure><blockquote class="nb nc nd"><p id="f1b5" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated"><em class="it"> 2.3下一步是特征选择，我还是用简单的特征选择。我使用的方法是查看预测器和目标特征之间的相关系数。</em></p></blockquote><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="e56a" class="od oe it nz b gy of og l oh oi"><strong class="nz iu">#I choose variables with the value of correlation coefficient r &lt; -0.2 and r &gt; 0.3<br/>#it is very subjective matter</strong><br/>plt.figure(figsize=(10,8))<br/>sns.heatmap(df.corr());</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/5c5a2c97829b93e2bd7f91728251173a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*lMy6Bgm2mNd3rwv0WPwJYQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Heatmap Correlation</figcaption></figure><p id="1b93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从总共62个特征中，我只选取了大约20个特征用于建模过程。</p><p id="e4a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi np translated"><span class="l nq nr ns bm nt nu nv nw nx di"> 3 </span>建模使用机器学习算法(<strong class="lb iu">线性回归</strong>、<strong class="lb iu">随机森林</strong>、<strong class="lb iu"> XGBoost </strong>)，也做一些调优<strong class="lb iu">超参数</strong>。</p><blockquote class="nb nc nd"><p id="3070" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated"><strong class="lb iu">我在建模过程中做了一些场景，目的是找到最佳模型，这些场景是:</strong> <br/> 1。没有特征选择和没有调整超参数的建模。<br/> 2。没有特征选择和调整超参数的建模。<br/> 3。具有特征选择和没有调整超参数的建模。<br/> 4。具有特征选择和wit调节超参数的建模。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/5e66595adb74486747ae5ffa01e5424e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rvsdtGML7MwvVDPyP08D8g.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Output of Modelling Process</figcaption></figure><p id="b4b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总共有<strong class="lb iu"> 10个场景</strong>完成了它们在数据训练、数据测试和数据训练+数据测试上的表现。我使用的度量评估只针对<strong class="lb iu">均方根误差(RMSE) </strong>。在所有场景中，<strong class="lb iu">随机森林</strong>与<strong class="lb iu">特征选择</strong>和<strong class="lb iu">调整超参数</strong>在RMSE列车、RMSE测试和RMSE测试中都给出了最佳结果。所以我选择这个模型作为最终模型进行预测。</p><p id="55e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi np translated"><span class="l nq nr ns bm nt nu nv nw nx di"> 4 </span> <strong class="lb iu">模型最终机器学习的预测输出结果</strong>的解释。</p><p id="cb6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预测结果显示，7月份将有<strong class="lb iu"> 513 </strong> Instagram影响者平均总参与度将<strong class="lb iu">增长</strong>和<strong class="lb iu"> 123 </strong>下降<strong class="lb iu"/>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/10e342942a7516b3c70ee47d3272a9c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*AbR2qJtWZFHq8LBtjfJHsQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Predicted Category Composition</figcaption></figure><p id="e600" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们查看我们的最佳模型特征重要性的结果，即随机森林，可以看到与喜欢和参与相关的特征具有较高的相对重要性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/30872254680dc65a83fc86aba9a501e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BOhRsczsqnI6L-PtyHlsrQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Feature Importance</figcaption></figure></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><p id="a412" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，还完成了一篇关于Instagram影响者预测的文章。如果我可以总结的话，我们已经做了很多事情:</p><blockquote class="nb nc nd"><p id="6ee5" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated">1.从Instagram <br/> 2获取外部数据。做一些数据预处理<br/> 3。用机器学习算法建模。<br/> 4。解释结果</p></blockquote><p id="ffb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这篇文章能帮助读者，如果有建议或意见，请写在下面的评论栏里。</p><h2 id="2aa8" class="od oe it bd ot ou ov dn ow ox oy dp oz li pa pb pc lm pd pe pf lq pg ph pi pj bi translated">访问专家视图— <a class="ae ky" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>