<html>
<head>
<title>Download PDF Files from the Web using Scala</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Scala从网上下载PDF文件</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/download-covid-19-pdf-reports-from-the-web-using-scala-191dd2a78729?source=collection_archive---------5-----------------------#2020-03-11">https://medium.datadriveninvestor.com/download-covid-19-pdf-reports-from-the-web-using-scala-191dd2a78729?source=collection_archive---------5-----------------------#2020-03-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/d6713feb7dbe90ae318169ce143d5a54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hXB0ePi1IaJF0I6f"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@sarabakhshi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Sara Bakhshi</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c7b6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最近我一直在用Scala练习函数式编程，为了练习，我想做一个小项目，从世界卫生组织自动下载新冠肺炎报告。</p><h2 id="68cc" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">关于Scala的一点信息</strong></h2><p id="982b" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">Scala(<strong class="ki iu">SCA</strong>lable<strong class="ki iu">la</strong>language)是一种静态类型的、函数式的、面向对象的语言，如果需要的话，它还允许你编写命令式代码。它编译到Java虚拟机，并针对大数据工作负载进行了优化，例如分布式大数据处理技术Apache Spark就是用Scala编写的。</p><div class="mc md gp gr me mf"><a href="https://www.datadriveninvestor.com/2019/02/21/best-coding-languages-to-learn-in-2019/" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">2019年最值得学习的编码语言|数据驱动的投资者</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">在我读大学的那几年，我跳过了很多次夜游去学习Java，希望有一天它能帮助我在…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt jz mf"/></div></div></a></div><p id="687b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这意味着您可以使用现有的java库(以及许多堆栈溢出答案！)，并编写优雅、简洁的代码来完成工作。糟糕的是你必须学习函数式编程。不过，相信我，你不会后悔的。</p><p id="262b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">向前！</p><h2 id="5ea1" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">第0步:依赖和导入</strong></h2><p id="fbe6" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">出于本教程的目的，我使用SBT (Scala构建工具)启动了一个关于IntelliJ的新项目。我已经在IntelliJ项目的build.sbt文件中作为依赖项导入了JSoup库。我们将使用JSoup作为库来解析来自世卫组织网站的HTML:</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="8e4d" class="le lf it mz b gy nd ne l nf ng"><em class="nh">libraryDependencies </em>++= Seq(<br/>  "org.jsoup" % "jsoup" % "1.8.3"<br/>)</span></pre><p id="eb0f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是我们将在整个项目中使用的导入。就个人而言，我对scala标准库的了解非常有限。因此，我不会在这一点上深入细节。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="7a96" class="le lf it mz b gy nd ne l nf ng">package main<br/><br/>import scala.language.<em class="nh">postfixOps<br/></em>import scala.jdk.CollectionConverters._<br/><br/>import sys.process._<br/>import java.net.URL<br/>import java.io.File<br/><br/>import org.jsoup.Jsoup<br/>import org.jsoup.nodes.Document<br/>import org.jsoup.select.Elements</span></pre><h2 id="d53e" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">第一步:从网页中获取链接</strong></h2><p id="4c2b" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">首先，让我们写一个函数，允许我们从一个叫做getLinks的网页上抓取链接。获取链接需要两个参数，url和选择器。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="3e6c" class="le lf it mz b gy nd ne l nf ng">def getLinks(url: String, selector: String) = {</span><span id="ef48" class="le lf it mz b gy ni ne l nf ng">/* url is the page you want to scrape for links, and selector, is the JSoup HTML content selector. JSoup is a Java Library that allows you to parse and read through HTML documents. It uses the content selector syntax to allow you to target the specific information you want on your target website. You can read more about JSoup <a class="ae kf" href="https://jsoup.org/" rel="noopener ugc nofollow" target="_blank">here</a>. */</span><span id="e126" class="le lf it mz b gy ni ne l nf ng">    // download the document<br/>    val document: Document = Jsoup.<em class="nh">connect</em>(url).get()<br/>    // get our target a tags</span><span id="5cef" class="le lf it mz b gy ni ne l nf ng">    val aTags: Elements = document.select(selector)<br/>    <br/>   // get the links from our a tags<br/>    val links = for(aTag &lt;- aTags.asScala) yield aTag.attr("href")</span><span id="4f3f" class="le lf it mz b gy ni ne l nf ng">   // convert our java collection in links to an IndexedSeq<br/>   links.toIndexedSeq<br/>  }</span></pre><h2 id="8bac" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">第二步:清理我们的网址</strong></h2><p id="e53b" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在世界卫生组织网站链接结构中，hrefs删除了根url并使用相对URL。为了处理这个问题，我们需要添加逻辑来将根url附加到我们的每个链接上</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="4380" class="le lf it mz b gy nd ne l nf ng">def appendRootUrl(rootUrl: String, links: IndexedSeq[String]) ={</span><span id="cf1c" class="le lf it mz b gy ni ne l nf ng">/*</span><span id="d6f4" class="le lf it mz b gy ni ne l nf ng">We'll provide the rootUrl as a string and the IndexedSequence of Strings we get from our getLinks function<br/>*/</span><span id="dc9f" class="le lf it mz b gy ni ne l nf ng">    //for each link, return the rootUrl appended with the link<br/>    val loadableLinks = for(link &lt;- links) yield rootUrl + link</span><span id="5cc3" class="le lf it mz b gy ni ne l nf ng">    // convert our links to a List.<br/>    loadableLinks.toList</span></pre><h2 id="de50" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">第三步:下载文件</strong></h2><p id="7fd9" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">最后，我们将编写downloadFiles函数，它将下载文件并将其写入指定的路径。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="5f15" class="le lf it mz b gy nd ne l nf ng">def downloadFiles(downloadableFileLinks: List[String], path: String): Unit = {</span><span id="bd1e" class="le lf it mz b gy ni ne l nf ng">/*<br/> given a set of links that are downloadable, and a target path, will download the files.<br/> <br/>Below, for each downloadable link, we'll instantiate a new URL object, then we will create our target filepath with the filename. <br/>Then, we will clean the file name.<br/>Finally, we will write to disk. */</span><span id="58be" class="le lf it mz b gy ni ne l nf ng">/* map functions are super cool! they essentially apply logic to each element in your collection. Below, for each downloadableLink in downloadableFileLinks, we're initializing a URL, creating a filepath, and then writing the urlObject to disk.</span><span id="6441" class="le lf it mz b gy ni ne l nf ng">    downloadableFileLinks.map( downloadableLink =&gt;<br/>    {</span><span id="4803" class="le lf it mz b gy ni ne l nf ng"><em class="nh"><br/>      </em>val urlObject = new URL(downloadableLink)<br/>      val filePath = path + "/" + urlObject.getPath().replaceAll("/", "")<br/>      urlObject #&gt; new File(filePath)!!<br/>    })<br/>  }</span></pre><h2 id="cbbe" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">第四步:让我们把它们放在一起</strong></h2><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="1e4a" class="le lf it mz b gy nd ne l nf ng">package main<br/><br/>import scala.language.<em class="nh">postfixOps<br/></em>import scala.jdk.CollectionConverters._<br/><br/>import sys.process._<br/>import java.net.URL<br/>import java.io.File<br/><br/>import org.jsoup.Jsoup<br/>import org.jsoup.nodes.Document<br/>import org.jsoup.select.Elements<br/><br/><br/>object main extends App {<br/><br/>  def getLinks(url: String, selector: String) = {<br/><br/>    val document: Document = Jsoup.<em class="nh">connect</em>(url).get()<br/>    val aTags: Elements = document.select(selector)<br/>    val links = for(aTag &lt;- aTags.asScala) yield aTag.attr("href")<br/>    links.toIndexedSeq<br/>  }<br/><br/>  def appendRootUrl(rootUrl: String, links: IndexedSeq[String]) ={<br/><br/>    val loadableLinks = for(link &lt;- links) yield rootUrl + link<br/>    loadableLinks.toList<br/>  }<br/><br/>  def downloadFiles(downloadableFileLinks: List[String], path: String): Unit = {<br/>    downloadableFileLinks.map( downloadableLink =&gt;<br/>    {<br/>      // <em class="nh">TODO: Only write if fileNotExists?<br/>      </em>val urlObject = new URL(downloadableLink)<br/>      val filePath = path + "/" + urlObject.getPath().replaceAll("/", "")<br/>      urlObject #&gt; new File(filePath)!!<br/>    })<br/>  }<br/><br/><br/>  val <em class="nh">rootUrl </em>= "https://www.who.int/"<br/>  val <em class="nh">scrapedUrl </em>= "https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports?fbclid=IwAR0bANT83XoqEwhEWnGvjmBSsGjy0S9smn1wP5wTtIyy_Oe78_NtMUATEqA"<br/>  val <em class="nh">regexPattern </em>= ".*\\/(.*)\\?".r<br/>  val <em class="nh">aLinksContentSelectpr </em>= ".sf-content-block a[target=_blank]"<br/>  val <em class="nh">linksOnPage </em>= <em class="nh">getLinks</em>(<em class="nh">scrapedUrl</em>, <em class="nh">aLinksContentSelectpr</em>)<br/>  val <em class="nh">downloadableLinks </em>= <em class="nh">appendRootUrl</em>(<em class="nh">rootUrl</em>, <em class="nh">linksOnPage</em>)<br/><br/>  <em class="nh">downloadFiles</em>(<em class="nh">downloadableLinks</em>, "./files")<br/><br/><br/><br/>}</span></pre><h2 id="1b9b" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">步骤4:使用Python从PDF文件中提取数据</strong></h2><p id="d390" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">我还没有用Scala解决这个问题，我以前写过如何使用Python从一个<a class="ae kf" href="https://medium.com/@rqaiserr/convert-tables-from-pdfs-to-pandas-with-python-d74f8ac31dc2" rel="noopener"> PDF文件中提取数据。你可以参考这篇文章来大致了解如何提取这些数据。</a></p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><p id="fd59" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">喜欢我的作品吗？雇用我做升级工作！</p><figure class="mu mv mw mx gt ju"><div class="bz fp l di"><div class="nq nr l"/></div></figure></div></div>    
</body>
</html>