<html>
<head>
<title>Artificial Intelligence and Changing Memory</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能和改变记忆</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/ai-and-changing-memory-de46ed102bce?source=collection_archive---------6-----------------------#2020-04-11">https://medium.datadriveninvestor.com/ai-and-changing-memory-de46ed102bce?source=collection_archive---------6-----------------------#2020-04-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/9ef426706d4e4c99daad959ff4a868c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fLIHuaDIKbMhf4-aNr04RQ.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Ribeirão Preto — SP, Brasil ,Photo by — <a class="ae jd" href="https://unsplash.com/@guicolosio" rel="noopener ugc nofollow" target="_blank">@guicolosio</a></figcaption></figure><div class=""/><div class=""><h2 id="9b27" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">非易失性存储器和人工智能加速器——探索硬件和软件之间的接口</h2></div><p id="d44a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最近，硬件发生了变化，以更大程度地促进专注于人工智能领域的应用的激增。正是这一点让我对这篇文章感兴趣，这篇文章关注的是IBM hardware的研究人员写的一篇文章，这篇文章提供了一些基本的解释。</p><h2 id="3f87" class="lr ls jg bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">IBM硬件</h2><p id="9d58" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">IBM成立了AI硬件中心。这是一个旨在提高人工智能性能的研发机构。该研究中心总部位于纽约奥尔巴尼。它专注于人工智能领域的下一代芯片。</p><h2 id="a2cd" class="lr ls jg bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">具有NVM可变性的DNN体重规划</h2><p id="2a85" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">IBM Hardware的一个团队于2019年4月23日发表了一篇论文<em class="mp">Charles Mack in *、Hsinyu Tsai、Stefano Ambrogio、Pritish Narayanan、陈安和Geoffrey W. Burr。</em>它有标题<a class="ae jd" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/aelm.201900026" rel="noopener ugc nofollow" target="_blank"> <em class="mp">权重编程在DNN模拟硬件加速器中存在NVM可变性</em> </a>。它的主要焦点是开发可以最小化编程工作量的策略，同时提供足够的调优精度，以实现训练和推理的软件等效精度。</p><blockquote class="mq mr ms"><p id="1d6e" class="kv kw mp kx b ky kz kh la lb lc kk ld mt lf lg lh mu lj lk ll mv ln lo lp lq ij bi translated">“在其核心，dnn广泛依赖乘累加(MAC)运算，使其非常适合高性能应用中的GPU。然而，GPU使用“存储程序”或冯诺依曼架构，这意味着内存块在物理上与计算块分离。这对内存和计算模块之间的数据传输造成了巨大且不可避免的时间和能量损失，即所谓的“冯·诺依曼”瓶颈。”</p></blockquote><p id="aa96" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">物理上分离的内存块意味着时间和能量花费在这些“计算块”之间的数据传输上。</p><figure class="mx my mz na gt is gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/538695c2c2d9fe30bc92f39f87241346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/0*XfJUJFrr0CG-oWJR.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Model by <a class="ae jd" href="https://www.researchgate.net/profile/Srivats_Shankar" rel="noopener ugc nofollow" target="_blank">Srivats Shankar</a></figcaption></figure><p id="6645" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">他们认为不同的架构可以显著提高速度:</p><blockquote class="mq mr ms"><p id="d839" class="kv kw mp kx b ky kz kh la lb lc kk ld mt lf lg lh mu lj lk ll mv ln lo lp lq ij bi translated">在这些交叉阵列中，非易失性存储器(NVM)元件用于编码突触权重。最近的研究表明，与最先进的GPU相比，这种技术能够将单位面积吞吐量加速280倍，同时将单位面积能效提高100倍。”</p></blockquote><div class="ip iq gp gr ir nb"><a href="https://www.datadriveninvestor.com/2020/02/12/has-general-ai-exceeded-the-intellectual-capacity-of-humans/" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab fo"><div class="nd ab ne cl cj nf"><h2 class="bd jh gy z fp ng fr fs nh fu fw jf bi translated">AI将军是否已经超过了人类的智力容量？数据驱动的投资者</h2><div class="ni l"><h3 class="bd b gy z fp ng fr fs nh fu fw dk translated">不仅在游戏中，而且在劳动力市场上，机器都比人类聪明。在今天的许多领域，使用…</h3></div><div class="nj l"><p class="bd b dl z fp ng fr fs nh fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nk l"><div class="nl l nm nn no nk np ix nb"/></div></div></a></div><p id="993a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">根据该文章，这些纵横阵列已经使用各种模拟NVM元件实现，包括</p><ul class=""><li id="6ddf" class="nq nr jg kx b ky kz lb lc le ns li nt lm nu lq nv nw nx ny bi translated">电阻式随机存储器</li><li id="9cce" class="nq nr jg kx b ky nz lb oa le ob li oc lm od lq nv nw nx ny bi translated">导电桥接RAM (CBRAM)</li><li id="5ea2" class="nq nr jg kx b ky nz lb oa le ob li oc lm od lq nv nw nx ny bi translated">灰</li><li id="6da4" class="nq nr jg kx b ky nz lb oa le ob li oc lm od lq nv nw nx ny bi translated">相变存储器(PCM)</li></ul><p id="d294" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">他们认为，深度学习的模拟硬件加速器可以通过使用交叉阵列结构在内存中执行MAC操作来避免这一瓶颈。</p><h2 id="fbb3" class="lr ls jg bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">什么是纵横阵列？</h2><p id="47d0" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">这篇文章理所当然地认为读者知道什么是crossbar数组，所以我想我应该花点时间来详细说明一下。我可能做得不够好，但我会尽力而为。</p><p id="6d95" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">《自然》杂志上的另一篇文章将此描述为一种大脑启发的计算。</p><blockquote class="mq mr ms"><p id="8dff" class="kv kw mp kx b ky kz kh la lb lc kk ld mt lf lg lh mu lj lk ll mv ln lo lp lq ij bi translated">“内置于大规模<strong class="kx jh">交叉阵列</strong>形成神经网络，它们通过直接使用物理定律，以大规模并行性执行高效的内存计算。人工突触和神经元之间的动态交互为网络提供了监督和非监督学习能力。”</p></blockquote><p id="bf83" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">IBM硬件对这些进步很感兴趣。</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oe"><img src="../Images/5ef679e8da879f6f7ca76459e0e4ddab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kwdH1VPn-DErnMK9.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">“Physical properties of materials, such as conductance, can be used to represent synaptic weights in neural networks. The conductance of a memristor can be modulated through different mechanisms. Shown in the bottom panel, with schematics and exemplary micrographs, are three typical conductance tuning mechanisms, by changing: the width of a conduction channel the gap between the channel and an electrode and the composition of the conductive channel. Consequently, a memristor crossbar array (an example is shown in the central panel) will carry different and tunable synaptic weights in each cell, forming a computational framework with a broad spectrum of artificial intelligence applications (top panel). “ from the <a class="ae jd" href="https://www.nature.com/articles/s41563-019-0291-x" rel="noopener ugc nofollow" target="_blank">article in Nature</a>.</figcaption></figure><p id="1a68" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所以可以用物理性质来表示突触的重量可以加速这个过程。</p><p id="bc52" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从IBM Hardware网站的截图中可以看出，这是IBM关注的一部分。</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/b1b5d66bbc759cc7aea2370ea5b9d153.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FAhD_YPZFZVR7V1ovvcZNw.png"/></div></div></figure><p id="792e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而也有一些挑战</p><blockquote class="mq mr ms"><p id="147d" class="kv kw mp kx b ky kz kh la lb lc kk ld mt lf lg lh mu lj lk ll mv ln lo lp lq ij bi translated">“…大多数NVM候选器件表现出不同程度的非理想行为，包括有限的电阻对比度、电导变化的显著非线性以及双向编程的强烈不对称性。”</p></blockquote><p id="4a34" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">他们提到对PCM的设备要求是一个重要方面。</p><p id="e978" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">相变存储器(PCM)。</p><p id="64f8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由<a class="ae jd" href="https://www.researchgate.net/profile/Xian_Bin_Li" rel="noopener ugc nofollow" target="_blank">李先彬</a>整理的一幅插图可能在某种程度上说明了这一点。</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi og"><img src="../Images/37347ceed1b4fe26912cbad5f9d47d70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RoH1JmFBLOB2e22Urb3GCg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">The applications of phase-change memory in optical memory and in-memory/neuromorphic computing. (a) The integrated all-optical nonvolatile memory based on PCM material Ge 2 Sb 2 Te 5 (GST). Here, the PCM material is placed on the top of a waveguide. The data recording is realized by the optical near-field effects. The writing and erasing operations are achieved by the laser pulse passes through the waveguide while the read operation relies on the transmission signal modulated by the optical absorption of PCM materials. (b) The illustration of in-memory arithmetic computing by optically-controlled phase change. © The all-optical neuromorphic computing system based on PCM material GST. The input pulses can induce the phase change (recrystallization) of PCM material, which in turn changes the output signals. Both the in-memory computing and the neuromorphic computing utilize the accumulation effect of the crystallization.</figcaption></figure><p id="9113" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一篇由<a class="ae jd" href="https://sciprofiles.com/profile/711771" rel="noopener ugc nofollow" target="_blank"><strong class="kx jh"/></a><strong class="kx jh"/><a class="ae jd" href="https://sciprofiles.com/profile/466886" rel="noopener ugc nofollow" target="_blank"><strong class="kx jh">Giovanna Turvani</strong></a><strong class="kx jh"/>和<strong class="kx jh">Mariagrazia Graziano</strong><strong class="kx jh"/>描述的论文是这样的。</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oh"><img src="../Images/6606921c47ae33c294898b45ce92968a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TDRxmDgx4GyoKS5s.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Depending on how the memory is used for computing data, four main in-memory computing approaches can be defined. (<strong class="bd lt">A</strong>) Computation-near-Memory (CnM): 3D-integration technologies allow one to bring computation and storage closer together by reducing the length of the interconnections. Logic and storage are still two separate entities. (<strong class="bd lt">B</strong>) Computation-in-Memory (CiM): The standard memory structure is not modified, while data computation is performed in the peripheral circuitry. © Computation-with-Memory (CwM): Memory is used as a Look Up Table to retrieve pre-computed results. (<strong class="bd lt">D</strong>) Logic-in-Memory (LiM): Data computation is performed directly inside the memory by adding simple logic in each memory cell.</figcaption></figure><p id="3730" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">他们在论文<a class="ae jd" href="https://www.mdpi.com/2072-666X/10/6/368/htm" rel="noopener ugc nofollow" target="_blank">中详细描述了这一点:新的内存逻辑范例:架构和技术视角</a>。</p><p id="e786" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我进一步简化了他们的总结，尽管我建议阅读他们的论文，而不是相信我:</p><ul class=""><li id="79da" class="nq nr jg kx b ky kz lb lc le ns li nt lm nu lq nv nw nx ny bi translated"><strong class="kx jh">计算-近内存:</strong>计算和存储靠得更近了，CnM这个名字就是由此而来的，通过将两个单元一个叠在另一个上面。</li><li id="cc53" class="nq nr jg kx b ky nz lb oa le ob li oc lm od lq nv nw nx ny bi translated"><strong class="kx jh">内存计算</strong>:不修改内存阵列的结构，而是利用其固有的模拟功能来执行计算。具体而言，内存中的计算是通过从内存中读取数据来实现的，然后由读出放大器(SAs)进行感测。</li><li id="7ab7" class="nq nr jg kx b ky nz lb oa le ob li oc lm od lq nv nw nx ny bi translated"><strong class="kx jh">带内存的计算</strong>:作为内容可寻址存储器(CAM)的内存，通过查找表检索预先计算的结果(LUT)。这种计算的工作原理是，任何涉及两个或更多输入的布尔函数都可以通过存储其真值表而被编码在存储器中。</li><li id="8d00" class="nq nr jg kx b ky nz lb oa le ob li oc lm od lq nv nw nx ny bi translated"><strong class="kx jh">内存逻辑</strong>:逻辑直接集成在存储单元内部。与其他三种方法不同，这里数据是在本地计算的，而不需要将它们移动到阵列之外(如CnM方法中的靠近计算单元，或如CiM方法中的靠近外围电路)。</li></ul><p id="33aa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">总之回到IBM hardware团队的文章。</p><p id="e3e2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">存在NVM可变性时DNN模拟硬件加速器中的权重编程</strong></p><blockquote class="oi"><p id="e8e5" class="oj ok jg bd ol om on oo op oq or lq dk translated"><strong class="ak">“非易失性存储器(NVM)的交叉阵列通过在数据位置实施关键的乘-累加(MAC)操作，有可能加速深度神经网络(DNNs)的开发。”</strong></p></blockquote><p id="d549" class="pw-post-body-paragraph kv kw jg kx b ky os kh la lb ot kk ld le ou lg lh li ov lk ll lm ow lo lp lq ij bi translated">如果我们看看别处，考虑一下人工智能芯片，我们可能会理解得稍微多一点。</p><p id="9bdc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请看这张来自<a class="ae jd" href="https://www.researchgate.net/publication/335895548_Photonic_Multiply-Accumulate_Operations_for_Neural_Networks" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh">神经网络</strong> </a> <strong class="kx jh">光子乘累加运算的插图。</strong></p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ox"><img src="../Images/be59d6ac5264f3aff2f46fff161a8fa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*l_d0QPvJ04W8upnj.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Standard configuration of a modern AI chip. Information is passed from the memory to the processor, which consists primarily of MAC operations. Moving data (blue arrows) takes up the majority of the energy budget, followed by MAC operations.</figcaption></figure><p id="115b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在计算中，特别是在数字信号处理中:<em class="mp">“……乘-累加运算是一个常见的步骤，它计算两个数的乘积，并将乘积加到累加器上。”—</em><a class="ae jd" href="https://opencores.org/projects/multiply-accumulate" rel="noopener ugc nofollow" target="_blank"><em class="mp">open cores</em></a>。</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oy"><img src="../Images/528618be5008fd265bee29f55d3a6943.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VYe86zTaJLYOTUgAyeXmFw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><em class="oz">from “</em><a class="ae jd" href="https://www.researchgate.net/publication/270898651_A_High_Speed_and_Low_Power_8_Bit_x_8_Bit_Multiplier_Design_using_Novel_Two_Transistor_2T_XOR_Gates" rel="noopener ugc nofollow" target="_blank"><em class="oz">A High Speed and Low Power 8 bit x 8 bit Multiplier Design Using Novel Two Transistor XOR Gates</em></a><em class="oz">,” 2015, by Himani Upadhyay and Shubhajit Roy Chowdhury.</em></figcaption></figure><p id="f221" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通过了解硬件和软件交互的方式，IBM hardware的研究人员能够考虑一种不同的有效方法。</p><blockquote class="oi"><p id="1c02" class="oj ok jg bd ol om on oo op oq or lq dk translated">IBM hardware的研究人员发现，使用并行行权重编程策略在NVM中编程的权重能够实现软件等效的精度。</p></blockquote><p id="a849" class="pw-post-body-paragraph kv kw jg kx b ky os kh la lb ot kk ld le ou lg lh li ov lk ll lm ow lo lp lq ij bi translated">他们认为，DNN模拟硬件加速器——已经能够显著提高单位面积的吞吐量和能源效率——可以实现软件中预先训练的DNN模型所提供的全面推广精度。尽管他们强调需要做更多的工作。</p></div><div class="ab cl pa pb hu pc" role="separator"><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf"/></div><div class="ij ik il im in"><p id="c885" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里是#500daysofAI，您正在阅读的是第313条。500天来，我每天都在写一篇关于或与人工智能相关的新文章。我300-400天的重点是关于人工智能、硬件和气候危机。</p><figure class="mx my mz na gt is"><div class="bz fp l di"><div class="ph pi l"/></div></figure></div></div>    
</body>
</html>