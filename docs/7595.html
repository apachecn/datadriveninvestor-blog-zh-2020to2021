<html>
<head>
<title>Top 10 Reddit Datasets for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的10大Reddit数据集</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/top-10-reddit-datasets-for-machine-learning-a3283b9c713f?source=collection_archive---------4-----------------------#2020-12-15">https://medium.datadriveninvestor.com/top-10-reddit-datasets-for-machine-learning-a3283b9c713f?source=collection_archive---------4-----------------------#2020-12-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="295f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">此前，我已经发布了其他社交媒体数据汇编。今天，我们将关注世界上最受欢迎的论坛网站Reddit。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f5dec6daf1fef1f85494a07f29f47394.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G_JvItE5Hx0kN118LEI_ag.png"/></div></div></figure><p id="1d9c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">本指南将介绍机器学习的10大Reddit数据集。</p><p id="d69e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Reddit被称为“互联网的首页”，是一个论坛/社交媒体网站，用户可以在这里发布几乎任何内容。与脸书、推特或Instagram不同，大多数Reddit用户保持匿名。Reddit版主严格审查和管理子论坛，称为subreddits。然而，匿名允许人们以他们希望的任何方式说出他们想要的。因此，Reddit的评论和帖子非常适合测试和训练众多自然语言处理(NLP)模型。其中一些模型包括内容调节模型和<a class="ae lq" href="https://lionbridge.ai/services/sentiment-analysis/" rel="noopener ugc nofollow" target="_blank">情感分类器。</a></p></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><h1 id="8803" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">机器学习的最佳Reddit数据集</h1><p id="7ea1" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">警告:下面的一些数据集是专门为内容审核模型的训练而编译的。因此，数据可以包括明确的内容。</p><h1 id="f1e3" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">Reddit评论数据集</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f1c8d40296f205cee9f9628f56ec48b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-Y3g9afo1fPcUh43.png"/></div></div></figure><p id="4598" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">1.<a class="ae lq" href="https://www.kaggle.com/nickreinerink/reddit-rcryptocurrency" rel="noopener ugc nofollow" target="_blank"> Cryptocurrency Reddit评论数据集</a> —该数据集包含来自subreddit r/cryptocurrency的评论。这些数据由2017年11月至2018年3月五个月内发布的评论组成。</p><p id="c051" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">2.<a class="ae lq" href="https://www.kaggle.com/amalinow/donald-trump-comments-on-reddit" rel="noopener ugc nofollow" target="_blank">唐纳德·特朗普在Reddit上的评论</a>——一个简单的数据集，包含从Reddit抓取的数千条提到唐纳德·特朗普的评论。</p><p id="d9f3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">3.<a class="ae lq" href="https://www.kaggle.com/ehallmar/reddit-comment-score-prediction" rel="noopener ugc nofollow" target="_blank"> Reddit评论得分预测</a> —该数据集旨在帮助创建一个模型，该模型可以预测一条Reddit评论是否会获得赞成票或反对票。该数据集包括400万条Reddit评论:200万条表现不佳(否决)和200万条表现良好(投票赞成)。</p><div class="na nb gp gr nc nd"><a href="https://www.datadriveninvestor.com/2020/11/19/how-machine-learning-and-artificial-intelligence-changing-the-face-of-ecommerce/" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd iu gy z fp ni fr fs nj fu fw is bi translated">机器学习和人工智能如何改变电子商务的面貌？|数据驱动…</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">电子商务开发公司，现在，整合先进的客户体验到一个新的水平…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr ks nd"/></div></div></a></div><h1 id="9a75" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">Reddit新闻数据集</h1><p id="abdd" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">4.<a class="ae lq" href="https://www.kaggle.com/aaron7sun/stocknews" rel="noopener ugc nofollow" target="_blank">股市预测每日新闻</a>——顾名思义，这个数据集最初是用来创建可以预测股市波动的模型的。数据由2008年6月至2016年7月从r/worldnews抓取的新闻，以及道琼斯工业平均指数股票数据组成。</p><p id="c855" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">5.Reddit上的世界新闻(World News)—取自r/worldnews子编辑，这个数据集包含了从2008年开始在这个子编辑上发布的所有新闻的信息。数据集包括以下信息:创建日期、投票数、标题、作者以及新闻是否包含成熟内容。</p><h1 id="b3c9" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">来自Reddit的其他数据</h1><p id="dac4" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">6.<a class="ae lq" href="https://www.kaggle.com/ammar111/reddit-top-1000" rel="noopener ugc nofollow" target="_blank"> Reddit的前1000篇</a> —这个数据集包含了18个子编辑区有史以来前1000篇帖子，就投票数而言。对于每个帖子，CSV文件包含帖子的标题和发帖人的用户名。此外，还包括了投票数、投票数、子编辑名、url和其他元数据。</p><p id="f719" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">7.<a class="ae lq" href="https://www.kaggle.com/colinmorris/reddit-usernames" rel="noopener ugc nofollow" target="_blank"> Reddit用户名</a> —一个简单的数据集，包含2600万Reddit用户的CSV文件。此外，数据集包括每个用户所做评论的总数。</p><p id="4f94" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">8.<a class="ae lq" href="http://nlp.cs.princeton.edu/SARC/0.0/" rel="noopener ugc nofollow" target="_blank"> SARC:自我注释的Reddit讽刺语料库</a>——这个数据集由超过130万条来自Reddit的讽刺评论和帖子组成。数据集创建者已经在每个语句中标记了讽刺。此外，发帖人的用户名、主题和上下文也包含在每个语句中。</p><p id="6d96" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">9.<a class="ae lq" href="https://www.kaggle.com/salbaroudi/reddit-scitech-acronyms" rel="noopener ugc nofollow" target="_blank">Reddit上的科技缩略语</a> —该数据集包含超过140，000个在科学、生物、技术和未来学子编辑上发现的缩略语。数据是CSV文件的形式，包括评论ID、时间、用户名、子编辑名和提到的缩写。</p><p id="4748" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">10.<a class="ae lq" href="https://github.com/ThingsOnReddit/top-things" rel="noopener ugc nofollow" target="_blank">Reddit上的东西(产品)</a> —这个产品数据集是从2015年到2017年发布亚马逊产品的每个子编辑中收集的排名前100的亚马逊产品。数据集中的每个CSV文件都包括产品名称、类别和产品的URL。此外，Reddit上的总提及次数和subreddit上的总提及次数也包含在数据中。</p></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><p id="eb38" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上面的数据集可以用来帮助训练情感分析模型、文本分类器、预测模型和其他NLP算法。更多社交媒体数据集，请查看我们下面的相关资源。</p><p id="fafd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">同时发布于:<a class="ae lq" href="https://lionbridge.ai/datasets/top-10-reddit-datasets-for-machine-learning/" rel="noopener ugc nofollow" target="_blank"> Lionbridge AI </a></p><h2 id="fc0e" class="ns lz it bd ma nt nu dn me nv nw dp mi ld nx ny mk lh nz oa mm ll ob oc mo od bi translated">访问专家视图— <a class="ae lq" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>