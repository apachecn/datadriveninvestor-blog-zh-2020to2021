<html>
<head>
<title>Udacity Capstone: Identifying Dog Breeds Using Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Udacity顶点:使用卷积神经网络识别狗的品种</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/udacity-capstone-identifying-dog-breeds-using-convoluted-neural-networks-c266cfd42b80?source=collection_archive---------8-----------------------#2020-04-21">https://medium.datadriveninvestor.com/udacity-capstone-identifying-dog-breeds-using-convoluted-neural-networks-c266cfd42b80?source=collection_archive---------8-----------------------#2020-04-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/adccb5e6b5141504211fcb3e4cc096c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3edhScjT2zbdhAQBpgYc2Q.jpeg"/></div></div></figure><p id="07e4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">根据美国养狗俱乐部的统计，有149种狗。一些消息来源称这个数字应该超过300，但可以肯定的说有很多狗的品种。一般人很难找到时间或动力去记住每一个犬种的特征，期望任何一个人拥有一眼就能认出犬种的技能也是一种奢望。</p><p id="4257" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">正是在这种情况下，我们有机会应用数据科学技术，让计算机填补人类一直难以填补的空白。对于这个项目，目标是当给定一张狗的照片作为输入时，使用卷积神经网络(CNN)根据狗的品种对狗的图像进行分类。</p><p id="75ba" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该项目在Udacity工作区中执行，项目数据已经加载到工作区中。然而，用于训练CNN的数据可以在<a class="ae kz" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><div class="la lb gp gr lc ld"><a href="https://www.datadriveninvestor.com/2020/02/19/five-data-science-and-machine-learning-trends-that-will-define-job-prospects-in-2020/" rel="noopener  ugc nofollow" target="_blank"><div class="le ab fo"><div class="lf ab lg cl cj lh"><h2 class="bd iu gy z fp li fr fs lj fu fw is bi translated">将定义2020年就业前景的五大数据科学和机器学习趋势|数据驱动…</h2><div class="lk l"><h3 class="bd b gy z fp li fr fs lj fu fw dk translated">数据科学和ML是2019年最受关注的趋势之一，毫无疑问，它们将继续发展…</h3></div><div class="ll l"><p class="bd b dl z fp li fr fs lj fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="lm l"><div class="ln l lo lp lq lm lr jz ld"/></div></div></a></div><p id="f103" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该项目是Udacity nanodegree计划的一部分，最终产品是一种算法，当提供图像作为输入时，该算法将使用CNN来执行以下操作:</p><p id="f8c3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">1.检测输入图像中的人脸</p><p id="5809" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">2.检测输入图像中的狗脸</p><p id="18cf" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">3.如果检测到狗，预测狗的品种</p><p id="df69" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">4.预测哪种狗最像它检测到的人脸</p><p id="dc51" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于本文，项目的执行将包含在以下步骤中:</p><p id="edd7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">检测图像中的人</p><p id="c6ca" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">检测图像中的狗</p><p id="2993" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从头开始建立一个CNN来分类狗的品种</p><p id="388f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用迁移学习建立一个CNN来分类狗的品种(使用迁移学习)</p><p id="b530" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">编写一个结合上述所有步骤的算法</p><p id="d6bc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">测试算法</p></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><p id="8159" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">检测图像中的人类</strong></p><p id="d7d1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用face_recognition库用python实现了图像中人脸的检测(文档<a class="ae kz" href="https://pypi.org/project/face-detector/" rel="noopener ugc nofollow" target="_blank">此处</a>)。该库提供了一种简单的方法来实现图像中的人脸检测，当在图像子集上测试时，它比Udacity推荐的使用OpenCV库来检测人脸的实现具有更高的准确性。下面显示了两个人脸检测实现，它们在一组200张图像上进行测试，其中100张包含狗，100张包含人。</p><p id="0bdd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">利用OpenCV实现人脸检测。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="3bb3" class="mi mj it me b gy mk ml l mm mn">#Define a function that returns true if it detects a human face</span><span id="8ec6" class="mi mj it me b gy mo ml l mm mn">def face_detector(img_path):<br/> img = cv2.imread(img_path)<br/> gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br/> faces = face_cascade.detectMultiScale(gray)<br/> return len(faces) &gt; 0</span></pre><p id="cada" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">利用这种实现，对于100%的人图像和11%的狗图像检测到面部。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="d891" class="mi mj it me b gy mk ml l mm mn">#Import the relevant library<br/>import face_recognition</span><span id="c289" class="mi mj it me b gy mo ml l mm mn">#Define a function that returns true if it detects a human face</span><span id="03ff" class="mi mj it me b gy mo ml l mm mn">def face_detector(path):<br/>    image = face_recognition.load_image_file(path)<br/>    face_locations = face_recognition.face_locations(image)<br/>    return len(face_locations) &gt; 0</span></pre><p id="0a0a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">上面是使用face_recognition库实现的人脸检测器。利用这种实现，对于100%的人图像和10%的狗图像检测到了面部。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="558c" class="mi mj it me b gy mk ml l mm mn">##Test the performance of the face_detector algorithm on the images in human_files_short and dog_files_short.</span><span id="dfc1" class="mi mj it me b gy mo ml l mm mn">#Import files for testing the face detector</span><span id="3c2e" class="mi mj it me b gy mo ml l mm mn">human_files_short = human_files[:100]<br/>dog_files_short = train_files[:100]</span><span id="211b" class="mi mj it me b gy mo ml l mm mn">#Instantiate counters for the number of faces detected in each set <br/>dog_count, human_count = 0,0</span><span id="c80f" class="mi mj it me b gy mo ml l mm mn">#Loop through all images and try detecting a face<br/>for count in range(100):<br/>    if face_detector(dog_files_short[count]):<br/>        dog_count+=1<br/>        <br/>    if face_detector(human_files_short[count]):<br/>        human_count+=1<br/>        <br/>print('Faces were detected for {0}% of human images'.format(human_count))</span><span id="f199" class="mi mj it me b gy mo ml l mm mn">print('Faces were detected for {0}% of dog images'.format(dog_count))</span></pre><p id="3496" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从使用上面的代码进行的测试中，我们发现这两个模型都不完美，但是第二个实现在选定的日期产生了稍好的结果。</p></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><p id="d746" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">检测图像中的狗</strong></p><p id="6fb3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">检测输入图像中的狗是使用Resnet 50 CNN架构和imagenet数据库执行的。CNN是使用下面的代码导入的。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="48f8" class="mi mj it me b gy mk ml l mm mn">from keras.applications.resnet50 import ResNet50</span><span id="3150" class="mi mj it me b gy mo ml l mm mn"># define ResNet50 model<br/>ResNet50_model = ResNet50(weights='imagenet')</span></pre><p id="e408" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在输入图像中检测狗的过程包括两个步骤。第一步是处理输入的图像数据，第二步是根据处理后的图像进行预测。</p><p id="f8b2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">预处理</strong></p><p id="6d6f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在将数据传递到Resnet 50模型进行预测之前，我们需要对图像数据进行一些预处理。我们这样做是因为使用TensorFlow作为后端的Keras CNNs要求输入是4D数组。输入数组的形式如下:</p><p id="2938" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">(样本数、行数、列数、通道数)</p><p id="3be3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了实现以下功能，定义了:</p><p id="20ad" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> Path_to_tensor </strong>:该函数接受一个彩色图像的字符串值文件路径作为输入，并返回一个适合提供给Keras CNN的4D张量。该函数首先加载图像，并将其调整为224×224像素的正方形图像。然后，图像被转换成一个数组，数组的大小被调整为4D张量。在这种情况下，由于我们正在处理彩色图像，每个图像有三个通道。</p><p id="3169" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> Paths_to_tensor: </strong>这个函数接受一个NumPy数组的字符串值图像路径作为输入，并返回一个具有所需形状的4D张量。在我们的数据为模型做好准备之前，要采取的最后一步包括额外的归一化步骤，即获取ImageNet中所有图像的所有像素的平均像素值(用RGB表示为[103.939，116.779，123.68])，并从每个图像的每个像素中减去它。这是在导入函数<code class="fe mp mq mr me b">preprocess_input</code>中实现的，在这里可以找到<a class="ae kz" href="https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="09eb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这两个函数的代码如下所示。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="25bb" class="mi mj it me b gy mk ml l mm mn">from keras.preprocessing import image                  <br/>from tqdm import tqdm</span><span id="394a" class="mi mj it me b gy mo ml l mm mn">def path_to_tensor(img_path):<br/>    # loads RGB image as PIL.Image.Image type<br/>    img = image.load_img(img_path, target_size=(224, 224))<br/>    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)<br/>    x = image.img_to_array(img)<br/>    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor<br/>    return np.expand_dims(x, axis=0)</span><span id="a67e" class="mi mj it me b gy mo ml l mm mn">def paths_to_tensor(img_paths):<br/>    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]<br/>    return np.vstack(list_of_tensors)</span></pre><p id="8c77" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">做出预测</strong></p><p id="a70d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面显示的函数是用于进行预测的函数，它使用predict函数来获得Imagenet的1000个类的数组。然后，我们使用NumPy的argmax函数来隔离概率最高的类。</p><p id="babe" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在Imagenet类的输出字典(在这里找到<a class="ae kz" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank"/>)中，条目151到269表示狗，因此我们编写了第二个函数，使用这个字典来确定图像中的任何已识别对象是否属于这个字典范围。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="28f9" class="mi mj it me b gy mk ml l mm mn">from keras.applications.resnet50 import preprocess_input, decode_predictions</span><span id="1508" class="mi mj it me b gy mo ml l mm mn">#Extract the label with the highest probability according to the CNN<br/>def ResNet50_predict_labels(img_path):<br/>    # returns prediction vector for image located at img_path<br/>    img = preprocess_input(path_to_tensor(img_path))<br/>    return np.argmax(ResNet50_model.predict(img))</span><span id="f9af" class="mi mj it me b gy mo ml l mm mn">### returns "True" if the extracted label corresponds to a dog <br/>def dog_detector(img_path):<br/>    prediction = ResNet50_predict_labels(img_path)<br/>    return ((prediction &lt;= 268) &amp; (prediction &gt;= 151))</span></pre><p id="4156" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面的代码用于测试狗检测器的准确性，结果是0%的人图像和100%的狗图像检测到人脸</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="3b8d" class="mi mj it me b gy mk ml l mm mn">dog_count = 0 <br/>human_count = 0<br/>#Loop through all images and try detecting a face<br/>for count in range(100):<br/>    if dog_detector(dog_files_short[count]):<br/>        dog_count+=1<br/>        <br/>    if dog_detector(human_files_short[count]):<br/>        human_count+=1<br/>        <br/>print('Dogs were detected for {0}% of human images'.format(human_count))<br/>print('Dogs were detected for {0}% of dog images'.format(dog_count))</span></pre></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><p id="ac05" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">从零开始建立CNN对狗的品种进行分类</strong></p><p id="7c44" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">尽管该项目的目标是使用迁移学习建立一个狗品种分类器，但该项目的这一部分对于理解CNN的基本原理及其工作方式是有用的。</p><p id="52a6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我为CNN选定的网络旨在通过使矩阵比其高或宽更深来降低图像的维度。使用max-pooling层减少维度，而使用卷积层增加图像的深度。</p><p id="d494" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在添加完全连接的层之前，使用间隙层来展平阵列，该完全连接的层以具有133个节点的完全连接的层结束——与狗品种的数量相同。脱落层用于降低过度拟合的可能性。</p><p id="976e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该模型使用rmsprop作为基于分类交叉熵的损失函数的优化器进行编译。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="1cce" class="mi mj it me b gy mk ml l mm mn">from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D<br/>from keras.layers import Dropout, Flatten, Dense<br/>from keras.models import Sequential</span><span id="a966" class="mi mj it me b gy mo ml l mm mn">model = Sequential()<br/>model.add(Conv2D(filters = 16, kernel_size = 2, padding = 'same', activation = 'relu', input_shape = (224, 224, 3)))<br/>model.add(MaxPooling2D(pool_size = 4, padding = 'same'))<br/>model.add(Conv2D(filters = 32, kernel_size = 2, padding = 'same', activation = 'relu'))<br/>model.add(MaxPooling2D(pool_size = 4, padding = 'same'))<br/>model.add(Conv2D(filters = 64, kernel_size = 2, padding = 'same', activation = 'relu'))<br/>model.add(MaxPooling2D(pool_size = 2, padding = 'same'))<br/>model.add(Dropout(0.3))<br/>model.add(GlobalAveragePooling2D())<br/>#model.add(Flatten())<br/>model.add(Dense(200, activation = 'relu'))<br/>model.add(Dropout(0.4))<br/>model.add(Dense(133, activation = 'softmax'))</span><span id="e82d" class="mi mj it me b gy mo ml l mm mn">model.summary()</span></pre><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/1cdc3c6fe9c471a1f93a26289b52bd3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*1jHaVtJ6pszP4rnjAvbfTQ.png"/></div></figure><p id="b58d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这项任务的目标是建立一个精确度大于1%的CNN。上述网络在没有任何参数微调或数据扩充的情况下实现了18.062%。</p></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><p id="1961" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">用迁移学习建立一个CNN对狗的品种进行分类</strong></p><p id="4358" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该项目的这一部分涉及利用现有的模型来提高我的CNN的准确性。这是通过切断先前存在的CNN的最终分类层并添加我设计的分类层来实现的。在此应用之后，整个模型将在狗图像数据集上训练，以调整添加的层的权重，同时保持原始模型的权重。</p><p id="0b5e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这种方法将使新CNN的训练非常快速，因为我们应用的图像中已经分离出了用于识别的主要特征。这意味着我们只有少量的参数或权重可以反向传播。</p><p id="2355" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我选择通过利用在imagenet数据库上训练的Resnet 50 CNN来构建我的CNN。Resnet 50模型的瓶颈特性是存在的，我只需要下载我们的Resnet 50 CNN的文件，然后用下面的代码导入它。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="cb21" class="mi mj it me b gy mk ml l mm mn">### TODO: Obtain bottleneck features from another pre-trained CNN.</span><span id="68c9" class="mi mj it me b gy mo ml l mm mn">bottleneck_features = np.load('bottleneck_features/DogResNet50Data.npz')<br/>train_Resnet50 = bottleneck_features['train']<br/>valid_Resnet50 = bottleneck_features['valid']<br/>test_Resnet50 = bottleneck_features['test']</span></pre><p id="5a78" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">模型架构</strong>如下图所示。我尝试了几种不同的组合，其中1和2个完全连接的层具有200和400个节点，不同的丢失率(0.4和0.5)和不同的优化器(Adam，rmsprop)。所有不同的架构给我的测试准确率在79%到83%之间。</p><p id="6266" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后一层是133个节点，以匹配我们的类的数量。</p><p id="56fc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以下架构的测试准确率为82.656%</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="47cc" class="mi mj it me b gy mk ml l mm mn">### TODO: Define your architecture.<br/>trans_model = Sequential()</span><span id="1f7e" class="mi mj it me b gy mo ml l mm mn">trans_model.add(GlobalAveragePooling2D(input_shape=train_Resnet50.shape[1:]))<br/>trans_model.add(Dense(200, activation = 'relu'))<br/>trans_model.add(Dropout(0.4))<br/>trans_model.add(Dense(133, activation = 'softmax'))</span><span id="04f5" class="mi mj it me b gy mo ml l mm mn">trans_model.summary()</span></pre><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/09f8f151dd3c7b6c1c08a9cbdd9785e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*e6NLZ4Bo4fQBnFWQ29iukg.png"/></div></figure><p id="633b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">定义架构后，使用下面的代码对其进行编译和训练。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="4d04" class="mi mj it me b gy mk ml l mm mn">### TODO: Compile the model.<br/>trans_model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])</span></pre><p id="fe53" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们跟踪所有时期并加载最佳参数，以确保我们的CNN在训练过程中具有最高精度的权重。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="6e7f" class="mi mj it me b gy mk ml l mm mn">### TODO: Train the model.</span><span id="4a2f" class="mi mj it me b gy mo ml l mm mn">from keras.callbacks import ModelCheckpoint</span><span id="23a1" class="mi mj it me b gy mo ml l mm mn">epochs = 50</span><span id="0cb0" class="mi mj it me b gy mo ml l mm mn">checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.trans.hdf5', verbose=1, save_best_only=True)</span><span id="869f" class="mi mj it me b gy mo ml l mm mn">trans_model.fit(train_Resnet50, train_targets, validation_data=(valid_Resnet50, valid_targets),epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)</span><span id="cea4" class="mi mj it me b gy mo ml l mm mn">trans_model.load_weights('saved_models/weights.best.trans.hdf5')</span></pre><p id="510b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们测试了用下面的代码实现的模型的准确性，得到了80.502%的准确性。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="c245" class="mi mj it me b gy mk ml l mm mn">### TODO: Calculate classification accuracy on the test dataset.</span><span id="9e48" class="mi mj it me b gy mo ml l mm mn"># get index of predicted dog breed for each image in test set<br/>new_dog_breed_predictions = [np.argmax(trans_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_Resnet50]</span><span id="6658" class="mi mj it me b gy mo ml l mm mn"># report test accuracy<br/>test_accuracy = 100*np.sum(np.array(new_dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(new_dog_breed_predictions)<br/>print('Test accuracy: %.4f%%' % test_accuracy)</span></pre><p id="acdd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在训练模型之后，下一步是将它放入一个函数中，该函数将接受图像路径并预测图像中的狗的品种。为此任务定义的函数如下所示。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="0f4c" class="mi mj it me b gy mk ml l mm mn">### TODO: Write a function that takes a path to an image as input<br/>### and returns the dog breed that is predicted by the model.</span><span id="078c" class="mi mj it me b gy mo ml l mm mn">from extract_bottleneck_features import *</span><span id="6196" class="mi mj it me b gy mo ml l mm mn">def Resnet50_predict_breed(img_path):<br/>    # extract bottleneck features<br/>    bottleneck_feature = extract_Resnet50(path_to_tensor(img_path))<br/>    # obtain predicted vector<br/>    predicted_vector = trans_model.predict(bottleneck_feature)<br/>    # return dog breed that is predicted by the model<br/>    pred1 = re.sub(r'[0-9]', '', dog_names[np.argmax(predicted_vector)][11:])<br/>    prediction = re.sub(r'_', ' ', pred1)<br/>    return prediction</span></pre><p id="b687" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">写出你的算法，它结合了上面</strong>的所有步骤</p><p id="6899" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了完成到目前为止的所有工作，构建了一个函数。该函数接受图像的文件路径，并首先确定图像是否包含人、狗或两者都不包含。然后，</p><ul class=""><li id="3ac5" class="mu mv it kd b ke kf ki kj km mw kq mx ku my ky mz na nb nc bi translated">如果在图像中检测到一只<strong class="kd iu">狗</strong>，返回预测的品种。</li><li id="f70e" class="mu mv it kd b ke nd ki ne km nf kq ng ku nh ky mz na nb nc bi translated">如果在图像中检测到一个<strong class="kd iu">人</strong>，返回相似的狗品种。</li><li id="c5e3" class="mu mv it kd b ke nd ki ne km nf kq ng ku nh ky mz na nb nc bi translated">如果在图像中没有检测到<strong class="kd iu">或</strong>，则提供一个指示错误的输出。</li></ul><p id="99ea" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们利用项目中前面指定的人脸检测器和狗检测器功能来检测图片中的人脸和狗脸。该算法接收图像路径，并基于上述要求进行操作。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="1291" class="mi mj it me b gy mk ml l mm mn">### TODO: Write your algorithm.<br/>### Feel free to use as many code cells as needed.</span><span id="f7a3" class="mi mj it me b gy mo ml l mm mn">def dog_breed_detector(path):<br/>    <br/>    print('---------Started----------')<br/>    <br/>    #Display the image<br/>    display_image(path)<br/>    <br/>    if dog_detector(path):<br/>        breed = Resnet50_predict_breed(path)<br/>        print('This dog is a ' + breed)<br/>    <br/>    elif new_face_detector(path):<br/>        breed = Resnet50_predict_breed(path)<br/>        print("This human resembles a " + breed)<br/>    else:<br/>        print("Theres neither a human nor a dog in this picture, review the input image")<br/>    pass</span></pre><p id="8956" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">测试算法</strong></p><p id="0ac6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我测试算法的能力受到这样一个事实的限制，即我没有大量的图片进行测试，但该模型在测试图片上的表现令人满意，如下所示。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="6b4d" class="mi mj it me b gy mk ml l mm mn">import os</span><span id="5d5c" class="mi mj it me b gy mo ml l mm mn">listr = [(str(i)[11:-2]) for i in os.scandir('images')]<br/>del(listr[11])<br/>print(listr)</span><span id="8c27" class="mi mj it me b gy mo ml l mm mn">for x in listr:<br/>    dog_breed_detector('images/' + x)<br/>    print ('/n')</span></pre><div class="lz ma mb mc gt ab cb"><figure class="ni ju nj nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/08d32fd17949c3927e277f1ae458f71d.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*FANaDKtE0tlgP3nlp6FhVw.png"/></div></figure><figure class="ni ju no nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/3f800918c54738c6793e1741fa28bb86.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*Jq8pwcA1_8ZVeWLe4_ToQA.png"/></div></figure><figure class="ni ju np nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/73e487461b422df470318bea2c98260c.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*acH498DLwY6JNVBWlwx5-Q.png"/></div></figure></div><div class="ab cb"><figure class="ni ju nq nk nl nm nn paragraph-image"><img src="../Images/5fc9329c627cfec2f4f1a5f87ae3a3df.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*AmfId9jn_K0n4Lo03mc5BQ.png"/></figure><figure class="ni ju nr nk nl nm nn paragraph-image"><img src="../Images/5e6fb2a0cd54905c0595aee62995c2f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*WdKlEkavl3Wb0nWEjmdfwA.png"/><figcaption class="ns nt gj gh gi nu nv bd b be z dk nw di nx ny">Images tested with the algorithm. Apparently I look like an American Foxhound</figcaption></figure></div><p id="5b69" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">倒影</strong></p><p id="3ca9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该模型表现令人满意，但未能达到90%的准确度。然而，所获得的结果可以通过以下方式进行改进:</p><p id="df5d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">通过提供更大的数据集和审查图像来提高训练数据的质量，以确保它们不会偏向一个品种，不会模糊或有任何负面影响CNN的缺陷。</p><p id="118b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">数据扩充，包括使用Keras ImageDataGenerator类对训练数据进行数据扩充。</p><p id="44c6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">进一步超参数调谐</p><figure class="lz ma mb mc gt ju"><div class="bz fp l di"><div class="nz oa l"/></div></figure></div></div>    
</body>
</html>