<html>
<head>
<title>Principal Component Analysis (PCA)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主成分分析</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/principal-component-analysis-pca-666f4424f798?source=collection_archive---------13-----------------------#2020-07-27">https://medium.datadriveninvestor.com/principal-component-analysis-pca-666f4424f798?source=collection_archive---------13-----------------------#2020-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="36a5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这个故事中，你将能够理解使用主成分分析进行降维以及它是如何工作的</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/3063c7e1bf92e08878975c4d31968121.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*SP1Yp_YwgBS7b24-.png"/></div></figure><h1 id="9d65" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">维度的诅咒</h1><p id="1d69" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">在机器学习中，“维数”只是指数据集中的特征(即输入变量)的数量。</p><p id="2d06" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">虽然如果我们添加额外的特征/维度，任何机器学习模型的性能都会提高，但在某些时候，进一步的插入会导致性能下降，即当特征的数量与数据集中的观察数量相当大时，一些线性算法会努力训练有效的模型。这就是所谓的“维数灾难”。</p><p id="615e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">降维</strong>是一套技术，研究如何缩小数据的规模，同时保留最重要的信息，进一步消除维数灾难。它在分类和聚类问题中起着重要的作用。</p><div class="lz ma gp gr mb mc"><a href="https://www.datadriveninvestor.com/2020/07/28/how-finance-sector-can-benefit-by-machine-learning-development-and-ai/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd iu gy z fp mh fr fs mi fu fw is bi translated">金融行业如何受益于机器学习发展和人工智能|数据驱动的投资者</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">在快速变化的金融世界中做出正确的决定并抓住机会可以让你的…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq ku mc"/></div></div></a></div><h1 id="a7e0" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">什么是PCA？</h1><p id="96f6" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">PCA是一种在数据集中提取模式的统计技术。是的，它是。你可能知道它是降维方法，是的。但实际上不止如此。PCA简单地转换你的数据集以识别隐藏的关系、相似性或差异，然后你可以对它的输出进行降维、数据压缩或特征提取。然而，PCA是最著名的，用于降低数据集的维度，这就是我们将在本文中做的:用PCA降维。</p><p id="edf4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在现实世界的数据分析任务中，我们分析复杂的数据，即多维数据。我们绘制数据，并在其中找到各种模式，或者用它来训练一些机器学习模型。考虑维度的一种方式是，假设您有一个数据点<strong class="js iu"> x </strong>，如果我们将该数据点视为一个物理对象，那么维度仅仅是视图的基础，就像从水平轴或垂直轴观察数据时，数据位于何处。</p><p id="84d9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">随着数据维度的增加，对其进行可视化和计算的难度也在增加。那么，如何降低一个数据的维度- <br/> *去掉冗余维度<br/> *只保留最重要的维度呢</p><h1 id="a9d0" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">PCA是如何工作的？</h1><p id="e45e" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">为了通过PCA从原始数据集分析和构建新的数据集(维数减少),通常使用以下步骤:</p><ol class=""><li id="3f3a" class="mr ms it js b jt ju jx jy kb mt kf mu kj mv kn mw mx my mz bi translated">获取数据集</li><li id="5813" class="mr ms it js b jt na jx nb kb nc kf nd kj ne kn mw mx my mz bi translated">计算数据的协方差矩阵</li></ol><p id="6aea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">协方差矩阵只是特征(维度)的协方差矩阵。协方差是两个特征的方差；换句话说，这两个特征是如何相互区别的。当您需要从现有特征中提取新的模式或特征时，这是一条非常有用的信息。因此，作为第二步，我们需要计算数据集的协方差矩阵。由于数据中有4个特征，因此我们需要计算6个协方差和4个方差。</p><p id="e1af" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.计算协方差矩阵的特征值和特征向量</p><p id="f9ba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">特征值和特征向量是PCA的核心；不仅是inPCA，还有SVD，LDA。但是为什么它们如此重要呢？相关的特征值和特征向量构成矩阵方程的根特征。我将把对此的解释留给<a class="ae nf" href="http://mathworld.wolfram.com/Eigenvalue.html" rel="noopener ugc nofollow" target="_blank">这个</a>源，并将继续讨论PCA的特征向量和特征值的重要特征。</p><p id="4776" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">4.选择主成分</p><p id="4999" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">5.根据所选组件构建新的专题数据集</p><h1 id="4089" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">主成分分析的应用</h1><ul class=""><li id="3438" class="mr ms it js b jt lu jx lv kb ng kf nh kj ni kn nj mx my mz bi translated">降维</li><li id="25b8" class="mr ms it js b jt na jx nb kb nc kf nd kj ne kn nj mx my mz bi translated">PCA主要用作<a class="ae nf" href="https://en.wikipedia.org/wiki/Exploratory_data_analysis" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">探索性数据分析</strong> </a>和制作<a class="ae nf" href="https://en.wikipedia.org/wiki/Predictive_modeling" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">预测模型</strong> </a>的工具。</li><li id="eb0a" class="mr ms it js b jt na jx nb kb nc kf nd kj ne kn nj mx my mz bi translated">高维数据的可视化——如果我们有高维数据，可能很难绘制成eﬀectively.有时绘制前两个主成分可以揭示数据中有趣的几何结构。</li><li id="0af1" class="mr ms it js b jt na jx nb kb nc kf nd kj ne kn nj mx my mz bi translated">寻找基本属性/变量(高维数据中的特征选择)</li><li id="68f2" class="mr ms it js b jt na jx nb kb nc kf nd kj ne kn nj mx my mz bi translated">PCA用于发现数据中的模式。</li><li id="d2df" class="mr ms it js b jt na jx nb kb nc kf nd kj ne kn nj mx my mz bi translated">噪声过滤。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nk"><img src="../Images/74b35238c374f4e51af90d9108df4293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kNhZ_Jkx37XOfN3F.jpeg"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><a class="ae nf" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2735096/" rel="noopener ugc nofollow" target="_blank">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2735096/</a></figcaption></figure><h1 id="42b2" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">PCA的弱点</h1><p id="6928" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">它很容易受到数据中异常值的影响。</p><p id="ef8c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了克服这个问题，已经开发了许多健壮版本的PCA，包括随机化PCA、稀疏PCA等。</p><h1 id="1e62" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">结论</h1><p id="c018" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">如果你正准备开始你的机器学习，并想从头开始学习，我将制作这个关于机器学习的5-6分钟长的系列，并在每章的结尾做一些辅助项目，所以请保持关注，祝学习愉快</p><p id="0ab2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些是我个人的研究，如果你有任何意见，请联系我。</p><p id="4897" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">欢迎来到我的媒体页面</p><p id="1e57" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae nf" href="https://github.com/zahrael97" rel="noopener ugc nofollow" target="_blank"> Github </a>，<a class="ae nf" href="https://www.linkedin.com/in/zahraelhamraoui97/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>，<a class="ae nf" href="http://zahraelhamraoui1997@gmail.com/" rel="noopener ugc nofollow" target="_blank"> Zahra Elhamraoui </a>，<a class="ae nf" href="https://www.upwork.com/o/profiles/users/~01e52291fa456a8934/" rel="noopener ugc nofollow" target="_blank"> Upwork </a></p><p id="d385" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">进入专家视角— </strong> <a class="ae nf" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">订阅DDI英特尔</strong> </a></p></div></div>    
</body>
</html>