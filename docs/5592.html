<html>
<head>
<title>Alternative Hyperparameter Optimization Techniques You Need to Know — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">您需要了解的替代超参数优化技术—第2部分</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/alternative-hyperparameter-optimization-techniques-you-need-to-know-part-2-e9b0d4d080a9?source=collection_archive---------1-----------------------#2020-09-25">https://medium.datadriveninvestor.com/alternative-hyperparameter-optimization-techniques-you-need-to-know-part-2-e9b0d4d080a9?source=collection_archive---------1-----------------------#2020-09-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="eef8" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">超参数优化技术。</h2><div class=""/><div class=""><h2 id="a1f4" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">微调机器学习模型以提高性能的不同方法。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/e7111db10a4ba4865265e5c6fc1800cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8kZ3Fvu6EPYXtWxxW7LI9Q.png"/></div></div></figure><p id="9233" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这是关注您需要了解的替代超参数优化技术系列的第二部分。在第一部分中，我们看了最常用的方法(GridsearchCV和randomizedSearchCV)和第一种替代方法<strong class="lc ja">hyperpt</strong>。如果这是你的第一次，我强烈建议你在这里阅读第一部分<a class="ae lw" href="https://medium.com/datadriveninvestor/alternative-hyperparameter-optimization-techniques-you-need-to-know-part-1-3f68d0448fcd" rel="noopener"/>。</p><p id="1e13" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在让我们学习第二种替代超参数优化技术。</p><h1 id="fa3e" class="lx ly iq bd lz ma mb mc md me mf mg mh kf mi kg mj ki mk kj ml kl mm km mn mo bi translated">sci kit-优化</h1><p id="30df" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">Scikit-optimize是另一个用于超参数优化的开源python库，它实现了几种基于模型的顺序优化方法。该库非常易于使用，并为贝叶斯优化提供了一个通用工具包，可用于超参数调优。它还支持对scikit-learn库提供的机器学习算法的超参数进行调优。</p><p id="ce37" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">scikit-optimize构建在Scipy、NumPy和Scikit-Learn之上。</p><h1 id="bb2b" class="lx ly iq bd lz ma mb mc md me mf mg mh kf mi kg mj ki mk kj ml kl mm km mn mo bi translated">scikit-optimize的特性</h1><p id="f5c3" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">Scikit-optimize包含至少四个您需要了解的重要特性，以便运行您的首次优化。</p><h2 id="5622" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">空间</h2><p id="d7c0" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">scikit-optimize具有不同的函数来定义包含一个或多个维度的优化空间。搜索空间最常见的选项有:</p><ul class=""><li id="ff47" class="nf ng iq lc b ld le lg lh lj nh ln ni lr nj lv nk nl nm nn bi translated"><strong class="lc ja">实数</strong> —这是一个搜索空间维度，可以采用任何实数。您需要定义下限和上限，并且两者都包含在内。<br/>举例:<code class="fe no np nq nr b">Real(low=0.2, high=0.9, name="min_samples_leaf")</code></li><li id="3265" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><strong class="lc ja">整数</strong> —这是一个可以采用整数值的搜索空间维度。<br/>例如:<code class="fe no np nq nr b">Integer(low=3, high=25, name="max_features")</code></li><li id="12ae" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><strong class="lc ja">分类</strong> —这是一个可以采用分类值的搜索空间维度。<br/>例如:<code class="fe no np nq nr b">Categorical(["gini","entropy"],name="criterion")</code></li></ul><p id="96c4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">注意:在每个搜索空间中，你必须使用<strong class="lc ja"> name </strong>参数来定义要优化的超参数名称。</p><h2 id="9317" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">BayesSearchCV</h2><p id="960b" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">BayesSearchCV类提供了一个类似于<code class="fe no np nq nr b">GridSearchCV</code>或<code class="fe no np nq nr b">RandomizedSearchCV</code>的接口，但是它对超参数执行贝叶斯优化。BayesSearchCV实现了“<strong class="lc ja">拟合</strong>”和“<strong class="lc ja">得分</strong>”方法以及其他常用方法(<em class="nx"> predict()、predict_proba()、decision_function()、transform()和inverse_transform() </em>)，如果它们在所使用的估计器中实现的话。</p><blockquote class="ny"><p id="366f" class="nz oa iq bd ob oc od oe of og oh lv dk translated">与GridSearchCV相反，不是所有的参数值都被尝试，而是从指定的分布中采样固定数量的参数设置。尝试的参数设置的数量由n_iter给出。</p></blockquote><p id="f2f9" class="pw-post-body-paragraph la lb iq lc b ld oi ka lf lg oj kd li lj ok ll lm ln ol lp lq lr om lt lu lv ij bi translated"><strong class="lc ja"> NB: </strong>您将在一个实际的例子中学习如何实现BayesSearchCV。</p><h2 id="22e5" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">目标函数</h2><p id="9731" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">这是一个将由搜索过程调用的函数，它从搜索空间接收超参数值作为输入，并返回损失(越低越好)。这意味着在优化过程中，我们用选定的超参数值训练模型，预测目标特征，然后评估预测误差并将其反馈给优化器。优化器将决定检查哪些值并再次迭代。你将在一个实例中学习如何创建一个目标函数。</p><h2 id="dbe1" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">优化程序</h2><p id="5140" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">这是执行贝叶斯超参数优化过程的函数。优化函数在每个模型和搜索空间迭代以优化然后最小化目标函数。<br/>sci kit-optimize库提供了不同的优化功能，例如:-</p><ul class=""><li id="79f5" class="nf ng iq lc b ld le lg lh lj nh ln ni lr nj lv nk nl nm nn bi translated"><strong class="lc ja"> dummy_minimize </strong> —在给定范围内均匀采样的随机搜索。</li><li id="de9d" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><strong class="lc ja"> forest_minimize </strong> —使用决策树的顺序优化。</li><li id="ecec" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><strong class="lc ja"> gbrt_minimize </strong> —使用梯度增强树的顺序优化。</li><li id="d1dc" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><strong class="lc ja"> gp_minimize — </strong>使用高斯过程的贝叶斯优化。<br/>注意:我们将在实际例子中实现gp_minimize。</li></ul><p id="7d40" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">其他需要学习的功能如下</p><ul class=""><li id="d328" class="nf ng iq lc b ld le lg lh lj nh ln ni lr nj lv nk nl nm nn bi translated"><a class="ae lw" href="https://scikit-optimize.github.io/0.7/modules/classes.html#module-skopt.space.transformers" rel="noopener ugc nofollow" target="_blank">空间变形金刚</a> s</li><li id="1493" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><a class="ae lw" href="https://scikit-optimize.github.io/0.7/modules/classes.html#module-skopt.utils" rel="noopener ugc nofollow" target="_blank">实用程序功能</a></li><li id="e028" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><a class="ae lw" href="https://scikit-optimize.github.io/0.7/modules/classes.html#module-skopt.plots" rel="noopener ugc nofollow" target="_blank">绘图功能</a></li><li id="cfe3" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><a class="ae lw" href="https://scikit-optimize.github.io/0.7/modules/classes.html#module-skopt.learning" rel="noopener ugc nofollow" target="_blank">基于模型优化的机器学习扩展</a></li></ul><h1 id="6ae2" class="lx ly iq bd lz ma mb mc md me mf mg mh kf mi kg mj ki mk kj ml kl mm km mn mo bi translated">sci kit-实践中的优化</h1><p id="3cbf" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">现在，您已经了解了scikit-optimize的重要特性，在这个实际示例中，我们将使用<strong class="lc ja">手机价格数据集</strong>，任务是创建一个模型来预测手机的价格有多高，即0( <em class="nx">低成本</em>)或1( <em class="nx">中等成本</em>)或2( <em class="nx">高成本</em>)或3( <em class="nx">极高成本</em>)。</p><div class="on oo gp gr op oq"><a href="https://www.datadriveninvestor.com/2020/07/23/learn-data-science-in-a-flash/" rel="noopener  ugc nofollow" target="_blank"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd ja gy z fp ov fr fs ow fu fw iz bi translated">一瞬间学会数据科学！？数据驱动的投资者</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">在我之前的职业生涯中，我是一名训练有素的古典钢琴家。还记得那些声称你可以…</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="oz l"><div class="pa l pb pc pd oz pe ky oq"/></div></div></a></div><h2 id="08ff" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">安装sci kit-优化</h2><p id="5f94" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">scikit-optimize需要以下python版本和包。</p><ul class=""><li id="3a80" class="nf ng iq lc b ld le lg lh lj nh ln ni lr nj lv nk nl nm nn bi translated">Python &gt;= 3.6</li><li id="2c84" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated">NumPy (&gt;= 1.13.3)</li><li id="e6ee" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated">SciPy (&gt;= 0.19.1)</li><li id="3ccc" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated">joblib (&gt;= 0.11)</li><li id="f649" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated">scikit-learn &gt;= 0.20</li><li id="8ca1" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated">matplotlib &gt;= 2.0.0</li></ul><p id="c013" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">您可以通过以下方式安装最新版本:</p><pre class="kp kq kr ks gt pf nr pg ph aw pi bi"><span id="1972" class="mu ly iq nr b gy pj pk l pl pm">pip install scikit-optimize</span></pre><p id="c3fa" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">然后导入重要的包，包括scikit-optimize。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><h2 id="b16c" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">资料组</h2><p id="09b2" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">让我们从数据目录加载数据集。要获得关于数据集的更多信息，请阅读此处的<a class="ae lw" href="https://www.kaggle.com/iabhishekofficial/mobile-price-classification?select=train.csv" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="0fc5" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">检查数据集的前五行。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pp"><img src="../Images/eda23aee8d93772540172deec902a823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WhTZ7XNaXbdbo6cs0jS9Yw.png"/></div></div></figure><p id="99f2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如您所见，在我们的数据集中，我们有不同的带有数值的要素。</p><p id="dbc8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们观察数据集的形状。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="7b25" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi">(2000, 21)</p><p id="d32a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在这个数据集中，我们有<em class="nx"> 2000行</em>和<em class="nx"> 21列</em>。现在，让我们来了解一下该数据集中的要素列表。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="74f2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">['battery_power '，' blue '，' clock_speed '，' dual_sim '，' fc '，' four_g '，' int_memory '，' m_dep '，' mobile_wt '，' n_cores '，' pc '，' px_height '，' px_width '，' ram '，' sc_h '，' sc_w '，' talk_time '，' three_g '，' touch_screen '，' wifi '，' price_range']</p><p id="e5d7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">你可以在这里找到每个列名<a class="ae lw" href="https://www.kaggle.com/iabhishekofficial/mobile-price-classification" rel="noopener ugc nofollow" target="_blank">的含义。</a></p><h2 id="1b7c" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">将数据集分割成目标要素和独立要素</h2><p id="1577" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">这是一个分类问题，我们将从数据集中分离目标特征和独立特征。我们的目标功能是<strong class="lc ja">价格范围</strong>。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><h2 id="3c44" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">预处理数据集。</h2><p id="22b0" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">然后使用scikit-learn的<a class="ae lw" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank">标准定标器</a>方法对独立特征进行标准化。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><h2 id="da80" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">第一种方法</h2><p id="5a83" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">在第一种方法中，我们将使用<strong class="lc ja"> BayesSearchCV </strong>为随机森林算法执行超参数优化。</p><h2 id="7992" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">定义搜索空间</h2><p id="218b" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">我们将调整随机森林模型的以下超参数:</p><ul class=""><li id="8b6b" class="nf ng iq lc b ld le lg lh lj nh ln ni lr nj lv nk nl nm nn bi translated"><strong class="lc ja"> n_estimators </strong> —森林中树木的数量。</li><li id="f646" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><strong class="lc ja"> max_depth </strong> —树的最大深度。</li><li id="4354" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><strong class="lc ja">标准</strong> —测量分割质量的功能。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="7558" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们将搜索空间定义为一个字典，其中超参数名称用作关键字，变量的范围用作值。</p><h2 id="a6ab" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">定义<em class="pq"> BayesSearchCV </em>配置</h2><p id="f7b5" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">BayesSearchCV的好处是搜索过程是自动执行的，只需要最少的配置。该类可以像Scikit-Learn一样使用(GridSearchCV和RandomizedSearchCV)。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><h2 id="95b5" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">微调模型</h2><p id="58b2" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">然后，我们通过传递预处理的特性和目标特性(price_range)来执行搜索。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="0a70" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">您可以从<strong class="lc ja">搜索</strong>中使用<strong class="lc ja"> best_score_ </strong>属性找到最佳分数，使用<strong class="lc ja"> best_params_ </strong>属性找到最佳参数。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="c794" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">注意:</strong>当前版本的scikit-optimize(0.7.4)与最新版本的scikit learn (0.23.1和0.23.2)不兼容，因此当您使用这种方法运行优化过程时，可能会出现如下错误:-</p><pre class="kp kq kr ks gt pf nr pg ph aw pi bi"><span id="8ce3" class="mu ly iq nr b gy pj pk l pl pm"><strong class="nr ja">TypeError</strong>: object.__init__() takes exactly one argument (the instance to initialize)</span></pre><p id="107b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">你可以在他们的GitHub账号里找到更多关于这个错误的信息。</p><ul class=""><li id="f867" class="nf ng iq lc b ld le lg lh lj nh ln ni lr nj lv nk nl nm nn bi translated"><a class="ae lw" href="https://github.com/scikit-optimize/scikit-optimize/issues/928" rel="noopener ugc nofollow" target="_blank">https://github . com/sci kit-optimize/sci kit-optimize/issues/928</a></li><li id="c9b3" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><a class="ae lw" href="https://github.com/scikit-optimize/scikit-optimize/issues/924" rel="noopener ugc nofollow" target="_blank">https://github . com/sci kit-optimize/sci kit-optimize/issues/924</a></li><li id="f44e" class="nf ng iq lc b ld ns lg nt lj nu ln nv lr nw lv nk nl nm nn bi translated"><a class="ae lw" href="https://github.com/scikit-optimize/scikit-optimize/issues/902" rel="noopener ugc nofollow" target="_blank">https://github . com/sci kit-optimize/sci kit-optimize/issues/902</a></li></ul><p id="0020" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我希望他们很快解决这个不兼容的问题。</p><h2 id="2f37" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">(b)第二种方法</h2><p id="bde8" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">在第二种方法中，我们首先通过使用scikit-optimize提供的空间方法来定义搜索空间，这些方法是<em class="nx">分类的和整数的。</em></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="27a7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们在上面选择的超参数中设置了不同的值。然后我们将定义目标函数。</p><h2 id="412a" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">定义一个函数来最小化(目标函数)</h2><p id="3913" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">我们最小化的函数叫做<strong class="lc ja"> evalute_model </strong>，优化其超参数的分类算法是<strong class="lc ja">随机森林</strong>。我使用交叉验证来避免过度拟合，然后函数将返回一个损失值。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="6277" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">use_named_args()  decorator允许您的目标函数接收参数作为关键字参数。当您想要设置scikit-learn估计器参数时，这尤其方便。</p><p id="e6f3" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">注意:记住scikit-optimize最小化了函数，这就是为什么我在acc中添加了负号。</p><h2 id="f4d7" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">微调模型</h2><p id="07a9" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">最后，我们使用scikit-optimize的<strong class="lc ja"> gp_minimize </strong>方法(它使用基于高斯过程的优化)对模型进行微调，然后打印最佳损失及其超参数值。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><p id="8990" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">输出:</strong> <br/> <em class="nx">开始第1次迭代。随机点的评价函数。<br/>1号迭代结束。在随机点进行评估。<br/>耗时:8.6910 <br/>获得函数值:-0.8585 <br/>当前最小值:-0.8585 <br/>第2次迭代开始。随机点的评价函数。第二次迭代结束。在随机点进行评估。<br/>耗时:4.5096 <br/>获得的函数值:-0.7680 <br/>当前最小值:-0.8585……………………</em></p><p id="a0cb" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">注意:</strong>它会一直运行到最后一次迭代。对于我们的优化过程，迭代的总数是30。</p><p id="453e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">然后，我们可以打印出最佳精度和所用的选定超参数值。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><pre class="kp kq kr ks gt pf nr pg ph aw pi bi"><span id="a0f8" class="mu ly iq nr b gy pj pk l pl pm">Best Accuracy: -0.882<br/>Best Parameters: [300, 'entropy', 9]</span></pre><p id="dc79" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在执行超参数优化后，损失为<strong class="lc ja"> -0.882 </strong>意味着通过使用随机森林分类器中的<em class="nx"> n_estimators = 300，max_depth = 9，criterion = "entropy" </em>，模型性能具有<strong class="lc ja"> 88.2% </strong>的准确度。<br/>我们的结果和第一篇文章的远视相差不大(准确率<strong class="lc ja"> 89.15% </strong>)。</p><h2 id="3b5a" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">打印函数值</h2><p id="3497" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">通过使用OptimizeResult对象(Result)的<strong class="lc ja"> func_vals </strong>属性，可以打印每次迭代的所有函数值。</p><pre class="kp kq kr ks gt pf nr pg ph aw pi bi"><span id="4c80" class="mu ly iq nr b gy pj pk l pl pm">print(result.func_vals)</span></pre><p id="e79c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">输出:</strong> <br/>数组([-0.8665，-0.7765，-0.7485，-0.86，-0.872，-0.545，-0.81，<br/> -0.7725，-0.8115，-0.8705，-0.8685，-0.879，-0.816，-0.8815，<br/> -0.8645，-0.8645</p><h2 id="f2fa" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">绘制收敛轨迹</h2><p id="cb01" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">我们可以使用scikit-optimize中的<strong class="lc ja"> plot_convergence </strong>方法来绘制一条或多条收敛轨迹。我们只需要在plot_convergence方法中传递OptimizeResult对象(Result)即可。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pn po l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/1f33647a581ca28de9a08daacce2fbe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*K9ng9AjHMgJHqYR8q8d4tQ.png"/></div><figcaption class="ps pt gj gh gi pu pv bd b be z dk">convergence plot</figcaption></figure><p id="b029" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">该图显示了优化过程中不同迭代的函数值。</p><h1 id="eb6b" class="lx ly iq bd lz ma mb mc md me mf mg mh kf mi kg mj ki mk kj ml kl mm km mn mo bi translated">包扎</h1><p id="e84c" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">祝贺您，您已经完成了本系列的第二篇文章。！</p><p id="106f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">你可以在这里下载本文使用的数据集和笔记本:<br/><a class="ae lw" href="https://github.com/Davisy/Hyperparameter-Optimization-Techniques" rel="noopener ugc nofollow" target="_blank">https://github . com/Davisy/Hyperparameter-Optimization-Techniques</a></p><h2 id="7b5e" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">下一步是什么？</h2><p id="c485" class="pw-post-body-paragraph la lb iq lc b ld mp ka lf lg mq kd li lj mr ll lm ln ms lp lq lr mt lt lu lv ij bi translated">在第3部分中，我将介绍第三种也是最后一种超参数优化技术，称为<strong class="lc ja"> Optuna。</strong></p><p id="81b1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果你学到了新的东西或者喜欢阅读这篇文章，请分享给其他人看。在那之前，第3部分再见！。也可以通过推特<a class="ae lw" href="https://twitter.com/Davis_McDavid" rel="noopener ugc nofollow" target="_blank"> @Davis_McDavid </a>联系到我</p><p id="5a29" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="nx">最后一件事:</em> </strong> <em class="nx">在下面的链接里多看看类似这样的文章。</em></p><div class="on oo gp gr op oq"><a href="https://medium.com/@Davis_David/alternative-hyperparameter-optimization-techniques-you-need-to-know-part-1-3f68d0448fcd" rel="noopener follow" target="_blank"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd ja gy z fp ov fr fs ow fu fw iz bi translated">您需要了解的替代超参数优化技术—第1部分</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">微调机器学习模型以提高性能的不同方法。</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">medium.com</p></div></div><div class="oz l"><div class="pw l pb pc pd oz pe ky oq"/></div></div></a></div><div class="on oo gp gr op oq"><a href="https://medium.com/datadriveninvestor/how-to-use-tree-based-algorithms-for-machine-learning-9da624c75755" rel="noopener follow" target="_blank"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd ja gy z fp ov fr fs ow fu fw iz bi translated">如何使用基于树的算法进行机器学习</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">使用和理解随机森林算法的指南</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">medium.com</p></div></div><div class="oz l"><div class="px l pb pc pd oz pe ky oq"/></div></div></a></div><div class="on oo gp gr op oq"><a href="https://medium.com/analytics-vidhya/how-to-write-configuration-files-in-your-machine-learning-project-47bc840acc19" rel="noopener follow" target="_blank"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd ja gy z fp ov fr fs ow fu fw iz bi translated">如何在你的机器学习项目中写配置文件？</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">用配置文件管理参数和初始设置。</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">medium.com</p></div></div><div class="oz l"><div class="py l pb pc pd oz pe ky oq"/></div></div></a></div><h2 id="3b00" class="mu ly iq bd lz mv mw dn md mx my dp mh lj mz na mj ln nb nc ml lr nd ne mn iw bi translated">访问专家视图— <a class="ae lw" href="https://datadriveninvestor.com/ddi-intel" rel="noopener ugc nofollow" target="_blank">订阅DDI英特尔</a></h2></div></div>    
</body>
</html>