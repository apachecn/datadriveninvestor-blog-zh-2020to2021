<html>
<head>
<title>Video Streaming Using Flask and OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Flask和OpenCV的视频流</h1>
<blockquote>原文：<a href="https://medium.datadriveninvestor.com/video-streaming-using-flask-and-opencv-c464bf8473d6?source=collection_archive---------0-----------------------#2020-02-11">https://medium.datadriveninvestor.com/video-streaming-using-flask-and-opencv-c464bf8473d6?source=collection_archive---------0-----------------------#2020-02-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/89831ae204ac17c669dde4debf72a239.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*jZN7NfvMYAuGdcEDKScsIA.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Stream video using OpenCV and Flask. (<a class="ae jy" href="https://www.pyimagesearch.com/2019/09/02/opencv-stream-video-to-web-browser-html-page/" rel="noopener ugc nofollow" target="_blank">Image Source</a>)</figcaption></figure><blockquote class="jz ka kb"><p id="0151" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我的名字是安摩尔·贝尔，我是团队<strong class="kf ir">比特-N-字节</strong>的领导者。我们是一个由三名团队成员组成的小组，他们来自位于Ghaziabad 的<strong class="kf ir"> KIET机构集团，正在攻读计算机科学与工程的B.Tech。本文以人脸检测为例，说明如何使用Flask和OpenCV进行视频流处理。</strong></p></blockquote><p id="1af4" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">如今，机器学习正在成为一个非常热门的领域。由于开发的日常需求和快速增加，需要部署机器学习模型。但是很难或者不可能在移动设备上部署它们。一种选择是使用机器学习移动框架，如<a class="ae jy" href="https://www.tensorflow.org/lite" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite </a>来调用预先训练好的模型。</p><div class="le lf gp gr lg lh"><a href="https://www.datadriveninvestor.com/2019/03/22/fixing-photography/" rel="noopener  ugc nofollow" target="_blank"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd ir gy z fp lm fr fs ln fu fw ip bi translated">修复摄影|数据驱动的投资者</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">汤姆·津伯洛夫在转向摄影之前曾在南加州大学学习音乐。作为一个…</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">www.datadriveninvestor.com</p></div></div><div class="lq l"><div class="lr l ls lt lu lq lv js lh"/></div></div></a></div><p id="ad9f" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">有没有更简单的选择？是啊！随着5G的到来，上传100KB的图像只需0.01秒，速度约为<a class="ae jy" href="https://5g.co.uk/guides/how-fast-is-5g/" rel="noopener ugc nofollow" target="_blank"> 100Mbps </a>，因此我们可以在服务器端部署几乎所有东西，包括人脸识别服务。考虑一个人脸检测的例子，本文将演示如何在Linux服务器上使用Python Flask和OpenCV进行视频流传输。</p><p id="de22" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">让我们开始吧…</p><h1 id="2c44" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">步骤1:创建和激活环境</h1><p id="44d1" class="pw-post-body-paragraph kc kd iq kf b kg mu ki kj kk mv km kn lb mw kq kr lc mx ku kv ld my ky kz la ij bi translated">我们将为项目创建一个虚拟环境。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi mz"><img src="../Images/5b847007d63ff6cf561fc5c4f4ab66ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtQ18XvkTAUXPGBfLMJ9iw.png"/></div></div></figure><p id="36f8" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">创建虚拟环境需要virtualenv包。您可以用pip安装它:</p><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="af68" class="nn lx iq nj b gy no np l nq nr">$ pip install virtualenv</span></pre><p id="c42a" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">要创建虚拟环境，您必须指定一个路径。我们正在主文件夹中创建环境的本地目录“Videorecognition ”,要创建该文件夹，请键入以下内容:</p><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="dcd9" class="nn lx iq nj b gy no np l nq nr">$ virtualenv Videorecognition</span></pre><p id="203d" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">要激活环境，请执行以下命令:</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi mz"><img src="../Images/2b76df5e3d1027e61c29a24f60dc1682.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YfHKWCahe2d1R3JTv7BiJQ.png"/></div></div></figure><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="c841" class="nn lx iq nj b gy no np l nq nr">$ source Videorecognition/bin/activate</span></pre><h1 id="a3c0" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">步骤2:安装Flask和OpenCV</h1><p id="9927" class="pw-post-body-paragraph kc kd iq kf b kg mu ki kj kk mv km kn lb mw kq kr lc mx ku kv ld my ky kz la ij bi translated">首先，我们需要用<a class="ae jy" href="https://help.ubuntu.com/community/AptGet/Howto" rel="noopener ugc nofollow" target="_blank"> apt-get </a>包管理器刷新/升级预安装的包/库:</p><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="bb3d" class="nn lx iq nj b gy no np l nq nr">$ sudo apt-get upgrade<br/>$ sudo apt-get upgrade </span></pre><p id="e72a" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">现在我们将执行以下命令来安装OpenCV和Flask:</p><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="c75c" class="nn lx iq nj b gy no np l nq nr">$ sudo apt install python3-opencv<br/>$ pip install Flask</span></pre><h1 id="e3cf" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">步骤3:创建项目结构</h1><p id="a3ec" class="pw-post-body-paragraph kc kd iq kf b kg mu ki kj kk mv km kn lb mw kq kr lc mx ku kv ld my ky kz la ij bi translated">现在，所有的先决条件都已安装，让我们设置我们的项目:</p><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="add6" class="nn lx iq nj b gy no np l nq nr">├── VideoStreaming/<br/>│   ├── camera.py<br/>│   ├── main.py<br/>│   ├── haarcascade_frontalface_alt2.xml<br/>│   ├── templates/<br/>│   │   ├── index.html</span></pre><h1 id="3050" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">步骤4:使用OpenCV检测人脸</h1><p id="3fe7" class="pw-post-body-paragraph kc kd iq kf b kg mu ki kj kk mv km kn lb mw kq kr lc mx ku kv ld my ky kz la ij bi translated">现在我们已经创建了我们的项目结构，我们将使用OpenCV来检测人脸。我们将使用最基本和最简单的方法来检测人脸，即使用Haarcascades。</p><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="3b54" class="nn lx iq nj b gy no np l nq nr"><strong class="nj ir">#camera.py</strong></span><span id="c540" class="nn lx iq nj b gy ns np l nq nr"><strong class="nj ir"><em class="ke"># import the necessary packages</em></strong><br/>import cv2</span><span id="20f8" class="nn lx iq nj b gy ns np l nq nr"><strong class="nj ir"><em class="ke"># defining face detector</em></strong><br/>face_cascade=cv2.CascadeClassifier("haarcascade_frontalface_alt2.xml")<br/>ds_factor=0.6</span><span id="eb1b" class="nn lx iq nj b gy ns np l nq nr">class VideoCamera(object):<br/>    def __init__(self):<br/>      <em class="ke"> </em><strong class="nj ir"><em class="ke">#capturing video</em></strong><em class="ke"><br/>       </em>self.video = cv2.VideoCapture(0)<br/>    <br/>    def __del__(self):<br/>       <strong class="nj ir"> <em class="ke">#releasing camera</em></strong><em class="ke"><br/></em>        self.video.release()</span><span id="17e9" class="nn lx iq nj b gy ns np l nq nr">def get_frame(self):<br/>       <strong class="nj ir">#extracting frames<br/>        </strong>ret, frame = self.video.read()<br/>        frame=cv2.resize(frame,None,fx=ds_factor,fy=ds_factor,<br/>        interpolation=cv2.INTER_AREA)                    <br/>        gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)<br/>        face_rects=face_cascade.detectMultiScale(gray,1.3,5)<br/>        for (x,y,w,h) in face_rects:<br/>         cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)<br/>         break</span><span id="90c5" class="nn lx iq nj b gy ns np l nq nr">       <strong class="nj ir"><em class="ke"> # encode OpenCV raw frame to jpg and displaying it<br/>        </em></strong>ret, jpeg = cv2.imencode('.jpg', frame)<br/>        return jpeg.tobytes()</span></pre><h1 id="9e1c" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">步骤5:创建显示视频的网页</h1><p id="c0b2" class="pw-post-body-paragraph kc kd iq kf b kg mu ki kj kk mv km kn lb mw kq kr lc mx ku kv ld my ky kz la ij bi translated">现在，我们将创建一个网页来显示我们的视频。</p><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="16ee" class="nn lx iq nj b gy no np l nq nr"><strong class="nj ir"><em class="ke">&lt;-- index.html --&gt;</em></strong><br/>&lt;html&gt;<br/>  &lt;head&gt;<br/>    &lt;title&gt;Video Streaming Demonstration&lt;/title&gt;<br/>  &lt;/head&gt;<br/>  &lt;body&gt;<br/>    &lt;h1&gt;Video Streaming Demonstration&lt;/h1&gt;<br/>    &lt;img id="bg" src="{{ url_for('video_feed') }}"&gt;<br/>  &lt;/body&gt;<br/>&lt;/html&gt;</span></pre><h1 id="c662" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">步骤6:创建流服务器</h1><p id="6b1b" class="pw-post-body-paragraph kc kd iq kf b kg mu ki kj kk mv km kn lb mw kq kr lc mx ku kv ld my ky kz la ij bi translated">现在，我们已经使用haarcascade检测到人脸，并创建了一个网页来显示视频，我们将把这两个模块与我们的服务器集成在一起。</p><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="2af7" class="nn lx iq nj b gy no np l nq nr"><strong class="nj ir"><em class="ke"># main.py</em></strong></span><span id="ace3" class="nn lx iq nj b gy ns np l nq nr"><strong class="nj ir"><em class="ke"># import the necessary packages<br/></em></strong>from flask import Flask, render_template, Response<br/>from camera import VideoCamera</span><span id="84bc" class="nn lx iq nj b gy ns np l nq nr">app = Flask(__name__)</span><span id="3ec9" class="nn lx iq nj b gy ns np l nq nr"><a class="ae jy" href="http://twitter.com/app" rel="noopener ugc nofollow" target="_blank">@app</a>.route('/')<br/>def index():<br/>    <strong class="nj ir"><em class="ke"># rendering webpage<br/>    </em></strong>return render_template('index.html')</span><span id="2772" class="nn lx iq nj b gy ns np l nq nr">def gen(camera):<br/>    while True:<br/>        <strong class="nj ir"><em class="ke">#get camera frame</em></strong><br/>        frame = camera.get_frame()<br/>        yield (b'--frame\r\n'<br/>               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n\r\n')</span><span id="bcb2" class="nn lx iq nj b gy ns np l nq nr"><a class="ae jy" href="http://twitter.com/app" rel="noopener ugc nofollow" target="_blank">@app</a>.route('/video_feed')<br/>def video_feed():<br/>    return Response(gen(VideoCamera()),<br/>                    mimetype='multipart/x-mixed-replace; boundary=frame')</span><span id="a317" class="nn lx iq nj b gy ns np l nq nr">if __name__ == '__main__':<br/>    <strong class="nj ir"><em class="ke"># defining server ip address and port</em></strong><br/>    app.run(host='0.0.0.0',port='5000', debug=True)</span></pre><h1 id="2b8d" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">步骤7:启动并访问服务器</h1><p id="07aa" class="pw-post-body-paragraph kc kd iq kf b kg mu ki kj kk mv km kn lb mw kq kr lc mx ku kv ld my ky kz la ij bi translated">通过执行以下命令，在项目目录中打开终端窗口:</p><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="ba3c" class="nn lx iq nj b gy no np l nq nr">$ cd Videorecognition<br/>$ cd VideoStreaming</span></pre><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nt"><img src="../Images/49d4c06f11b6a44c4048f163928a0d34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CYspEgLqI9r9alE151e85Q.jpeg"/></div></div></figure><p id="ca02" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">要启动服务器，请执行以下命令:</p><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="51ed" class="nn lx iq nj b gy no np l nq nr">python main.py</span></pre><p id="0865" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">要访问服务器，请打开浏览器并导航到服务器URL:</p><pre class="na nb nc nd gt ni nj nk nl aw nm bi"><span id="af45" class="nn lx iq nj b gy no np l nq nr"><a class="ae jy" href="http://0.0.0.0:5000/" rel="noopener ugc nofollow" target="_blank">http://0.0.0.0:5000/</a></span></pre><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nu"><img src="../Images/053dd247cecad392730fc9100c5aae07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jX5gylCJqZesfHQM7OxmJA.png"/></div></div></figure><h1 id="72be" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">结论</h1><p id="d8a9" class="pw-post-body-paragraph kc kd iq kf b kg mu ki kj kk mv km kn lb mw kq kr lc mx ku kv ld my ky kz la ij bi translated">希望这篇教程能帮助其他人找到Flask和OpenCV的入门之路！</p><p id="8eb6" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">详情和最终代码，请访问我的GitHub仓库:<a class="ae jy" href="https://github.com/behl1anmol/VideoStreamingFlask" rel="noopener ugc nofollow" target="_blank">带烧瓶的视频流</a></p><p id="cb4b" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">下节课再见！</p><p id="d104" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">谢谢你，</p><p id="72d6" class="pw-post-body-paragraph kc kd iq kf b kg kh ki kj kk kl km kn lb kp kq kr lc kt ku kv ld kx ky kz la ij bi translated">安摩尔</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="nv nw l"/></div></figure></div></div>    
</body>
</html>